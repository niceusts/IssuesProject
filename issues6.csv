id,number,title,state,created_at,updated_at,closed_at,assignee,milestone,html_url,labels,comments,description
2289457792,67323,Iterating over a symbolic `tf.Tensor` is not allowed: AutoGraph did convert this function,closed,2024-05-10 10:28:34+00:00,2024-05-16T02:53:42Z,2024-05-16T02:53:40Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/67323,"['type:bug', 'TF 2.9']","['Hi **@saturn-drm** ,\r\n- Sorry for the delay, I tried to run your code on colab using TF v2.9, 2.16.1 and i am not facing any issue. Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/5a66577867096254c08ee9ab56831d9c/67323_2-9-2-16-1.ipynb) here for reference.\r\n- And it looks like you are using an older Version of Tensorflow (2.9). Many bugs have been fixed in the latest version. Can you please execute your code using Latest Version (2.16.1) and let us know if the issue still persists?\r\n\r\nThank you!', 'Thank you for the reply. I will try it out as you recommended.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67323"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67323"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.9

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I have a function as below. I have `N = tf.shape(y_true)[0]` where `y_ture` is `<tf.Tensor 'y_true:0' shape=(None, 8, 6) dtype=float32>`. I later iterate over N as `for i in tf.range(N)`, but get an error.

```
def transform_targets_for_output(y_true, grid_size, anchor_idxs):
    # y_true: (N, boxes, (x1, y1, x2, y2, class, best_anchor))
    print('y-true',y_true)
    N = tf.shape(y_true)[0]
    print('%%%',N)

    # y_true_out: (N, grid, grid, anchors, [x1, y1, x2, y2, obj, class])
    y_true_out = tf.zeros(
        (N, grid_size, grid_size, tf.shape(anchor_idxs)[0], 6))

    anchor_idxs = tf.cast(anchor_idxs, tf.int32)

    indexes = tf.TensorArray(tf.int32, 1, dynamic_size=True)
    updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)
    idx = 0
    for i in tf.range(N):
        for j in tf.range(tf.shape(y_true)[1]):
            if tf.equal(y_true[i][j][2], 0):
                continue
            anchor_eq = tf.equal(
                anchor_idxs, tf.cast(y_true[i][j][5], tf.int32))

            if tf.reduce_any(anchor_eq):
                box = y_true[i][j][0:4]
                box_xy = (y_true[i][j][0:2] + y_true[i][j][2:4]) / 2

                anchor_idx = tf.cast(tf.where(anchor_eq), tf.int32)
                grid_xy = tf.cast(box_xy // (1/grid_size), tf.int32)

                # grid[y][x][anchor] = (tx, ty, bw, bh, obj, class)
                indexes = indexes.write(
                    idx, [i, grid_xy[1], grid_xy[0], anchor_idx[0][0]])
                updates = updates.write(
                    idx, [box[0], box[1], box[2], box[3], 1, y_true[i][j][4]])
                idx += 1

    # tf.print(indexes.stack())
    # tf.print(updates.stack())

    return tf.tensor_scatter_nd_update(
        y_true_out, indexes.stack(), updates.stack())
```

But I get error like this:

```
raise e.with_traceback(filtered_tb) from None
  File ""/home/shakey/yolov3-tf2/yolov3_tf2/dataset.py"", line 42, in transform_targets_for_output
    for i in tf.range(N):
tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.
```

How can I solve that?

### Standalone code to reproduce the issue

```shell
nothing.
```


### Relevant log output

_No response_"
2289496772,67327,"Why tf.data.Dataset.choose_from_datasets() chooses only one element from dataset of size-element 5, I want to unite with other dataset of size-element 5 the same. If I want to merge dataset with all their elements and get  <ChooseDataset ...> with 10 elements inside",closed,2024-05-10 10:53:08+00:00,2024-07-02T01:51:55Z,2024-07-02T01:51:51Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/67327,"['stat:awaiting response', 'type:bug', 'stale', 'comp:data', 'TF 2.16']","['@Hell576 tf.data.Dataset.choose_from_datasets() isn\'t designed to merge datasets element-wise. It actually picks elements one at a time, deterministically choosing from the provided datasets based on a separate ""choice"" dataset.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', 'If It actually picks elements one at a time, that means TF should either fix it or edit documentation for this function', '@Hell576,\r\nTo merge two datasets and get all their elements combined, you can try using **tf.data.Dataset.concatenate** or **tf.data.Dataset.flat_map**.  \r\n\r\nUse tf.data.Dataset.concatenate to create a new dataset by appending elements from the second dataset to the first \r\nIf your datasets are nested (e.g., each element is a dataset itself), use tf.data.Dataset.flat_map to flatten them into a single-level dataset. \r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/data/Dataset#concatenate\r\nhttps://www.tensorflow.org/api_docs/python/tf/data/Dataset#flat_map\r\n\r\nThank you!', 'I know concatenate() method, However there was troubles after doing such operation. When I cocncatenated two datasets (every has 5 elements, 5+5 totally) tried to check tf.data.Dataset It threw in the 1st element: tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__MakeIterator_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes at component 0: expected [150,128,1] but got []. \r\nI still try to reproduce this error using numpy arrays included to datasets, however this error does not repoduce. In real code I used tensors you can see in my example above from RaggedTensor, then used tf.data.Dataset.zip(), then  tf.data.Dataset.choose_from_dataset() then tf.data.Dataset.concatenate().\r\nBut my error slips away if I use after concatenate function tf.data.Dataset.save() and tf.data.Dataset.load() after.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67327"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67327"">No</a>\n', '@Hell576,\r\nGlad the above methods worked with numpy arrays without any issue. For ragged batch, could you please take a look at this reference document and try to execute the code. \r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/data/Dataset#ragged_batch\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67327"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67327"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf v2.16.0-rc0-18-g5bc9d26649c 2.16.1

### Custom code

Yes

### OS platform and distribution

Windows 10 Home

### Mobile device

_No response_

### Python version

3.11.8

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

Ryzen 5 5600U 8 gb RAM

### Current behavior?

I expect to have one dataset with 21 elements from SUB_DATASETS trainSubDs***(unpack it): 
[Uploading SUB_DATASETS.7z…]() link if archive didn't upload: https://drive.google.com/drive/folders/1yg2QL6uXUwNikSVNduBl0tMvOSqTa050?usp=sharing
It looks like(console could show only last elements to output, it could copy only last snippet):
[[0.5359075],
        [0.2795821],
        [0.0720736],
        ...,
        [0.0077176],
        [0.1932825],
        [0.0856282]],

       [[0.5283639],
        [0.2746144],
        [0.0710207],
        ...,
        [0.0052901],
        [0.1952176],
        [0.0862649]],

       ...,

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]]])>, <tf.Tensor: shape=(), dtype=string, numpy=b'Mental_grip'>)
train_ds el 12 :  (<tf.Tensor: shape=(150, 128, 1), dtype=float64, numpy=
array([[[0.5237354],
        [0.2701872],
        [0.0703329],
        ...,
        [0.008211 ],
        [0.196203 ],
        [0.088349 ]],

       [[0.5247858],
        [0.2711178],
        [0.070595 ],
        ...,
        [0.0099486],
        [0.1979399],
        [0.0891815]],

       [[0.5274265],
        [0.2729441],
        [0.0710507],
        ...,
        [0.0072448],
        [0.199901 ],
        [0.0902823]],

       ...,

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]]])>, <tf.Tensor: shape=(), dtype=string, numpy=b'Mental_grip'>)
train_ds el 13 :  (<tf.Tensor: shape=(150, 128, 1), dtype=float64, numpy=
array([[[0.5219159],
        [0.2691515],
        [0.0700537],
        ...,
        [0.0110053],
        [0.2001242],
        [0.0888058]],

       [[0.5231395],
        [0.2692853],
        [0.0701746],
        ...,
        [0.0099637],
        [0.2019817],
        [0.0895737]],

       [[0.5253162],
        [0.2704399],
        [0.0704052],
        ...,
        [0.0077836],
        [0.2037999],
        [0.0902737]],

       ...,

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]]])>, <tf.Tensor: shape=(), dtype=string, numpy=b'Mental_grip'>)
train_ds el 14 :  (<tf.Tensor: shape=(150, 128, 1), dtype=float64, numpy=
array([[[0.5171451],
        [0.2742897],
        [0.0721269],
        ...,
        [0.0055069],
        [0.2053241],
        [0.0913286]],

       [[0.5189649],
        [0.2752684],
        [0.0723212],
        ...,
        [0.011555 ],
        [0.2068635],
        [0.0918813]],

       [[0.5214246],
        [0.2764484],
        [0.0727693],
        ...,
        [0.0114146],
        [0.2091298],
        [0.0929936]],

       ...,

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]]])>, <tf.Tensor: shape=(), dtype=string, numpy=b'Mental_grip'>)
train_ds el 15 :  (<tf.Tensor: shape=(150, 128, 1), dtype=float64, numpy=
array([[[0.5192521],
        [0.277901 ],
        [0.0729991],
        ...,
        [0.0039281],
        [0.2143918],
        [0.0939896]],

       [[0.5229708],
        [0.2794364],
        [0.073528 ],
        ...,
        [0.0112221],
        [0.2173722],
        [0.0953516]],

       [[0.5269855],
        [0.2820122],
        [0.0741047],
        ...,
        [0.0105395],
        [0.2104741],
        [0.0923529]],

       ...,

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]]])>, <tf.Tensor: shape=(), dtype=string, numpy=b'Mental_grip'>)
train_ds el 16 :  (<tf.Tensor: shape=(150, 128, 1), dtype=float64, numpy=
array([[[0.5331477],
        [0.2739582],
        [0.0717712],
        ...,
        [0.0109573],
        [0.1940901],
        [0.0880007]],

       [[0.5335427],
        [0.2737107],
        [0.071813 ],
        ...,
        [0.0037366],
        [0.1964362],
        [0.0886652]],

       [[0.5356644],
        [0.2747716],
        [0.0720867],
        ...,
        [0.0090865],
        [0.1971512],
        [0.0893587]],

       ...,

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]]])>, <tf.Tensor: shape=(), dtype=string, numpy=b'Mental_ungrip'>)
train_ds el 17 :  (<tf.Tensor: shape=(150, 128, 1), dtype=float64, numpy=
array([[[0.526029 ],
        [0.2695351],
        [0.0711689],
        ...,
        [0.0050149],
        [0.2037496],
        [0.0924048]],

       [[0.5300163],
        [0.2719229],
        [0.0718631],
        ...,
        [0.0069598],
        [0.1986737],
        [0.0902188]],

       [[0.5202652],
        [0.2676857],
        [0.0705827],
        ...,
        [0.0083441],
        [0.1983998],
        [0.0903398]],

       ...,

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]]])>, <tf.Tensor: shape=(), dtype=string, numpy=b'Mental_ungrip'>)
train_ds el 18 :  (<tf.Tensor: shape=(150, 128, 1), dtype=float64, numpy=
array([[[0.5228637],
        [0.2701937],
        [0.0715879],
        ...,
        [0.0051579],
        [0.2034421],
        [0.0902776]],

       [[0.5247263],
        [0.2706789],
        [0.0718333],
        ...,
        [0.0046164],
        [0.204667 ],
        [0.0909407]],

       [[0.5265769],
        [0.2717923],
        [0.072096 ],
        ...,
        [0.0095011],
        [0.2066145],
        [0.0916767]],

       ...,

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]]])>, <tf.Tensor: shape=(), dtype=string, numpy=b'Mental_ungrip'>)
train_ds el 19 :  (<tf.Tensor: shape=(150, 128, 1), dtype=float64, numpy=
array([[[0.5154157],
        [0.2765533],
        [0.0723962],
        ...,
        [0.0059454],
        [0.2126359],
        [0.0933117]],

       [[0.5172763],
        [0.277748 ],
        [0.0726707],
        ...,
        [0.0079134],
        [0.2137299],
        [0.0938761]],

       [[0.5202885],
        [0.2787489],
        [0.0730177],
        ...,
        [0.0077494],
        [0.2166882],
        [0.0949059]],

       ...,

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],

       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]]])>, <tf.Tensor: shape=(), dtype=string, numpy=b'Mental_ungrip'>)
train_ds el 20 :  (<tf.Tensor: shape=(150, 128, 1), dtype=float64, numpy=
array([[[0.5253529],
        [0.2798946],
        [0.0724061],
        ...,
        [0.0083182],
        [0.2105255],
        [0.0941397]],

       [[0.5157818],
        [0.2750256],
        [0.0710735],
        ...,
        [0.0070147],
        [0.2102364],
        [0.0941667]],

       [[0.5171091],
        [0.2751543],
        [0.0711846],
        ...,
        [0.0105602],
        [0.2124142],
        [0.094877 ]],

       ...,

       [[0.53277  ],
        [0.2829515],
        [0.0742321],
        ...,
        [0.0052444],
        [0.2241798],
        [0.0944005]],

       [[0.5211917],
        [0.2779166],
        [0.0727785],
        ...,
        [0.0074783],
        [0.2260852],
        [0.0950583]],

       [[0.5240757],
        [0.2794829],
        [0.0732059],
        ...,
        [0.0126765],
        [0.2276907],
        [0.0955679]]])>, <tf.Tensor: shape=(), dtype=string, numpy=b'Mental_ungrip'>)

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

train_subdses = []
for i in range(5):
    train_subdses.append(tf.data.Dataset.load('SUB_DATASETS/trainSubDSpt' + str(i)))
    train_ds = tf.data.Dataset.choose_from_datasets(sub_dses, tf.data.Dataset.range(len(sub_dses)))


i = 0
for elem in train_ds:#.as_numpy_iterator():
    print('train_ds el',i,': ', elem)
    i = i + 1
```


### Relevant log output

```shell
output: 5 elements instead of 21:
train_ds el 0 :  (<tf.Tensor: shape=(150, 128, 1), dtype=float64, numpy=
array([[[0.5369535],
        [0.2724565],
        [0.073154 ],
        ...,
        [0.0074817],
        [0.2035824],
        [0.0882927]],
       [[0.5376732],
        [0.2733304],
        [0.0730333],
        ...,
        [0.0017834],
        [0.1970369],
        [0.0859187]],
       [[0.5307747],
        [0.2692053],
        [0.0720603],
        ...,
        [0.0029357],
        [0.1989727],
        [0.0866213]],
       ...,
       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],
       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],
       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]]])>, <tf.Tensor: shape=(), dtype=string, numpy=b'Relaxation'>)
train_ds el 1 :  (<tf.Tensor: shape=(150, 128, 1), dtype=float64, numpy=
array([[[0.5342219],
        [0.2789463],
        [0.0737332],
        ...,
        [0.0081697],
        [0.2026219],
        [0.0868143]],
       [[0.5382575],
        [0.2805069],
        [0.0741783],
        ...,
        [0.0140429],
        [0.2039362],
        [0.0874103]],
       [[0.5390069],
        [0.2813562],
        [0.0740098],
        ...,
        [0.0100257],
        [0.1966492],
        [0.0847842]],
       ...,
       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],
       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],
       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]]])>, <tf.Tensor: shape=(), dtype=string, numpy=b'Physical_grip'>)
train_ds el 2 :  (<tf.Tensor: shape=(150, 128, 1), dtype=float64, numpy=
array([[[0.5101197],
        [0.2706629],
        [0.0697101],
        ...,
        [0.0135378],
        [0.1926464],
        [0.0866967]],
       [[0.514319 ],
        [0.2727665],
        [0.0703219],
        ...,
        [0.0082093],
        [0.1880849],
        [0.0848876]],
       [[0.5069909],
        [0.2686928],
        [0.0690993],
        ...,
        [0.0075324],
        [0.1876027],
        [0.0847249]],
       ...,
       [[0.5385068],
        [0.2723664],
        [0.0731111],
        ...,
        [0.0123314],
        [0.2012639],
        [0.0878491]],
       [[0.5350855],
        [0.2717791],
        [0.0727867],
        ...,
        [0.0062128],
        [0.197012 ],
        [0.0863911]],
       [[0.5311691],
        [0.2695098],
        [0.0722636],
        ...,
        [0.0034987],
        [0.1995552],
        [0.0873127]]])>, <tf.Tensor: shape=(), dtype=string, numpy=b'Physical_ungrip'>)
train_ds el 3 :  (<tf.Tensor: shape=(150, 128, 1), dtype=float64, numpy=
array([[[0.5344185],
        [0.278568 ],
        [0.0721303],
        ...,
        [0.0091263],
        [0.2004447],
        [0.0882447]],
       [[0.5359075],
        [0.2795821],
        [0.0720736],
        ...,
        [0.0077176],
        [0.1932825],
        [0.0856282]],
       [[0.5283639],
        [0.2746144],
        [0.0710207],
        ...,
        [0.0052901],
        [0.1952176],
        [0.0862649]],
       ...,
       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],
       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],
       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]]])>, <tf.Tensor: shape=(), dtype=string, numpy=b'Mental_grip'>)
train_ds el 4 :  (<tf.Tensor: shape=(150, 128, 1), dtype=float64, numpy=
array([[[0.5331477],
        [0.2739582],
        [0.0717712],
        ...,
        [0.0109573],
        [0.1940901],
        [0.0880007]],
       [[0.5335427],
        [0.2737107],
        [0.071813 ],
        ...,
        [0.0037366],
        [0.1964362],
        [0.0886652]],
       [[0.5356644],
        [0.2747716],
        [0.0720867],
        ...,
        [0.0090865],
        [0.1971512],
        [0.0893587]],
       ...,
       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],
       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]],
       [[0.       ],
        [0.       ],
        [0.       ],
        ...,
        [0.       ],
        [0.       ],
        [0.       ]]])>, <tf.Tensor: shape=(), dtype=string, numpy=b'Mental_ungrip'>)
```
"
2289596817,67334,Broken ExtensionType interoperability with Keras in 2.16,closed,2024-05-10 11:59:39+00:00,2024-05-31T01:49:32Z,2024-05-31T01:49:25Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/67334,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'TF 2.16']","['Hi **@karelhorak-gen** ,\r\n- Sorry for the delay, I tried to run your code on colab using TF v2.15, 2.16.1, nightly and in 2.15 it is working fine, remaining versions getting the same issue. please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/63cf5b4bc484ac837ff24245b4c3356d/67334_2-15-2-16-1-nightly.ipynb) here for reference.\r\n- And Please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999).\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67334"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67334"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

v2.16.1-0-g5bc9d26649c 2.16.1

### Custom code

No

### OS platform and distribution

MacOS 14.4.1 (Arm)

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

The [ExtensionType guide](https://www.tensorflow.org/guide/extension_type#keras) suggests that it is possible to create `tf.keras.layers.Input` for ExtensionTypes using the `type_spec` argument. This argument, however, seems to be missing in Keras 3 / TF 2.16. It is not clear how the integration with Keras should work in 2.16 (if it is even possible due to the absence of the critical argument).

### Standalone code to reproduce the issue

```shell
# Taken from the guide for reference (https://www.tensorflow.org/guide/extension_type#keras):

class Network(tf.experimental.BatchableExtensionType):
  shape: tf.TensorShape  # batch shape. A single network has shape=[].
  work: tf.Tensor        # work[*shape, n] = work left to do at node n
  bandwidth: tf.Tensor   # bandwidth[*shape, n1, n2] = bandwidth from n1->n2

  def __init__(self, work, bandwidth):
    self.work = tf.convert_to_tensor(work)
    self.bandwidth = tf.convert_to_tensor(bandwidth)
    work_batch_shape = self.work.shape[:-1]
    bandwidth_batch_shape = self.bandwidth.shape[:-2]
    self.shape = work_batch_shape.merge_with(bandwidth_batch_shape)

  def __repr__(self):
    return network_repr(self)


input_spec = Network.Spec(shape=None,
                          work=tf.TensorSpec(None, tf.float32),
                          bandwidth=tf.TensorSpec(None, tf.float32))
model = tf.keras.Sequential([
    tf.keras.layers.Input(type_spec=input_spec),
    # BalanceNetworkLayer(),
    ])
```


### Relevant log output

```shell
TypeError: Input() got an unexpected keyword argument 'type_spec'
```
"
2290810863,67386,tf.keras.utils.Sequence or tf.keras.utils.PyDataset is abnormal in tensorflow2.16,closed,2024-05-11 09:45:14+00:00,2024-05-31T01:49:29Z,2024-05-31T01:49:23Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/67386,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'TF 2.16']","['@zx-lhb \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thank you!', '> @zx-lhb In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thank you!\r\n\r\n# my dataset definition\r\n```python\r\nclass Seg3DRandomDataset(tf.keras.utils.Sequence):\r\n    def __init__(self, images_dir, labels_dir, input_size, num_classes, batch_size,\r\n                 hu_min_val, hu_max_val, mode:str,**kwargs):\r\n        super(Seg3DRandomDataset, self).__init__(**kwargs)\r\n\r\n        self.images_dir = images_dir\r\n        self.labels_dir = labels_dir\r\n        self.input_size = input_size\r\n        self.num_classes = num_classes\r\n        self.batch_size = batch_size\r\n        self.hu_min_val = hu_min_val\r\n        self.hu_max_val = hu_max_val\r\n        self.mode = mode\r\n    \r\n        file_names = os.listdir(images_dir) # nii.gz\r\n        \r\n\r\n        self.images_path = []\r\n        self.labels_path = []\r\n        for file_name in file_names:\r\n            image_path = os.path.join(images_dir, file_name)\r\n            label_path = os.path.join(labels_dir, file_name)\r\n            self.images_path.append(image_path)\r\n            self.labels_path.append(label_path)\r\n        \r\n    def __len__(self):\r\n        return math.ceil(len(self.images_path) / self.batch_size)\r\n    \r\n    def __getitem__(self, idx):\r\n        low = idx * self.batch_size\r\n        high = min(low + self.batch_size, len(self.images_path))\r\n\r\n        batch_x_path = self.images_path[low:high]\r\n        batch_y_path = self.labels_path[low:high]\r\n        \r\n        batch_x = []\r\n        batch_y = []\r\n        for x_path, y_path in zip(batch_x_path, batch_y_path):\r\n            image = sitk.ReadImage(x_path)\r\n            label = sitk.ReadImage(y_path)\r\n            self.curimagePath = x_path\r\n\r\n            \r\n            image = self.custom_window(image,self.hu_min_val,self.hu_max_val)\r\n            # \r\n            imageArray = sitk.GetArrayFromImage(image)\r\n            labelArray = sitk.GetArrayFromImage(label)\r\n\r\n            \r\n            self.d_range, self.h_range, self.w_range = self.cal_board(labelArray)\r\n\r\n            \r\n            imageArray = self.normalize_imageArray(imageArray[self.d_range[0]:self.d_range[1]+1, self.h_range[0]:self.h_range[1]+1, self.w_range[0]:self.w_range[1]+1])\r\n            labelArray = labelArray[self.d_range[0]:self.d_range[1]+1, self.h_range[0]:self.h_range[1]+1, self.w_range[0]:self.w_range[1]+1]\r\n\r\n            \r\n            imageArray, labelArray = self.random_crop(imageArray, labelArray, self.input_size)\r\n\r\n            if self.mode == \'train\':\r\n                if random.randint(0, 1) == 1:                    \r\n                    imageArray = np.flip(imageArray, axis=1)\r\n                    labelArray = np.flip(labelArray, axis=1)\r\n                if random.randint(0, 1) == 1:\r\n                    imageArray = np.flip(imageArray, axis=2)\r\n                    labelArray = np.flip(labelArray, axis=2)\r\n                if random.randint(0, 1) == 1:\r\n                    rotate_angle = random.randint(0, 360)\r\n                    imageArray = ndimage.rotate(imageArray, rotate_angle, axes=[1,2],reshape=False,mode=\'nearest\',order=0)\r\n                    labelArray = ndimage.rotate(labelArray, rotate_angle, axes=[1,2],reshape=False,mode=\'nearest\',order=0)\r\n            \r\n\r\n           \r\n            # ->[1,d,h,w]\r\n            img_c = np.expand_dims(imageArray, axis=-1).astype(np.float32)\r\n            \r\n            # labelArray onehot ->[d,h,w,num_classes]\r\n            lab_c = np.zeros((*labelArray.shape,self.num_classes),dtype=np.float32)\r\n            for i in range(self.num_classes):\r\n                lab_c[...,i] = (labelArray == i).astype(np.float32)\r\n           \r\n            batch_x.append(img_c)\r\n            batch_y.append(lab_c)\r\n\r\n        \r\n        return np.array(batch_x), np.array(batch_y)\r\n\r\n    def random_crop(self, imageArray, labelArray, crop_size):\r\n        D,H,W = imageArray.shape\r\n        d,h,w = crop_size\r\n\r\n        if D<d:\r\n            padding = np.zeros((d-D,H,W),dtype=np.float32)\r\n            imageArray = np.concatenate((imageArray, padding), axis=0)\r\n            labelArray = np.concatenate((labelArray, padding), axis=0)\r\n        if H<h:\r\n            D,H,W = imageArray.shape\r\n            padding = np.zeros((D,h-H,W),dtype=np.float32)\r\n            imageArray = np.concatenate((imageArray, padding), axis=1)\r\n            labelArray = np.concatenate((labelArray, padding), axis=1)\r\n        if W<w:\r\n            D,H,W = imageArray.shape\r\n            padding = np.zeros((D,H,w-W),dtype=np.float32)\r\n            imageArray = np.concatenate((imageArray, padding), axis=2)\r\n            labelArray = np.concatenate((labelArray, padding), axis=2)\r\n        \r\n        D,H,W = imageArray.shape\r\n\r\n        d_start = random.randint(0, D-1)\r\n        d_end = d_start + d\r\n        if d_end > D:\r\n            d_end = D\r\n            d_start = D - d\r\n\r\n        h_start = random.randint(0, H-1)\r\n        h_end = h_start + h\r\n        if h_end > H:\r\n            h_end = H\r\n            h_start = H - h\r\n\r\n        w_start = random.randint(0, W-1)\r\n        w_end = w_start + w\r\n        if w_end > W:\r\n            w_end = W\r\n            w_start = W - w\r\n        \r\n        img = imageArray[d_start:d_end, h_start:h_end, w_start:w_end]\r\n        lab = labelArray[d_start:d_end, h_start:h_end, w_start:w_end]\r\n        assert img.shape == (d,h,w) and lab.shape==(d,h,w), f""img.shape={img.shape}, lab.shape={lab.shape}, (d,h,w)={crop_size}""\r\n            \r\n        return img, lab\r\n    \r\n\r\n    def normalize_imageArray(self, image_array):   \r\n        max_value = np.max(image_array)\r\n        min_value = np.min(image_array)\r\n        assert max_value==self.hu_max_val and min_value==self.hu_min_val,f""max_value={max_value}, hu_max_val={self.hu_max_val}; min_value={min_value}, hu_min_val={self.hu_min_val}, they are not equal!, image_path={self.curimagePath}""\r\n\r\n        img_01 = (image_array - min_value) / (max_value - min_value)\r\n        return np.clip(img_01, 0, 1)\r\n    \r\n\r\n    def cal_board(self, label_array):\r\n        dots = np.argwhere(label_array != 0)\r\n        mins = np.min(dots, axis=0)\r\n        maxs = np.max(dots, axis=0)\r\n\r\n        d_range = [mins[0], maxs[0]]\r\n        h_range = [mins[1], maxs[1]]\r\n        w_range = [mins[2], maxs[2]]\r\n        \r\n        return d_range, h_range, w_range\r\n\r\n\r\n    def custom_window(self,image,hu_min_val,hu_max_val):\r\n        ww_filter = sitk.IntensityWindowingImageFilter()\r\n        ww_filter.SetWindowMinimum(hu_min_val)\r\n        ww_filter.SetWindowMaximum(hu_max_val)\r\n\r\n        ww_filter.SetOutputMinimum(hu_min_val)\r\n        ww_filter.SetOutputMaximum(hu_max_val)\r\n        return ww_filter.Execute(image)\r\n\r\n    def on_epoch_end(self):\r\n        if self.mode == \'train\':\r\n            seed = random.randint(1,100)\r\n            random.seed(seed)\r\n            random.shuffle(self.images_path)\r\n            random.seed(seed)\r\n            random.shuffle(self.labels_path)\r\n```\r\n\r\n# check dataset\r\n```python\r\nval_images_dir = ""D:/data/lung/images/val""\r\nval_labels_dir = ""D:/data/lung/labels/val""\r\nval_dataset = Seg3DRandomDataset(\r\n    images_dir=val_images_dir,labels_dir=val_labels_dir,\r\n    input_size=input_size,num_classes=num_classes,  \r\n    batch_size=batch_size,   \r\n    hu_min_val=-1000,hu_max_val=800,\r\n    mode=""val""\r\n)\r\nfor x,y in val_dataset:\r\n        print(x.shape,y.shape)\r\n        if(x.shape[0]==0):\r\n            input(""zzzz"")\r\n\r\ninput(""zzz2"")\r\n```\r\n# tf2.9 output\r\n![image](https://github.com/tensorflow/tensorflow/assets/98244381/66c38ef5-9828-4559-a715-4ecdf83f2cdc)\r\n# tf2.16 output\r\n![image](https://github.com/tensorflow/tensorflow/assets/98244381/469cdf75-76b2-4965-9d5b-10919a95b7a7)\r\n\r\n', '@zx-lhb Could you please share the gist with the error . I tried to replicate the issue reported here but facing a different error, please have a look at the [gist](https://colab.research.google.com/gist/sushreebarsa/a1d21f8e49e5e2e4b5b104041f1c9c59/67386.ipynb) and let us know. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67386"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67386"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf2.16

### Custom code

Yes

### OS platform and distribution

windows10

### Mobile device

_No response_

### Python version

3.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

when the dataset has run out, the dataset still generator something, but the shape is 0, so it cuase model.fit() failed when an epoch end. But I also test the same code in tf29, it wa OK.
![image](https://github.com/tensorflow/tensorflow/assets/98244381/08b611b0-92f2-42b0-832f-f73ffe4fac5b)
![image](https://github.com/tensorflow/tensorflow/assets/98244381/ce8eef6c-e889-4ebc-b593-83e8598193f7)


### Standalone code to reproduce the issue

```shell
print(f""len_dataset={len(val_dataset)}"")
    for x,y in val_dataset:
        print(x.shape,y.shape)
        if(x.shape[0]==0):
            input(""zzzz"")
```


### Relevant log output

```shell
9/9 ━━━━━━━━━━━━━━━━━━━━ 0s 10s/step - dice_score: 0.7916 - loss: 0.9173Traceback (most recent call last):
  File ""D:\pythonProj\tensorflow_projects\seg3d\train.py"", line 135, in <module>
    history = model.fit(
              ^^^^^^^^^^
  File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\keras\src\utils\traceback_utils.py"", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorboard\plugins\scalar\summary_v2.py"", line 89, in scalar
    return tf.summary.write(
           ^^^^^^^^^^^^^^^^^
TypeError: <tf.Tensor 'truediv:0' shape=() dtype=float32> is out of scope and cannot be used here. Use return values, explicit Python locals or TensorFlow collections to access it. 
Please see https://www.tensorflow.org/guide/function#all_outputs_of_a_tffunction_must_be_return_values for more information.

<tf.Tensor 'truediv:0' shape=() dtype=float32> was defined here:
    File ""D:\pythonProj\tensorflow_projects\seg3d\train.py"", line 135, in <module>
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\keras\src\utils\traceback_utils.py"", line 117, in error_handler
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\keras\src\backend\tensorflow\trainer.py"", line 339, in fit
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\keras\src\utils\traceback_utils.py"", line 117, in error_handler
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\keras\src\backend\tensorflow\trainer.py"", line 425, in evaluate
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\util\traceback_utils.py"", line 150, in error_handler
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\eager\polymorphic_function\polymorphic_function.py"", line 833, in __call__
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\eager\polymorphic_function\polymorphic_function.py"", line 889, in _call
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\eager\polymorphic_function\polymorphic_function.py"", line 696, in _initialize
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\eager\polymorphic_function\tracing_compilation.py"", line 178, in trace_function
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\eager\polymorphic_function\tracing_compilation.py"", line 283, in _maybe_define_function
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\eager\polymorphic_function\tracing_compilation.py"", line 310, in _create_concrete_function      
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\framework\func_graph.py"", line 1059, in func_graph_from_py_func
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\eager\polymorphic_function\polymorphic_function.py"", line 599, in wrapped_fn
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\eager\polymorphic_function\autograph_util.py"", line 41, in autograph_handler
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\autograph\impl\api.py"", line 339, in converted_call
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\autograph\impl\api.py"", line 459, in _call_unconverted
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\autograph\impl\api.py"", line 643, in wrapper
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\keras\src\backend\tensorflow\trainer.py"", line 161, in one_step_on_iterator
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\distribute\distribute_lib.py"", line 1673, in run
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\distribute\distribute_lib.py"", line 3263, in call_for_each_replica
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\distribute\distribute_lib.py"", line 4061, in _call_for_each_replica
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\autograph\impl\api.py"", line 643, in wrapper
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\keras\src\backend\tensorflow\trainer.py"", line 150, in one_step_on_data
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\keras\src\backend\tensorflow\trainer.py"", line 87, in test_step
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\keras\src\trainers\trainer.py"", line 412, in compute_metrics
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\keras\src\trainers\compile_utils.py"", line 330, in update_state
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\keras\src\trainers\compile_utils.py"", line 17, in update_state
    File ""D:\pythonProj\tensorflow_projects\seg3d\utils\losses.py"", line 45, in update_state
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\util\traceback_utils.py"", line 150, in error_handler
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\framework\override_binary_operator.py"", line 113, in binary_op_wrapper
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\ops\tensor_math_operator_overrides.py"", line 88, in _truediv_factory
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\util\traceback_utils.py"", line 150, in error_handler
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\util\dispatch.py"", line 1260, in op_dispatch_handler
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\ops\math_ops.py"", line 1485, in truediv
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\ops\weak_tensor_ops.py"", line 142, in wrapper
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\ops\math_ops.py"", line 1423, in _truediv_python3
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\ops\weak_tensor_ops.py"", line 142, in wrapper
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\ops\gen_math_ops.py"", line 8192, in real_div
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 796, in _apply_op_helper
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\framework\func_graph.py"", line 670, in _create_op_internal
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\framework\ops.py"", line 2682, in _create_op_internal
    File ""C:\Users\admin\.conda\envs\py312_tf216\Lib\site-packages\tensorflow\python\framework\ops.py"", line 1177, in from_node_def

The tensor <tf.Tensor 'truediv:0' shape=() dtype=float32> cannot be accessed from here, because it was defined in FuncGraph(name=one_step_on_iterator, id=2094210790336), which is out of scope.

(py312_tf216) D:\pythonProj\tensorflow_projects\seg3d>
```
"
2293602625,67473,"Apple Silicon, building pip package ... clang: error: linker command failed with exit code 1",closed,2024-05-13 19:05:28+00:00,2024-06-19T01:51:12Z,2024-06-19T01:51:10Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/67473,"['stat:awaiting response', 'type:bug', 'type:build/install', 'stale', 'comp:lite', 'subtype:macOS', 'TF 2.16']","['Hi @zepouet, can you try with `Clang from xcode 13.6`: https://www.tensorflow.org/install/source#macos ensure your versions are aligned with the compatibility matrix. Thanks.', 'Hello @pkgoogle, can you give me the compatibily matrix please ? Thanks. \r\nI fear to downgrade CLang and have side effect elsewhere.\r\nI will try neverthless outside.\r\nThanks a lot', ""Hi @zepouet, apologies, it's lower down the link's page, I had thought I linked it directly: https://www.tensorflow.org/install/source#cpu_2"", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67473"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67473"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.16.1

### Custom code

No

### OS platform and distribution

Mac Sonoma 14.4.1

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

Apple clang version 15.0.0 (clang-1500.3.9.4) Target: arm64-apple-darwin23.4.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

M3 MAX

### Current behavior?

Hello,

Cannot compile the python library for Apple Silicon about TF Lite

### Standalone code to reproduce the issue

```shell
Try to compile with and without aarch64 target because of arm64 doesn't succed

PYTHON=python3 tensorflow/lite/tools/pip_package/build_pip_package_with_cmake.sh native
```


### Relevant log output

```shell
pybind11::detail::type_caster<bool, void>& pybind11::detail::load_type<bool, void>(pybind11::detail::type_caster<bool, void>&, pybind11::handle const&) in interpreter_wrapper_pybind11.cc.o
      bool pybind11::detail::argument_loader<tflite::interpreter_wrapper::InterpreterWrapper&, int, pybind11::handle&, bool, int>::load_impl_sequence<0ul, 1ul, 2ul, 3ul, 4ul>(pybind11::detail::function_call&, std::__1::integer_sequence<unsigned long, 0ul, 1ul, 2ul, 3ul, 4ul>) in interpreter_wrapper_pybind11.cc.o
ld: symbol(s) not found for architecture arm64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make[3]: *** [_pywrap_tensorflow_interpreter_wrapper.dylib] Error 1
make[2]: *** [CMakeFiles/_pywrap_tensorflow_interpreter_wrapper.dir/all] Error 2
make[1]: *** [CMakeFiles/_pywrap_tensorflow_interpreter_wrapper.dir/rule] Error 2
make: *** [_pywrap_tensorflow_interpreter_wrapper] Error 2

make[1]: *** [CMakeFiles/_pywrap_tensorflow_interpreter_wrapper.dir/rule] Error 2
make: *** [_pywrap_tensorflow_interpreter_wrapper] Error 2
```
"
2294835818,67531,Segmentation fault (core dumped) in `tf.raw_ops.SoftmaxCrossEntropyWithLogits`,closed,2024-05-14 08:47:15+00:00,2024-06-07T01:50:58Z,2024-06-07T01:50:55Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/67531,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.16']","['Hi **@LongZE666** ,\r\n- Sorry for the delay, Can you please try with recent TF version? I tried with TF-nightly and I cannot reproduce the error. It might be solved in upcoming version. Please check the [gist](https://colab.sandbox.google.com/gist/Venkat6871/14f9445b68ea666c07e766277ecd3299/67531_2-16-1-nightly-v.ipynb) here.\r\n\r\nThank you!', 'I can reproduce this problem on tensorflow version 2.16.1, and it can be executed normally on tf-nightly.', 'Hi **@LongZE666** ,\r\n- Yes, I also reproduce same error with version 2.16.1. But it is working fine with tf-nightly. So, It might be solve in upcoming version.\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67531"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67531"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.16.1

### Custom code

Yes

### OS platform and distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Triggered when input parameters `features` and `labels` are incorrect.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

features = tf.constant([], shape=[3,0], dtype=tf.float64)
labels = tf.constant([], shape=[0], dtype=tf.float64)
tf.raw_ops.SoftmaxCrossEntropyWithLogits(features=features, labels=labels)
```


### Relevant log output

```shell
ASAN Report:

AddressSanitizer:DEADLYSIGNAL
=================================================================
==2083523==ERROR: AddressSanitizer: SEGV on unknown address 0x000000000000 (pc 0x7fe71e96a65b bp 0x7ffd6f3a7700 sp 0x7ffd6f3a7620 T0)
==2083523==The signal is caused by a READ memory access.
==2083523==Hint: address points to the zero page.
    #0 0x7fe71e96a65b in std::_Function_handler<void (long, long), tensorflow::functor::XentFunctorBase<Eigen::ThreadPoolDevice, double>::operator()(Eigen::ThreadPoolDevice const&, Eigen::DSizes<long, 2> const&, Eigen::array<long, 2ul> const&, Eigen::array<long, 2ul> const&, Eigen::TensorMap<Eigen::Tensor<double const, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<double const, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<double, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<double, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<double, 2, 1, long>, 16, Eigen::MakePointer>)::{lambda(long, long)#1}>::_M_invoke(std::_Any_data const&, long&&, long&&) (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x38bcb65b)
    #1 0x7fe6fb7f638b in Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x15a5738b)
    #2 0x7fe71e976680 in tensorflow::SoftmaxXentWithLogitsOp<Eigen::ThreadPoolDevice, double>::Compute(tensorflow::OpKernelContext*) (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x38bd7680)
    #3 0x7fe74fe0714a in tensorflow::ThreadPoolDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x1cdc14a)
    #4 0x7fe74f98dfe6 in tensorflow::(anonymous namespace)::SingleThreadedExecutorImpl::Run(tensorflow::Executor::Args const&) (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x1862fe6)
    #5 0x7fe74f86a306 in tensorflow::FunctionLibraryRuntimeImpl::RunSync(tensorflow::FunctionLibraryRuntime::Options, unsigned long, absl::lts_20230802::Span<tensorflow::Tensor const>, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*) (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x173f306)
    #6 0x7fe74f8c7f74 in tensorflow::ProcessFunctionLibraryRuntime::RunMultiDeviceSync(tensorflow::FunctionLibraryRuntime::Options const&, unsigned long, std::vector<std::variant<tensorflow::Tensor, tensorflow::TensorShape>, std::allocator<std::variant<tensorflow::Tensor, tensorflow::TensorShape> > >*, std::function<absl::lts_20230802::Status (tensorflow::ProcessFunctionLibraryRuntime::ComponentFunctionData const&, tensorflow::ProcessFunctionLibraryRuntime::InternalArgs*)>) const (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x179cf74)
    #7 0x7fe74f8d58b1 in tensorflow::ProcessFunctionLibraryRuntime::RunSync(tensorflow::FunctionLibraryRuntime::Options const&, unsigned long, absl::lts_20230802::Span<tensorflow::Tensor const>, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*) const (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x17aa8b1)
    #8 0x7fe7179f72eb in tensorflow::KernelAndDeviceFunc::Run(tensorflow::ScopedStepContainer*, tensorflow::EagerKernelArgs const&, std::vector<std::variant<tensorflow::Tensor, tensorflow::TensorShape>, std::allocator<std::variant<tensorflow::Tensor, tensorflow::TensorShape> > >*, tsl::CancellationManager*, std::optional<tensorflow::EagerFunctionParams> const&, std::optional<tensorflow::ManagedStackTrace> const&, tsl::CoordinationServiceAgent*) (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x31c582eb)
    #9 0x7fe71788cc2c in tensorflow::EagerKernelExecute(tensorflow::EagerContext*, absl::lts_20230802::InlinedVector<tensorflow::TensorHandle*, 4ul, std::allocator<tensorflow::TensorHandle*> > const&, std::optional<tensorflow::EagerFunctionParams> const&, tsl::core::RefCountPtr<tensorflow::KernelAndDevice> const&, tensorflow::GraphCollector*, tsl::CancellationManager*, absl::lts_20230802::Span<tensorflow::TensorHandle*>, std::optional<tensorflow::ManagedStackTrace> const&) (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x31aedc2c)
    #10 0x7fe71788f66a in tensorflow::ExecuteNode::Run() (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x31af066a)
    #11 0x7fe7179c9939 in tensorflow::EagerExecutor::SyncExecute(tensorflow::EagerNode*) (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x31c2a939)
    #12 0x7fe71787cde4 in tensorflow::(anonymous namespace)::EagerLocalExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*) (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x31addde4)
    #13 0x7fe717880dd4 in tensorflow::DoEagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*) (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x31ae1dd4)
    #14 0x7fe71788ad26 in tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*) (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x31aebd26)
    #15 0x7fe706873c33 in tensorflow::EagerOperation::Execute(absl::lts_20230802::Span<tensorflow::AbstractTensorHandle*>, int*) (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x20ad4c33)
    #16 0x7fe7179bee5e in tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*) (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x31c1fe5e)
    #17 0x7fe6f63f145b in TFE_Execute (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x1065245b)
    #18 0x7fe74dd9f274 in TFE_Py_FastPathExecute_C(_object*) (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so+0x3c2274)
    #19 0x7fe6e1d5cccb in pybind11::cpp_function::initialize<pybind11_init__pywrap_tfe(pybind11::module_&)::{lambda(pybind11::args)#61}, pybind11::object, pybind11::args, pybind11::name, pybind11::scope, pybind11::sibling>(pybind11_init__pywrap_tfe(pybind11::module_&)::{lambda(pybind11::args)#61}&&, pybind11::object (*)(pybind11::args), pybind11::name const&, pybind11::scope const&, pybind11::sibling const&)::{lambda(pybind11::detail::function_call&)#3}::_FUN(pybind11::detail::function_call&) (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/_pywrap_tfe.so+0xb7ccb)
    #20 0x7fe6e1e73899 in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/_pywrap_tfe.so+0x1ce899)
    #21 0x51ad66  (/usr/bin/python3.11+0x51ad66)
    #22 0x4e75db in _PyObject_MakeTpCall (/usr/bin/python3.11+0x4e75db)
    #23 0x4fb151 in _PyEval_EvalFrameDefault (/usr/bin/python3.11+0x4fb151)
    #24 0x531822 in _PyFunction_Vectorcall (/usr/bin/python3.11+0x531822)
    #25 0x541194 in PyObject_Call (/usr/bin/python3.11+0x541194)
    #26 0x4fefe0 in _PyEval_EvalFrameDefault (/usr/bin/python3.11+0x4fefe0)
    #27 0x62e1b3  (/usr/bin/python3.11+0x62e1b3)
    #28 0x4f3a66 in PyEval_EvalCode (/usr/bin/python3.11+0x4f3a66)
    #29 0x647c36  (/usr/bin/python3.11+0x647c36)
    #30 0x64534f  (/usr/bin/python3.11+0x64534f)
    #31 0x650d14  (/usr/bin/python3.11+0x650d14)
    #32 0x650a63 in _PyRun_SimpleFileObject (/usr/bin/python3.11+0x650a63)
    #33 0x650832 in _PyRun_AnyFileObject (/usr/bin/python3.11+0x650832)
    #34 0x64f786 in Py_RunMain (/usr/bin/python3.11+0x64f786)
    #35 0x61ee0c in Py_BytesMain (/usr/bin/python3.11+0x61ee0c)
    #36 0x7fe7fbe3cd8f  (/lib/x86_64-linux-gnu/libc.so.6+0x29d8f)
    #37 0x7fe7fbe3ce3f in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x29e3f)
    #38 0x61ec94 in _start (/usr/bin/python3.11+0x61ec94)

AddressSanitizer can not provide additional info.
SUMMARY: AddressSanitizer: SEGV (/mnt//venv/tensorflow-2.16.1-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x38bcb65b) in std::_Function_handler<void (long, long), tensorflow::functor::XentFunctorBase<Eigen::ThreadPoolDevice, double>::operator()(Eigen::ThreadPoolDevice const&, Eigen::DSizes<long, 2> const&, Eigen::array<long, 2ul> const&, Eigen::array<long, 2ul> const&, Eigen::TensorMap<Eigen::Tensor<double const, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<double const, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<double, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<double, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<double, 2, 1, long>, 16, Eigen::MakePointer>)::{lambda(long, long)#1}>::_M_invoke(std::_Any_data const&, long&&, long&&)
==2083523==ABORTING
```
```
"
2295483429,67556,Remove null pointer from error message in mlir::odml,closed,2024-05-14 13:34:35+00:00,2024-07-08T06:46:48Z,2024-07-08T06:46:45Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/67556,"['stat:awaiting tensorflower', 'type:bug', 'comp:lite', 'TF 2.16']","['Hi @apach301 is this issue still open?\r\nIf so,  could you tell me how to replicate the bug so that I may have a go at it?', '> Hi @apach301 is this issue still open?\n> \n> If so,  could you tell me how to replicate the bug so that I may have a go at it?\n\nThis bug was detected by static analysis, therefore I have no input to reproduce it during execution. But I propose a fix in PR #67557', 'Hi @apach301 the PR looks great,  if you would like any help with CI, do let me know.\r\n\r\nThanks and regards', 'will wait for review.', '> will wait for review.\r\n\r\nHi @pkgoogle How to enable CI tests run in PR #67557? Is it wait any approval to run?', ""Hi @apach301, we'll have to wait for review, we run CI/CD internally and review the PR."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67556"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67556"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.16.1

### Custom code

No

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Possible null pointer dereference in `mlir::odml::MatchInverseScalesOperand()`: undefined variable `inverse_scale_constant_op` is printed in error message.
https://github.com/tensorflow/tensorflow/blob/08a13d2991724a4b0039237ce07340e16b760656/tensorflow/compiler/mlir/lite/stablehlo/transforms/compose_uniform_quantized_type_pass.cc#L172-L178

### Standalone code to reproduce the issue

```shell
Bug was found with Svace static analyzer
```


### Relevant log output

_No response_"
2295937338,67566,Unexpected behavior in tf.data.Dataset.from_generator when there is a naming collision,closed,2024-05-14 16:46:32+00:00,2024-06-04T13:36:47Z,2024-06-04T13:36:43Z,aaudiber,,https://github.com/tensorflow/tensorflow/issues/67566,"['stat:awaiting tensorflower', 'type:bug', 'comp:data', 'TF 2.16']","['Hi @kralka ,\r\n\r\nI have replicated the issue with `TF2.15v` and `tf-nightly` as well. On Colab the code executes indefinitely due to naming collision of generator and finally runtime will crash without any logs. Attaching [gist](https://colab.sandbox.google.com/gist/SuryanarayanaY/07facdb64fa42d474b68cbe875040fd7/67566.ipynb) for reference.', '@SuryanarayanaY thank you for your response. One can get a crash (as opposed to indefinite execution without errors) in an official docker (`docker pull tensorflow/tensorflow:latest-gpu`). I will provide concrete steps if needed.', 'Hi @SuryanarayanaY is there some plan to resolve this issue? Do you know what causes it? In case resolving would require too large changes do you think it is worth putting a note in the documentation since it is rather hard to figure out what causes this behavior?\r\n\r\nPersonally I would be interested in the cause of this since some magic needs to be happening here :-)', 'Sorry my fault. This is not a TensorFlow issue.\r\n\r\n```python\r\nmy_list = [1, 2, 3]\r\n\r\ndef gen():\r\n  yield from my_list\r\n\r\nmy_list = [5, 6, 7]\r\n\r\nassert list(gen()) == [5, 6, 7]\r\n```', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67566"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67566"">No</a>\n']","### Issue type

Documentation Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.15.0

### Custom code

Yes

### OS platform and distribution

colab

### Mobile device

_No response_

### Python version

3.10.12

### Bazel version

_No response_

### GCC/compiler version

11.4.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When creating a `tf.data.Dataset` object using `from_generator` a naming collision with an iterable used in the `generator` parameter causes a crash.

On Ubuntu I got the following error (not in colab):
date: F external/local_tsl/tsl/platform/default/env.cc:74] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.

### Standalone code to reproduce the issue

```shell
import sys
print(f""Python version: {sys.version}"")

import tensorflow as tf
print(f""{tf.__version__ = }"")

# This runs as expected:

ds_no_name_collision = list(range(100))

def gen():
  print(""gen called"")
  for x in ds_no_name_collision:
    print(f""{x = }"")
    yield x

# Notice there is no name collision:
ds_without_name_collision = tf.data.Dataset.from_generator(gen, output_signature=tf.TensorSpec(shape=(), dtype=tf.int32))

print(""All good so far"")

for x in ds_without_name_collision.take(10):
  print(x)



# This fails:

ds_name_collision = list(range(100))

def gen():
  print(""gen called"")
  for x in ds_name_collision:
    print(f""{x = }"")
    yield x

# Notice the name collision:
ds_name_collision = tf.data.Dataset.from_generator(gen, output_signature=tf.TensorSpec(shape=(), dtype=tf.int32))

print(""All good so far"")

for x in ds_name_collision.take(10):
  print(x)
```


### Relevant log output

```shell
Python version: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]
tf.__version__ = '2.15.0'
All good so far
gen called
x = 0
x = 1
tf.Tensor(0, shape=(), dtype=int32)
tf.Tensor(1, shape=(), dtype=int32)
x = 2
x = 3
x = 4
tf.Tensor(2, shape=(), dtype=int32)
x = 5
tf.Tensor(3, shape=(), dtype=int32)
tf.Tensor(4, shape=(), dtype=int32)
tf.Tensor(5, shape=(), dtype=int32)
x = 6
x = 7
x = 8
x = 9
tf.Tensor(6, shape=(), dtype=int32)
tf.Tensor(7, shape=(), dtype=int32)
tf.Tensor(8, shape=(), dtype=int32)
tf.Tensor(9, shape=(), dtype=int32)
All good so far
gen called
gen called
gen called
gen called
gen called
gen called
gen called
[log truncated]
```
"
2298100991,67642, ABORTED: Shutdown in `tf.raw_ops.PriorityQueueV2`,closed,2024-05-15 14:29:27+00:00,2024-05-24T11:01:58Z,2024-05-24T11:01:55Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/67642,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.16']","['@x0w3n `tf.raw_ops.PriorityQueueV2`  function creates a priority queue data structure. The container name ""test_container"" contains characters that are not allowed. Could we try to rename the container to use only alphanumeric characters (a-z, A-Z, 0-9) and underscores (_). Avoid special characters like ""-"", ""*"", ""!"". I was able to replicate the issue reported [here](https://colab.research.google.com/gist/sushreebarsa/5615a41a5b64ea5bc2de53ad94a3ce71/67642.ipynb). Thank you!', '> @x0w3n `tf.raw_ops.PriorityQueueV2` function creates a priority queue data structure. The container name ""test_container"" contains characters that are not allowed. Could we try to rename the container to use only alphanumeric characters (a-z, A-Z, 0-9) and underscores (_). Avoid special characters like ""-"", ""*"", ""!"". I was able to replicate the issue reported [here](https://colab.research.google.com/gist/sushreebarsa/5615a41a5b64ea5bc2de53ad94a3ce71/67642.ipynb). Thank you!\r\n\r\nNoted with thanks.', '@x0w3n Could you please let us know if the issue got resolved ?', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', '> @x0w3n Could you please let us know if the issue got resolved ?\r\n\r\nI have got it. Thank you.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67642"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67642"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When the component_types parameter of tf.raw_ops.PriorityQueueV2 contains some special characters, such as ""-"", ""*"", ""!"" etc., it will trigger ""Local rendezvous is aborting with status: ABORTED: Shutdown"" error.



### Standalone code to reproduce the issue

```shell
import tensorflow as tf
shapes = [1, 1]
component_types = [tf.float32, tf.int32]
capacity = 10
container = ""test_container"" 
shared_name = ""testsharedname""
queue_handle = tf.raw_ops.PriorityQueueV2(
    shapes=shapes,
    component_types=component_types,
    capacity=capacity,
    container=container,
    shared_name=shared_name
)
```


### Relevant log output

```shell
2024-05-15 14:25:39.269296: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at resource_op_kernel.h:76 : INVALID_ARGUMENT: container contains invalid characters: test!container
2024-05-15 14:25:39.269340: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: container contains invalid characters: test!container
Traceback (most recent call last):
  File ""/home/tf/test.py"", line 10, in <module>
    queue_handle = tf.raw_ops.PriorityQueueV2(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/root/anaconda3/envs/tf2.16/lib/python3.11/site-packages/tensorflow/python/util/tf_export.py"", line 377, in wrapper
    return f(**kwargs)
           ^^^^^^^^^^^
  File ""/root/anaconda3/envs/tf2.16/lib/python3.11/site-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 3240, in priority_queue_v2
    return priority_queue_v2_eager_fallback(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/root/anaconda3/envs/tf2.16/lib/python3.11/site-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 3312, in priority_queue_v2_eager_fallback
    _result = _execute.execute(b""PriorityQueueV2"", 1, inputs=_inputs_flat,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/root/anaconda3/envs/tf2.16/lib/python3.11/site-packages/tensorflow/python/eager/execute.py"", line 53, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__PriorityQueueV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} container contains invalid characters: test!container [Op:PriorityQueueV2]
2024-05-15 14:25:39.422495: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: ABORTED: Shutdown
```
"
2299070714,67699,Tensorflow lite in Android App,closed,2024-05-16 00:21:52+00:00,2024-08-22T01:55:47Z,2024-08-22T01:55:41Z,sawantkumar,,https://github.com/tensorflow/tensorflow/issues/67699,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'TFLiteGpuDelegate', 'Android']","['hi @LiangZhaoSRA ,\r\n\r\nIf possible , can you share me the .tflite file please ', '@sawantkumar Attaches is the tflite file. Thanks.\r\n[model.zip](https://github.com/tensorflow/tensorflow/files/15379814/model.zip)\r\n', 'Hi @LiangZhaoSRA ,\r\n\r\nI inspected your model using custom code and I found out that your model has dynamic sized tensors . If possible can you provide me the model conversion code. \r\n\r\n```\r\nDynamic tensors found:\r\nName: Where_101;StatefulPartitionedCall/Where_101, Shape: [0 1]\r\nName: Squeeze_83;StatefulPartitionedCall/Squeeze_83, Shape: [0]\r\nName: GatherV2_83;StatefulPartitionedCall/GatherV2_83;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2_78;StatefulPartitionedCall/GatherV2_78;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2_79;StatefulPartitionedCall/GatherV2_79;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2_71;StatefulPartitionedCall/GatherV2_71;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2_66;StatefulPartitionedCall/GatherV2_66;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2_67;StatefulPartitionedCall/GatherV2_67;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2_59;StatefulPartitionedCall/GatherV2_59;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2_54;StatefulPartitionedCall/GatherV2_54;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2_55;StatefulPartitionedCall/GatherV2_55;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2_12;StatefulPartitionedCall/GatherV2_12;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2_13;StatefulPartitionedCall/GatherV2_13;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2_26;StatefulPartitionedCall/GatherV2_26;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2_27;StatefulPartitionedCall/GatherV2_27;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2_40;StatefulPartitionedCall/GatherV2_40;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2_41;StatefulPartitionedCall/GatherV2_41;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2_5;StatefulPartitionedCall/GatherV2_5;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2;StatefulPartitionedCall/GatherV2;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2_1;StatefulPartitionedCall/GatherV2_1;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2_47;StatefulPartitionedCall/GatherV2_47;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2_42;StatefulPartitionedCall/GatherV2_42;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\nName: GatherV2_43;StatefulPartitionedCall/GatherV2_43;GatherV2_99/axis;StatefulPartitionedCall/GatherV2_99/axis, Shape: [0]\r\n```\r\n\r\n\r\n', 'Hi Sawant,\r\nI converted the torch model to tflite via torch to onnx, onnx to tensorflow and tensorflow to tflite. Attached are the scripts for model conversion. Please let me know if you have any questions. Thanks.\r\n[tr2lite.zip](https://github.com/tensorflow/tensorflow/files/15488465/tr2lite.zip)\r\n', 'Hi Sawant,\r\n\r\nI have shared the scripts for model conversion two weeks ago. Please let me know if you have any questions and progress. Thanks.\r\n\r\nLiang\r\n', 'Hi @LiangZhaoSRA ,\r\n\r\nIf you are able to access a linux system you may be able to resolve your issue by using [AI-Edge-Torch](https://github.com/google-ai-edge/ai-edge-torch), you can find more information here: [googleblog](https://developers.googleblog.com/en/ai-edge-torch-high-performance-inference-of-pytorch-models-on-mobile-devices/).\r\n\r\nYou can directly convert your pytorch model to a tflite model.I have actually created a sample script below :\r\n\r\n```py\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nimport ai_edge_torch\r\n\r\nclass PadLayer(nn.Module):\r\n    def __init__(self):\r\n        super(PadLayer, self).__init__()\r\n        self.paddings = (0, 0, 1, 1)  # Padding for the second and third dimensions\r\n\r\n    def forward(self, x):\r\n        return F.pad(x, pad=self.paddings, mode=""constant"", value=-1)\r\n\r\nclass SimpleModel(nn.Module):\r\n    def __init__(self):\r\n        super(SimpleModel, self).__init__()\r\n        self.conv = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(1, 7), padding=\'same\')\r\n        self.pad = PadLayer()\r\n        self.mpool = nn.MaxPool2d(kernel_size=(1, 3), stride=(1, 2), padding=0)\r\n\r\n    def forward(self, x):\r\n        x = self.conv(x)\r\n        x = self.pad(x)\r\n        x = self.mpool(x)\r\n        return x\r\n\r\nmodel = SimpleModel()\r\n\r\nexample_input = torch.randn(1, 1, 32, 25)\r\n\r\nedge_model = ai_edge_torch.convert(model.eval(), (example_input,))\r\n\r\n# Export the model to TFLite format\r\nedge_model.export(\'simple_model_with_pad.tflite\')\r\n```\r\n\r\nIf you want to, you can actually try visualizing the result in [model-explorer](https://github.com/google-ai-edge/model-explorer) as well.\r\n', 'Hi Sawant,\r\n\r\nThanks for suggesting using ai-edge-torch to convert torch model to tflite directly. I was able to install ai-edge-torch and using it to convert my torch model to tflite successfully. However, when I ran the android app on S24, it raised the same error as before when enable GPU delegate:\r\nIgnoring failed delegate application: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.\r\n\r\nPlease let me know what else we can try.\r\nThanks,\r\n\r\nLiang\r\n', 'Hi Sawant,\r\n\r\nI have tried the ai-edge-torch as you suggested and got the same error as before due to dynamic-sized tensors. Please let me know if there are any other options.\r\nThanks,\r\n\r\nLiang', 'Hi @LiangZhaoSRA ,\r\n\r\nI ran your model using tflite benchmark , it is giving the below output which tells that your model contains \'select tensorflow ops\'  . Can you add \'org.tensorflow:tensorflow-lite-select-tf-ops\' to your dependency and rerun the model again and let me know if it runs on GPU.\r\n\r\n```\r\n07-22 14:19:01.506 25918 25918 I tflite_BenchmarkModelActivity: Running TensorFlow Lite benchmark with args: --graph=/data/local/tmp/student_woc.tflite   --use_gpu=true   --dry_run=true   --print_preinvoke_state=true   --num_runs=100\r\n07-22 14:19:01.532 25918 25918 I tflite  : Log parameter values verbosely: [0]\r\n07-22 14:19:01.533 25918 25918 I tflite  : Min num runs: [100]\r\n07-22 14:19:01.533 25918 25918 I tflite  : Run w/o invoking kernels: [1]\r\n07-22 14:19:01.533 25918 25918 I tflite  : Graph: [/data/local/tmp/student_woc.tflite]\r\n07-22 14:19:01.533 25918 25918 I tflite  : Signature to run: []\r\n07-22 14:19:01.533 25918 25918 I tflite  : Print pre-invoke interpreter state: [1]\r\n07-22 14:19:01.533 25918 25918 I tflite  : Use gpu: [1]\r\n07-22 14:19:01.559 25918 25918 I tflite  : Loaded model /data/local/tmp/student_woc.tflite\r\n07-22 14:19:01.571 25918 25918 I tflite  : Initialized TensorFlow Lite runtime.\r\n07-22 14:19:01.584 25918 25918 I tflite  : Created TensorFlow Lite delegate for GPU.\r\n07-22 14:19:01.584 25918 25918 I tflite  : GPU delegate created.\r\n07-22 14:19:01.584 25918 25918 E tflite  : Select TensorFlow op(s), included in the given model, is(are) not supported by this interpreter. Make sure you apply/link the Flex delegate before inference. For the Android, it can be resolved by adding ""org.tensorflow:tensorflow-lite-select-tf-ops"" dependency. See instructions: https://www.tensorflow.org/lite/guide/ops_select\r\n07-22 14:19:01.584 25918 25918 E tflite  : Node number 22 (FlexAddV2) failed to prepare.\r\n07-22 14:19:01.584 25918 25918 E tflite  : Failed to apply GPU delegate.\r\n```', 'Hi Sawant,\r\n\r\nThanks for the suggestion. After I added \'org.tensorflow:tensorflow-lite-select-tf-ops\' to  dependency and rerun the model, the error ""java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors."" is gone. However, the inference time on GPU and CPU are similar around 7sec. I wonder how to check if it\'s really running on GPU. Thanks.', 'Hi @LiangZhaoSRA ,\r\n\r\nYou can check the logs from the android logcat to see how the model is being partitioned and how many parts of it are being delegated to GPU and CPU. Let me know if you have any problem understanding the logs .', 'I checked the log and here is how the model is being partitioned:\r\nTfLiteFlexDelegate delegate: 76 nodes delegated out of 5623 nodes with 51 partitions.', ""Hi @LiangZhaoSRA ,\r\n\r\nThe log indicates that out of the 5623 nodes in your TensorFlow Lite model, 76 nodes are using the Flex Delegate for execution, and these nodes are grouped into 51 partitions. This means that the majority of your model's operations are natively supported by TensorFlow Lite, and only a small subset requires the extended functionality provided by the Flex Delegate. Let me know if this answers your question."", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67699"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67699"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.3

### Custom code

Yes

### OS platform and distribution

Ubuntu 20.04

### Mobile device

Galaxy S24

### Python version

3.8

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Got the following error when try to run a tflite model on GPU:
<img width=""483"" alt=""model"" src=""https://github.com/tensorflow/tensorflow/assets/169956268/14c52c47-cd75-4658-a6ab-3d78ba21b92d"">
W/System.err(30515): Ignoring failed delegate application: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.

When I visualize the model using Netron, there is no dynamic-sized tensor (see attached file).
<img width=""483"" alt=""model"" src=""https://github.com/tensorflow/tensorflow/assets/169956268/e6b3c023-db12-4002-af92-951b412742f9"">


### Standalone code to reproduce the issue

```shell
W/System.err(30515): Ignoring failed delegate application: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.
```


### Relevant log output

```shell
W/System.err(30515): Ignoring failed delegate application: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.
```
"
2300862002,67748,TensorFlowLiteSelectTfOps - Compile error,closed,2024-05-16 16:35:01+00:00,2024-06-29T01:49:55Z,2024-06-29T01:49:52Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/67748,"['stat:awaiting response', 'type:bug', 'type:build/install', 'stale', 'comp:lite', 'iOS']","['Hi @thereallee, are you using an emulator or a real phone? The steps to integrate Select ops with iOS are different depending on that, so I want to understand your situation.', 'Hi -  I see essentially the same error when building for device and simulator.  See attached.\r\n\r\nSimulator build:\r\n\r\n![Simulator_—_module_modulemap](https://github.com/tensorflow/tensorflow/assets/98909739/aa445363-5b55-4ed1-badc-b53f425316dd)\r\n\r\n\r\nDevice build:\r\n\r\n\r\n![Device_—_module_modulemap](https://github.com/tensorflow/tensorflow/assets/98909739/9a4f978f-fe6b-48f5-9e38-3f420b2273b5)\r\n', 'Hi @thereallee, I\'m not sure if the Pod build is the right way for iOS emulator so let\'s stick with the Device build for now. How did you fix the ""-force_load"" issue? Have you tried getting it to work w/ the image Classification app like the bottom of this section suggested? https://www.tensorflow.org/lite/guide/ops_select#ios Thanks for your help. If you can zip and share your xcode project, that\'ll be easier to check. (Perhaps just a copy of the classification app with your attempted changes)', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""I'll check out the classification app in the next few days and report back."", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67748"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67748"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

	pod 'TensorFlowLiteSwift'   # or 'TensorFlowLiteObjC' 	pod 'TensorFlowLiteSelectTfOps', '~> 0.0.1-nightly'

### Custom code

Yes

### OS platform and distribution

iOS 16.2

### Mobile device

iOS

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Podfile:

	pod 'TensorFlowLiteSwift'   # or 'TensorFlowLiteObjC'
	pod 'TensorFlowLiteSelectTfOps', '~> 0.0.1-nightly'


After fixing the '-force_load' issue, I now see this compiller error:

> Inferred submodules require a module with an umbrella

<img width=""408"" alt=""Screenshot 2024-05-16 at 9 34 32 AM"" src=""https://github.com/tensorflow/tensorflow/assets/98909739/9bd549e3-8de2-481c-bc15-e7fa0233751a"">


### Standalone code to reproduce the issue

```shell
Use the podfile as indicated above.

Disable user script sandboxing

Fix the force_update script bug

In a Swift file, have these two imports:

import TensorFlowLite
import TensorFlowLiteSelectTfOps


Try to build.

See the error on the ""import TensorFlowLiteSelectTfOps"" line

> Inferred submodules require a module with an umbrella
```


### Relevant log output

_No response_"
2301087654,67758,Need Help with a Softmax Warning in TensorFlow 2.16,closed,2024-05-16 18:35:33+00:00,2024-06-18T01:51:36Z,2024-06-18T01:51:31Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/67758,"['stat:awaiting response', 'type:bug', 'stale', 'subtype:windows', 'TF 2.16']","[""I am experiencing the same issue when implementing my own transformer encoder decoder. So far, i am still missing positional encoding and some masking layers, i don't know whether those would affect it in any way. \r\n\r\nHere is my code, showing the same warning with tf-nightly, and python 3.11.9\r\n\r\n\r\n    import keras\r\n    import numpy as np\r\n    \r\n    def possitionalEmbedding(input_dim, output_dim):  # TODO\r\n        return keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim)\r\n    \r\n    def model_func(encoder_vocab_len, decoder_vocab_len, encoder_maxlen, decoder_maxlen, params):\r\n        num_heads, key_dim, d_v, d_ff, d_model, n = params\r\n    \r\n        encoder_input = keras.Input(shape=(None,))\r\n        decoder_input = keras.Input(shape=(None,))\r\n    \r\n        # encoder part\r\n        embedded = possitionalEmbedding(encoder_vocab_len, d_model)(encoder_input) # todo possitional embedding\r\n        embedded = keras.layers.Dropout(0.1)(embedded)\r\n    \r\n        encoded = embedded\r\n        for i in range(n):\r\n            attended_encoded = keras.layers.MultiHeadAttention(num_heads,\r\n                                            key_dim,\r\n                                            dropout=0.1,\r\n                                            use_bias=True,\r\n                                            output_shape=(d_model,))(encoded, encoded, encoded)  # todo padding_mask\r\n            attended_encoded_d = keras.layers.Dropout(0.1)(attended_encoded)\r\n            add = encoded + attended_encoded_d\r\n            normalised = keras.layers.LayerNormalization()(add)\r\n            fed_f = keras.layers.Dense(d_ff)(normalised)  # feed forward 1 part\r\n            fed_ff = keras.layers.Dense(d_model)(keras.activations.relu(fed_f))  # feed forward 2 part\r\n            fed_ff_d = keras.layers.Dropout(0.1)(fed_ff)\r\n    \r\n            add2 = normalised + fed_ff_d\r\n            normalised2 = keras.layers.LayerNormalization()(add2)\r\n    \r\n            encoded = normalised2  # and the loop is repeated\r\n    \r\n        encoder_output = encoded  # output from encoder\r\n    \r\n        # decoder part\r\n        de_embed = possitionalEmbedding(decoder_vocab_len, d_model)(decoder_input)\r\n        de_embed = keras.layers.Dropout(0.1)(de_embed)\r\n    \r\n        for i in range(n):\r\n            self_attention = (keras.layers.MultiHeadAttention(num_heads,\r\n                                            key_dim,\r\n                                            dropout=0.1,\r\n                                            use_bias=True,\r\n                                            output_shape=(d_model,))\r\n                                (de_embed, de_embed, de_embed))\r\n            self_attention_d = keras.layers.Dropout(0.1)(self_attention)\r\n            add = de_embed + self_attention_d\r\n            normalised1 = keras.layers.LayerNormalization()(add)\r\n            cross_attention = (keras.layers.MultiHeadAttention(num_heads,\r\n                                            key_dim,\r\n                                            dropout=0.1,\r\n                                            use_bias=True,\r\n                                            output_shape=(d_model,))\r\n                               (normalised1, encoder_output,encoder_output))\r\n            cross_attention_d = keras.layers.Dropout(0.1)(cross_attention)\r\n    \r\n            add2 = normalised1 + cross_attention_d\r\n            normalised2 = keras.layers.LayerNormalization()(add2)\r\n    \r\n            fed_f = keras.layers.Dense(d_ff)(normalised2)  # feed forward 1 part\r\n            fed_ff = keras.layers.Dense(d_model)(keras.activations.relu(fed_f))  # feed forward 2 part\r\n            fed_ff_d = keras.layers.Dropout(0.1)(fed_ff)\r\n    \r\n            add3 = normalised2 + fed_ff_d\r\n            normalised3 = keras.layers.LayerNormalization()(add3)\r\n    \r\n            de_embed = normalised3\r\n    \r\n        decoder_dense_output = keras.layers.Dense(decoder_vocab_len, activation='softmax', name='decoder_output')(de_embed)\r\n    \r\n        return keras.Model(inputs=[encoder_input, decoder_input], outputs=decoder_dense_output)\r\n    \r\n    if __name__ == '__main__':\r\n        params = (8, 64, 64, 256, 512, 6)\r\n        model = model_func(10000, 10000, 100, 100, params)\r\n        model.summary()\r\n    \r\n        # Generate random input data with appropriate shapes\r\n        encoder_input_data = np.random.randint(0, 10000, (2, 1))  # (batch_size, sequence_length)\r\n        decoder_input_data = np.random.randint(0, 10000, (2, 4))  # (batch_size, sequence_length)\r\n    \r\n        # Call the model with the random input data\r\n        output = model.call([encoder_input_data, decoder_input_data], training=False)\r\n    \r\n        # Print the shape of the output\r\n        print(f'Output shape: {output.shape}')\r\n\r\nUserWarning: You are using a softmax over axis 3 of a tensor of shape (2, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\r\n  warnings.warn(\r\nUserWarning: You are using a softmax over axis 3 of a tensor of shape (2, 8, 4, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\r\n  warnings.warn(\r\n  \r\nOutput shape: (2, 4, 10000)\r\n\r\n"", 'Hi **@sp00N221** ,\r\n- Sorry for the delay, Can you please check with recent TF compatibility versions? I tried with TF2.16.1 and I cannot reproduce the error. \r\nPlease check the screenshot\r\n![test1](https://github.com/tensorflow/tensorflow/assets/147127861/8dcef0bb-8bd5-4b77-9920-b6871fb57dc2) here. Thanks!', ""Hey,\r\n\r\nThank you for taking the time to review my issue. I've had nothing but problems with my task over the past few days. I had a combination of a TransformerBlock and LSTM layers. Coupled with Optuna, it was probably just too many variables and possibilities, causing the model to become unstable. I have now switched to this task:\r\n\r\n\r\ndef objective(trial, features, target):\r\n    n_estimators = trial.suggest_int('n_estimators', 50, 300)\r\n    max_depth = trial.suggest_int('max_depth', 3, 15)\r\n    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\r\n    subsample = trial.suggest_float('subsample', 0.5, 1.0)\r\n    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\r\n    gamma = trial.suggest_float('gamma', 0, 5)\r\n    min_child_weight = trial.suggest_int('min_child_weight', 1, 10)\r\n    reg_lambda = trial.suggest_float('lambda', 1e-8, 10.0, log=True)\r\n    reg_alpha = trial.suggest_float('alpha', 1e-8, 10.0, log=True)\r\n\r\n    model = XGBClassifier(\r\n        n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate,\r\n        subsample=subsample, colsample_bytree=colsample_bytree, gamma=gamma,\r\n        min_child_weight=min_child_weight, reg_lambda=reg_lambda, reg_alpha=reg_alpha,\r\n        random_state=42\r\n    )\r\n\r\n    x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\r\n\r\n    numeric_features = x_train.columns\r\n    preprocessor = ColumnTransformer(\r\n        transformers=[\r\n            ('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')), ('scaler', StandardScaler())]),\r\n             numeric_features)\r\n        ])\r\n\r\n    x_train = preprocessor.fit_transform(x_train)\r\n    x_test = preprocessor.transform(x_test)\r\n\r\n    model.set_params(early_stopping_rounds=10, eval_metric='logloss')\r\n    model.fit(x_train, y_train, eval_set=[(x_test, y_test)], verbose=False)\r\n\r\n    predictions = model.predict(x_test)\r\n    accuracy = accuracy_score(y_test, predictions)\r\n\r\n    return accuracy\r\n    \r\n    \r\nWith this, I have no problems.\r\nHave a nice day!"", 'Hi **@sp00N221** ,\r\n- Could you please confirm if this issue is resolved for you? Please feel free to close the issue.\r\n\r\nThank you!\r\n', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67758"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67758"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.16.1

### Custom code

Yes

### OS platform and distribution

Windows 11

### Mobile device

_No response_

### Python version

3.12.3

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Hey everyone,
I'm running into a bit of a headache with TensorFlow 2.16 and could really use some help. I'm getting this annoying warning about a Softmax operation over an axis with size 1. This pops up when I'm using a custom TransformerBlock layer that includes MultiHeadAttention.

What I've Tried:
Debugging Dimensions:

Added print statements to check tensor shapes at different stages.
Used tf.squeeze to remove dimensions of size 1 before passing the tensor to MultiHeadAttention.

What I Need:
Is this a bug in TensorFlow 2.16? If yes, any workarounds or patches?
Best practices for handling tensor dimensions in MultiHeadAttention to avoid this?
Should I downgrade or wait for an update? If yes, which version should I try?

Additional Info:
Using LSTM and GRU layers followed by the custom TransformerBlock.
Running on Windows with Python 3.12.

Any help or pointers would be greatly appreciated! Thanks!

### Standalone code to reproduce the issue

```shell
class TransformerBlock(tf.keras.layers.Layer):
    def __init__(self, t_num_heads, t_key_dim, t_ff_dim, dropout_rate=0.1, activation_function='relu',
                 initializer='glorot_uniform', **kwargs):
        super(TransformerBlock, self).__init__(**kwargs)
        self.att = MultiHeadAttention(num_heads=t_num_heads, key_dim=t_key_dim)
        self.ffn = tf.keras.Sequential([
            Dense(t_ff_dim, activation=activation_function, kernel_initializer=initializer),
            Dense(t_key_dim, kernel_initializer=initializer),
        ])
        self.layernorm1 = LayerNormalization(epsilon=1e-6)
        self.layernorm2 = LayerNormalization(epsilon=1e-6)
        self.dropout1 = Dropout(dropout_rate)
        self.dropout2 = Dropout(dropout_rate)
        self.dense_proj = Dense(t_key_dim, kernel_initializer=initializer)

    def call(self, inputs, training=None, *args, **kwargs):
        inputs_proj = self.dense_proj(inputs)
        print(f""inputs_proj shape: {inputs_proj.shape}"")

        if len(inputs_proj.shape) == 4 and inputs_proj.shape[2] == 1:
            inputs_proj = tf.squeeze(inputs_proj, axis=2)
            print(f""inputs_proj after squeeze shape: {inputs_proj.shape}"")

        attn_output = self.att(inputs_proj, inputs_proj)
        print(f""attn_output shape: {attn_output.shape}"")
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs_proj + attn_output)
        ffn_output = self.ffn(out1)
        print(f""ffn_output shape: {ffn_output.shape}"")
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)

    def compute_output_shape(self, input_shape):
        return input_shape

    def get_config(self):
        config = super(TransformerBlock, self).get_config()
        config.update({
            't_num_heads': self.att.num_heads,
            't_key_dim': self.att.key_dim,
            't_ff_dim': self.ffn.layers[0].units,
            'dropout_rate': self.dropout1.rate,
            'activation_function': self.ffn.layers[0].activation.__name__,
            'initializer': self.ffn.layers[0].kernel_initializer.__class__.__name__
        })
        return config

    @classmethod
    def from_config(cls, config):
        return cls(**config)
```


### Relevant log output

```shell
UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?
```
"
2302348058,67829,tf.keras.layers.Dense leads to significant differences between CPU and GPU runs of the model implementation code,closed,2024-05-17 10:19:55+00:00,2024-06-22T01:49:23Z,2024-06-22T01:49:20Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/67829,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'TF2.14']","['Data from /Users/pinji/Desktop/MoCoDiff/tf-0513/tensorflow-LeNet/LeNet-12-654/case/tensorflow_cpu/output.npz:\r\nArray name: output\r\n[[-0.19694163, -0.09662387, -0.2447289 , ..., -0.03054091, -0.01255638,\r\n   0.11781679],\r\n [-0.09944421, -0.1292284 , -0.20278051, ..., -0.01450334,  0.1526829 ,\r\n   0.2054872 ],\r\n [ 0.07628068, -0.14517091, -0.16096437, ..., -0.21423727,  0.14428714,\r\n   0.09608107],\r\n ...,\r\n [-0.20587711, -0.10656235, -0.33036825, ..., -0.13541238,  0.3215404 ,\r\n   0.2165656 ],\r\n [-0.11513966, -0.1102111 , -0.3434586 , ..., -0.19525276,  0.08722814,\r\n  -0.05503507],\r\n [-0.09822497, -0.10671525, -0.2368006 , ..., -0.16467465,  0.15050802,\r\n   0.10809175]]\r\n\r\n========================================\r\nData from /Users/pinji/Desktop/MoCoDiff/tf-0513/tensorflow-LeNet/LeNet-12-654/case/tensorflow_gpu/output.npz:\r\nArray name: output\r\n[[-0.19693479, -0.09660047, -0.24478191, ..., -0.03068957, -0.01259471,\r\n   0.1177731 ],\r\n [-0.09948827, -0.12920822, -0.20286846, ..., -0.01475166,  0.15262538,\r\n   0.20549278],\r\n [ 0.07635015, -0.14510253, -0.16103148, ..., -0.21449052,  0.14431402,\r\n   0.09607705],\r\n ...,\r\n [-0.20597562, -0.1065662 , -0.33040133, ..., -0.13553414,  0.32143065,\r\n   0.2166584 ],\r\n [-0.1152329 , -0.11016633, -0.34351912, ..., -0.19536608,  0.08703801,\r\n  -0.05509032],\r\n [-0.09832728, -0.10680126, -0.2368007 , ..., -0.1649086 ,  0.1503351 ,\r\n   0.10806311]]\r\n\r\n========================================\r\n543 diff: 0.055949583649635315\r\ncpu-543: [-0.1139553  -0.04668004 -0.4390249   0.20775127  0.0899936   0.22854462\r\n -0.46038878 -0.15526699  0.23111053 -0.03327706]\r\ngpu-543: [-0.12328502 -0.0404007  -0.4342668   0.21254592  0.05579592  0.24491714\r\n -0.479826   -0.15429592  0.17516094 -0.05355967]\r\n', '@PhyllisJi,\r\nI tried to execute the mentioned code. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/72178a625ffc1c316d3f59475794c9e9/untitled1907.ipynb). In the given code snippet you have defined the class and its methods but are not calling them anywhere. Also try to execute the code with the keras3.0 which is default for the TensorFlow 2.16 and let us know if you are facing the same issue. Thank you!', '> @PhyllisJi, I tried to execute the mentioned code. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/72178a625ffc1c316d3f59475794c9e9/untitled1907.ipynb). In the given code snippet you have defined the class and its methods but are not calling them anywhere. Also try to execute the code with the keras3.0 which is default for the TensorFlow 2.16 and let us know if you are facing the same issue. Thank you!\r\n\r\nDue to the need for data support, I have put the reproduction code, data and steps in the repository, which you can reproduce by clone. https://github.com/PhyllisJi/MoCoDiff_Bug/tree/tf-issue%2367829', ""@PhyllisJi,\r\nAFAIK generally there shouldn't be much difference between CPU and GPU runs. And also the API **tf.keras.layers.dense** might not be the reason for the difference. The reason could be due to the optimized way of calculating numbers on Nvidia which is different compared to others, there will be a small amount of precision errors. Could you please try to check the same code with the keras3.0 and tensorflowv2.16 and let us know whether you are facing the same issue. Thank you!"", ""Ok，I will try today\n\n---- Replied Message ----\n| From | ***@***.***> |\n| Date | 06/05/2024 22:21 |\n| To | tensorflow/tensorflow ***@***.***> |\n| Cc | PinJi_NJU ***@***.***>,\nMention ***@***.***> |\n| Subject | Re: [tensorflow/tensorflow] tf.keras.layers.Dense leads to significant differences between CPU and GPU runs of the model implementation code (Issue #67829) |\n\n@PhyllisJi,\nAFAIK generally there shouldn't be much difference between CPU and GPU runs. And also the API tf.keras.layers.dense might not be the reason for the difference. The reason could be due to the optimized way of calculating numbers on Nvidia which is different compared to others, there will be a small amount of precision errors. Could you please try to check the same code with the keras3.0 and let us know whether you are facing the same issue. Thank you!\n\n—\nReply to this email directly, view it on GitHub, or unsubscribe.\nYou are receiving this because you were mentioned.Message ID: ***@***.***>"", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67829"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/67829"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

tf 2.14.0

### Custom code

Yes

### OS platform and distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.2

### GPU model and memory

_No response_

### Current behavior?

The difference in the output values of the entire neural network for forward propagation exceeds 0.05 when trained with CPU and GPU respectively. But the outputs are consistent before adding the line f**c3_output = tf.keras.layers.Dense(units=10, use_bias=True, name=""linear3_mutated"") ( relu4_output)**.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
import os


os.environ['CUDA_VISIBLE_DEVICES'] = ''

def Model_VlysjQxB81qtaIXsA_VkCXmPGmE7aDNP(input):
    input = tf.keras.Input(shape=input)
    _zeropadding_input = tf.keras.layers.ZeroPadding2D(padding=((0, 0), (0, 0)))(input)
    conv1_output = tf.keras.layers.Conv2DTranspose(filters=6, kernel_size=(5, 5), strides=(1, 1), padding=""valid"", output_padding=(0, 0), data_format=""channels_last"", dilation_rate=(1, 1), use_bias=True, name=""conv1_mutated"")(input)
    relu1_output = tf.nn.relu(conv1_output)
    _zeropadding_relu1_output = tf.keras.layers.ZeroPadding2D(padding=((0, 0), (0, 0)))(relu1_output)
    maxpool1_output = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=""valid"", data_format=""channels_last"", name=""pool1"")(_zeropadding_relu1_output)
    _zeropadding_maxpool1_output = tf.keras.layers.ZeroPadding2D(padding=((0, 0), (0, 0)))(maxpool1_output)
    conv2_output = tf.keras.layers.Conv2D(filters=16, kernel_size=(6, 8), strides=(1, 1), padding=""valid"", data_format=""channels_last"", dilation_rate=(1, 1), groups=1, use_bias=True, name=""conv2_mutated"")(_zeropadding_maxpool1_output)
    relu2_output = tf.math.softsign(conv2_output)
    _zeropadding_relu2_output = tf.keras.layers.ZeroPadding2D(padding=((0, 0), (0, 0)))(relu2_output)
    maxpool2_output = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=""valid"", data_format=""channels_last"", name=""pool2"")(_zeropadding_relu2_output)
    output_transpose = [(0), (0, 1), (0, 2, 1), (0, 3, 1, 2), (0, 4, 1, 2, 3)]
    maxpool2_output = tf.transpose(maxpool2_output, list(output_transpose[(len(maxpool2_output.shape) - 1)]))
    flatten_output = tf.keras.layers.Flatten(data_format=""channels_last"", name=""flatten"")(maxpool2_output)
    fc1_output = tf.keras.layers.Dense(units=120, use_bias=True, name=""linear1"")(flatten_output)
    relu3_output = tf.keras.layers.ThresholdedReLU(theta=0.1, name=""relu3_mutated"")(fc1_output)
    fc2_output = tf.keras.layers.Dense(units=84, use_bias=True, name=""linear2_mutated"")(relu3_output)
    relu4_output = tf.math.erf(fc2_output)
    fc3_output = tf.keras.layers.Dense(units=10, use_bias=True, name=""linear3_mutated"")(relu4_output)
    output_transpose = [(0), (0, 1), (0, 2, 1), (0, 3, 1, 2), (0, 4, 1, 2, 3)]
    fc3_output = tf.transpose(fc3_output, list(output_transpose[(len(fc3_output.shape) - 1)]))
    tail_flatten_output = tf.keras.layers.Flatten(data_format=""channels_last"", name=""tail_flatten"")(fc3_output)
    tail_fc_output = tf.keras.layers.Dense(units=10, use_bias=True, name=""tail_fc"")(tail_flatten_output)

    tail_fc_output = tail_fc_output
    model = tf.keras.models.Model(inputs=input, outputs=tail_fc_output)
    return model


def go():
    with tf.device('/CPU:0'):
        try:
            shape = [1, 1, 28, 28]
            _numpy = np.random.random(shape).astype(np.float32)
            tf_input = tf.convert_to_tensor(_numpy.transpose(0, 2, 3, 1), dtype=tf.float32)
            tf_model = Model_VlysjQxB81qtaIXsA_VkCXmPGmE7aDNP(tf_input.shape[1:])
            tf_output = tf_model(tf_input)
            flag = True
        except Exception:
            flag = False
        return flag


def initialize(model):
    module_dir = os.path.dirname(__file__)
    gradient_transpose = [(0,), (1, 0), (2, 1, 0), (2, 3, 1, 0), (2, 3, 4, 1, 0)]
    for layer in model.layers:
        matrix_path = module_dir + '/../initializer/' + layer.name
        if hasattr(layer, 'kernel_initializer'):
            weight_init_path = matrix_path + '/weight.npz'
            weight_init = np.load(weight_init_path)
            weight_init = weight_init['matrix']
            tf_weight = tf.convert_to_tensor(weight_init, dtype=tf.float32)
            tf_weight = tf.transpose(tf_weight, gradient_transpose[len(tf_weight.shape) - 1])
            layer.kernel.assign(tf.keras.initializers.Constant(tf_weight)(layer.kernel.shape))
        if hasattr(layer, 'bias_initializer') and layer.use_bias:
            bias_init_path = matrix_path + '/bias.npz'
            bias_init = np.load(bias_init_path)
            bias_init = bias_init['matrix']
            tf_bias = tf.convert_to_tensor(bias_init, dtype=tf.float32)
            tf_bias = tf.transpose(tf_bias, gradient_transpose[len(tf_bias.shape) - 1])
            layer.bias.assign(tf.keras.initializers.Constant(tf_bias)(layer.bias.shape))

def train(inp, label):
    with tf.device('/CPU:0'):
        shape = inp.shape
        tf_input = tf.convert_to_tensor(inp.transpose(0, 2, 3, 1), dtype=tf.float32)
        tf_model = Model_VlysjQxB81qtaIXsA_VkCXmPGmE7aDNP(tf_input.shape[1:])

        initialize(tf_model)
        tf_output = tf_model(tf_input)
        output_transpose = [(0), (0, 1), (0, 2, 1), (0, 3, 1, 2), (0, 4, 1, 2, 3)]
        tf_output_trans = tf.transpose(tf_output, list(output_transpose[(len(tf_output.shape) - 1)])).numpy()

        tf_targets = tf.convert_to_tensor(label)
        with tf.GradientTape() as tape:
            tf_predictions = tf_model(tf_input)
            tf_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)(tf_targets, tf_predictions)
        tf_gradients = tape.gradient(tf_loss, tf_model.trainable_variables)
        tf_gradients_dic = {}
        for var, gradient in zip(tf_model.trainable_variables, tf_gradients):
            gradient_transpose = [(0, ), (1, 0), (2, 0, 1), (3, 2, 0, 1), (4, 3, 0, 1, 2)]
            tf_gradient = tf.transpose(gradient, list(gradient_transpose[len(gradient.shape) - 1])).numpy()
            tf_gradients_dic.setdefault(var.name.replace('/', '.')[:-2], tf_gradient)
        return tf_gradients_dic, float(tf_loss.numpy()), tf_output_trans
```


### Relevant log output

_No response_"
2303787048,68194,DeprecationWarning from google.protobuf,closed,2024-05-18 01:59:24+00:00,2024-08-08T09:14:06Z,2024-05-27T15:40:10Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/68194,"['stat:awaiting response', 'type:bug', 'comp:apis', 'TF 2.16']","['@lazarust Could you consider explicitly upgrading protobuf. You can find compatible versions on the official protobuf website [here](https://grpc.io/docs/protoc-installation/).  Kindly refer to [this](https://github.com/protocolbuffers/protobuf/issues/15077) issue as well for more information.\r\nThank you!', ""Thanks for the response @sushreebarsa. I tried upgrading `protobuf` by running `pip install -U protobuf` and still get the same deprecation warning with protobuf 5.26.1. \r\n\r\nIs there something else I should do/could try? \r\n\r\nIt also looks like tensorflow requires a version of `protobuf` that's < 5.0.0. Is 5.0 + support something that could be updated?"", ""@lazarust The error you're encountering is related to a deprecation warning in protobuf and its incompatibility with TensorFlow in your current environment. Kindly ensure you're upgrading protobuf and TensorFlow within the same virtual environment you're using for your project. This avoids conflicts with other projects that might have different dependency requirements. Another workaround could be downgrading protobuf to a version below 5.0.0 which is not ideal.\r\nTensorFlow is yet to fully support protobuf versions above 5.0.\r\n\r\nThank you!  "", ""@sushreebarsa I've verified that I'm using tensorflow `2.16.1` and protobuf `4.25.3` (this is the newest protobuf supported by tensorflow from what I can tell). I'm still running into the DeprecationWarnings.\r\n\r\nIf it's not an easy fix since tensorflow doesn't support protobuf 5.0+, we can ignore those warnings for now. Unless you have a better idea?"", 'Hi, @lazarust ! Ignoring the warnings might seem like a quick solution. If downgrading protobuf or upgrading TensorFlow is not feasible, you can suppress the warnings. \r\n```\r\nimport warnings\r\nwarnings.filterwarnings(""ignore"", message="".*DeprecationWarning.*"")\r\n\r\n\r\n```\r\n\r\nPlease find the doc [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py) which has the supported protobuf versions mentioned in it.  Kindly stay updated with TF [releases](https://github.com/tensorflow/tensorflow/releases). \r\n\r\nThank you!', ""@sushreebarsa We've decided to just suppress the warnings for now until TensorFlow supports the new version of protobuf. Should I close this issue? "", '@lazarust Sure, you could move this issue to close status for now and stay updated for new [releases](https://github.com/tensorflow/tensorflow/releases). Thank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68194"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68194"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16.1

### Custom code

Yes

### OS platform and distribution

MacOS 14.4.1

### Mobile device

_No response_

### Python version

3.12.2

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When running a `pytest` that import tensorflow, I get the following DeprecrecationWarnings:

- `Type google._upb._message.MessageMapContainer uses PyType_Spec with a metaclass that has custom tp_new. This is deprecated and will no longer be allowed in Python 3.14`
- `Type google._upb._message.ScalarMapContainer uses PyType_Spec with a metaclass that has custom tp_new. This is deprecated and will no longer be allowed in Python 3.14`



### Standalone code to reproduce the issue

```shell
Since this happens specifically in a `pytest` and not when importing tensorflow via the shell I'm unsure how to replicate this, but I've attached the traceback.
```


### Relevant log output

```shell
import tensorflow as tf
../../../.virtualenvs/skops/lib/python3.12/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
../../../.virtualenvs/skops/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
../../../.virtualenvs/skops/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
../../../.virtualenvs/skops/lib/python3.12/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
../../../.virtualenvs/skops/lib/python3.12/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
../../../.virtualenvs/skops/lib/python3.12/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
../../../.virtualenvs/skops/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:33: in <module>
    from tensorflow.core.framework import attr_value_pb2
../../../.virtualenvs/skops/lib/python3.12/site-packages/tensorflow/core/framework/attr_value_pb2.py:5: in <module>
    from google.protobuf.internal import builder as _builder
../../../.virtualenvs/skops/lib/python3.12/site-packages/google/protobuf/internal/builder.py:18: in <module>
    from google.protobuf.internal import python_message
../../../.virtualenvs/skops/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:36: in <module>
    from google.protobuf import descriptor as descriptor_mod
../../../.virtualenvs/skops/lib/python3.12/site-packages/google/protobuf/descriptor.py:17: in <module>
    from google.protobuf.internal import api_implementation
../../../.virtualenvs/skops/lib/python3.12/site-packages/google/protobuf/internal/api_implementation.py:51: in <module>
    if _CanImport('google._upb._message'):
../../../.virtualenvs/skops/lib/python3.12/site-packages/google/protobuf/internal/api_implementation.py:41: in _CanImport
    mod = importlib.import_module(mod_name)
../../../.pyenv/versions/3.12.2/lib/python3.12/importlib/__init__.py:90: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
E   SystemError: <class 'DeprecationWarning'> returned a result with an exception set
_______________________________________________________________________________________________________________________________________ ERROR collecting skops/io/tests/test_visualize.py ________________________________________________________________________________________________________________________________________
DeprecationWarning: Type google._upb._message.MessageMapContainer uses PyType_Spec with a metaclass that has custom tp_new. This is deprecated and will no longer be allowed in Python 3.14.```
```
"
2304027145,68210,TPU v3-8 CrossReplicaSum_33 Error,closed,2024-05-18 11:04:38+00:00,2024-05-30T23:54:10Z,2024-05-30T19:27:22Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/68210,"['type:bug', 'comp:tpus', 'TF 2.15']","[""What's even more weirder is that I'm defining the input sizes explicitly like so:\r\n\r\n```py\r\nConfig.COMPUTED_BATCH_SIZE = 128\r\n\r\nwith strategy.scope():\r\n    model = my_model()\r\n    input_shapes = [\r\n        [Config.COMPUTED_BATCH_SIZE, 192], \r\n        [Config.COMPUTED_BATCH_SIZE, 192], \r\n        [COMPUTED_CHANNELS, 105, 129, 100], \r\n        [COMPUTED_CHANNELS, 105, 129, 100], \r\n        [COMPUTED_CHANNELS, 105, 129, 100], \r\n        [Config.COMPUTED_BATCH_SIZE, 70], \r\n        [Config.COMPUTED_BATCH_SIZE, 320]\r\n    ]\r\n    model.build(input_shape=input_shapes)\r\n```\r\n\r\n~But the batch size shown in the error log is 256 in [70, 256] which I assume is the transposed tensor.~\r\n\r\nIgnore this since it appears that Hidden Size * 2 is also 256. So it could be a transpose inside a Dense layer.\r\n\r\nEdit:\r\n\r\nI've tracked it down to this code:\r\n\r\n```py\r\nhidden_size = 128\r\nself.descriptor_embedding = layers.Dense(\r\n    hidden_size * 2, # 256\r\n    activation='relu',\r\n    input_shape=(Config.COMPUTED_BATCH_SIZE, 70)\r\n)\r\n\r\n\r\nlearned_descriptors = tf.expand_dims(\r\n    self.descriptor_embedding(descriptors),\r\n    1\r\n) # [BS, 1, HS * 2]\r\n```"", 'It seems to be an issue with `tf.expand_dims(x, axis=1)`. Any axis other than 0 will cause this error. `tf.transpose` also causes this error. ', '@vivekjoshy,\r\nWhen I tried to execute the code by explicitly setting the size after you decode, using tf.reshape, the code was executed successfully. While with the other approach it was executed with the error. \r\n\r\n```python\r\ntf.reshape(tf.image.decode_jpeg(image, channels = 3),[256,256, 3]), class_idx\r\n\r\n```\r\n\r\nKindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/115211b9a4bbadbb30533d3eea1b773d/untitled1908.ipynb).\r\n\r\n', 'Fixed by passing in explicit shapes everywhere.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68210"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68210"">No</a>\n']","### Issue type

Support

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.15.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I'm getting this error when I run model.fit

```txt
tensorflow/core/tpu/kernels/tpu_compilation_cache_external.cc:112] Asked to propagate a dynamic dimension from hlo transpose.3750@{}@0 to hlo %all-reduce.3755 = f32[<=70,256]{1,0} all-reduce(f32[<=70,256]{1,0} %transpose.3750), replica_groups={{0,1,2,3,4,5,6,7}}, to_apply=%sum.3751, metadata={op_type=""CrossReplicaSum"" op_name=""CrossReplicaSum_33"" source_file=""dummy_file_name"" source_line=10}, which is not implemented.

1013 tpu_program_group.cc:90] Check failed: xla_tpu_programs.size() > 0 (0 vs. 0) 
```

I have a very large code base, and am unable to reproduce. I was using AUC metric, but removed it as seen here https://github.com/tensorflow/tensorflow/issues/33890. The issue still persists. 

Another relevant issue is https://github.com/tensorflow/tensorflow/issues/41590.

I have attached an MVCE example to reproduce, but it's still not enough to know that explicit shapes are needed as explained in #41590 since I don't know where I'm using transpose. I need a stack trace to point to where in the code it's causing the issue.

### Standalone code to reproduce the issue

```shell
https://colab.research.google.com/drive/1bYuuwG0pFnIQe1X6jA7FJMLjZtvAmqlj?usp=sharing
```


### Relevant log output

_No response_"
2306878729,68290,tensorflow[and-cuda] 2.15.0/2.15.1 compatibility with jax[cuda12],closed,2024-05-20 22:07:01+00:00,2024-06-15T01:49:58Z,2024-06-15T01:49:54Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/68290,"['stat:awaiting response', 'type:bug', 'stale', 'TF 2.15']","[""@attaluris  TensorFlow[and-cuda] 2.15.0/2.15.1 is likely not compatible with jax[cuda12]. There's a version mismatch with respect to the NVIDIA NCCL library, a component needed for GPU support in both TensorFlow and JAX.\r\nTensorFlow 2.15.0/2.15.1 might depend on an older NCCL version (e.g., nvidia-nccl-cu12 version 2.16.5).\r\nFor any further queries please raise an issue in [Jax](https://github.com/google/jax/issues) repository.\r\n\r\nThank you!"", '@sushreebarsa Is there a way we could loosen the strict requirement in tensorflow from `=2.16.5` to `>2.16.5`?\r\n\r\nI also raised an issue in the Jax repo', ""@attaluris Could you try to update tensorflow to 2.16.1 and jax to 0.4.28?\r\nTF 2.16.1 uses  nvidia-nccl-cu12==2.19.3 (from tensorflow[and-cuda]) which is compatible with JAX's requirement of >=2.18.3.\r\n\r\nThank you!\r\n"", ""@sushreebarsa thanks for the detail! 👀 \r\nI'm seeing the same issue as https://github.com/tensorflow/tensorflow/issues/63362 with tensorflow 2.16.1 so I'm using 2.15.1\r\ncan I get a confirmation that the tensorflow 2.16.1 installation will be fixed and maybe a timeline? thanks in advance!"", '@attaluris On ubuntu 20.04LTS machine with Tesla P100 GPU, we tried to install JAX 0.4.28 cuda version first and then installed tensorflow 2.15.1. Both were installed successfully. JAX and tf were able to detect GPUs as well. Please have a look at the below screenshot for reference.\r\n<img width=""1505"" alt=""image (4)"" src=""https://github.com/tensorflow/tensorflow/assets/84765720/99770c0e-e604-4b24-bd15-e7277214aab4"">\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68290"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68290"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.15.0/2.15.1

### Custom code

Yes

### OS platform and distribution

Debian Bulleye

### Mobile device

_No response_

### Python version

3.9/3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.2

### GPU model and memory

v100

### Current behavior?

Hey y'all! I think `tensorflow[and-cuda]` is incompatible with `jax[cuda12]` and just wanted to clarify if this was expected.
The solve error I'm getting is:
```
Because tensorflow[and-cuda] (2.15.0) depends on nvidia-nccl-cu12 (2.16.5)
 and jax[cuda12] (0.4.23) depends on nvidia-nccl-cu12 (>=2.18.3), tensorflow[and-cuda] (2.15.0) is incompatible with jax[cuda12] (0.4.23).
So, because hex-packages depends on both jax[cuda12] (0.4.23) and tensorflow[and-cuda] (2.15.0), version solving failed.
```
and none of the `jax[cuda12]` versions with GPU compatibility support `nvidia-nccl-cu12=2.16.5`; does this requirement need to be hard or can it be looser to accomodate higher versions of `nvidia-nccl-cu12`?

### Standalone code to reproduce the issue

```shell
[tool.poetry]
name = ""test-jax-and-poetry""
version = ""0.1.0""
description = """"
authors = [""Tim Nonet <tnonet@hex.tech>""]
readme = ""README.md""

[tool.poetry.dependencies]
python = "">=3.9,<3.11""
tensorflow = { ""version"" = ""2.15.1"", extras = [""and-cuda""] }
jax = {""version"" = ""*"", extras = [""cuda12""] }


[build-system]
requires = [""poetry-core""]
build-backend = ""poetry.core.masonry.api""
```


### Relevant log output

```shell
Because tensorflow[and-cuda] (2.15.0) depends on nvidia-nccl-cu12 (2.16.5)
 and jax[cuda12] (0.4.23) depends on nvidia-nccl-cu12 (>=2.18.3), tensorflow[and-cuda] (2.15.0) is incompatible with jax[cuda12] (0.4.23).
So, because hex-packages depends on both jax[cuda12] (0.4.23) and tensorflow[and-cuda] (2.15.0), version solving failed.
```

whenever I use a version of `jax` that has the `cuda12` extra
```
"
2307175944,68308,Fail to run person_detect.tflite via TFLite benchmark_model,closed,2024-05-21 03:13:13+00:00,2024-10-08T07:58:17Z,2024-10-08T07:58:13Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/68308,"['stat:awaiting response', 'type:bug', 'comp:lite', 'comp:micro']","['hi @bhbruce ,\r\n\r\nI will benchmark the model and will get back to you.', ""hi @bhbruce ,\r\n\r\nI replicated the issue and i got the same error. So its probably a bug in the model's metadata .  I will raise a PR to get it fixed. Thank you "", 'Hi @sawantkumar \r\nAppreciate for confirming it. If you have a PR to fix it, please share it with me. \r\nThanks.\r\n', 'Hi @bhbruce ,\r\n\r\nCan you please post your issue at https://github.com/tensorflow/tflite-micro/issues for a quicker resolution. ', ""Hi @sawantkumar \r\nI've added an issue https://github.com/tensorflow/tflite-micro/issues/2680.\r\n"", ""Hi, @bhbruce\r\n\r\nI apologize for the delayed response, I was able to run the tests on a development machine for [Person detection example](https://github.com/tensorflow/tflite-micro/tree/main/tensorflow/lite/micro/examples/person_detection) successfully for your reference I've added output log below and the quantization axis of 3 is correct for DEPTHWISE_CONV and the person detection model in the TFLM repo works as expected passing all continuous integration tests. Please refer this [official documentation](https://github.com/tensorflow/tflite-micro/tree/main/tensorflow/lite/micro/examples/person_detection#run-the-tests-on-a-development-machine)\r\n\r\n\r\n```\r\ntensorflow/lite/micro/tools/make/test_latency_log.sh person_detection_test  gen/linux_x86_64_default_gcc/bin/person_detection_test '~~~ALL TESTS PASSED~~~' linux\r\nTesting TestInvoke\r\nperson data.  person score: 113, no person score: -113\r\n\r\nno person data.  person score: -57, no person score: 57\r\n\r\nRan successfully\r\n\r\n1/1 tests passed\r\n~~~ALL TESTS PASSED~~~\r\n\r\nRunning person_detection_test took 0.122 seconds\r\n```\r\n\r\nIf I have missed something here please let me know.\r\n\r\nThank you for your cooperation and patience."", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""Hi @gaikwadrahul8 \r\nThank you for trying with TFLM. I can understand that it's available for TFLM.\r\nHowever, it cannot run on TFL. Is it reasonable?"", 'Hi, @bhbruce\r\n\r\nI apologize for the delayed response, as far I know TFLM is designed for a very different target platform (microcontrollers) and therefore has specific optimizations that may not translate directly to the standard TensorFlow Lite runtime. Trying to run a TFLM model on the standard TensorFlow Lite interpreter might expose issues with metadata, operator support or quantization that are specific to TFLM.\r\n\r\nIf you need the model to run on standard TensorFlow Lite you might need to re-convert the model from TensorFlow with settings appropriate for TensorFlow Lite which compatible with mobile or edge devices rather than microcontrollers. You can use different Model optimization techniques\r\n\r\nTensorFlow Lite currently supports optimization via quantization, pruning and clustering.\r\n\r\nThese are part of the [TensorFlow Model Optimization Toolkit](https://www.tensorflow.org/model_optimization), which provides resources for model optimization techniques that are compatible with TensorFlow Lite. Please refer this [official documentation](https://ai.google.dev/edge/litert/models/model_optimization)\r\n\r\nIf I have missed something here please let me know. \r\n\r\nThank you for your cooperation and patience.\r\n', 'Hi @gaikwadrahul8 \r\nThank you for your explanation. ', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68308"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68308"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

97a794b0199b6e507e3f577861856ff09357a3cd

### Current behavior?

There is a TFLite model called `person_detect.tflite` in tflite-micro https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/models/person_detect.tflite.
I cannot run this model via tensorflow's benchmark_model. 
It looks like all depthwise_convolutions' quantization_dim meta-data are wrong.


### Command to reproduce the issue

```shell
`tools/benchmark/benchmark_model  --num_runs=3 --enable_op_profiling=true --num_threads=2 --graph=person_detect.tflite`
```


### Relevant log output

```shell
### Error Log 

INFO: STARTING!
INFO: Log parameter values verbosely: [0]
INFO: Min num runs: [3]
INFO: Num threads: [2]
INFO: Graph: [person_detect.tflite]
INFO: Signature to run: []
INFO: Enable op profiling: [1]
INFO: #threads used for CPU inference: [2]
INFO: Loaded model person_detect.tflite
ERROR: quantized_dimension must be in range [0, 1). Was 3.
ERROR: Tensor 33 has invalid quantization parameters.
ERROR: quantized_dimension must be in range [0, 1). Was 3.
ERROR: Tensor 36 has invalid quantization parameters.
ERROR: quantized_dimension must be in range [0, 1). Was 3.
ERROR: Tensor 40 has invalid quantization parameters.
ERROR: quantized_dimension must be in range [0, 1). Was 3.
ERROR: Tensor 44 has invalid quantization parameters.
ERROR: quantized_dimension must be in range [0, 1). Was 3.
ERROR: Tensor 48 has invalid quantization parameters.
ERROR: quantized_dimension must be in range [0, 1). Was 3.
ERROR: Tensor 52 has invalid quantization parameters.
ERROR: quantized_dimension must be in range [0, 1). Was 3.
ERROR: Tensor 56 has invalid quantization parameters.
ERROR: quantized_dimension must be in range [0, 1). Was 3.
ERROR: Tensor 60 has invalid quantization parameters.
ERROR: quantized_dimension must be in range [0, 1). Was 3.
ERROR: Tensor 64 has invalid quantization parameters.
ERROR: quantized_dimension must be in range [0, 1). Was 3.
ERROR: Tensor 68 has invalid quantization parameters.
ERROR: quantized_dimension must be in range [0, 1). Was 3.
ERROR: Tensor 72 has invalid quantization parameters.
ERROR: quantized_dimension must be in range [0, 1). Was 3.
ERROR: Tensor 76 has invalid quantization parameters.
ERROR: quantized_dimension must be in range [0, 1). Was 3.
ERROR: Tensor 80 has invalid quantization parameters.
ERROR: quantized_dimension must be in range [0, 1). Was 3.
ERROR: Tensor 84 has invalid quantization parameters.
ERROR: Failed to initialize the interpreter
ERROR: Benchmarking failed.
```


"
2310088535,68420,Tensorflow Docker Instructions,closed,2024-05-22 09:52:28+00:00,2024-08-22T01:55:41Z,2024-08-22T01:55:37Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/68420,"['type:docs-bug', 'stat:awaiting response', 'type:bug', 'stale', 'TF 2.16']","['Hi **@gcelano** ,\r\n- This issue belongs to NVIDIA. Please post this issue on NVIDIA repo.\r\n\r\nThank you!', '@Venkat6871 , in the Tensorflow instructions [1], one requirement is installing NVIDIA Docker support [2], but this is wrong, because that software has been deprecated in January 2024 and superseded by NVIDIA Container Toolkit [3]: therefore, no reference should appear in current Tensorflow instructions.\r\n\r\nI have been able to run Docker images recently just installing NVIDIA container Toolkit, but probably you guys should run a few tests.\r\n\r\n---\r\n[1] https://www.tensorflow.org/install/docker\r\n[2] https://github.com/NVIDIA/nvidia-docker?tab=readme-ov-file\r\n[3] https://github.com/NVIDIA/nvidia-container-toolkit', 'Hi **@gcelano** ,\r\n- Would you mind submitting a Pull Request to update the TensorFlow installation instructions with the information about NVIDIA Container Toolkit?\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68420"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68420"">No</a>\n']","### Issue type

Documentation Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.16

### Custom code

No

### OS platform and distribution

Debian 12 Bookworm

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Installation instructions for Tensorflow Docker  [1] refer to Invidia Docker, which however has been archived on January 22 2024. The page needs to be updated.

---
[1] https://www.tensorflow.org/install/docker

### Standalone code to reproduce the issue

```shell
No code required
```


### Relevant log output

_No response_"
2311534266,68474,RuntimeError when invoking TFLite INT8 model with tile operation,closed,2024-05-22 11:53:06+00:00,2024-05-30T06:18:01Z,2024-05-30T06:17:58Z,sawantkumar,,https://github.com/tensorflow/tensorflow/issues/68474,"['type:bug', 'comp:lite']","['Hi @ShabbirMarfatiya ,\r\n\r\nThanks for filing an issue, Could you please file a bug in the [TensorFlow](https://github.com/tensorflow/tensorflow/issues) where you can get the issue resolution faster.It is not related to the Model Garden models.\r\n\r\nThanks.', ""Hi @laxmareddyp,\r\n\r\nThanks for the reply. I have filed a bug at the TensorFlow repo but haven't received a resolution yet."", 'Hi @ShabbirMarfatiya ,\r\n\r\nThere is already an issue with the same bug, so I am closing this one since its a duplicate. Please track [this](https://github.com/tensorflow/tensorflow/issues/67789) for reference .', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68474"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68474"">No</a>\n']","I'm facing an issue while trying to run inference with a TensorFlow Lite model quantized to INT8 precision. The model was trained using CenterNet MobileNet for hand keypoint detection, and I'm getting a `RuntimeError` when invoking the interpreter, with the following error message:

```
Cell In[6], line 34
     31 # Note that CenterNet doesn't require any pre-processing except resizing to the
     32 # input size that the TensorFlow Lite Interpreter was generated with.
     33 input_tensor = tf.image.resize(input_tensor, (224, 224))
---> 34 (boxes, classes, scores, num_detections, kpts, kpts_scores) = detect(interpreter, input_tensor,include_keypoint=True)
     35 print(""kpts:"",scores[0])
     36 print(""kpts_scores:"",kpts[0][0]*image_numpy.shape[1])

Cell In[5], line 40
     38 print(input_tensor.dtype)
     39 interpreter.set_tensor(input_details[0]['index'], input_tensor)
---> 40 interpreter.invoke()
     42 scores = interpreter.get_tensor(output_details[3]['index'])
     43 boxes = interpreter.get_tensor(output_details[2]['index'])

File ~/.local/lib/python3.8/site-packages/tensorflow/lite/python/interpreter.py:923, in Interpreter.invoke(self)
    911 """"""Invoke the interpreter.
    912 
    913 Be sure to set the input sizes, allocate tensors and fill values before
   (...)
    920   ValueError: When the underlying interpreter fails raise ValueError.
    921 """"""
    922 self._ensure_safe()
--> 923 self._interpreter.Invoke()

RuntimeError: Type 'INT8' is not supported by tile.Node number 198 (TILE) failed to invoke.
```

Environment:
- TensorFlow version: 2.7.0
- TensorFlow GPU version: 2.7.0
- Python version: 3.8.10
- Operating System: Ubuntu 20.04

Steps to Reproduce:
1. Train a CenterNet MobileNet model for hand keypoint detection
2. Convert the trained model to TensorFlow Lite INT8 precision using the following code:
```
import tensorflow as tf

def parse_tfrecord_fn(example):
    feature_description = {
        'image/encoded': tf.io.FixedLenFeature([], tf.string),
        # Add other features here if necessary
    }
    example = tf.io.parse_single_example(example, feature_description)
    image = tf.io.decode_jpeg(example['image/encoded'], channels=3)
    image = tf.image.resize(image, [224, 224])  # Adjust size as necessary
    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0,1] if required
    return image

def load_tfrecord_dataset(tfrecord_path, batch_size=1):
    raw_dataset = tf.data.TFRecordDataset(tfrecord_path)
    dataset = raw_dataset.map(parse_tfrecord_fn)
    dataset = dataset.batch(batch_size)
    return dataset


def representative_dataset(tfrecord_path, num_samples):
    dataset = load_tfrecord_dataset(tfrecord_path)
    for data in dataset.take(num_samples):
        yield [data]


# Load the TensorFlow SavedModel
saved_model_dir = 'model_weights/tflite/saved_model'
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)

# Set optimization to default for INT8 conversion
converter.optimizations = [tf.lite.Optimize.DEFAULT]

# Set the representative dataset
tfrecord_path = '/home/ai_server/Shabbir/Hand_Keypoint_Detection/data/coco_testdev.record-00001-of-00050'
num_samples = 100  # Adjust the number of samples as needed
converter.representative_dataset = lambda: representative_dataset(tfrecord_path, num_samples)

# Ensure that input and output tensors are quantized
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.allow_custom_ops = True
converter.inference_input_type = tf.uint8  # or tf.int8
converter.inference_output_type = tf.uint8  # or tf.int8

# Convert the model
tflite_quant_model = converter.convert()

# Save the quantized model
with open('centernet_int8_03.tflite', 'wb') as f:
    f.write(tflite_quant_model)
```

3. Run inference with the converted INT8 model using the following code:

```
import tensorflow as tf

from object_detection.utils import label_map_util
from object_detection.utils import config_util
from object_detection.utils import visualization_utils as viz_utils
from object_detection.utils import config_util
from object_detection.builders import model_builder

%matplotlib inline

# Print the image we are going to test on as a sanity check.

def load_image_into_numpy_array(path):
  """"""Load an image from file into a numpy array.

  Puts image into numpy array to feed into tensorflow graph.
  Note that by convention we put it into a numpy array with shape
  (height, width, channels), where channels=3 for RGB.

  Args:
    path: a file path.

  Returns:
    uint8 numpy array with shape (img_height, img_width, 3)
  """"""
  img_data = tf.io.gfile.GFile(path, 'rb').read()
  image = Image.open(BytesIO(img_data))
  (im_width, im_height) = image.size
  return np.array(image.getdata()).reshape(
      (im_height, im_width, 3)).astype(np.uint8)

from tensorflow.python.ops.numpy_ops import np_config
np_config.enable_numpy_behavior()

def detect(interpreter, input_tensor, include_keypoint=False):
  """"""Run detection on an input image.

  Args:
    interpreter: tf.lite.Interpreter
    input_tensor: A [1, height, width, 3] Tensor of type tf.float32.
      Note that height and width can be anything since the image will be
      immediately resized according to the needs of the model within this
      function.
    include_keypoint: True if model supports keypoints output. See
      https://cocodataset.org/#keypoints-2020

  Returns:
    A sequence containing the following output tensors:
      boxes: a numpy array of shape [N, 4]
      classes: a numpy array of shape [N]. Note that class indices are 
        1-based, and match the keys in the label map.
      scores: a numpy array of shape [N] or None.  If scores=None, then
        this function assumes that the boxes to be plotted are groundtruth
        boxes and plot all boxes as black with no classes or scores.
      category_index: a dict containing category dictionaries (each holding
        category index `id` and category name `name`) keyed by category 
        indices.
    If include_keypoints is True, the following are also returned:
      keypoints: (optional) a numpy array of shape [N, 17, 2] representing
        the yx-coordinates of the detection 17 COCO human keypoints
        (https://cocodataset.org/#keypoints-2020) in normalized image frame
        (i.e. [0.0, 1.0]). 
      keypoint_scores: (optional) a numpy array of shape [N, 17] representing the
        keypoint prediction confidence scores.
  """"""
  input_details = interpreter.get_input_details()
  output_details = interpreter.get_output_details()
  input_tensor = (input_tensor*255).astype(np.uint8)
  print(input_tensor.dtype)
  interpreter.set_tensor(input_details[0]['index'], input_tensor)
  interpreter.invoke()

  scores = interpreter.get_tensor(output_details[3]['index'])
  boxes = interpreter.get_tensor(output_details[2]['index'])
  num_detections = interpreter.get_tensor(output_details[5]['index'])
  classes = interpreter.get_tensor(output_details[0]['index'])

  if include_keypoint:
    kpts_scores = interpreter.get_tensor(output_details[4]['index'])
    kpts = interpreter.get_tensor(output_details[1]['index'])
    return boxes, classes, scores, num_detections, kpts, kpts_scores
  else:
    return boxes, classes, scores, num_detections

# Utility for visualizing results
def plot_detections(image_np,
                    boxes,
                    classes,
                    scores,
                    category_index,
                    keypoints=None,
                    keypoint_scores=None,
                    figsize=(12, 16),
                    image_name=None):
  """"""Wrapper function to visualize detections.

  Args:
    image_np: uint8 numpy array with shape (img_height, img_width, 3)
    boxes: a numpy array of shape [N, 4]
    classes: a numpy array of shape [N]. Note that class indices are 1-based,
      and match the keys in the label map.
    scores: a numpy array of shape [N] or None.  If scores=None, then
      this function assumes that the boxes to be plotted are groundtruth
      boxes and plot all boxes as black with no classes or scores.
    category_index: a dict containing category dictionaries (each holding
      category index `id` and category name `name`) keyed by category indices.
    keypoints: (optional) a numpy array of shape [N, 17, 2] representing the 
      yx-coordinates of the detection 17 COCO human keypoints
      (https://cocodataset.org/#keypoints-2020) in normalized image frame
      (i.e. [0.0, 1.0]). 
    keypoint_scores: (optional) anumpy array of shape [N, 17] representing the
      keypoint prediction confidence scores.
    figsize: size for the figure.
    image_name: a name for the image file.
  """"""

  keypoint_edges = [(0, 1), (1, 2), (0, 3), (3, 4), (0, 5), (5, 6), (0, 7), (7, 8), (0, 9), (9, 10)]
  image_np_with_annotations = image_np.copy()
  # Only visualize objects that get a score > 0.3.
  viz_utils.visualize_boxes_and_labels_on_image_array(
      image_np_with_annotations,
      boxes,
      classes,
      scores,
      category_index,
      keypoints=keypoints,
      keypoint_scores=keypoint_scores,
      keypoint_edges=keypoint_edges,
      use_normalized_coordinates=True,
      min_score_thresh=0.2)
  if image_name:
    plt.imsave(image_name, image_np_with_annotations)
  else:
    return image_np_with_annotations
```

```
# Load the TFLite model and allocate tensors.
# model_path = ""workspace/tflite/model_6_May.tflite""
model_path = ""/home/ai_server/Shabbir/DISIGN/model_weights/centernet_int8_03.tflite""
label_map_path = '/home/ai_server/Shabbir/DISIGN/model_weights/label_map.pbtxt'
image_path = '/home/ai_server/Shabbir/Hand_Keypoint_Detection/test/806.jpg'
# image_path = '/home/shabbirmarfatiya/Shabbir/Project/ML_Tasks/Hand_Gesture_Recognition/Hand_Keypoint_Detection/FreiHAND_Dataset/test/'+str(dir_list[15])

# Initialize TensorFlow Lite Interpreter.object_detection.utils import label_map_util
interpreter = tf.lite.Interpreter(model_path=model_path)
interpreter.allocate_tensors()

# Label map can be used to figure out what class ID maps to what
# label. `label_map.txt` is human-readable.
# category_index = {1: {'id': 1, 'name': 'person'}}
category_index = label_map_util.create_category_index_from_labelmap(
    label_map_path)

# print(category_index)

label_id_offset = 1

image = tf.io.read_file(image_path)
image = tf.compat.v1.image.decode_jpeg(image)
image = tf.expand_dims(image, axis=0)
image_numpy = image.numpy()
print(image_numpy.shape)

input_tensor = tf.convert_to_tensor(image_numpy, dtype=tf.uint8)
# Note that CenterNet doesn't require any pre-processing except resizing to the
# input size that the TensorFlow Lite Interpreter was generated with.
input_tensor = tf.image.resize(input_tensor, (224, 224))
(boxes, classes, scores, num_detections, kpts, kpts_scores) = detect(interpreter, input_tensor,include_keypoint=True)
print(""kpts:"",scores[0])
print(""kpts_scores:"",kpts[0][0]*image_numpy.shape[1])
print(""Boxes:"", boxes)
print(""classes:"", classes)
print(""num_detections:"", num_detections)
# print(""kpts_scores:"",kpts[0][0])
vis_image = plot_detections(
    image_numpy[0],
    boxes[0],
    classes[0].astype(np.uint32) + label_id_offset,
    scores[0],
    category_index,
    keypoints=kpts[0],
    keypoint_scores=kpts_scores[0])

plt.figure(figsize = (15, 10))
plt.imshow(vis_image)
```

Expected Behavior:
The TensorFlow Lite INT8 model should run inference successfully without any errors.

Actual Behavior:
The RuntimeError is raised when invoking the interpreter, indicating that the tile operation is not supported in INT8 precision.

Additional Information:
I've followed the recommended steps for INT8 quantization, including setting the optimization flags, providing a representative dataset, and setting the target specs for INT8 operations. However, the issue persists.

@srjoglekar246 @PINTO0309 @NobuoTsukamoto @aeozyalcin @mpa74, Could you please assist me in resolving this issue? I would greatly appreciate any guidance or suggestions."
2311487915,68470,Android Tflite model fails to load on GPU Delegate: CL_OUT_OF_HOST_MEMORY,closed,2024-05-22 21:10:26+00:00,2024-07-25T09:04:35Z,2024-07-09T01:52:41Z,sawantkumar,,https://github.com/tensorflow/tensorflow/issues/68470,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'type:performance', 'TFLiteGpuDelegate', 'Android', 'TF 2.16']","['Hi @filip-halt ,\r\n\r\nCan you please provide the tflite model file so that i can replicate the issue?', '> Hi @filip-halt ,\r\n> \r\n> Can you please provide the tflite model file so that i can replicate the issue?\r\n\r\nYou can find a copy here: https://github.com/filip-halt/tflite_bug It was too large to upload directly into this chat.', ""Turns out that this is most likely due to a conv2dtranspose layer in the model.  I was under the impression that [conv2dtranpose](https://github.com/tensorflow/tensorflow/blob/43ce5b4267d89b9e7f96821495ce4f6bdc7aa1e6/tensorflow/lite/delegates/gpu/gl/kernels/transpose_conv.cc#L39) was supported but I could be wrong. \r\n\r\n\r\nAnother interesting thing that happens is that when you convert the model with:\r\n\r\n```python\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_types = [tf.float16]\r\n```\r\n\r\nthe resulting binary is 2x as large as float32 and 20% slower on mobile. When I inspected the graph with Netron, it looks like nothing was converted to float16, not even the conv2d's"", 'Hi  @filip-halt ,\r\n\r\nI ran your model using GPU delegate on dimensity 9000 and it ran fine without giving any issues.  Can you please try it out with a different device and let me know if it worked there. However the list of supported operators for tflite is [here](https://www.tensorflow.org/lite/performance/gpu) and TRANSPOSE_CONV is listed there.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', 'I believe that this is a grouped TRANSPOSE_CONV conversion problem. Tensorflow seems to barely support this and is what is breaking when converting onnx to tf. The default conversion creates a large amount of layers that ultimately cause an OOM on the phone when loading. \r\n\r\n<img width=""1403"" alt=""image"" src=""https://github.com/tensorflow/tensorflow/assets/81822489/5c93b64a-b188-4fa3-9ea8-8c01abdf073a"">\r\n', 'Hi @filip-halt  , we\'re wondering if you may be able to resolve your issue by using [AI-Edge-Torch](https://github.com/google-ai-edge/ai-edge-torch), you can find more information here: [googleblog](https://developers.googleblog.com/en/ai-edge-torch-high-performance-inference-of-pytorch-models-on-mobile-devices/).\r\n\r\nI have actually created a simple script for converting a mobilenet model here:\r\n\r\n```py\r\nimport torch\r\nimport torchvision\r\nimport ai_edge_torch\r\n\r\nmobilenet_model = torchvision.models.mobilenet_v3_small()\r\nsample_inputs = (torch.randn(1, 3, 224, 224),)\r\n\r\nedge_model = ai_edge_torch.convert(mobilenet_model.eval(), sample_inputs)\r\nedge_model.export(""mobilenet_v3_small.tflite"")\r\n```\r\nIf you want to, you can actually try visualizing the result in [model-explorer](https://github.com/google-ai-edge/model-explorer) as well.\r\n\r\nPlease try them out and let us know if this resolves your issue. If you still need further help, feel free to open a new issue at the respective repo.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68470"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68470"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

org.tensorflow:tensorflow-lite:2.16.1

### Custom code

Yes

### OS platform and distribution

Android

### Mobile device

Samsung S23

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Currently trying to get a larger model to load on an S23 but I am running into OOM errors. When initializing an Interpreter using a GPUDelegate with factory options grabbed from CompatibilityList.getBestOptionsForThisDevice(), the Interpreter crashes with `Failed to apply delegate: Failed to build program executable - Out of host memoryError: Program not built!`.  This seems to pop up from an OpenCL error that is parsed with: https://github.com/tensorflow/tensorflow/blob/dd5c42638ac3c19c7facffb4c3cdadd2524cc6a5/tensorflow/lite/delegates/gpu/cl/util.cc#L42

My best guess is that this is due to hitting the Dalvik-heap memory limit of 512mb found on my device with Runtime.maxMemory(). I profiled the memory usage and it seems to crash around the 450mb  mark. Does Tflite on android not use native memory to get around this? I seem to recall people getting 1gb+ models running on their devices. I guess this could possibly be a build step that is going over the limits, but once built it would be offloaded to native?

Note: I am using pyjnius to do this which might be causing problems, but I feel like that isn't the cause. 

### Standalone code to reproduce the issue

```shell
Not sure how useful.
```


### Relevant log output

```shell
05-22 16:31:08.869 23806 23859 I python  :  jnius.jnius.JavaException: JVM exception occurred: Internal error: Failed to apply delegate: Failed to build program executable - Out of host memoryError: Program not built!
05-22 16:31:08.869 23806 23859 I python  :  Falling back to OpenGL
05-22 16:31:08.869 23806 23859 I python  :  TfLiteGpuDelegate Init: No shader implementation for transpose
05-22 16:31:08.869 23806 23859 I python  :  TfLiteGpuDelegate Prepare: delegate is not initialized
05-22 16:31:08.869 23806 23859 I python  :  Node number 2612 (TfLiteGpuDelegateV2) failed to prepare.
```
"
2312405550,68505,output_padding argument in Conv1DTranspose,closed,2024-05-23 09:21:38+00:00,2024-06-24T12:48:40Z,2024-06-21T01:49:56Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/68505,"['stat:awaiting response', 'type:bug', 'stale', 'comp:apis', 'TF 2.16']","[""@olive380 If you don't require any padding for the output, simply omit the output_padding argument altogether. The default behavior in TensorFlow 2.16 for Conv1DTranspose is to not add any padding, which aligns with your case of using output_padding=0. Also please refer to the Keras [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1DTranspose) for the Conv1DTranspose layer specifically. This might provide additional details and examples regarding the output_padding argument.\r\n\r\nThank you!"", '@sushreebarsa Thank you for the answer, but your proposal does not solve the issue since the behavior of TensorFlow is totally different if output_padding is omitted or set to zero in all versions of the code up to 2.15. If you are not aware of this, please have a look at the deconv_output_length method defined in /tensorflow/python/keras/utils/conv_utils.py available [here](https://github.com/tensorflow/tensorflow/blob/43fcba8aeb627182afea8c5655f55d0557ab53dd/tensorflow/python/keras/utils/conv_utils.py#L4). So, please fix the bug in version 2.16 to allow set output_padding=0 in Conv1DTraspose and Conv2DTranspose.\r\n\r\nThank you !', '@olive380,\r\nThank you for the issue. By default Tensorflow v2.16.1 contains keras3.0 version which might be the issue, as you mentioned this feature is available in Tensorflow v2.15 which contains tf-keras. If the same feature needs to be implemented in the keras3.0, could you please raise the request in [keras-team/Keras](https://github.com/keras-team/keras/issues) repo for the quick response. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68505"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68505"">No</a>\n', 'Thanks, an issue was opened for Keras 3.0 [here](https://github.com/keras-team/keras/issues/19909)']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf2.16.1

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 20.04 LTS

### Mobile device

_No response_

### Python version

3.9.16

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

With TF2.16, it is no more possible to set output_padding=0 when using Conv1DTranspose.
This feature is still needed and was allowed in previous versions of TF (e..g TF2.15).


### Standalone code to reproduce the issue

```shell
To reproduce the bug, please use the following python script : 
[models.zip](https://github.com/tensorflow/tensorflow/files/15414612/models.zip)
```


### Relevant log output

```shell
File ""tf2.16/lib/python3.9/site-packages/keras/src/layers/convolutional/conv1d_transpose.py"", line 113, in __init__
    super().__init__(
  File ""tf2.16/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv_transpose.py"", line 111, in __init__
    self.output_padding = standardize_tuple(
  File ""tf2.16/lib/python3.9/site-packages/keras/src/utils/argument_validation.py"", line 51, in standardize_tuple
    raise ValueError(error_msg)
ValueError: The `output_padding` argument must be a tuple of 1 integers. Received output_padding=0, including values {0} that do not satisfy `value > 0`
```
"
2314672081,68585,I was using tf lite and trying to get the examples but cant,closed,2024-05-24 07:47:39+00:00,2024-05-27T15:35:53Z,2024-05-27T15:35:49Z,sawantkumar,,https://github.com/tensorflow/tensorflow/issues/68585,['type:bug'],"['Hi @nikechase3 ,\r\n\r\nCan you provide the code for detect.py or can you provide the link for the same , also can you tell me what is setup.sh about ?', 'it is on the tensorflow lite example repository, i tried yesterday, and it worked but i fear that next time the same thing will happen again', 'hi @nikechase3 ,\r\n\r\nCan you please retry one more time in a different python enviornment and let me know .', 'i ve tried again and the results are unreliable between just opening the window on display without any output or just lagging', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68585"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68585"">No</a>\n', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68585"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68585"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.11

### Custom code

No

### OS platform and distribution

_No response_

### Mobile device

Linux raspberrypi 6.1.21-v7

### Python version

3.7.3

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

-

### GPU model and memory

_No response_

### Current behavior?

ive tried using the setup `sh setup.sh` but it will revert my opencv version to 4.5.x and wont detect it which in turn result in an import error. so i use an opencv with version 4.6.x and it shows the code under. 

### Standalone code to reproduce the issue

```shell
python3 detect.py   --model efficientdet_lite0.tflite
```


### Relevant log output

```shell
python3 detect.py   --model efficientdet_lite0.tflite
Traceback (most recent call last):
  File ""detect.py"", line 150, in <module>
    main()
  File ""detect.py"", line 146, in main
    int(args.numThreads), bool(args.enableEdgeTPU))
  File ""detect.py"", line 63, in run
    detector = vision.ObjectDetector.create_from_options(options)
  File ""/home/haikalasa/tflitr/lib/python3.7/site-packages/tensorflow_lite_support/python/task/vision/object_detector.py"", line 88, in create_from_options
    options.base_options.to_pb2(), options.detection_options.to_pb2())
RuntimeError: Unable to open file at efficientdet_lite0.tflite
```
"
2317071033,68647,Aborted (core dumped) in `tf.fftnd/rfftnd`,closed,2024-05-25 14:57:53+00:00,2024-06-07T00:23:45Z,2024-06-07T00:23:43Z,SuryanarayanaY,,https://github.com/tensorflow/tensorflow/issues/68647,"['type:bug', 'comp:ops', 'TF 2.16']","['Hi @x0w3n ,\r\n\r\nI could able to reproduce the issue with tf-nightly. Attched screen shot below for reference.\r\n\r\n<img width=""1506"" alt=""Screenshot 2024-05-27 at 10 32 48\u202fAM"" src=""https://github.com/tensorflow/tensorflow/assets/116063290/3e53092b-18b4-4ecc-997d-4e5da17de204"">\r\n', 'I got it. Thank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68647"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68647"">No</a>\n', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68647"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68647"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.12.3

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When the fft_length and axes parameter of tf.fftnd/rfftnd is less than or equal to 0, it will trigger a crash, resulting in Check failed.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
input1 = tf.random.normal([10,10,10,10,10], dtype=tf.float32)
input2 = tf.random.normal([10,10,10,10,10], dtype=tf.float32)
input3 = tf.complex(input1,input2)

tf.rfftnd(input2,-3,-3)  # crash 
# tf.fftnd(input3,-3,-3) # crash
```


### Relevant log output

```shell
2024-05-25 09:56:35.992696: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-25 09:56:36.037881: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-25 09:56:36.642157: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-05-25 09:56:37.331878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7689 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:18:00.0, compute capability: 8.6
2024-05-25 09:56:37.332465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22453 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:af:00.0, compute capability: 8.6
2024-05-25 09:56:37.479752: F tensorflow/core/framework/tensor_shape.cc:45] Check failed: NDIMS == dims() (1 vs. 0)Asking for tensor of 1 dimensions from a tensor of 0 dimensions
Aborted (core dumped
```
"
2317074345,68648,Aborted (core dumped) in `tf.raw_ops.IRFFTND\RFFTND\FFTND\IFFTND`,closed,2024-05-25 15:06:15+00:00,2024-06-10T13:39:34Z,2024-06-10T13:38:30Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/68648,"['stat:awaiting response', 'type:bug', 'comp:ops', 'TF 2.16']","['@x0w3n,\r\nLooks like this is the issue [#67098](https://github.com/tensorflow/tensorflow/issues/67098) which is already addressed and assigned to the Developer. Could you please confirm and close this issue, since it is already being tracked there. Thank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68648"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68648"">No</a>\n', 'Thank you for your response.', '@x0w3n,\r\nAs mentioned please move this issue to the closed status, https://github.com/tensorflow/tensorflow/issues/68648#issuecomment-2135026372 since it is already being tracked there. Thank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68648"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68648"">No</a>\n', 'I noticed that. Thanks for reminding me.']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.12.3

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When the fft_length and axes parameter of tf.raw_ops.IRFFTND\RFFTND\FFTND\IFFTND than or equal to 0, it will trigger a crash, resulting in Check failed.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
input1 = tf.random.normal([10,10,10,10,10], dtype=tf.float32)
input2 = tf.random.normal([10,10,10,10,10], dtype=tf.float32)
input3 = tf.complex(input1,input2)

tf.raw_ops.IRFFTND(input=input3,fft_length=(1,1),axes=-1,Treal=tf.dtypes.float32)     #crash
# tf.raw_ops.RFFTND(input=input2,fft_length=(1,1),axes=-1,Tcomplex=tf.dtypes.complex64) #crash
# tf.raw_ops.FFTND(input = input3,fft_length=-3,axes=-3)   #crash
# tf.raw_ops.IFFTND(input = input3,fft_length=(1,1,1),axes=-1)  #crash
```


### Relevant log output

```shell
2024-05-25 10:04:17.096394: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-25 10:04:17.138470: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-25 10:04:17.732064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-05-25 10:04:18.435334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12867 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:18:00.0, compute capability: 8.6
2024-05-25 10:04:18.435959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22453 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:af:00.0, compute capability: 8.6
2024-05-25 10:04:18.650709: F tensorflow/core/framework/tensor_shape.cc:45] Check failed: NDIMS == dims() (1 vs. 0)Asking for tensor of 1 dimensions from a tensor of 0 dimensions
Aborted (core dumped)
```
"
2318837053,68690,     TypeError: len is not well defined for a symbolic Tensor (rnn_decoder_1/gru_1/Squeeze:0). Please call `x.shape` rather than `len(x)` for shape information.,closed,2024-05-27 10:38:01+00:00,2024-06-04T11:23:03Z,2024-06-04T11:22:59Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/68690,"['stat:awaiting response', 'type:bug', 'comp:keras', 'TF 2.15']","['@ViratCh04, \r\nLooks like this is an issue from the Keras side. Also there is an [issue](https://github.com/keras-team/keras/issues/19754) raised in the Keras-team/Keras repo for the similar error on the RNN_decoder/gru and assigned to the Developer. Kindly take a look and try to follow the same for the quick response. Thank you!', 'Oh alright @tilakrayal. Thanks for your response. I will try to contribute towards this issue there then!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68690"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68690"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.15

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I am trying to train my encoder-decoder(GRU) with attention mechanism but on calling the ```@tf.function()``` `trainStep()`, tf gives this error where it claims to be unable to measure a tensor's length using len and refers me to use tf.shape() instead. How can one do such changes in a package's code on a cloud compiler if there is no workaround for this?

Please let me know if I have to provide more resources to address this problem as this is my first raised issue on github

### Standalone code to reproduce the issue

```shell
https://www.kaggle.com/code/viratchauhan/image-captioner-with-visual-attention
```


### Relevant log output

```shell
TypeError                                 Traceback (most recent call last)
Cell In[41], line 9
      6 totalLoss = 0
      8 for(batch, (imgTensor, target)) in enumerate(dataset):
----> 9     batchLoss, tLoss = trainStep(imgTensor, target)
     10     totalLoss += tLoss
     12     if batch % 100 == 0:

File /opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:423, in RNN.call(self, sequences, initial_state, mask, training)
    420     output = last_output
    422 if self.return_state:
--> 423     if len(states) == 1:
    424         state = states[0]
    425         return output, state

TypeError: in user code:

    File ""/tmp/ipykernel_25/1943535969.py"", line 17, in trainStep  *
        predictions, hidden, _ = decoder(decoderInput, features, hidden)
    File ""/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py"", line 113, in error_handler  **
        return fn(*args, **kwargs)
    File ""/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/gru.py"", line 580, in call
        return super().call(
    File ""/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py"", line 423, in call
        if len(states) == 1:

    TypeError: len is not well defined for a symbolic Tensor (rnn_decoder_1/gru_1/Squeeze:0). Please call `x.shape` rather than `len(x)` for shape information.
```
"
2319018823,68696,Trouble Running TensorFlow v2.16.1 with NVIDIA GeForce 940MX GPU #914,closed,2024-05-27 12:15:16+00:00,2024-06-15T01:49:55Z,2024-06-15T01:49:51Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/68696,"['stat:awaiting response', 'type:bug', 'stale', 'comp:gpu', 'TF 2.16']","[""@KushanManahara If you're using TensorFlow v2.16.1, kindly ensure your CUDA and cuDNN versions are compatible. \r\nPlease refer to TensorFlow [documentation](https://www.tensorflow.org/install/pip) for supported versions for TensorFlow v2.16.1 and let us know?\r\nThank you!"", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68696"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68696"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

tf 2.16.1

### Custom code

Yes

### OS platform and distribution

Linux

### Mobile device

Linux

### Python version

3.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.4/V11.8.89

### GPU model and memory

_No response_

### Current behavior?

I attempted to run **TensorFlow version 2.16.1** on my local machine, which is equipped with an NVIDIA GeForce 940MX GPU. However, I encountered a kernel crash error while executing the following code in a Jupyter Notebook cell, 

This code snippet worked perfectly fine when I used **TensorFlow v2.4.1**, which I installed using Conda (`conda install anaconda::tensorflow-gpu==2.4.1`). However, after upgrading to TensorFlow v2.16.1 via Conda (`conda install anaconda::tensorflow-gpu==2.16.11`), the kernel crashed with the error message: 
_**""The Kernel crashed while executing code in the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure.""**_

**System Configuration:**

- CUDA Version: 12.4
- cuDNN Version: Not specified
- GPU: NVIDIA GeForce 940MX
- Driver Version: 550.54.14

**Issue is,**
- Verified that the code runs **successfully with TensorFlow v2.4.1**.
- Encountered a **kernel crash error** when running the code **with TensorFlow v2.16.1**.

Seeking guidance on how to resolve the kernel crash issue and successfully run TensorFlow v2.16.1 with my NVIDIA GeForce 940MX GPU. Any insights, troubleshooting steps, or workaround suggestions would be greatly appreciated.

Thank you for your assistance!

### Standalone code to reproduce the issue

```shell
model = keras.Sequential(
    [
        keras.layers.Flatten(input_shape=(28, 28)),
        keras.layers.Dense(100, activation=""relu""),
        keras.layers.Dense(10, activation=""sigmoid""),
    ]
)
```


### Relevant log output

```shell
16:43:31.562 [info] Generated code for 5 = <ipython-input-5-4e58535241f8> with 6 lines
16:43:32.012 [error] Disposing session as kernel process died ExitCode: undefined, Reason: 2024-05-27 16:43:14.979186: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-27 16:43:31.611060: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-05-27 16:43:31.678484: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-05-27 16:43:31.678870: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-05-27 16:43:31.679090: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 5.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2024-05-27 16:43:31.680484: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-05-27 16:43:31.680861: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-05-27 16:43:31.681155: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-05-27 16:43:31.681340: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 5.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2024-05-27 16:43:31.741853: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-05-27 16:43:31.742222: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-05-27 16:43:31.742465: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-05-27 16:43:31.742647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1169 MB memory:  -> device: 0, name: NVIDIA GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0

16:43:32.071 [info] Cell 4 completed in -1716808411.592s (start: 1716808411592, end: undefined)
16:43:38.622 [error] Failed to write data to the kernel channel shell [
  <Buffer 3c 49 44 53 7c 4d 53 47 3e>,
  <Buffer 64 34 30 65 66 35 36 34 32 62 65 33 61 61 63 36 30 32 62 32 61 65 33 32 30 36 62 30 36 36 34 36 61 33 39 38 32 61 62 32 31 32 39 39 64 34 62 33 38 37 ... 14 more bytes>,
  <Buffer 7b 22 64 61 74 65 22 3a 22 32 30 32 34 2d 30 35 2d 32 37 54 31 31 3a 31 33 3a 33 38 2e 36 32 31 5a 22 2c 22 6d 73 67 5f 69 64 22 3a 22 34 62 61 36 35 ... 177 more bytes>,
  <Buffer 7b 7d>,
  <Buffer 7b 7d>,
  <Buffer 7b 22 73 69 6c 65 6e 74 22 3a 66 61 6c 73 65 2c 22 73 74 6f 72 65 5f 68 69 73 74 6f 72 79 22 3a 66 61 6c 73 65 2c 22 75 73 65 72 5f 65 78 70 72 65 73 ... 12329 more bytes>
] Error: Socket is closed
    at a.postToSocket (/home/~/.vscode/extensions/ms-toolsai.jupyter-2024.4.0-linux-x64/dist/extension.node.js:318:10349)
    at /home/~/.vscode/extensions/ms-toolsai.jupyter-2024.4.0-linux-x64/dist/extension.node.js:318:10099 {
  errno: 9,
  code: 'EBADF'
}
```
"
2319265820,68702,There is no target called wheel,closed,2024-05-27 14:13:27+00:00,2024-09-06T01:58:10Z,2024-09-06T01:58:05Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/68702,"['stat:awaiting response', 'type:bug', 'type:build/install', 'stale', 'TF 2.16']","['Sure. So just update the website with the correct instructions I guess.', '> Sure. So just update the website with the correct instructions I guess.\r\n\r\nlol', '@Ichimikichiki,\r\nTo build a pip package, **you need to specify** **--repo_env=WHEEL_NAME** flag. depending on the provided name, package will be created.\r\n\r\n`bazel build //tensorflow/tools/pip_package:wheel --repo_env=WHEEL_NAME=tensorflow_cpu`\r\n\r\nAs a result, generated wheel will be located in\r\n\r\n`bazel-bin/tensorflow/tools/pip_package/wheel_house/`\r\n\r\nhttps://www.tensorflow.org/install/source#build_the_package', ""> @Ichimikichiki, To build a pip package, **you need to specify** **--repo_env=WHEEL_NAME** flag. depending on the provided name, package will be created.\r\n> \r\n> `bazel build //tensorflow/tools/pip_package:wheel --repo_env=WHEEL_NAME=tensorflow_cpu`\r\n> \r\n> As a result, generated wheel will be located in\r\n> \r\n> `bazel-bin/tensorflow/tools/pip_package/wheel_house/`\r\n> \r\n> https://www.tensorflow.org/install/source#build_the_package\r\n\r\nI follow official instruction and still got the error `no such target '//tensorflow/tools/pip_package:wheel': target 'wheel' not declared in package 'tensorflow/tools/pip_package'`\r\n\r\nI also do `bazel query //tensorflow/tools/pip_package:*` and I got following:\r\n```\r\n//tensorflow/tools/pip_package:BUILD\r\n//tensorflow/tools/pip_package:MANIFEST.in\r\n//tensorflow/tools/pip_package:README\r\n//tensorflow/tools/pip_package:THIRD_PARTY_NOTICES.txt\r\n//tensorflow/tools/pip_package:build_pip_package\r\n//tensorflow/tools/pip_package:build_pip_package.sh\r\n//tensorflow/tools/pip_package:included_headers\r\n//tensorflow/tools/pip_package:included_headers_gather\r\n//tensorflow/tools/pip_package:licenses\r\n//tensorflow/tools/pip_package:setup.py\r\n//tensorflow/tools/pip_package:simple_console\r\n//tensorflow/tools/pip_package:simple_console.py\r\n//tensorflow/tools/pip_package:xla_build/CMakeLists.txt\r\n//tensorflow/tools/pip_package:xla_cmake\r\n//tensorflow/tools/pip_package:xla_compiled_cpu_runtime_srcs.txt\r\n//tensorflow/tools/pip_package:xla_compiled_cpu_runtime_srcs.txt_file\r\n```\r\n\r\nNo wheel any idea?"", 'Thanks @tilakrayal I followed the instructions exactly as they are on the website.\r\n\r\nAlso I posted all the packages, and there isn\'t one called wheel. So your instructions are no different to the instructions I put in my original post.\r\n\r\n```bazel\r\nbazel query ""//tensorflow/tools/pip_package:*""\r\n//tensorflow/tools/pip_package:BUILD\r\n//tensorflow/tools/pip_package:MANIFEST.in\r\n//tensorflow/tools/pip_package:README\r\n//tensorflow/tools/pip_package:THIRD_PARTY_NOTICES.txt\r\n//tensorflow/tools/pip_package:build_pip_package\r\n//tensorflow/tools/pip_package:build_pip_package.sh\r\n//tensorflow/tools/pip_package:included_headers\r\n//tensorflow/tools/pip_package:included_headers_gather\r\n//tensorflow/tools/pip_package:licenses\r\n//tensorflow/tools/pip_package:setup.py\r\n//tensorflow/tools/pip_package:simple_console\r\n//tensorflow/tools/pip_package:simple_console.py\r\n//tensorflow/tools/pip_package:xla_build/CMakeLists.txt\r\n//tensorflow/tools/pip_package:xla_cmake\r\n//tensorflow/tools/pip_package:xla_compiled_cpu_runtime_srcs.txt\r\n//tensorflow/tools/pip_package:xla_compiled_cpu_runtime_srcs.txt_file\r\n```\r\nIf you\'re saying the website instructions are wrong, then that\'s the purpose of posting this issue to get you to update with the correct instructions.\r\n![Screenshot_2024-06-15_11-03-24](https://github.com/tensorflow/tensorflow/assets/40658431/8ffbd251-c3f2-425b-93de-db85e737191c)\r\n', ""I'm also facing the same issue. No wheel target found.\r\nWhen I built the first time in a Ubuntu 22.04 virtual machine in VirtualBox it worked nicely last week.\r\n\r\nHowever, when I did the same steps in Windows WSL with the same Ubuntu 22.04 it's not working. It always says:\r\n`ERROR: Skipping '//tensorflow/tools/pip_package:wheel': no such target '//tensorflow/tools/pip_package:wheel': target 'wheel' not declared in package 'tensorflow/tools/pip_package'`\r\n\r\nI already tried to install wheel with pip, but it's already installed, reinstalled pip, but nothing until now."", '@Ichimikichiki,\r\nCould you try to replace ""//tensorflow/tools/pip_package:wheel"" to ""//tensorflow/tools/pip_package:build_pip_package"" and try again if it working in this case. Thank you!', '@tilakrayal I built the TensorFlow yesterday successfully at night using the exact suggestion.\r\n\r\nThe difference is that the **whl** packing must be done in another step executing:\r\n`tensorflor/tools/pip_package/build_pip_package.sh --dst <destination_folder> --project_name <file_name_prefix>`\r\n\r\nAt this point, I realized that ""//tensorflow/tools/pip_package:wheel"" is just a convenience to build and packing all at once.', '> @tilakrayal I built the TensorFlow yesterday successfully at night using the exact suggestion.\r\n> \r\n> The difference is that the **whl** packing must be done in another step executing: `tensorflor/tools/pip_package/build_pip_package.sh --dst <destination_folder> --project_name <file_name_prefix>`\r\n> \r\n> At this point, I realized that ""//tensorflow/tools/pip_package:wheel"" is just a convenience to build and packing all at once.\r\n\r\nHello. I am facing the exact same problem, and just to make things clear: are you suggesting that we should run the command:\r\n**1.** `bazel build //tensorflow/tools/pip_package:build_pip_package`\r\n\r\nThen:\r\n**2.** `bazel build //tensorflor/tools/pip_package/build_pip_package.sh --dst <destination_folder> --project_name <file_name_prefix>` ?\r\n\r\n\r\nI am a bit confused since running the 1st command generated a `.whl` file in `/tensorflow/bazel-bin/tensorflow/tools/pip_package/wheel_house`. The name of the file is `tensorflow_cpu-2.18.0-cp311-cp311-linux_x86_64.whl` \r\n\r\nAlthough i am trying to build TF 2.13.0 in a Python 3.8 environment, the `.whl` file always has the same name as above with TF 2.18 and cp11 (CPython 11), what could be the source of this problem? I have already run `git checkout r2.13` to get the intended TF 2.13, but no matter what I do, it always generates `tensorflow_cpu-2.18.0-cp311-cp311-linux_x86_64.whl` ??!!', ""None of solution above work for me.\r\n\r\n`bazel build //tensorflow/tools/pip_package:wheel --repo_env=WHEEL_NAME=tensorflow_cpu`\r\ndoesn't work\r\n```\r\nERROR: Skipping '//tensorflow/tools/pip_package:wheel': no such target '//tensorflow/tools/pip_package:wheel': target 'wheel' not declared in package 'tensorflow/tools/pip_package'\r\n```\r\n\r\n`bazel build //tensorflor/tools/pip_package/build_pip_package.sh --dst <destination_folder> --project_name <file_name_prefix>`\r\ndoesn't work\r\n`ERROR: --dst :: Unrecognized option: --dst`\r\n\r\nThe only method work for me is\r\n`bazel build //tensorflow/tools/pip_package:build_pip_package --repo_env=WHEEL_NAME=tensorflow_cpu`\r\nto build package then to generate wheel file\r\n`./bazel-bin/tensorflow/tools/pip_package/build_pip_package ./tmp/tf_pkg`\r\nfinally a file `tensorflow-2.16.2-cp311-cp311-linux_x86_64.whl` is generated under directory `./tmp/tf_pkg`.\r\nIf I encounter a problem during file generation `command not found patchelf` then just `sudo apt install patchelf` and rerun last command again to solve it.\r\n\r\nI test it on Ubuntu 22.04 amd64(VirtualBox) for my tensorflow project and it run well without issue. \r\n\r\n\r\n\r\n\r\n"", ""> None of solution above work for me.\r\n> \r\n> `bazel build //tensorflow/tools/pip_package:wheel --repo_env=WHEEL_NAME=tensorflow_cpu` doesn't work\r\n> \r\n> ```\r\n> ERROR: Skipping '//tensorflow/tools/pip_package:wheel': no such target '//tensorflow/tools/pip_package:wheel': target 'wheel' not declared in package 'tensorflow/tools/pip_package'\r\n> ```\r\n> \r\n> `bazel build //tensorflor/tools/pip_package/build_pip_package.sh --dst <destination_folder> --project_name <file_name_prefix>` doesn't work `ERROR: --dst :: Unrecognized option: --dst`\r\n> \r\n> The only method work for me is `bazel build //tensorflow/tools/pip_package:build_pip_package --repo_env=WHEEL_NAME=tensorflow_cpu` to build package then to generate wheel file `./bazel-bin/tensorflow/tools/pip_package/build_pip_package ./tmp/tf_pkg` finally a file `tensorflow-2.16.2-cp311-cp311-linux_x86_64.whl` is generated under directory `./tmp/tf_pkg`. If I encounter a problem during file generation `command not found patchelf` then just `sudo apt install patchelf` and rerun last command again to solve it.\r\n> \r\n> I test it on Ubuntu 22.04 amd64(VirtualBox) for my tensorflow project and it run well without issue.\r\n\r\nThis worked for me exactly as described by @tomneo2004. Thanks."", '> > @tilakrayal I built the TensorFlow yesterday successfully at night using the exact suggestion.\r\n> > The difference is that the **whl** packing must be done in another step executing: `tensorflor/tools/pip_package/build_pip_package.sh --dst <destination_folder> --project_name <file_name_prefix>`\r\n> > At this point, I realized that ""//tensorflow/tools/pip_package:wheel"" is just a convenience to build and packing all at once.\r\n> \r\n> Hello. I am facing the exact same problem, and just to make things clear: are you suggesting that we should run the command: **1.** `bazel build //tensorflow/tools/pip_package:build_pip_package`\r\n> \r\n> Then: **2.** `bazel build //tensorflor/tools/pip_package/build_pip_package.sh --dst <destination_folder> --project_name <file_name_prefix>` ?\r\n> \r\n> I am a bit confused since running the 1st command generated a `.whl` file in `/tensorflow/bazel-bin/tensorflow/tools/pip_package/wheel_house`. The name of the file is `tensorflow_cpu-2.18.0-cp311-cp311-linux_x86_64.whl`\r\n> \r\n> Although i am trying to build TF 2.13.0 in a Python 3.8 environment, the `.whl` file always has the same name as above with TF 2.18 and cp11 (CPython 11), what could be the source of this problem? I have already run `git checkout r2.13` to get the intended TF 2.13, but no matter what I do, it always generates `tensorflow_cpu-2.18.0-cp311-cp311-linux_x86_64.whl` ??!!\r\n\r\nHave you found the solution for different python version? It seems that it automatically set python version to 3.11.', ""@tomneo2004 Assuming your environment has Python 3.8 (as an example), u have to specify the location of Python when you run the `./configure' script, as instructed here https://www.tensorflow.org/install/source#expandable-1. This should be done before building anything with bazel."", '@Ichimikichiki,\r\nAs mentioned please try to specify the python location in the ./configure and Could you try bazel clean --expunge followed by bazel sync.\r\n\r\nhttps://www.tensorflow.org/install/source#expandable-1\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68702"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68702"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

r2.16

### Custom code

No

### OS platform and distribution

Arch Linux

### Mobile device

_No response_

### Python version

3.10

### Bazel version

6.5.0

### GCC/compiler version

13.3.0

### CUDA/cuDNN version

9.1.1

### GPU model and memory

NVIDIA 4090

### Current behavior?

You say to
```
bazel build //tensorflow/tools/pip_package:wheel --repo_env=WHEEL_NAME=tensorflow 
```
But there isn't even a target called ""wheel""


### Standalone code to reproduce the issue

```shell
bazel query ""//tensorflow/tools/pip_package:*""
//tensorflow/tools/pip_package:BUILD
//tensorflow/tools/pip_package:MANIFEST.in
//tensorflow/tools/pip_package:README
//tensorflow/tools/pip_package:THIRD_PARTY_NOTICES.txt
//tensorflow/tools/pip_package:build_pip_package
//tensorflow/tools/pip_package:build_pip_package.sh
//tensorflow/tools/pip_package:included_headers
//tensorflow/tools/pip_package:included_headers_gather
//tensorflow/tools/pip_package:licenses
//tensorflow/tools/pip_package:setup.py
//tensorflow/tools/pip_package:simple_console
//tensorflow/tools/pip_package:simple_console.py
//tensorflow/tools/pip_package:xla_build/CMakeLists.txt
//tensorflow/tools/pip_package:xla_cmake
//tensorflow/tools/pip_package:xla_compiled_cpu_runtime_srcs.txt
//tensorflow/tools/pip_package:xla_compiled_cpu_runtime_srcs.txt_file
Loading: 1 packages loaded
```


### Relevant log output

```shell
ERROR: Skipping '//tensorflow/tools/pip_package:wheel': no such target '//tensorflow/tools/pip_package:wheel': target 'wheel' not declared in package 'tensorflow/tools/pip_package' defined by /fourth/github.com/tensorflow/tensorflow/tools/pip_package/BUILD (Tip: use `query ""//tensorflow/tools/pip_package:*""` to see all the targets in that package)

WARNING: Target pattern parsing failed.

ERROR: no such target '//tensorflow/tools/pip_package:wheel': target 'wheel' not declared in package 'tensorflow/tools/pip_package' defined by /fourth/github.com/tensorflow/tensorflow/tools/pip_package/BUILD (Tip: use `query ""//tensorflow/tools/pip_package:*""` to see all the targets in that package)
```
"
2319604976,68711,"""CUDA_ERROR_NOT_FOUND: named symbol not found"" in Docker container",closed,2024-05-27 18:13:29+00:00,2024-11-25T18:15:26Z,2024-05-28T15:57:05Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/68711,"['type:bug', 'TF 2.16']","['I have the same issue: #68710', ""Please make sure that you have installed the Nvidia container toolkit before. Your docker container is not able to find the relevant CUDA, hence the error. Here's the documention: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html"", ""I have tried that already and it did not make a difference. AFAIK it's only necessary when running Docker on a native Linux host. In my configuration with WSL2 it should already be covered by Docker Desktop.\nI have found this YouTube tutorial where it works without the container Toolkit too: https://youtu.be/YozfiLI1ogY."", ""**I'm getting the same issue, within the docker image  tensorflow/tensorflow:latest-gpu-jupyter (2.16.1) I am getting...\r\n\r\n# ./__nvcc_device_query\r\n./__nvcc_device_query failed to call cudaLoader::cuInit(0) with error 0x1f4 (CUDA_ERROR_NOT_FOUND)\r\n# ./nvcc --version \r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2023 NVIDIA Corporation\r\nBuilt on Wed_Nov_22_10:17:15_PST_2023\r\nCuda compilation tools, release 12.3, V12.3.107\r\nBuild cuda_12.3.r12.3/compiler.33567101_0\r\n# nvidia-smi\r\nTue May 28 10:03:54 2024       \r\n+-----------------------------------------------------------------------------------------+\r\n| NVIDIA-SMI 555.42.03              Driver Version: 555.85         CUDA Version: 12.5     |\r\n|-----------------------------------------+------------------------+----------------------+\r\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n|                                         |                        |               MIG M. |\r\n|=========================================+========================+======================|\r\n|   0  NVIDIA GeForce RTX 3070        On  |   00000000:02:00.0  On |                  N/A |\r\n|  0%   48C    P8             21W /  220W |     637MiB /   8192MiB |      0%      Default |\r\n|                                         |                        |                  N/A |\r\n+-----------------------------------------+------------------------+----------------------+\r\n                                                                                         \r\n+-----------------------------------------------------------------------------------------+\r\n| Processes:                                                                              |\r\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n|        ID   ID                                                               Usage      |\r\n|=========================================================================================|\r\n|  No running processes found                                                             |\r\n+-----------------------------------------------------------------------------------------+**"", ""I'm getting the same issue with tensorflow/tensorflow:2.13.0-gpu-jupyter ....\r\nE tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NOT_FOUND: named symbol not found"", 'I can install and run CUDA samples in WSL....(Ubuntu 22.04) by installing the CUDA tool kit 12.5\r\n\r\nDevice 0: ""NVIDIA GeForce RTX 3070"" with Compute 8.6 capability\r\nprintf() is called. Output:\r\n\r\n[2, 0]:         Value is:10\r\n[2, 1]:         Value is:10\r\n[2, 2]:         Value is:10\r\n[2, 3]:         Value is:10\r\n[2, 4]:         Value is:10\r\n[2, 5]:         Value is:10\r\n[2, 6]:         Value is:10\r\n[2, 7]:         Value is:10\r\n[3, 0]:         Value is:10', 'I have found a solution and shared it here: #68710 ', 'The workaround is working. Since this issue is pretty much a duplicate of the other one I will close it now. The other one should be left open until the latest drivers is working again.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68711"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68711"">No</a>\n', '\r\n\r\nNvidia 555.85 not working. Cuda 12.5 buggy\r\n\r\nUse 551.86 game ready driver and Cuda 12.4 with docker tensorflow/tensorflow:latest-gpu\r\n', '> Nvidia 555.85 not working. Cuda 12.5 buggy\r\n> \r\n> Use 551.86 game ready driver and Cuda 12.4 with docker tensorflow/tensorflow:latest-gpu\r\n\r\nthe solution you provided it worked for me even NVidia has stated that they have fixed this specific issue in thier nvidia driver download website but seems like its not solved yet, i was on latest version as 555.85 i downgraded it to 551.86 and everything worked fine thnak you. ', '> Nvidia 555.85 not working. Cuda 12.5 buggy\r\n> \r\n> Use 551.86 game ready driver and Cuda 12.4 with docker tensorflow/tensorflow:latest-gpu\r\n\r\nI\'ve been running v552.22 for some time now and I don\'t like being so out of date. Can you, @pyjsql or anyone else, give any more details? You say that CUDA v12.5 is buggy, but [the latest Nvidia driver v561.09 includes CUDA v12.6](https://us.download.nvidia.com/Windows/561.09/561.09-win11-win10-release-notes.pdf) and I still have this issue under that version. In fact, I just tested every Nvidia driver v552.22-v561.09, and v552.44 is the most recent that works. Are there users using Nvidia CUDA under WSL with v561.09 successfully? What\'s the causal factor here? Is it the age of the GPU hardware? The WSL kernel version? What\'s the right place to follow this issue and find out when it\'s safe to upgrade the Nvidia driver? I\'ve done a ton of googling and your ""Cuda 12.5 buggy"" is the most complete explanation I\'ve found. ;-)', ""Thanks for all of you guys !\r\nI've updated docker desktop on windows 10 and now it is working !""]","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.16.1-0-g5bc9d26649c

### Custom code

No

### OS platform and distribution

Windows 11 Pro + WSL2 Ubuntu 22.04

### Mobile device

_No response_

### Python version

3.11.0rc1

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

RTX 4080

### Current behavior?

I am using Docker Desktop with WSL2 on Windows 11 Pro to run the `tensorflow-gpu:latest` Docker container. After starting it no GPU is found and the error `failed call to cuInit: CUDA_ERROR_NOT_FOUND: named symbol not found` occurs. CUDA, cuDNN and Python versions are all dictated by the Docker image so I cannot change them.

Things I have tried without success:
- using a different container version (2.16.1, 2.15.0, 2.14.0, 2.13.0)
- reinstalling WSL2/Ubuntu
- reinstalling Docker Desktop
- reinstalling GPU drivers

Reinstalling the drivers is the only thing that had any effect at all. It changed the error from CUDA_ERROR_NO_DEVICE to CUDA_ERROR_NOT_FOUND.

I have found https://github.com/google/jax/issues/13570 with a similar error but it's fix doesn't apply here. RTX 4000 cards require CUDA >=11.8 which I am using.

### Standalone code to reproduce the issue

```shell
docker run --rm --gpus all -it tensorflow/tensorflow:latest-gpu bash
python3 -c ""import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))""
```


### Relevant log output

```shell
2024-05-27 18:05:30.149964: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-27 18:05:31.089452: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NOT_FOUND: named symbol not found
[]
```
"
2323112541,68797,[RNN] LSTM Model conversion error after upgrading to tf 2.16.1 from 2.15,closed,2024-05-29 11:44:02+00:00,2024-05-30T07:06:18Z,2024-05-30T07:06:16Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/68797,"['type:bug', 'comp:lite', 'TFLiteConverter', 'TF 2.16']","['@sonofisp,\r\nBy default the Tensorflow v2.16 contains the keras3.0 which might be the cause for the error. I suggest using the tf_keras 2.16 version for executing the code. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/f66a1510824cbab5199e3efe3992910e/untitled1922.ipynb). \r\n\r\nAlso add the below code for the execution.\r\n```python\r\n!pip install -U tf_keras # Keras 2\r\nimport os\r\nos.environ[""TF_USE_LEGACY_KERAS""] = ""1""\r\n```\r\n\r\nThank you!\r\n', 'That works! Thanks a lot!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68797"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68797"">No</a>\n']","### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10/Debian
- TensorFlow installation (pip package or built from source): pip package
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.16.1

### 2. Code

A minimum example that produced a tflite model when using tf 2.15.

```
import tensorflow as tf
import numpy as np

# generate random train data (32 samples, 1 time step, 10 features)
NUM_FEAT = 10
rand_train_data_x = np.array(np.random.randn(32, 1, NUM_FEAT), dtype=np.float32)
# generate targets of 3 classes
NUM_CLASSES = 3
rand_train_data_y = np.ones(32)
rand_train_data_y[0:11] = 0
rand_train_data_y[20:31] = 2
rand_train_data_y = np.array(tf.one_hot(rand_train_data_y, NUM_CLASSES)).reshape(
    -1, NUM_CLASSES
)
norm_layer = tf.keras.layers.Normalization(axis=-1)
norm_layer.adapt(rand_train_data_x)

x_train = norm_layer(rand_train_data_x)
y_train = tf.constant(rand_train_data_y)

# Build net
input_layer = tf.keras.Input(shape=(1, NUM_FEAT))
lstm_layer = tf.keras.layers.LSTM(
    NUM_FEAT, input_shape=(1, NUM_FEAT), dropout=0.2, recurrent_dropout=0.2
)(input_layer)
dense_layer = tf.keras.layers.Dense(15, activation=""relu"")(lstm_layer)
outputs = tf.keras.layers.Dense(NUM_CLASSES, activation=""softmax"")(dense_layer)
model = tf.keras.Model(inputs=[input_layer], outputs=outputs)

loss_fn = tf.keras.losses.MeanSquaredLogarithmicError()

model.compile(optimizer=""adam"", loss=loss_fn, metrics=[""accuracy""])
print(model.summary())

model.fit(
    x_train,
    y_train,
    epochs=10,
)
model.export(""test_model"")  # , format=""tf_saved_model"")

converter = tf.lite.TFLiteConverter.from_saved_model(""test_model"")
converter.experimental_enable_resource_variables = True
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS,
    tf.lite.OpsSet.SELECT_TF_OPS,
]
model_lite = converter.convert()

```

This leads to the following errors:
```
error: 'tfl.assign_variable' op operand #1 must be tensor of 32-bit float or 64-bit float or 1-bit signless integer or 8-bit unsigned integer or 8-bit signless integer or QI8 type or QUI8 type or 32-bit signless integer or 64-bit signless integer or QI16 type or complex type with 32-bit float elements or complex type with 64-bit float elements values, but got 'tensor<2xui32>'
loc(callsite(callsite(fused[""ReadVariableOp:"", ""functional_1_1/lstm_1/ReadVariableOp_1@__inference___call___3175""] at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall@__inference_signature_wrapper___call___3218""]) at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall_1""])): error: 'tfl.read_variable' op result #0 must be tensor of 32-bit float or 64-bit 
float or 1-bit signless integer or 8-bit unsigned integer or 8-bit signless integer or QI8 type or QUI8 type or 32-bit signless integer or 64-bit signless integer or QI16 type or complex 
type with 32-bit float elements or complex type with 64-bit float elements values, but got 'tensor<2xui32>'
loc(callsite(callsite(fused[""AssignVariableOp:"", ""functional_1_1/lstm_1/AssignVariableOp@__inference___call___3175""] at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall@__inference_signature_wrapper___call___3218""]) at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall_1""])): error: 'tfl.assign_variable' op operand #1 must be tensor of 32-bit float or 64-bit float or 1-bit signless integer or 8-bit unsigned integer or 8-bit signless integer or QI8 type or QUI8 type or 32-bit signless integer or 64-bit signless integer or QI16 type or complex type with 32-bit float elements or complex type with 64-bit float elements values, but got 'tensor<2xui32>'
loc(callsite(callsite(fused[""ReadVariableOp:"", ""functional_1_1/lstm_1/ReadVariableOp_3@__inference___call___3175""] at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall@__inference_signature_wrapper___call___3218""]) at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall_1""])): error: 'tfl.read_variable' op result #0 must be tensor of 32-bit float or 64-bit 
float or 1-bit signless integer or 8-bit unsigned integer or 8-bit signless integer or QI8 type or QUI8 type or 32-bit signless integer or 64-bit signless integer or QI16 type or complex 
type with 32-bit float elements or complex type with 64-bit float elements values, but got 'tensor<2xui32>'
loc(callsite(callsite(fused[""AssignVariableOp:"", ""functional_1_1/lstm_1/AssignVariableOp_1@__inference___call___3175""] at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall@__inference_signature_wrapper___call___3218""]) at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall_1""])): error: 'tfl.assign_variable' op operand #1 must be tensor of 32-bit float or 
64-bit float or 1-bit signless integer or 8-bit unsigned integer or 8-bit signless integer or QI8 type or QUI8 type or 32-bit signless integer or 64-bit signless integer or QI16 type or complex type with 32-bit float elements or complex type with 64-bit float elements values, but got 'tensor<2xui32>'
Traceback (most recent call last):
  File "".\lstm_minimum_bug.py"", line 48, in <module>
    model_lite = converter.convert()
                 ^^^^^^^^^^^^^^^^^^^
  File ""C:\Python311\Lib\site-packages\tensorflow\lite\python\lite.py"", line 1175, in wrapper
    return self._convert_and_export_metrics(convert_func, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Python311\Lib\site-packages\tensorflow\lite\python\lite.py"", line 1129, in _convert_and_export_metrics
    result = convert_func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Python311\Lib\site-packages\tensorflow\lite\python\lite.py"", line 1500, in convert
    return self._convert_from_saved_model(graph_def)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Python311\Lib\site-packages\tensorflow\lite\python\lite.py"", line 1367, in _convert_from_saved_model
    result = _convert_saved_model(**converter_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Python311\Lib\site-packages\tensorflow\lite\python\convert_phase.py"", line 212, in wrapper
    raise converter_error from None  # Re-throws the exception.
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Python311\Lib\site-packages\tensorflow\lite\python\convert_phase.py"", line 205, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Python311\Lib\site-packages\tensorflow\lite\python\convert.py"", line 1012, in convert_saved_model
    data = convert(
           ^^^^^^^^
  File ""C:\Python311\Lib\site-packages\tensorflow\lite\python\convert.py"", line 367, in convert
    raise converter_error
tensorflow.lite.python.convert_phase.ConverterError: Variable constant folding is failed. Please consider using enabling `experimental_enable_resource_variables` flag in the TFLite converter object. For example, converter.experimental_enable_resource_variables = True<unknown>:0: error: 'tfl.assign_variable' op operand #1 must be tensor of 32-bit float or 64-bit float or 1-bit signless integer or 8-bit unsigned integer or 8-bit signless integer or QI8 type or QUI8 type or 32-bit signless integer or 64-bit signless integer or QI16 type or complex type with 
32-bit float elements or complex type with 64-bit float elements values, but got 'tensor<2xui32>'
<unknown>:0: error: loc(callsite(callsite(fused[""ReadVariableOp:"", ""functional_1_1/lstm_1/ReadVariableOp_1@__inference___call___3175""] at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall@__inference_signature_wrapper___call___3218""]) at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall_1""])): 'tfl.read_variable' op result #0 must be tensor of 32-bit float or 64-bit float or 1-bit signless integer or 8-bit unsigned integer or 8-bit signless integer or QI8 type or QUI8 type or 32-bit signless integer or 64-bit signless integer or QI16 type or complex type with 32-bit float elements or complex type with 64-bit float elements values, but got 'tensor<2xui32>'
<unknown>:0: note: loc(fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall_1""]): called from
<unknown>:0: error: loc(callsite(callsite(fused[""AssignVariableOp:"", ""functional_1_1/lstm_1/AssignVariableOp@__inference___call___3175""] at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall@__inference_signature_wrapper___call___3218""]) at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall_1""])): 'tfl.assign_variable' op operand #1 must be tensor of 32-bit float or 64-bit float or 1-bit signless integer or 8-bit unsigned integer or 8-bit signless integer or QI8 type or QUI8 type or 32-bit signless integer or 64-bit signless integer or QI16 type or complex type with 32-bit float elements or complex type with 64-bit float elements values, but got 'tensor<2xui32>'
<unknown>:0: note: loc(fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall_1""]): called from
<unknown>:0: error: loc(callsite(callsite(fused[""ReadVariableOp:"", ""functional_1_1/lstm_1/ReadVariableOp_3@__inference___call___3175""] at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall@__inference_signature_wrapper___call___3218""]) at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall_1""])): 'tfl.read_variable' op result #0 must be tensor of 32-bit float or 64-bit float or 1-bit signless integer or 8-bit unsigned integer or 8-bit signless integer or QI8 type or QUI8 type or 32-bit signless integer or 64-bit signless integer or QI16 type or complex type with 32-bit float elements or complex type with 64-bit float elements values, but got 'tensor<2xui32>'
<unknown>:0: note: loc(fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall_1""]): called from
<unknown>:0: error: loc(callsite(callsite(fused[""AssignVariableOp:"", ""functional_1_1/lstm_1/AssignVariableOp_1@__inference___call___3175""] at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall@__inference_signature_wrapper___call___3218""]) at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall_1""])): 'tfl.assign_variable' op operand #1 must be tensor of 32-bit float or 64-bit float or 1-bit signless integer or 8-bit unsigned integer or 8-bit signless integer or QI8 type or QUI8 type or 32-bit signless integer or 64-bit signless integer or QI16 type or complex type with 32-bit float elements or complex type with 64-bit float elements values, but got 'tensor<2xui32>'
<unknown>:0: note: loc(fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall_1""]): called from
```

### 5. (optional) Any other info / logs
I'm aware that this is using experimental settings, but I wanted to share the error I got and I'm wondering if there is a way to export a LSTM model to tflite that uses dropout? Or are these not supported for tflite? 
I never really tested the .tflite models that were exported with tf 2.15, because I had trouble with building the tensorflowlite_c.dll for tf 2.15 (this got solved with 2.16.1).
"
2325875068,68882,"ValueError: `validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [<class 'int'>]",closed,2024-05-30 14:53:08+00:00,2024-06-18T01:51:18Z,2024-06-18T01:51:15Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/68882,"['stat:awaiting response', 'type:bug', 'stale', 'comp:apis', 'TF 2.9']","[' history = model.fit([X_word_train,np.array(X_char_train).reshape((len(X_char_train),max_len,max_len_char)),np.array(pos_tag_train), max_len], np.array(y_train).reshape(len(y_train),max_len,1), batch_size=5, epochs=60, validation_split=0.2, verbose=1)\r\n  File ""C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py"", line 66, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File ""C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py"", line 797, in fit\r\n    shuffle=False))\r\n  File ""C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py"", line 1311, in train_validation_split\r\n    ""arrays, found: {}"".format(arrays))\r\nValueError: `validation_split` is only supported for Tensors or NumPy arrays, found: ([array([[ 481,    8, 1128, ...,    0,    0,    0],\r\n       [  19,  693,    3, ...,    0,    0,    0],\r\n       [2044,   31, 1254, ...,    0,    0,    0],\r\n       ...,\r\n       [  54, 1545,   31, ...,    0,    0,    0],\r\n       [ 699,    2, 1068, ...,    0,    0,    0],\r\n       [ 230,   40,   18, ...,    0,    0,    0]]), array([[[ 92,  83,  51, ...,   0,   0,   0],\r\n        [ 29,  83,   0, ...,   0,   0,   0],\r\n        [ 29,  38,  16, ...,   0,   0,   0],\r\n        ...,\r\n        [  0,   0,   0, ...,   0,   0,   0],\r\n        [  0,   0,   0, ...,   0,   0,   0],\r\n        [  0,   0,   0, ...,   0,   0,   0]],\r\n\r\n       [[  2,  52,   0, ...,   0,   0,   0],\r\n        [ 33,  83,  33, ...,   0,   0,   0],\r\n        [ 33,  14,   4, ...,   0,   0,   0],\r\n        ...,\r\n        [  0,   0,   0, ...,   0,   0,   0],\r\n        [  0,   0,   0, ...,   0,   0,   0],\r\n        [  0,   0,   0, ...,   0,   0,   0]],\r\n\r\n       [[ 59,  33,  47, ...,   0,   0,   0],\r\n        [ 22,   0,   0, ...,   0,   0,   0],\r\n        [ 29,  71,  47, ...,   0,   0,   0],\r\n        ...,\r\n        [  0,   0,   0, ...,   0,   0,   0],\r\n        [  0,   0,   0, ...,   0,   0,   0],\r\n        [  0,   0,   0, ...,   0,   0,   0]],\r\n\r\n       ...,\r\n\r\n       [[105,  51,  47, ...,   0,   0,   0],\r\n        [ 84,   7,   7, ...,   0,   0,   0],\r\n        [ 22,   0,   0, ...,   0,   0,   0],\r\n        ...,\r\n        [  0,   0,   0, ...,   0,   0,   0],\r\n        [  0,   0,   0, ...,   0,   0,   0],\r\n        [  0,   0,   0, ...,   0,   0,   0]],\r\n\r\n       [[105,  38,  83, ...,   0,   0,   0],\r\n        [ 29,  14,   0, ...,   0,   0,   0],\r\n        [ 93,  38,   0, ...,   0,   0,   0],\r\n        ...,\r\n        [  0,   0,   0, ...,   0,   0,   0],\r\n        [  0,   0,   0, ...,   0,   0,   0],\r\n        [  0,   0,   0, ...,   0,   0,   0]],\r\n\r\n       [[ 40,  38,  83, ...,   0,   0,   0],\r\n        [ 88,  29,   0, ...,   0,   0,   0],\r\n        [ 29,  39,   0, ...,   0,   0,   0],\r\n        ...,\r\n        [  0,   0,   0, ...,   0,   0,   0],\r\n        [  0,   0,   0, ...,   0,   0,   0],\r\n        [  0,   0,   0, ...,   0,   0,   0]]]), array([[28, 21, 15, ...,  9,  9,  9],\r\n       [27, 28, 21, ...,  9,  9,  9],\r\n       [31,  9, 16, ...,  9,  9,  9],\r\n       ...,\r\n       [28, 16,  9, ...,  9,  9,  9],\r\n       [18, 21,  8, ...,  9,  9,  9],\r\n       [18, 21, 17, ...,  9,  9,  9]]), 100], array([[[2],\r\n        [3],\r\n        [3],\r\n        ...,\r\n        [0],\r\n        [0],\r\n        [0]],\r\n\r\n       [[2],\r\n        [2],\r\n        [3],\r\n        ...,\r\n        [0],\r\n        [0],\r\n        [0]],\r\n\r\n       [[2],\r\n        [1],\r\n        [1],\r\n        ...,\r\n        [0],\r\n        [0],\r\n        [0]],\r\n\r\n       ...,\r\n\r\n       [[2],\r\n        [2],\r\n        [1],\r\n        ...,\r\n        [0],\r\n        [0],\r\n        [0]],\r\n\r\n       [[2],\r\n        [3],\r\n        [2],\r\n        ...,\r\n        [0],\r\n        [0],\r\n        [0]],\r\n\r\n       [[2],\r\n        [3],\r\n        [3],\r\n        ...,\r\n        [0],\r\n        [0],\r\n        [0]]]), None)', '@kusumlata123 Could you please try to upgrade to the latest TF version as you are using an older TF version which is not actively supported.  You might be using the validation_split argument in an unsupported format with your machine learning model. Kindly share the standalone code to replicate the issue if you still have any concern in the latest TF version?\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68882"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68882"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf2.9

### Custom code

Yes

### OS platform and distribution

window

### Mobile device

_No response_

### Python version

3.7.6

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

cuda_12.4.r12.4/compiler.34097967_0

### GPU model and memory

_No response_

### Current behavior?

 File ""MDLSTM7_CRF.py"", line 381, in <module>
    model_build(input_file)
  File ""MDLSTM7_CRF.py"", line 275, in model_build
    history = model.fit([np.array(X_word_train),np.array(X_char_train).reshape((len(X_char_train),max_len,max_len_char)),np.array(pos_tag_train), max_len], np.array(y_train).reshape(len(y_train),max_len,1), batch_size=5, epochs=60, validation_split=0.2, verbose=1)
  File ""C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\keras\utils\traceback_utils.py"", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\keras\engine\data_adapter.py"", line 1482, in train_validation_split
    ""arrays, found following types in the input: {}"".format(unsplitable))
ValueError: `validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [<class 'int'>]

### Standalone code to reproduce the issue

```shell
history = model.fit([np.array(X_word_train),np.array(X_char_train).reshape((len(X_char_train),max_len,max_len_char)),np.array(pos_tag_train), max_len], np.array(y_train).reshape(len(y_train),max_len,1), batch_size=5, epochs=60, validation_split=0.2, verbose=1)
```


### Relevant log output

```shell
File ""MDLSTM7_CRF.py"", line 381, in <module>
    model_build(input_file)
  File ""MDLSTM7_CRF.py"", line 275, in model_build
    history = model.fit([np.array(X_word_train),np.array(X_char_train).reshape((len(X_char_train),max_len,max_len_char)),np.array(pos_tag_train), max_len], np.array(y_train).reshape(len(y_train),max_len,1), batch_size=5, epochs=60, validation_split=0.2, verbose=1)
  File ""C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\keras\utils\traceback_utils.py"", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\keras\engine\data_adapter.py"", line 1482, in train_validation_split
    ""arrays, found following types in the input: {}"".format(unsplitable))
ValueError: `validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [<class 'int'>]
```
"
2326718773,68923,__add__ with floating point values,closed,2024-05-30 23:46:45+00:00,2024-06-29T01:49:50Z,2024-06-29T01:49:46Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/68923,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.16']","['Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68923"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68923"">No</a>\n', '@namitha01m,\r\nApologies for the delay. Could you please confirm if this issue is related to TensorFlow. AFAIK it is not looking like the tensorflow related bug. Please let me know if my understanding is right in this case. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68923"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68923"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.16.1

### Custom code

Yes

### OS platform and distribution

Windows

### Mobile device

_No response_

### Python version

3.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

It's currently not possible for `add' to interpret a floating point values as an integer



### Standalone code to reproduce the issue

```shell
# New code
import numpy as np

class TnpArray:
    def __init__(self, data):
        self.data = np.array(data)

    def __add__(self, other):
        if isinstance(other, (int, float)):
            return TnpArray(self.data + other)
        else:
            raise TypeError(f""Unsupported operand type(s) for +: 'TnpArray' and '{type(other).__name__}'"")

    def __repr__(self):
        return repr(self.data)

# Example usage:
a = TnpArray([1, 2, 3])
result = a + 1.5
print(result)  # Output: array([2.5, 3.5, 4.5])
```


### Relevant log output

_No response_"
2328221927,68959," TypeError: Expected int32, got 1e-07 of type 'float' instead.",closed,2024-05-31 16:44:08+00:00,2024-06-21T01:49:58Z,2024-06-21T01:49:53Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/68959,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'TF 2.2']","['Can you help me out\r\n', 'Epoch 1/60\r\nTraceback (most recent call last):\r\n  File ""MDLSTM7_CRF.py"", line 422, in <module>\r\n    model_build(input_file)\r\n  File ""MDLSTM7_CRF.py"", line 311, in model_build\r\n    history = model.fit([X_word_train, X_char_train, pos_tag_train, max_len_array], y_train, batch_size=5, epochs=60, validation_split=0.2, verbose=1)\r\n  File ""C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py"", line 66, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File ""C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py"", line 848, in fit\r\n    tmp_logs = train_function(iterator)\r\n  File ""C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py"", line 580, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File ""C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py"", line 627, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File ""C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py"", line 506, in _initialize\r\n    *args, **kwds))\r\n  File ""C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\eager\\function.py"", line 2446, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File ""C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\eager\\function.py"", line 2777, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File ""C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\eager\\function.py"", line 2667, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File ""C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py"", line 981, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File ""C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py"", line 441, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File ""C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py"", line 968, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nTypeError: in user code:\r\n\r\n    C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:571 train_function  *\r\n        outputs = self.distribute_strategy.run(\r\n    C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:533 train_step  **\r\n        y, y_pred, sample_weight, regularization_losses=self.losses)\r\n    C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:205 __call__\r\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\r\n    C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:143 __call__\r\n        losses = self.call(y_true, y_pred)\r\n    C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:246 call\r\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\r\n    C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1558 sparse_categorical_crossentropy\r\n        y_true, y_pred, from_logits=from_logits, axis=axis)\r\n    C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4620 sparse_categorical_crossentropy\r\n        epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\r\n    C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:709 _constant_to_tensor\r\n        return constant_op.constant(x, dtype=dtype)\r\n    C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:262 constant\r\n        allow_broadcast=True)\r\n    C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:300 _constant_impl\r\n        allow_broadcast=allow_broadcast))\r\n    C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:451 make_tensor_proto\r\n        _AssertCompatible(values, dtype)\r\n    C:\\Users\\saivi\\anaconda3\\envs\\mention\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:331 _AssertCompatible\r\n        (dtype.name, repr(mismatch), type(mismatch).__name__))\r\n\r\n    TypeError: Expected int32, got 1e-07 of type \'float\' instead.', '@kusumlata123,\r\nLooks like the provided code is not the complete code. Can you please, share colab link or complete code with supporting files to reproduce the issue in our environment. It helps us in localizing the issue faster.\r\n\r\nAlso the Tensorflow v2.2 is a pretty old version. Could you please test the code in the latest TensorFlow v2.15 or v2.16 where most of the bugs are resolved in the updated versions.\r\nThank you!', 'As my code supported this one , i have run this code in 2021 and now\r\nagain want to run for research purpose\r\n\r\n\r\nOn Mon, Jun 3, 2024 at 12:47\u202fPM tilakrayal ***@***.***> wrote:\r\n\r\n> @kusumlata123 <https://github.com/kusumlata123>,\r\n> Looks like the provided code is not the complete code. Can you please,\r\n> share colab link or complete code with supporting files to reproduce the\r\n> issue in our environment. It helps us in localizing the issue faster.\r\n>\r\n> Also the Tensorflow v2.2 is a pretty old version. Could you please test\r\n> the code in the latest TensorFlow v2.15 or v2.16 where most of the bugs are\r\n> resolved in the updated versions.\r\n> Thank you!\r\n>\r\n> —\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tensorflow/tensorflow/issues/68959#issuecomment-2144449490>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AJKEARCIVD6RAYB7FXIK3NLZFQKABAVCNFSM6AAAAABITECF4SVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDCNBUGQ2DSNBZGA>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>\r\n', "" from tensorflow.keras.preprocessing.sequence import pad_sequences\r\nModuleNotFoundError: No module named 'tensorflow.keras'\r\n\r\n if i have upgraded version from 2.2.0 to 2.11.0 with  keras 2.11.0"", ""@kusumlata123,\r\nI guess your code was written which was compatible with the tensorflow v2.2. There are more number of apis which were deprecated in the older versions and couldn't be used in the latest versions. \r\n\r\nEg:from tensorflow.keras.preprocessing.sequence import pad_sequences---tf.keras.preprocessing.sequence was deprecated\r\n![image](https://github.com/tensorflow/tensorflow/assets/81610181/c1d66f54-2afd-4a3a-be83-d6558b7badde)\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence\r\n\r\nhttps://stackoverflow.com/questions/72326025/cannot-import-name-pad-sequences-from-keras-preprocessing-sequence\r\n\r\nPlease try to convert the complete code and try to execute the code. Thank you!"", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68959"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/68959"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.2.0, tf-gpu-2.2.0

### Custom code

Yes

### OS platform and distribution

window

### Mobile device

Laptop

### Python version

3.7.6

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

model_build(input_file)
  File ""MDLSTM7_CRF.py"", line 307, in model_build
    verbose=int(1)
  File ""C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 66, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 848, in fit
    tmp_logs = train_function(iterator)
  File ""C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\eager\def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\eager\def_function.py"", line 627, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\eager\def_function.py"", line 506, in _initialize
    *args, **kwds))
  File ""C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\eager\function.py"", line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\eager\function.py"", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\eager\function.py"", line 2667, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\framework\func_graph.py"", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\eager\def_function.py"", line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\framework\func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
TypeError: in user code:

    C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\keras\engine\training.py:571 train_function  *
        outputs = self.distribute_strategy.run(
    C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2649 _call_for_each_replica
        return fn(*args, **kwargs)
    C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\keras\engine\training.py:533 train_step  **
        y, y_pred, sample_weight, regularization_losses=self.losses)
    C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\keras\engine\compile_utils.py:205 __call__
        loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\keras\losses.py:143 __call__
        losses = self.call(y_true, y_pred)
    C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\keras\losses.py:246 call
        return self.fn(y_true, y_pred, **self._fn_kwargs)
    C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\keras\losses.py:1558 sparse_categorical_crossentropy
        y_true, y_pred, from_logits=from_logits, axis=axis)
    C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\keras\backend.py:4620 sparse_categorical_crossentropy
        epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)
    C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\keras\backend.py:709 _constant_to_tensor
        return constant_op.constant(x, dtype=dtype)
    C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\framework\constant_op.py:262 constant
        allow_broadcast=True)
    C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\framework\constant_op.py:300 _constant_impl
        allow_broadcast=allow_broadcast))
    C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\framework\tensor_util.py:451 make_tensor_proto
        _AssertCompatible(values, dtype)
    C:\Users\saivi\anaconda3\envs\mention\lib\site-packages\tensorflow\python\framework\tensor_util.py:331 _AssertCompatible
        (dtype.name, repr(mismatch), type(mismatch).__name__))

    TypeError: Expected int32, got 1e-07 of type 'float' instead.

### Standalone code to reproduce the issue

```shell
X_word_train = np.array(X_word_train, dtype=np.int32)
    X_char_train = np.array(X_char_train, dtype=np.int32).reshape((len(X_char_train), max_len, max_len_char))
    pos_tag_train = np.array(pos_tag_train, dtype=np.int32)
    y_train = np.array(y_train, dtype=np.int32).reshape(len(y_train), max_len, 1)

    # Use np.full to create an array of integers
    max_len_array = np.full(len(X_word_train), max_len, dtype=np.int32)
 
    history = model.fit(
        [X_word_train, X_char_train, pos_tag_train, max_len_array],
        y_train,
        batch_size=5,
        epochs=60,
        shuffle=False,
        validation_split=0.2,
        verbose=1
    )
```


### Relevant log output

```shell
model should be train
```
"
2331426711,69054,Aborted in `tf.reduce_mean` occurs when gpu is not available,closed,2024-06-03 15:15:20+00:00,2024-06-27T01:51:04Z,2024-06-27T01:51:01Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/69054,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.16']","['I pulled the latest tensorflow through docker again and then after running the code, the results were the same with the following output:\r\n![image](https://github.com/tensorflow/tensorflow/assets/165141765/93bc4ce6-2291-4746-994d-3cbffaca7413)\r\n', '@x0w3n,\r\nI tried to execute the mentioned code on tensorflow v2.15, v2.16, tf-nightly on GPU and CPU with colab and other Linux environement, and observed that it is not anorted as mentioned, and it is providing the error message which was expected. Kindly find the [gists](https://colab.research.google.com/gist/tilakrayal/50b10e56330c9696ebd84b5a73ab0c99/untitled1928.ipynb) of [both](https://colab.research.google.com/gist/tilakrayal/26ebf14f312cebe9203bcf8d56560d06/untitled1927.ipynb) environments and the error log of the linux environments as well.\r\n\r\n```python\r\n2024-06-04 12:14:55.608481: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\r\ntensorflow version: 2.16.1\r\nWARNING:tensorflow:From /home/tilakrayal/mbn.py:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.config.list_physical_devices(\'GPU\')` instead.\r\ngpu available：False\r\n************\r\n2024-06-04 12:14:56.512379: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at conv_ops_impl.h:668 : INVALID_ARGUMENT: convolution input must be 4-dimensional: [100]\r\n2024-06-04 12:14:56.512466: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: convolution input must be 4-dimensional: [100]\r\nTraceback (most recent call last):\r\n  File ""/home/tilakrayal/mbn.py"", line 9, in <module>\r\n    y = tf.nn.conv2d(x_data, Weights, strides=[1, 1, 1, 1], padding=\'SAME\')\r\n  File ""/home/tilakrayal/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py"", line 153, in error_handler\r\n    raise e.with_traceback(filtered_tb) from None\r\n  File ""/home/tilakrayal/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/framework/ops.py"", line 5983, in raise_from_not_ok_status\r\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:CPU:0}} convolution input must be 4-dimensional: [100] [Op:Conv2D] name: \r\n```\r\n\r\n', ""Thank you! I've noticed this. I ran the code in colab and it really didn't trigger a crash. and pulled the latest tensorflow and ran the code using docker on a new physical machine (no gpu) and it didn't trigger a crash either. however, on my original machine(with gpu but installed tensorflow-cpu version ) I still got an error running this string of code. Here's the environment info I've gathered, hope it's useful.\r\n\r\n```\r\n== check python ===================================================\r\n\r\n== check os platform ===============================================\r\n\r\n== are we in docker =============================================\r\nYes\r\n\r\n== compiler =====================================================\r\n./tf_env_collect.sh: line 102: c++: command not found\r\n\r\n== check pips ===================================================\r\nnumpy                         1.26.4\r\nnumpydoc                      1.4.0\r\nprotobuf                      4.25.3\r\ntensorflow                    2.15.0\r\ntensorflow-estimator          2.15.0\r\ntensorflow-io-gcs-filesystem  0.37.0\r\n\r\n== check for virtualenv =========================================\r\n\r\n== tensorflow import ============================================\r\n./tf_env_collect.sh: line 127: Cannot: command not found\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n./tf_env_collect.sh: line 147: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\n== tensorflow installed from info ==================\r\nName: tensorflow\r\nVersion: 2.15.0\r\nSummary: TensorFlow is an open source machine learning framework for everyone.\r\nHome-page: https://www.tensorflow.org/\r\nAuthor-email: packages@tensorflow.org\r\nLicense: Apache 2.0\r\nLocation: /root/anaconda3/lib/python3.9/site-packages\r\nRequired-by:\r\n\r\n== python version  ==============================================\r\n(major, minor, micro, releaselevel, serial)\r\n(3, 9, 13, 'final', 0)\r\n\r\n== bazel version  ===============================================\r\n\r\n== check python ===================================================\r\npython version: 3.11.0rc1\r\npython branch:\r\npython build version: ('main', 'Aug 12 2022 10:02:14')\r\npython compiler version: GCC 11.2.0\r\npython implementation: CPython\r\n\r\n\r\n== check os platform ===============================================\r\n\r\n== are we in docker =============================================\r\nYes\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\r\nCopyright (C) 2021 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== check pips ===================================================\r\nnumpy                        1.26.4\r\nprotobuf                     4.25.3\r\ntensorflow-cpu               2.16.1\r\ntensorflow-io-gcs-filesystem 0.36.0\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.version.VERSION = 2.16.1\r\ntf.version.GIT_VERSION = v2.16.1-0-g5bc9d26649c\r\ntf.version.COMPILER_VERSION = Ubuntu Clang 17.0.6 (++20231208085846+6009708b4367-1~exp1~20231208085949.74)\r\n       115:     find library=libm.so.6 [0]; searching\r\n       115:      search cache=/etc/ld.so.cache\r\n       115:       trying file=/lib/x86_64-linux-gnu/libm.so.6\r\n       115:\r\n       115:     find library=libz.so.1 [0]; searching\r\n       115:      search cache=/etc/ld.so.cache\r\n       115:       trying file=/lib/x86_64-linux-gnu/libz.so.1\r\n       115:\r\n       115:     find library=libexpat.so.1 [0]; searching\r\n       115:      search cache=/etc/ld.so.cache\r\n       115:       trying file=/lib/x86_64-linux-gnu/libexpat.so.1\r\n       115:\r\n       115:     find library=libc.so.6 [0]; searching\r\n       115:      search cache=/etc/ld.so.cache\r\n       115:       trying file=/lib/x86_64-linux-gnu/libc.so.6\r\n       115:\r\n       115:\r\n       115:     calling init: /lib64/ld-linux-x86-64.so.2\r\n       115:\r\n       115:\r\n       115:     calling init: /lib/x86_64-linux-gnu/libc.so.6\r\n       115:\r\n       115:\r\n       115:     calling init: /lib/x86_64-linux-gnu/libexpat.so.1\r\n       115:\r\n       115:\r\n       115:     calling init: /lib/x86_64-linux-gnu/libz.so.1\r\n       115:\r\n       115:\r\n       115:     calling init: /lib/x86_64-linux-gnu/libm.so.6\r\n       115:\r\n       115:\r\n       115:     initialize program: /usr/bin/python\r\n       115:\r\n       115:\r\n       115:     transferring control: /usr/bin/python\r\n       115:\r\n       115:     find library=libbz2.so.1.0 [0]; searching\r\n       115:      search cache=/etc/ld.so.cache\r\n       115:       trying file=/lib/x86_64-linux-gnu/libbz2.so.1.0\r\n       115:\r\n       115:\r\n       115:     calling init: /lib/x86_64-linux-gnu/libbz2.so.1.0\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/lib/python3.11/lib-dynload/_bz2.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:     find library=liblzma.so.5 [0]; searching\r\n       115:      search cache=/etc/ld.so.cache\r\n       115:       trying file=/lib/x86_64-linux-gnu/liblzma.so.5\r\n       115:\r\n       115:\r\n       115:     calling init: /lib/x86_64-linux-gnu/liblzma.so.5\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/lib/python3.11/lib-dynload/_lzma.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/lib/python3.11/lib-dynload/_typing.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/lib/python3.11/lib-dynload/_queue.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/lib/python3.11/lib-dynload/_json.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:     find library=libdl.so.2 [0]; searching\r\n       115:      search path=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/glibc-hwcaps/x86-64-v3:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/glibc-hwcaps/x86-64-v2:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/tls/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/tls/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/tls/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/tls:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../glibc-hwcaps/x86-64-v3:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../glibc-hwcaps/x86-64-v2:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../tls/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../tls/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../tls/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../tls:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/..:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../glibc-hwcaps/x86-64-v3:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../glibc-hwcaps/x86-64-v2:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../tls/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../tls/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../tls/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../tls:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../..          (RUNPATH from file /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_tf2.so)\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/glibc-hwcaps/x86-64-v3/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/glibc-hwcaps/x86-64-v2/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/tls/haswell/x86_64/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/tls/haswell/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/tls/x86_64/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/tls/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/haswell/x86_64/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/haswell/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/x86_64/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../glibc-hwcaps/x86-64-v3/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../glibc-hwcaps/x86-64-v2/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../tls/haswell/x86_64/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../tls/haswell/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../tls/x86_64/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../tls/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../haswell/x86_64/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../haswell/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../x86_64/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../glibc-hwcaps/x86-64-v3/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../glibc-hwcaps/x86-64-v2/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../tls/haswell/x86_64/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../tls/haswell/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../tls/x86_64/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../tls/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../haswell/x86_64/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../haswell/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../x86_64/libdl.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../libdl.so.2\r\n       115:      search cache=/etc/ld.so.cache\r\n       115:       trying file=/lib/x86_64-linux-gnu/libdl.so.2\r\n       115:\r\n       115:     find library=libpthread.so.0 [0]; searching\r\n       115:      search path=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/..:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../.. (RUNPATH from file /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_tf2.so)\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/libpthread.so.0\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../libpthread.so.0\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../libpthread.so.0\r\n       115:      search cache=/etc/ld.so.cache\r\n       115:       trying file=/lib/x86_64-linux-gnu/libpthread.so.0\r\n       115:\r\n       115:     find library=libstdc++.so.6 [0]; searching\r\n       115:      search path=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/..:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../.. (RUNPATH from file /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_tf2.so)\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/libstdc++.so.6\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../libstdc++.so.6\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../libstdc++.so.6\r\n       115:      search cache=/etc/ld.so.cache\r\n       115:       trying file=/lib/x86_64-linux-gnu/libstdc++.so.6\r\n       115:\r\n       115:     find library=libgcc_s.so.1 [0]; searching\r\n       115:      search path=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/..:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../.. (RUNPATH from file /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_tf2.so)\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/libgcc_s.so.1\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../libgcc_s.so.1\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../libgcc_s.so.1\r\n       115:      search cache=/etc/ld.so.cache\r\n       115:       trying file=/lib/x86_64-linux-gnu/libgcc_s.so.1\r\n       115:\r\n       115:\r\n       115:     calling init: /lib/x86_64-linux-gnu/libgcc_s.so.1\r\n       115:\r\n       115:\r\n       115:     calling init: /lib/x86_64-linux-gnu/libstdc++.so.6\r\n       115:\r\n       115:\r\n       115:     calling init: /lib/x86_64-linux-gnu/libpthread.so.0\r\n       115:\r\n       115:\r\n       115:     calling init: /lib/x86_64-linux-gnu/libdl.so.2\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_tf2.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/lib/python3.11/lib-dynload/termios.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:     find library=libopenblas64_p-r0-0cf96a72.3.23.dev.so [0]; searching\r\n       115:      search path=/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/glibc-hwcaps/x86-64-v3:/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/glibc-hwcaps/x86-64-v2:/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/tls/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/tls/haswell:/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/tls/x86_64:/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/tls:/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/haswell:/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/x86_64:/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs         (RPATH from file /usr/local/lib/python3.11/dist-packages/numpy/core/_multiarray_umath.cpython-311-x86_64-linux-gnu.so)\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/glibc-hwcaps/x86-64-v3/libopenblas64_p-r0-0cf96a72.3.23.dev.so\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/glibc-hwcaps/x86-64-v2/libopenblas64_p-r0-0cf96a72.3.23.dev.so\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/tls/haswell/x86_64/libopenblas64_p-r0-0cf96a72.3.23.dev.so\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/tls/haswell/libopenblas64_p-r0-0cf96a72.3.23.dev.so\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/tls/x86_64/libopenblas64_p-r0-0cf96a72.3.23.dev.so\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/tls/libopenblas64_p-r0-0cf96a72.3.23.dev.so\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/haswell/x86_64/libopenblas64_p-r0-0cf96a72.3.23.dev.so\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/haswell/libopenblas64_p-r0-0cf96a72.3.23.dev.so\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/x86_64/libopenblas64_p-r0-0cf96a72.3.23.dev.so\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/libopenblas64_p-r0-0cf96a72.3.23.dev.so\r\n       115:\r\n       115:     find library=libgfortran-040039e1.so.5.0.0 [0]; searching\r\n       115:      search path=/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs                (RPATH from file /usr/local/lib/python3.11/dist-packages/numpy/core/_multiarray_umath.cpython-311-x86_64-linux-gnu.so)\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/libgfortran-040039e1.so.5.0.0\r\n       115:\r\n       115:     find library=libquadmath-96973f99.so.0.0.0 [0]; searching\r\n       115:      search path=/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs                (RPATH from file /usr/local/lib/python3.11/dist-packages/numpy/core/_multiarray_umath.cpython-311-x86_64-linux-gnu.so)\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/libquadmath-96973f99.so.0.0.0\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/libquadmath-96973f99.so.0.0.0\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/libgfortran-040039e1.so.5.0.0\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/libopenblas64_p-r0-0cf96a72.3.23.dev.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/numpy/core/_multiarray_umath.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/lib/python3.11/lib-dynload/_contextvars.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/numpy/core/_multiarray_tests.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:     find library=libffi.so.8 [0]; searching\r\n       115:      search cache=/etc/ld.so.cache\r\n       115:       trying file=/lib/x86_64-linux-gnu/libffi.so.8\r\n       115:\r\n       115:\r\n       115:     calling init: /lib/x86_64-linux-gnu/libffi.so.8\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/numpy/linalg/_umath_linalg.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/numpy/fft/_pocketfft_internal.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/numpy/random/mtrand.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/numpy/random/bit_generator.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/numpy/random/_common.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:     find library=libcrypto.so.3 [0]; searching\r\n       115:      search cache=/etc/ld.so.cache\r\n       115:       trying file=/lib/x86_64-linux-gnu/libcrypto.so.3\r\n       115:\r\n       115:\r\n       115:     calling init: /lib/x86_64-linux-gnu/libcrypto.so.3\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/lib/python3.11/lib-dynload/_hashlib.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/numpy/random/_bounded_integers.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/numpy/random/_mt19937.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/numpy/random/_philox.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/numpy/random/_pcg64.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/numpy/random/_sfc64.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/numpy/random/_generator.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:\r\n       115:     find library=libssl.so.3 [0]; searching\r\n       115:      search cache=/etc/ld.so.cache\r\n       115:       trying file=/lib/x86_64-linux-gnu/libssl.so.3\r\n       115:\r\n       115:\r\n       115:     calling init: /lib/x86_64-linux-gnu/libssl.so.3\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/lib/python3.11/lib-dynload/_ssl.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:     find library=libtensorflow_framework.so.2 [0]; searching\r\n       115:      search path=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/glibc-hwcaps/x86-64-v3:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/glibc-hwcaps/x86-64-v2:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/tls/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/tls/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/tls/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/tls:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/glibc-hwcaps/x86-64-v3:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/glibc-hwcaps/x86-64-v2:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/tls/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/tls/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/tls/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/tls:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/glibc-hwcaps/x86-64-v3:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/glibc-hwcaps/x86-64-v2:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/tls/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/tls/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/tls/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/tls:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/glibc-hwcaps/x86-64-v3:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/glibc-hwcaps/x86-64-v2:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/tls/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/tls/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/tls/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/tls:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/..:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../..          (RUNPATH from file /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so)\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/glibc-hwcaps/x86-64-v3/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/glibc-hwcaps/x86-64-v2/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/tls/haswell/x86_64/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/tls/haswell/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/tls/x86_64/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/tls/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/haswell/x86_64/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/haswell/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/x86_64/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/glibc-hwcaps/x86-64-v3/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/glibc-hwcaps/x86-64-v2/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/tls/haswell/x86_64/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/tls/haswell/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/tls/x86_64/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/tls/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/haswell/x86_64/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/haswell/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/x86_64/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Clibtensorflow_Uframework_Uimport_Ulib___Utensorflow/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/glibc-hwcaps/x86-64-v3/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/glibc-hwcaps/x86-64-v2/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/tls/haswell/x86_64/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/tls/haswell/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/tls/x86_64/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/tls/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/haswell/x86_64/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/haswell/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/x86_64/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/glibc-hwcaps/x86-64-v3/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/glibc-hwcaps/x86-64-v2/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/tls/haswell/x86_64/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/tls/haswell/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/tls/x86_64/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/tls/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/haswell/x86_64/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/haswell/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/x86_64/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Ulinux___Utensorflow_Spython/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../libtensorflow_framework.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2\r\n       115:\r\n       115:     find library=_pywrap_tensorflow_internal.so [0]; searching\r\n       115:      search path=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/..:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../.. (RUNPATH from file /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so)\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_tensorflow_internal.so\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so\r\n       115:\r\n       115:     find library=librt.so.1 [0]; searching\r\n       115:      search path=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../..           (RUNPATH from file /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_tf2.so)\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../librt.so.1\r\n       115:      search cache=/etc/ld.so.cache\r\n       115:       trying file=/lib/x86_64-linux-gnu/librt.so.1\r\n       115:\r\n       115:     find library=libtensorflow_cc.so.2 [0]; searching\r\n       115:      search path=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/glibc-hwcaps/x86-64-v3:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/glibc-hwcaps/x86-64-v2:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/tls/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/tls/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/tls/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/tls:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/glibc-hwcaps/x86-64-v3:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/glibc-hwcaps/x86-64-v2:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/tls/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/tls/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/tls/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/tls:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow/glibc-hwcaps/x86-64-v3:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow/glibc-hwcaps/x86-64-v2:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow/tls/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow/tls/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow/tls/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow/tls:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow/glibc-hwcaps/x86-64-v3:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow/glibc-hwcaps/x86-64-v2:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow/tls/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow/tls/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow/tls/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow/tls:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/..:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../..:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../tensorflow/tsl/python/lib/core/glibc-hwcaps/x86-64-v3:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../tensorflow/tsl/python/lib/core/glibc-hwcaps/x86-64-v2:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../tensorflow/tsl/python/lib/core/tls/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../tensorflow/tsl/python/lib/core/tls/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../tensorflow/tsl/python/lib/core/tls/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../tensorflow/tsl/python/lib/core/tls:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../tensorflow/tsl/python/lib/core/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../tensorflow/tsl/python/lib/core/haswell:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../tensorflow/tsl/python/lib/core/x86_64:/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../tensorflow/tsl/python/lib/core        (RUNPATH from file /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so)\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/glibc-hwcaps/x86-64-v3/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/glibc-hwcaps/x86-64-v2/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/tls/haswell/x86_64/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/tls/haswell/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/tls/x86_64/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/tls/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/haswell/x86_64/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/haswell/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/x86_64/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/glibc-hwcaps/x86-64-v3/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/glibc-hwcaps/x86-64-v2/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/tls/haswell/x86_64/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/tls/haswell/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/tls/x86_64/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/tls/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/haswell/x86_64/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/haswell/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/x86_64/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so_Ucclib___Utensorflow/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow/glibc-hwcaps/x86-64-v3/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow/glibc-hwcaps/x86-64-v2/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow/tls/haswell/x86_64/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow/tls/haswell/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow/tls/x86_64/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow/tls/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow/haswell/x86_64/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow/haswell/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow/x86_64/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../../_solib_local/_Utensorflow/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow/glibc-hwcaps/x86-64-v3/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow/glibc-hwcaps/x86-64-v2/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow/tls/haswell/x86_64/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow/tls/haswell/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow/tls/x86_64/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow/tls/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow/haswell/x86_64/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow/haswell/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow/x86_64/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so.runfiles/org_tensorflow/_solib_local/_Utensorflow/libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../libtensorflow_cc.so.2\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2\r\n       115:\r\n       115:\r\n       115:     calling init: /lib/x86_64-linux-gnu/librt.so.1\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2\r\n       115:\r\n2024-06-04 00:35:43.392972: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so\r\n       115:\r\n2024-06-04 00:35:43.417602: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\r\nTo enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/_pywrap_tfe.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/client/_pywrap_tf_session.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/_tf_stack.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/_pywrap_py_exception_registry.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/ml_dtypes/_ml_dtypes_ext.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/_dtypes.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/_pywrap_nest.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/_pywrap_utils.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/wrapt/_wrappers.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/profiler/internal/_pywrap_traceme.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/flags_pybind.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/_pywrap_determinism.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/_pywrap_tensor_float_32_execution.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/_pywrap_dtensor_device.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/_op_def_registry.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/_op_def_library_pybind.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/_pywrap_python_api_dispatcher.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/lib/python3.11/lib-dynload/_multiprocessing.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/client/_pywrap_device_lib.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/lib/io/_pywrap_record_io.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/_proto_comparators.so\r\n       115:\r\n       115:     find library=libmpdec.so.3 [0]; searching\r\n       115:      search cache=/etc/ld.so.cache\r\n       115:       trying file=/lib/x86_64-linux-gnu/libmpdec.so.3\r\n       115:\r\n       115:\r\n       115:     calling init: /lib/x86_64-linux-gnu/libmpdec.so.3\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/lib/python3.11/lib-dynload/_decimal.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/_pywrap_parallel_device.so\r\n       115:\r\n       115:     find library=libuuid.so.1 [0]; searching\r\n       115:      search cache=/etc/ld.so.cache\r\n       115:       trying file=/lib/x86_64-linux-gnu/libuuid.so.1\r\n       115:\r\n       115:\r\n       115:     calling init: /lib/x86_64-linux-gnu/libuuid.so.1\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/lib/python3.11/lib-dynload/_uuid.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/data/experimental/service/_pywrap_server_lib.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/data/experimental/service/_pywrap_utils.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/lib/io/_pywrap_file_io.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/pywrap_saved_model.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/_pywrap_checkpoint_reader.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/lib/core/_pywrap_py_func.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/profiler/internal/_pywrap_profiler.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/lib/python3.11/lib-dynload/_asyncio.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/_pywrap_sanitizers.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/_test_metrics_util.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_stacktrace_handler.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/_pywrap_util_port.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/client/_pywrap_events_writer.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/compiler/tf2tensorrt/_pywrap_py_utils.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/grappler/_pywrap_tf_optimizer.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/grappler/_pywrap_tf_cluster.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/charset_normalizer/md.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/charset_normalizer/md__mypyc.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/lib/python3.11/lib-dynload/_multibytecodec.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:     find library=libhdf5-7f639dcd.so.310.2.0 [0]; searching\r\n       115:      search path=/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/glibc-hwcaps/x86-64-v3:/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/glibc-hwcaps/x86-64-v2:/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/tls/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/tls/haswell:/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/tls/x86_64:/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/tls:/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/haswell/x86_64:/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/haswell:/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/x86_64:/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs              (RPATH from file /usr/local/lib/python3.11/dist-packages/h5py/_errors.cpython-311-x86_64-linux-gnu.so)\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/glibc-hwcaps/x86-64-v3/libhdf5-7f639dcd.so.310.2.0\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/glibc-hwcaps/x86-64-v2/libhdf5-7f639dcd.so.310.2.0\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/tls/haswell/x86_64/libhdf5-7f639dcd.so.310.2.0\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/tls/haswell/libhdf5-7f639dcd.so.310.2.0\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/tls/x86_64/libhdf5-7f639dcd.so.310.2.0\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/tls/libhdf5-7f639dcd.so.310.2.0\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/haswell/x86_64/libhdf5-7f639dcd.so.310.2.0\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/haswell/libhdf5-7f639dcd.so.310.2.0\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/x86_64/libhdf5-7f639dcd.so.310.2.0\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/libhdf5-7f639dcd.so.310.2.0\r\n       115:\r\n       115:     find library=libhdf5_hl-123198ff.so.310.0.2 [0]; searching\r\n       115:      search path=/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs          (RPATH from file /usr/local/lib/python3.11/dist-packages/h5py/_errors.cpython-311-x86_64-linux-gnu.so)\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/libhdf5_hl-123198ff.so.310.0.2\r\n       115:\r\n       115:     find library=libsz-b66d1717.so.2.0.1 [0]; searching\r\n       115:      search path=/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs          (RPATH from file /usr/local/lib/python3.11/dist-packages/h5py/_errors.cpython-311-x86_64-linux-gnu.so)\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/libsz-b66d1717.so.2.0.1\r\n       115:\r\n       115:     find library=libaec-001fb5f0.so.0.0.12 [0]; searching\r\n       115:      search path=/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs          (RPATH from file /usr/local/lib/python3.11/dist-packages/h5py/_errors.cpython-311-x86_64-linux-gnu.so)\r\n       115:       trying file=/usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/libaec-001fb5f0.so.0.0.12\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/libaec-001fb5f0.so.0.0.12\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/libsz-b66d1717.so.2.0.1\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/libhdf5-7f639dcd.so.310.2.0\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/libhdf5_hl-123198ff.so.310.0.2\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/_errors.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/h5.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/defs.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/_objects.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/_conv.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/h5r.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/h5p.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/h5t.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/utils.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/h5s.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/h5ac.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/_proxy.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/h5z.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/h5a.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/h5d.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/h5ds.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/h5f.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/h5g.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/h5i.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/h5fd.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/h5pl.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/h5o.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/h5l.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/h5py/_selector.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/fast_module_type.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/client/_pywrap_debug_events_writer.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/_pywrap_python_op_gen.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/_pywrap_toco_api.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/compiler/mlir/quantization/tensorflow/calibrator/pywrap_calibration.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/compiler/mlir/quantization/tensorflow/python/pywrap_function_lib.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/metrics/_pywrap_tensorflow_lite_metrics_wrapper.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/lite/experimental/microfrontend/python/ops/_audio_microfrontend_op.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/interpreter_wrapper/_pywrap_tensorflow_interpreter_wrapper.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/analyzer_wrapper/_pywrap_analyzer_wrapper.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/_pywrap_mlir.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/_pywrap_tfprof.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/compiler/mlir/quantization/tensorflow/python/pywrap_quantize_model.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/tpu/_pywrap_tpu_embedding.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/python/_pywrap_quantize_training.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so\r\n       115:\r\n       115:\r\n       115:     calling init: /usr/local/lib/python3.11/dist-packages/tree/_tree.cpython-311-x86_64-linux-gnu.so\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/bin/python [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /lib/x86_64-linux-gnu/libexpat.so.1 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/lib/python3.11/lib-dynload/_bz2.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /lib/x86_64-linux-gnu/libbz2.so.1.0 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/lib/python3.11/lib-dynload/_lzma.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /lib/x86_64-linux-gnu/liblzma.so.5 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/lib/python3.11/lib-dynload/_typing.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/lib/python3.11/lib-dynload/_queue.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/lib/python3.11/lib-dynload/_json.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_tf2.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/lib/python3.11/lib-dynload/termios.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/numpy/core/_multiarray_umath.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/lib/python3.11/lib-dynload/_contextvars.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/numpy/core/_multiarray_tests.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /lib/x86_64-linux-gnu/libffi.so.8 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/numpy/linalg/_umath_linalg.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/libopenblas64_p-r0-0cf96a72.3.23.dev.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/libgfortran-040039e1.so.5.0.0 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/numpy/core/../../numpy.libs/libquadmath-96973f99.so.0.0.0 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/numpy/fft/_pocketfft_internal.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/numpy/random/mtrand.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/numpy/random/bit_generator.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/numpy/random/_common.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/lib/python3.11/lib-dynload/_hashlib.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/numpy/random/_bounded_integers.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/numpy/random/_mt19937.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/numpy/random/_philox.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/numpy/random/_pcg64.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/numpy/random/_sfc64.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/numpy/random/_generator.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/lib/python3.11/lib-dynload/_ssl.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /lib/x86_64-linux-gnu/libssl.so.3 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /lib/x86_64-linux-gnu/libcrypto.so.3 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/_pywrap_tfe.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/client/_pywrap_tf_session.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/_tf_stack.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/_pywrap_py_exception_registry.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/ml_dtypes/_ml_dtypes_ext.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/_dtypes.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/_pywrap_nest.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/_pywrap_utils.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/wrapt/_wrappers.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/profiler/internal/_pywrap_traceme.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/flags_pybind.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/_pywrap_determinism.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/_pywrap_tensor_float_32_execution.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/_pywrap_dtensor_device.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/_op_def_registry.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/_op_def_library_pybind.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/_pywrap_python_api_dispatcher.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/lib/python3.11/lib-dynload/_multiprocessing.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/client/_pywrap_device_lib.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/lib/io/_pywrap_record_io.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/_proto_comparators.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/lib/python3.11/lib-dynload/_decimal.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /lib/x86_64-linux-gnu/libmpdec.so.3 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/_pywrap_parallel_device.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/lib/python3.11/lib-dynload/_uuid.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /lib/x86_64-linux-gnu/libuuid.so.1 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/data/experimental/service/_pywrap_server_lib.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/data/experimental/service/_pywrap_utils.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/lib/io/_pywrap_file_io.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/pywrap_saved_model.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/_pywrap_checkpoint_reader.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/lib/core/_pywrap_py_func.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/profiler/internal/_pywrap_profiler.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/lib/python3.11/lib-dynload/_asyncio.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/_pywrap_sanitizers.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/_test_metrics_util.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/_pywrap_stacktrace_handler.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/_pywrap_util_port.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/client/_pywrap_events_writer.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/compiler/tf2tensorrt/_pywrap_py_utils.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/grappler/_pywrap_tf_optimizer.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/grappler/_pywrap_tf_cluster.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/charset_normalizer/md.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/charset_normalizer/md__mypyc.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/lib/python3.11/lib-dynload/_multibytecodec.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/_errors.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/h5.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/defs.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/_objects.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/_conv.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/h5r.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/h5p.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/h5t.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/utils.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/h5s.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/h5ac.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/_proxy.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/h5z.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/h5a.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/h5d.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/h5ds.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/h5f.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/h5g.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/h5i.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/h5fd.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/h5pl.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/h5o.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/h5l.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/_selector.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/libhdf5_hl-123198ff.so.310.0.2 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/libhdf5-7f639dcd.so.310.2.0 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /lib/x86_64-linux-gnu/libz.so.1 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/libsz-b66d1717.so.2.0.1 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/h5py/../h5py.libs/libaec-001fb5f0.so.0.0.12 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/fast_module_type.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/client/_pywrap_debug_events_writer.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/_pywrap_python_op_gen.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/_pywrap_toco_api.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/compiler/mlir/quantization/tensorflow/calibrator/pywrap_calibration.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/compiler/mlir/quantization/tensorflow/python/pywrap_function_lib.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/metrics/_pywrap_tensorflow_lite_metrics_wrapper.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/lite/experimental/microfrontend/python/ops/_audio_microfrontend_op.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/interpreter_wrapper/_pywrap_tensorflow_interpreter_wrapper.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/analyzer_wrapper/_pywrap_analyzer_wrapper.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/_pywrap_mlir.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/_pywrap_tfprof.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/compiler/mlir/quantization/tensorflow/python/pywrap_quantize_model.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/tpu/_pywrap_tpu_embedding.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/_pywrap_quantize_training.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /lib/x86_64-linux-gnu/librt.so.1 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /lib/x86_64-linux-gnu/libpthread.so.0 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /lib/x86_64-linux-gnu/libdl.so.2 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /usr/local/lib/python3.11/dist-packages/tree/_tree.cpython-311-x86_64-linux-gnu.so [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /lib/x86_64-linux-gnu/libstdc++.so.6 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /lib/x86_64-linux-gnu/libgcc_s.so.1 [0]\r\n       115:\r\n       115:\r\n       115:     calling fini: /lib/x86_64-linux-gnu/libm.so.6 [0]\r\n       115:\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n./tf_env_collect.sh: line 147: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\n== tensorflow installed from info ==================\r\n\r\n== python version  ==============================================\r\n(major, minor, micro, releaselevel, serial)\r\n(3, 11, 0, 'candidate', 1)\r\n\r\n== bazel version  ===============================================\r\n```"", '@x0w3n,\r\nAs mentioned, the tf.reduce_mean is not aborted and it is failing with the error which is expected. As the error(convolution input must be 4-dimensional) mentioned the API is expecting the input as the 4-dimensional. Could you please try with the expected input and try to execute. \r\nThank you!\r\n', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69054"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69054"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

The crash occurs when calling tf.reduce_mean when my machine has no gpu. interestingly when I run the code under the latest TensorFlow Nightly version on the colab, the colab throws an error instead of a crash.
I'm not sure if the cause of this problem is because of my python version, or some other environmental effect, I'm running the code on the same machine with tf version 2.16 which also causes a crash.



### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
print(""tensorflow version: ""+ tf.__version__)
print(""gpu available：""+ str(tf.test.is_gpu_available()))
print(""************"")
x_data = np.random.rand(100).astype(np.float32)
y_data = np.random.rand(100).astype(np.float32)
Weights = tf.Variable(tf.random.uniform([1], (- 1.0), 1.0))
y = tf.nn.conv2d(x_data, Weights, strides=[1, 1, 1, 1], padding='SAME')
loss = tf.reduce_mean(tf.square((y - y_data)))
```


### Relevant log output

```shell
2024-06-03 14:53:46.290687: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-03 14:53:46.290874: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-03 14:53:46.293040: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-03 14:53:46.317175: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-03 14:53:46.927920: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/root/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4
  warnings.warn(f""A NumPy version >={np_minversion} and <{np_maxversion}""
tensorflow version: 2.17.0-dev20240527
WARNING:tensorflow:From /home/tf/test_get.py:6: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.config.list_physical_devices('GPU')` instead.
gpu available__False
************
2024-06-03 14:53:47.528427: F ./tensorflow/core/util/tensor_format.h:428] Check failed: index >= 0 && index < num_total_dims Invalid index from the dimension: 3, 0, C
Aborted
```
"
2332513921,69101,Missing legal value check for groups parameter of tf.keras.layers.Conv1D,closed,2024-06-04 04:26:00+00:00,2024-06-21T01:49:55Z,2024-06-21T01:49:51Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/69101,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'TF2.14']","['@PhyllisJi,\r\nAFAIK the argument Groups should A positive int specifying the number of groups in which the  input is split along the channel axis. Each group is convolved separately with `filters // groups` filters. The output is the concatenation of all the `groups` results along the channel axis.\r\n\r\nAlso the Input channels and `filters`  provided must both be divisible by `groups`. Here you are trying with the groups=0 which is not divisible. And also it is working as intended in the Tensorflow 2.16. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/93ebecc9d54fd953439d4feddabbfcc0/untitled1933.ipynb).\r\n\r\nhttps://keras.io/api/layers/convolution_layers/convolution1d/\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69101"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69101"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.14.0

### Custom code

Yes

### OS platform and distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

tf.keras.layers.Conv1D still works fine when groups is set to 0.
With the same parameter settings, pytorch throws the following exception:
```
ValueError: groups must be a positive integer
```

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

conv_layer = tf.keras.layers.Conv1D(
    filters=64,
    kernel_size=1,
    strides=1,
    padding=""valid"",
    data_format=""channels_last"",
    dilation_rate=1,
    groups=0, 
    use_bias=True,
    name=""conv2""
)

input_tensor = tf.keras.Input(shape=(32, 3))

output_tensor = conv_layer(input_tensor)

print(output_tensor.shape)
```


### Relevant log output

_No response_"
2332529233,69103,The documentation for Conv1DTranspose does not state that the CPU does not support dilation rates larger than 1,closed,2024-06-04 04:38:01+00:00,2024-06-26T01:50:46Z,2024-06-26T01:50:43Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/69103,"['type:docs-bug', 'stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'TF2.14']","['Hi **@PhyllisJi** ,\r\n- Sorry for the dealy, Please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999).\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69103"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69103"">No</a>\n']","### Issue type

Documentation Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.14.0

### Custom code

Yes

### OS platform and distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Throw Error:
```
tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling layer 'conv4_mutated' (type Conv1DTranspose).

{{function_node __wrapped__Conv2DBackpropInput_device_/job:localhost/replica:0/task:0/device:CPU:0}} Current CPU implementations do not yet support dilation rates larger than 1. [Op:Conv2DBackpropInput] name: 

Call arguments received by layer 'conv4_mutated' (type Conv1DTranspose):
  • inputs=tf.Tensor(shape=(2, 2048, 64), dtype=float32)
```
Also, I'm not quite sure why the error message relates to Conv2DBackpropInput

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
import os


os.environ['CUDA_VISIBLE_DEVICES'] = ''

def Model_HqTi1yjRFc7Dz1RLSJOvA9XX16R5Wp01(x):
    x = tf.keras.Input(shape=x)
    _x = x
    _zeropadding_x = tf.keras.layers.ZeroPadding1D(padding=(0, 0))(x)
    x = tf.keras.layers.Conv1D(filters=64, kernel_size=1, strides=1, padding=""valid"", data_format=""channels_last"", dilation_rate=1, groups=1, use_bias=True, name=""conv1"")(_zeropadding_x)
    x = tf.keras.layers.BatchNormalization(axis=-1, epsilon=1e-05, momentum=0.9, center=True, scale=True, name=""bn1"")(x)
    x = tf.nn.relu(x)
    _zeropadding_x = tf.keras.layers.ZeroPadding1D(padding=(0, 0))(x)
    x = tf.keras.layers.Conv1D(filters=64, kernel_size=1, strides=1, padding=""valid"", data_format=""channels_last"", dilation_rate=1, groups=1, use_bias=True, name=""conv2"")(_zeropadding_x)
    x = tf.keras.layers.BatchNormalization(axis=-1, epsilon=1e-05, momentum=0.9, center=True, scale=True, name=""bn2"")(x)
    x = tf.nn.relu(x)
    _zeropadding_x = tf.keras.layers.ZeroPadding1D(padding=(0, 0))(x)
    x = tf.keras.layers.Conv1D(filters=64, kernel_size=1, strides=1, padding=""valid"", data_format=""channels_last"", dilation_rate=1, groups=1, use_bias=True, name=""conv3"")(_zeropadding_x)
    x = tf.keras.layers.BatchNormalization(axis=-1, epsilon=1e-05, momentum=0.9, center=True, scale=True, name=""bn3"")(x)
    x = tf.keras.activations.relu(x)
    _zeropadding_x = tf.keras.layers.ZeroPadding1D(padding=(0, 0))(x)
    x = tf.keras.layers.Conv1DTranspose(filters=128, kernel_size=1, strides=1, padding=""valid"", output_padding=0, data_format=""channels_last"", dilation_rate=8, use_bias=True, name=""conv4_mutated"")(x)

    x = x
    model = tf.keras.models.Model(inputs=_x, outputs=x)
    return model


def go():
    with tf.device('/CPU:0'):
        shape = [2, 3, 2048]
        _numpy = np.random.random(shape).astype(np.float32)
        tf_input = tf.convert_to_tensor(_numpy.transpose(0, 2, 1), dtype=tf.float32)
        tf_model = Model_HqTi1yjRFc7Dz1RLSJOvA9XX16R5Wp01(tf_input.shape[1:])
        tf_output = tf_model(tf_input)




go()
```


### Relevant log output

_No response_"
2335395287,69215,Aborted (core dumped) in `tf.raw_ops.FakeQuantWithMinMaxVarsPerChannelGradient`,closed,2024-06-05 09:40:24+00:00,2024-06-05T12:28:28Z,2024-06-05T12:28:24Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/69215,"['stat:awaiting response', 'type:bug', 'comp:ops', 'TF 2.16']","['@x0w3n,\r\nLooks like there is another issue raised for the same API mentioning that it is also aborted. This is a duplicate of issue [#66759](https://github.com/tensorflow/tensorflow/issues/66759). Can you please check and close this issue, since it is already being tracked there? \r\n\r\nThank you!\r\n', ""I've noticed this. Thank you!"", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69215"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69215"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

A crash is triggered when input some boundary values to the gradients or inputs parameter of the tf.raw_ops.FakeQuantWithMinMaxVarsPerChannelGradient function. the affected APIs are listed below:

1. tf.raw_ops.FakeQuantWithMinMaxVarsPerChannel
2. tf.raw_ops.FakeQuantWithMinMaxVarsPerChannelGradient
3. tf.quantization.fake_quant_with_min_max_vars_per_channel
4. tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

min_data = tf.constant([0.0, 1.0, 2.0])
max_data = tf.constant([1.0, 2.0, 3.0])
input_data = tf.random.normal(shape=(),dtype=tf.float32)
# crash
tf.raw_ops.FakeQuantWithMinMaxVarsPerChannel(inputs=input_data, min=0, max=3)
# crash
# tf.raw_ops.FakeQuantWithMinMaxVarsPerChannelGradient(gradients=input_data, inputs=input_data, min=2, max=2, num_bits=8, narrow_range=False, name=None)
# crash
# tf.quantization.fake_quant_with_min_max_vars_per_channel(inputs=input_data, min=2, max=2, num_bits=8, narrow_range=False, name=None)
# crash
# tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient(gradients=input_data,inputs=input_data, min=2, max=2, num_bits=8, narrow_range=False, name=None)
```


### Relevant log output

```shell
2024-06-05 09:38:08.909464: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-05 09:38:09.950624: F tensorflow/core/framework/tensor_shape.cc:356] Check failed: d >= 0 (0 vs. -1)
Aborted (core dumped)
```
"
2335542724,69219,Aborted (core dumped) in `tf.raw_ops.ThreadUnsafeUnigramCandidateSampler/LearnedUnigramCandidateSampler`,closed,2024-06-05 10:38:33+00:00,2024-06-06T08:35:51Z,2024-06-06T08:35:48Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/69219,"['type:bug', 'comp:ops', 'TF 2.16']","['Hi @x0w3n ,\r\n- I was able to reproduce the issue on Colab using TF v2.15 and TF-nightly ,Please find the [gist](https://colab.research.google.com/gist/Venkat6871/bb0860f8ca2f02755ff47c36b6857502/69219_2-15-nightly-v.ipynb) here for reference.\r\n\r\nThank you!\r\n', 'Thank you for your response.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69219"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69219"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

A crash is triggered when input some boundary values to the range_max parameter of the tf.raw_ops.ThreadUnsafeUnigramCandidateSampler/LearnedUnigramCandidateSampler function.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

true_classes = np.random.randint(0, 1000, size=(10, 1))
num_true = 1
num_sampled = 10
unique = True
range_max = (2 ** 32)
seed = 0
seed2 = 0

# crash
tf.raw_ops.ThreadUnsafeUnigramCandidateSampler(true_classes=true_classes, num_true=num_true, num_sampled=num_sampled, unique=unique, range_max=range_max, seed=seed, seed2=seed2)
# crash
# tf.raw_ops.LearnedUnigramCandidateSampler(true_classes=true_classes, num_true=num_true, num_sampled=num_sampled, unique=unique, range_max=range_max, seed=seed, seed2=seed2)
```


### Relevant log output

```shell
2024-06-05 10:33:44.105929: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-05 10:33:45.163653: F tensorflow/core/kernels/range_sampler.cc:183] Check failed: range < kint32max (4294967296 vs. 2147483647)
Aborted (core dumped)
```
"
2335563685,69221,Aborted (core dumped) in `tf.scatter_nd`,closed,2024-06-05 10:49:00+00:00,2024-06-10T06:03:18Z,2024-06-07T00:26:24Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/69221,"['type:bug', 'comp:ops', 'TF 2.16']","['Hi @x0w3n ,\r\n- I was able to reproduce the issue on Colab using TF v2.15 and TF-nightly ,Please find the [gist](https://colab.research.google.com/gist/Venkat6871/140c866714fb864890903cb3a5380a36/69221_2-15-nightly-v.ipynb) here for reference.\r\n\r\nThank you!', 'Thank you for your response.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69221"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69221"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Triggers crash when setting boundary values for the indices parameter of tf.scatter_nd.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

indices = tf.constant([[4], [3], [1], [7]], dtype=tf.int32)
updates = tf.constant([9, 10, 11, 12], dtype=tf.int32)
shape = tf.cast([8], dtype=tf.int32)
scatter_nd = tf.scatter_nd(tf.expand_dims(indices, 1), updates, shape)
```


### Relevant log output

```shell
2024-06-05 10:47:19.247456: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-05 10:47:20.277026: F tensorflow/core/framework/tensor_shape.cc:357] Check failed: d < dims() (1 vs. 1)
Aborted (core dumped)
```
"
2335656497,69229,Assertion failure in `tf.signal.irfft/irfft2d/irfft3d`,closed,2024-06-05 11:32:26+00:00,2024-06-06T08:34:17Z,2024-06-06T08:34:15Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/69229,"['type:bug', 'comp:ops', 'TF 2.16']","['Hi @x0w3n ,\r\n- I was able to reproduce the issue on Colab using TF v2.16.1 and TF-nightly ,Please find the [gist](https://colab.research.google.com/gist/Venkat6871/339ff14afb0d1eab6d1a3c0dbdc4697d/69229_2-16-1-nightly-v.ipynb) here for reference.\r\n\r\nThank you!', 'Thank you for your response.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69229"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69229"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Assertion failure when entering boundary values for tf.signal.irfft/irfft2d/irfft3d parameters and trigger crash

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

x = np.array([[[0]]])      
y = tf.signal.irfft(x)     # crash 
# y = tf.signal.irfft2d(x)   # crash
# y = tf.signal.irfft3d(x)   # crash
```


### Relevant log output

```shell
2024-06-05 11:32:13.365512: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
DUCC FFT c2r failed: 
bazel-out/k8-opt/bin/external/ducc/_virtual_includes/fft/ducc/src/ducc0/fft/fft1d_impl.h: 2948 (static Trpass<Tfs> ducc0::detail_fft::rfftpass<float>::make_pass(size_t, size_t, size_t, const Troots<Tfs> &, bool) [Tfs = float]):

Assertion failure
no zero-sized FFTs

Aborted (core dumped)
```
"
2335783775,69232,Aborted (core dumped) in `tf.compat.v1.image.draw_bounding_boxes`,closed,2024-06-05 12:32:45+00:00,2024-06-27T01:51:01Z,2024-06-27T01:50:59Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/69232,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.16']","['@x0w3n  I tried to replicate the issue reported using tf-nightly and faced the following error rather than core dumped issue. \r\n```\r\nInvalidArgumentError: {{function_node __wrapped__DrawBoundingBoxesV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} The rank of the images should be 4 [Op:DrawBoundingBoxesV2] name: \r\n```\r\nPlease find the gist [here](https://colab.research.google.com/gist/sushreebarsa/9dc92a428a14abd9e3a433dd95ab5d39/69232.ipynb#scrollTo=YUSZ3wQ5a9HV).\r\nThank you! ', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69232"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69232"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

A crash is triggered when tf.compat.v1.image.draw_bounding_boxes is given a specific input, the APIs affected by this are as follows：

1. tf.compat.v1.image.draw_bounding_boxes(images, boxes, colors=colors)
2. tf.raw_ops.DrawBoundingBoxesV2(images=images, boxes=boxes, colors=colors)
3. tf.raw_ops.DrawBoundingBoxes(images=images, boxes=boxes)
4. tf.image.draw_bounding_boxes(images, boxes, colors=colors)

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

images = tf.random.normal(shape=(2, 3, 4))
boxes = tf.random.normal(shape=(2, 2, 4))
colors = tf.random.normal(shape=(2, 4))

result = tf.compat.v1.image.draw_bounding_boxes(images, boxes, colors=colors)
# crash
# output = tf.raw_ops.DrawBoundingBoxesV2(images=images, boxes=boxes, colors=colors)
# crash
# output = tf.raw_ops.DrawBoundingBoxes(images=images, boxes=boxes)
# crash 
# result = tf.image.draw_bounding_boxes(images, boxes, colors=colors)
```


### Relevant log output

```shell
2024-06-05 12:32:06.850044: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-05 12:32:07.838677: F tensorflow/core/framework/tensor_shape.cc:357] Check failed: d < dims() (3 vs. 3)
Aborted (core dumped)
```
"
2336059910,69234,Efficientdet models do not work on hexagon delegate,closed,2024-06-05 14:19:44+00:00,2024-11-27T18:06:46Z,2024-11-27T18:06:43Z,arfaian,,https://github.com/tensorflow/tensorflow/issues/69234,"['stat:awaiting tensorflower', 'type:bug', 'comp:lite', 'type:performance', 'TFLiteHexagonDelegate', 'TF 2.16']","[""Hi @Hozzu ,\r\n\r\nI don't have a device with hexagon delegate so i tried  out your model on the neuron delegate by mediatek and it failed there also wit the error:\r\n`java.lang.IllegalArgumentException: Cannot copy from a TesorflowLite tensor (statefulPartitonedCall_2:1) with 400 bytes to a Java Buffer with 100 bytes.`\r\n\r\nCan you please provide your crash logs from the hexagon delegate?"", ""> Hi @Hozzu ,\r\n> \r\n> I don't have a device with hexagon delegate so i tried out your model on the neuron delegate by mediatek and it failed there also wit the error: `java.lang.IllegalArgumentException: Cannot copy from a TesorflowLite tensor (statefulPartitonedCall_2:1) with 400 bytes to a Java Buffer with 100 bytes.`\r\n> \r\n> Can you please provide your crash logs from the hexagon delegate?\r\n\r\nHello.\r\nIt does not crash.\r\nIt runs but the output value is invalid.\r\n\r\nWhen I use cpu or gpu delegate, the output values are valid.\r\nBut when I use hexagon delegate, the output value is different from the cpu and gpu ones and invalid.\r\n\r\nThe other models like yolov8 and mobilenet v2 work well on hexagon delegate.\r\nHowever, efficientdet which made from google does not work on the hexagon delegate.\r\n\r\n![image](https://github.com/user-attachments/assets/7eb49c64-4c87-45f2-a85f-1a4858749cd9)\r\n"", 'Hi @pkgoogle ,\r\n\r\nCan you please take a look ?', 'I also do not have a device that can properly reproduce this, @arfaian can you please take a look? Thanks.', ""Hi, @Hozzu\r\nThanks for raising this issue. Are you aware of the migration to [LiteRT](https://developers.googleblog.com/en/tensorflow-lite-is-now-litert/)? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: \r\nhttps://github.com/google-ai-edge/LiteRT/issues/61\r\n\r\nLet us know if you have any questions. Thanks.\r\n\r\n\r\n\r\n"", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69234"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69234"">No</a>\n']","**System information**
Tensorflow lite v2.16.1
Hexagon library 1.20.0.1

**Standalone code to reproduce the issue**
I generated efficientdet normal and lite int8 models from automl github.
https://github.com/google/automl/blob/master/efficientdet/tf2/tutorial.ipynb

The models work well on CPU, but do not work on hexagon delegate.
When I put the same input value, the output of the hexagon delegate is invalid value.

**Any other info / logs**
I attached the efficientdet lite0 int8 model as a sample.
https://1drv.ms/u/s!AnqHHtrBqwyUg8N31bJmQjMmrF9QnA?e=lmvIdI
"
2336460401,69252,Unable to build TensorFlowLite GPU Delegate for Android,closed,2024-06-05 17:31:46+00:00,2024-09-20T12:06:13Z,2024-06-21T17:41:24Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/69252,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.15']","['@cpappasILMX Please make sure that Android NDK has a version compatible with your target Android API level.\r\nBazel build system. Could you check TensorFlow [documentation](https://www.tensorflow.org/lite/api_docs/java/org/tensorflow/lite/gpu/package-summary) for specific version requirements for these tools for building the GPU Delegate?\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', 'I was able to build the gpu delegate using NDK version 25 with NDK API Level set to 26.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69252"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69252"">No</a>\n', '> I was able to build the gpu delegate using NDK version 25 with NDK API Level set to 26.\r\n\r\ncan u share details how it work to compile for gpu ? not wokring for me . can u share ur text file may be thanks.']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.15

### Custom code

No

### OS platform and distribution

Android

### Mobile device

Android

### Python version

3.9

### Bazel version

7.1.2

### GCC/compiler version

Apple Clang 15.0.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

On a Mac machine, I am trying to build the tensorflow-lite gpu delegate for android. I have followed the build instructions without docker found at https://www.tensorflow.org/lite/android/lite_build to build tflite for android and was successful. I attempted to build the native gpu delegate as a shared library as well following the instructions found at https://www.tensorflow.org/lite/android/delegates/gpu_native. The goal is to build the delegate as a shared library to simply copy over into my own project.

The problem appears to be when building a dependency of the delegate, dependency declarations are missing.

### Standalone code to reproduce the issue

```shell
TF_LITE_TARGET_NDK_VERSION_DIRECTORY=$(ls -1 /Users/$USER/Library/Android/sdk/ndk/ | tail -n 1)
export ANDROID_NDK_HOME=""/Users/$USER/Library/Android/sdk/ndk/26.3.11579264""
export ANDROID_SDK_API_LEVEL=""34""
export ANDROID_NDK_API_LEVEL=""26""

# AndroidConfiguration is a simple text file to auto fill the queries from the provided configure script
./configure < AndroidConfiguration

bazel build -c opt --config android_arm64 tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so
```


### Relevant log output

```shell
/private/var/tmp/_bazel_user/897db67e3896f5db6d832aa86833dcea/external/XNNPACK/BUILD.bazel:2884:19: Compiling src/operators/convolution-nchw.c failed: undeclared inclusion(s) in rule '@XNNPACK//:operators':
this rule is missing dependency declarations for the following files included by 'src/operators/convolution-nchw.c':
  'external/androidndk/toolchains/llvm/prebuilt/darwin-x86_64/lib/clang/17/include/limits.h'
  'external/androidndk/toolchains/llvm/prebuilt/darwin-x86_64/lib/clang/17/include/float.h'
  'external/androidndk/toolchains/llvm/prebuilt/darwin-x86_64/lib/clang/17/include/stdbool.h'
  'external/androidndk/toolchains/llvm/prebuilt/darwin-x86_64/lib/clang/17/include/stddef.h'
  'external/androidndk/toolchains/llvm/prebuilt/darwin-x86_64/lib/clang/17/include/stdint.h'
  'external/androidndk/toolchains/llvm/prebuilt/darwin-x86_64/lib/clang/17/include/stdarg.h'
  'external/androidndk/toolchains/llvm/prebuilt/darwin-x86_64/lib/clang/17/include/inttypes.h'
Target //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so failed to build
```
"
2336790121,69266,Build from source C doesn't produce .tar.gz archive,closed,2024-06-05 20:37:39+00:00,2024-06-14T13:09:46Z,2024-06-14T13:09:43Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/69266,"['stat:awaiting response', 'type:bug', 'type:build/install', 'subtype: ubuntu/linux', 'TF 2.16']","['@erik-fauna Bazel allows for conditional build rules based on configurations like target architecture. It\'s possible the archive creation step is defined only for specific architectures (e.g., amd64). Kindly search for conditional statements (""if"", ""select"") within the Bazel build files in the lib_package folder.\r\n\r\n```\r\nbazel build --verbose_failures //lib_package:your_target\r\n\r\n```\r\nAlso try to replace `your_target` with the specific build target defined in the Bazel files.\r\nThank you!', ""I see that there are some differences in the build commands defined in the lib_package, so I've made some adjustments to my build line. It should finish building by the morning, so I can report back then. I added the verbose_failures flag as well."", '@erik-fauna Yes, please! Let us know kindly.\r\nThank you!', 'This worked to get the tar.gz archive. `../bazel-6.5.0-linux-arm64 build --verbose_failures --jobs=12 --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=1"" -c opt //tensorflow/tools/lib_package:libtensorflow` For anyone who comes across this looking for number of jobs, bazel maxes out at 8. \r\n\r\nI guess rather than just building //tensorflow:libtensorflow.so, the entire library package was needed. I will eventually go and checkout 2.15 and see if the package for that builds successfully (with bazel 6.1.0), because that failed when trying to build the .so file directly.', '@erik-fauna Please let us know if the issue got resolved and if not then kindly share the error log to analyze the issue?\r\nThank you!', ""Using the code from my previous comment, the bug that I specifically raised this issue about is resolved. I haven't tested the other packages to confirm those work, but will raise another issue if they don't, as it's not exactly the same issue seen here."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69266"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69266"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.16

### Custom code

No

### OS platform and distribution

Linux Ubuntu 20.04 (arm64)

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

6.5.0

### GCC/compiler version

gcc

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

The readme within the the [lib_package](https://github.com/tensorflow/tensorflow/tree/r2.16/tensorflow/tools/lib_package) folder indicates that a tar.gz archive should be created upon building with bazel to finish installation. Currently trying to build on arm64 architecture (jetson orin) as there are no docker images on dockerhub for Tensorflow C with that architecture. I would have preferred to use 2.15 to stay the same as the version used by the [amd64 desktops](https://www.tensorflow.org/install/lang_c), but that failed to build because of stubs being too large (using bazel 6.1.0, gcc, cxxopt flag used).

There are no logs because the build claims it completed successfully, there are the usual shared library files within `bazel-bin/tensorflow`, but porting them and all the dependencies to the right locations sounds like a nightmare.

Any thoughts why the archive isn't being built?

### Standalone code to reproduce the issue

```shell
cd ~/workspace
wget https://github.com/bazelbuild/bazel/releases/download/6.5.0/bazel-6.5.0-linux-arm64
chmod +x bazel-6.5.0-linux-arm64
git clone https://github.com/tensorflow/tensorflow
cd ./tensorflow
git checkout r2.16 #may need to change the number of jobs that can run at once
../bazel-6.5.0-linux-arm64 build --jobs=12 --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=1"" -c opt //tensorflow:libtensorflow.so //tensorflow:libtensorflow_cc.so //tensorflow:libtensorflow_framework.so //tensorflow:install_headers
```


### Relevant log output

_No response_"
2337061979,69277,Aborted (core dumped) in `tf.raw_ops.ResourceSparseApplyMomentum` ,closed,2024-06-06 00:45:15+00:00,2024-06-06T08:36:38Z,2024-06-06T08:36:36Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/69277,"['type:bug', 'comp:ops', 'TF 2.16']","['Hi @x0w3n ,\r\n- I was able to reproduce the issue on Colab using TF v2.15 and TF-nightly ,Please find the [gist](https://colab.research.google.com/gist/Venkat6871/3803d5ae106ddd0467235c62249970d2/69277_2-15-nightly-v.ipynb) here for reference.\r\n\r\nThank you!', 'Thank you for your response.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69277"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69277"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

On specific input, tf.raw_ops.ResourceSparseApplyMomentum triggers ""Aborted (core dumped)"".
tf.raw_ops.ResourceApplyMomentum also has the same crash.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

var = tf.Variable([1.0, 2.0, 3.0])
accum = tf.Variable([0.1, 0.2, 0.3], dtype=tf.complex64) 
accum2 = tf.Variable([0, 1.2, -3.3], dtype=tf.complex64) 
lr = 0.01
grad = tf.constant([0.1, 0.2, 0.3])
momentum = 0.9
# crash
tf.raw_ops.ResourceSparseApplyMomentum(var=var.handle,
    accum=accum.handle,
    grad=grad,
    lr=lr,
    indices=tf.constant([1,2,2]),
    momentum=0.1,
    use_locking=False,
    use_nesterov=False,
    name=None)
# crash
# tf.raw_ops.ResourceApplyMomentum(var=var.handle, accum=accum.handle, lr=lr, grad=grad, momentum=momentum)
```


### Relevant log output

```shell
2024-06-06 00:45:01.131952: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-06 00:45:02.203082: F tensorflow/core/framework/tensor.cc:844] Check failed: dtype() == expected_dtype (8 vs. 1) float expected, got complex64
Aborted (core dumped)
```
"
2337089220,69280,Aborted (core dumped) in `tf.raw_ops.ResourceApplyPowerSign`,closed,2024-06-06 01:05:06+00:00,2024-06-06T08:36:54Z,2024-06-06T08:36:52Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/69280,"['type:bug', 'comp:ops', 'TF 2.16']","['Hi @x0w3n ,\r\n- I was able to reproduce the issue on Colab using TF v2.15 and TF-nightly ,Please find the [gist](https://colab.research.google.com/gist/Venkat6871/ed408a56233362e9701c61bd56e5d7ea/69280_2-15-nightly.ipynb) here for reference.\r\n\r\nThank you!', 'Thank you for your response.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69280"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69280"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

On specific input, tf.raw_ops.ResourceApplyPowerSign triggers ""Aborted (core dumped)"". We ran the code on colab's latest TensorFlow Nightly, which also triggers the crash. The cause of the crash may be the grad parameter.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

var = tf.Variable([1.0, 2.0, 3.0])
accum = tf.Variable([0.1, 0.2, 0.3], dtype=tf.complex64) 
accum2 = tf.Variable([0, 1.2, -3.3], dtype=tf.complex64) 
lr = 0.01
grad = tf.constant([0.1, 0.2, 0.3])
momentum = 0.9

# crash
tf.raw_ops.ResourceApplyPowerSign(var=var.handle, m=accum.handle, lr=lr, logbase=lr,
                                  sign_decay=lr, beta=lr, grad=grad,
                                  use_locking=False)
```


### Relevant log output

```shell
2024-06-06 01:04:36.157948: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-06 01:04:37.219223: F tensorflow/core/framework/tensor.cc:844] Check failed: dtype() == expected_dtype (8 vs. 1) float expected, got complex64
Aborted (core dumped)
```
"
2337118102,69288,Aborted (core dumped) in `tf.raw_ops.ResourceSparseApplyProximalAdagrad`,closed,2024-06-06 01:28:34+00:00,2024-06-07T00:28:15Z,2024-06-07T00:28:11Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/69288,"['type:bug', 'comp:ops', 'TF 2.16']","['Hi @x0w3n ,\r\n- I was able to reproduce the issue on Colab using TF v2.15 and TF-nightly ,Please find the [gist](https://colab.research.google.com/gist/Venkat6871/a279ab73a9514adbe2a349c98bff883b/69288_2-15-nightly.ipynb) here for reference.\r\n\r\nThank you!', 'Thank you for your response.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69288"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69288"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

On specific input, tf.raw_ops.ResourceApplyCenteredRMSProp/tf.raw_ops.ResourceSparseApplyCenteredRMSProp triggers ""Aborted (core dumped)"". We ran the code on colab's latest TensorFlow Nightly, which also triggers the crash. The cause of the crash may be the grad parameter. 

tf.raw_ops.ResourceApplyProximalAdagrad also has the same crash.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

var = tf.Variable([1.0, 2.0, 3.0])
accum = tf.Variable([0.1, 0.2, 0.3], dtype=tf.complex64) 
accum2 = tf.Variable([0, 1.2, -3.3], dtype=tf.complex64) 
lr = 0.01
grad = tf.constant([0.1, 0.2, 0.3])
momentum = 0.9

# crash
tf.raw_ops.ResourceSparseApplyProximalAdagrad(var=var.handle, accum=accum.handle, lr=lr,
                                              l1=0.1, l2=0.2, grad=grad,
                                              indices=tf.constant([1,2,2]),
                                              use_locking=False)
# crash
# tf.raw_ops.ResourceApplyProximalAdagrad(var=var.handle, accum=accum.handle, lr=lr, l1=1, 
#                                         l2=1, grad=grad,
#                                         use_locking=False)
```


### Relevant log output

```shell
2024-06-06 01:28:02.747576: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-06 01:28:02.780112: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-06 01:28:03.819782: F tensorflow/core/framework/tensor.cc:844] Check failed: dtype() == expected_dtype (8 vs. 1) float expected, got complex64
Aborted (core dumped)
```
"
2337120533,69289,Aborted (core dumped) in `tf.raw_ops.ResourceApplyAdaMax/tf.raw_ops.ResourceApplyAdam/tf.raw_ops.ResourceApplyAdamWithAmsgrad`,closed,2024-06-06 01:31:52+00:00,2024-07-04T01:51:40Z,2024-07-04T01:51:29Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/69289,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.16']","['@x0w3n I was able to replicate the issue reported [here](https://colab.research.google.com/gist/sushreebarsa/f3cf5f228a77377fac2c014411ea6e76/69289.ipynb). The accum and accum2 variables are defined as tf.complex64 while they should be tf.float32. Could you please let us know if it helps?\r\nThank You!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69289"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69289"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

On specific input, tf.raw_ops.ResourceApplyAdaMax/tf.raw_ops.ResourceApplyAdam/tf.raw_ops.ResourceApplyAdamWithAmsgrad triggers ""Aborted (core dumped)"". We ran the code on colab's latest TensorFlow Nightly, which also triggers the crash. The cause of the crash may be the grad parameter.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

var = tf.Variable([1.0, 2.0, 3.0])
accum = tf.Variable([0.1, 0.2, 0.3], dtype=tf.complex64) 
accum2 = tf.Variable([0, 1.2, -3.3], dtype=tf.complex64) 
lr = 0.01
grad = tf.constant([0.1, 0.2, 0.3])
momentum = 0.9

# crash
tf.raw_ops.ResourceApplyAdaMax(var=var.handle, m=accum.handle, v=accum2.handle, beta1_power=10,
                               lr=lr, beta1=1, beta2=1,
                               epsilon=0.9, grad=grad,
                               use_locking=False)

# crash
# tf.raw_ops.ResourceApplyAdam(var=var.handle, m=accum.handle, v=accum2.handle, beta1_power=10,beta2_power=10,
#                                lr=lr, beta1=1, beta2=1,
#                                epsilon=0.9, grad=grad,
#                                use_locking=False, use_nesterov=False)

# crash
# tf.raw_ops.ResourceApplyAdamWithAmsgrad(var=var.handle, m=accum.handle, v=accum2.handle,vhat=var.handle,
#                                         beta1_power=10,
#                                         beta2_power=10, lr=lr,
#                                         beta1=1, beta2=2,
#                                         epsilon=0.9, grad=grad,
#                                         use_locking=False)
```


### Relevant log output

```shell
2024-06-06 01:30:44.494465: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-06 01:30:44.527542: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-06 01:30:45.578367: F tensorflow/core/framework/tensor.cc:844] Check failed: dtype() == expected_dtype (8 vs. 1) float expected, got complex64
Aborted (core dumped)
```
"
2337122153,69290,Aborted (core dumped) in `tf.raw_ops.ResourceApplyAddSign`,closed,2024-06-06 01:34:07+00:00,2024-06-10T06:04:08Z,2024-06-07T00:27:51Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/69290,"['type:bug', 'comp:ops', 'TF 2.16']","['Hi @x0w3n ,\r\n- I was able to reproduce the issue on Colab using TF v2.15 and TF-nightly ,Please find the [gist](https://colab.research.google.com/gist/Venkat6871/e3f79a407fd9bb3411ccda2d94893efe/69290_2-15-nightly-v.ipynb) here for reference.\r\n\r\nThank you!', 'Thank you for your response.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69290"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69290"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

On specific input, tf.raw_ops.ResourceApplyAddSign triggers ""Aborted (core dumped)"". We ran the code on colab's latest TensorFlow Nightly, which also triggers the crash. The cause of the crash may be the grad parameter.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

var = tf.Variable([1.0, 2.0, 3.0])
accum = tf.Variable([0.1, 0.2, 0.3], dtype=tf.complex64) 
accum2 = tf.Variable([0, 1.2, -3.3], dtype=tf.complex64) 
lr = 0.01
grad = tf.constant([0.1, 0.2, 0.3])
momentum = 0.9

# crash
tf.raw_ops.ResourceApplyAddSign(var=var.handle, m=accum.handle, lr=lr, alpha=1,
                                sign_decay=1, beta=1, grad=grad,
                                use_locking=False)
```


### Relevant log output

```shell
2024-06-06 01:33:21.409990: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-06 01:33:21.443054: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-06 01:33:22.498992: F tensorflow/core/framework/tensor.cc:844] Check failed: dtype() == expected_dtype (8 vs. 1) float expected, got complex64
Aborted (core dumped)
```
"
2337823255,69307,The signatures in SavedModel do not contain serving_default when a subclass of the keras model has multiple inputs,closed,2024-06-06 09:43:20+00:00,2024-07-03T20:41:10Z,2024-07-03T00:04:30Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/69307,"['stat:awaiting response', 'type:bug', 'comp:apis', 'TF 2.16']","[""@ian-huu One workaround could be to specify the input names during saving using the tf.saved_model.save API with the input argument. This ensures that all your model's inputs are included in the serving_default signature.\r\nThank you!"", '> @ian-huu One workaround could be to specify the input names during saving using the tf.saved_model.save API with the input argument. This ensures that all your model\'s inputs are included in the serving_default signature. Thank you!\r\n\r\nDo you mean to do it this way? It seems to be working.\r\n```python\r\nclass Model3(keras.Model):\r\n    def __init__(self):\r\n        super().__init__()\r\n\r\n        self.fc1 = keras.layers.Dense(8)\r\n        self.fc2 = keras.layers.Dense(1)\r\n\r\n    def build(self, input_shape):\r\n        self.fc1.build((None, sum([shape[1] for shape in input_shape])))\r\n        self.fc2.build((None, 8))\r\n\r\n    @tf.function\r\n    def call(self, inputs, **kwargs):\r\n        concat_inputs = keras.ops.concatenate(inputs, axis=1)\r\n        out1 = self.fc1(concat_inputs)\r\n        out2 = self.fc2(out1)\r\n        return out2\r\n\r\n\r\nmodel3 = Model3()\r\nmodel3.build([(None, 8), (None, 8)])\r\ntf.saved_model.save(\r\n    model3,\r\n    f""{path}/model3"",\r\n    signatures=model3.call.get_concrete_function(\r\n        (\r\n            tf.TensorSpec(shape=(None, 8), dtype=tf.float32),\r\n            tf.TensorSpec(shape=(None, 8), dtype=tf.float32),\r\n        )\r\n    ),\r\n)\r\n\r\nloaded3 = tf.saved_model.load(f""{path}/model3"")\r\nprint(f""loaded3: {loaded3.signatures}"")\r\n\r\n# got:\r\n# loaded3: _SignatureMap({\'serving_default\': <ConcreteFunction (*, inputs: TensorSpec(shape=(None, 8), dtype=tf.float32, name=\'inputs\'), inputs_1: TensorSpec(shape=(None, 8), dtype=tf.float32, name=\'inputs_1\')) -> Dict[[\'output_0\', TensorSpec(shape=(None, 1), dtype=tf.float32, name=\'output_0\')]] at 0x7F2CB1FF4190>})\r\n```\r\n\r\nHowever, it seems there is another problem. The loaded SavedModel does not have attributes like `trainable_variables` and `__call__` anymore.\r\n\r\n```python\r\n# for all loaded1, loaded2, loaded3\r\nprint(loaded1.trainable_variables)\r\n# got: AttributeError: \'_UserObject\' object has no attribute \'trainable_variables\'.\r\n\r\nprint(loaded1.__call__)\r\n# got: AttributeError: \'_UserObject\' object has no attribute \'__call__\'.\r\n```\r\n\r\nAnd if I directly call model3.call, an error occurs, even though I manage to obtain the result.\r\n```python\r\nprint(loaded3.call((tf.zeros((1, 8)), tf.zeros((1, 8)))))\r\n\r\n```\r\ngot:\r\n```\r\ntf.Tensor([[0.]], shape=(1, 1), dtype=float32)\r\nException ignored in: <function AtomicFunction.__del__ at 0x72f6cf3a7760>\r\nTraceback (most recent call last):\r\n  File ""***/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py"", line 291, in __del__\r\nTypeError: \'NoneType\' object is not subscriptable\r\n```\r\n', '@ian-huu Could you try to use tf.keras.models.load_model() to load the model and let us know? Please make sure that you are using the latest TF version?\r\nThank you!', '> @ian-huu Could you try to use tf.keras.models.load_model() to load the model and let us know? Please make sure that you are using the latest TF version? Thank you!\r\n\r\n@sushreebarsa It seems that `tf.keras.models.load_model` supports only the Keras or H5 format, not the TensorFlow SavedModel format:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File ""test.py"", line 13, in <module>\r\n    loaded1 = tf.keras.models.load_model(f""{path}/model1"")\r\n  File ""**/python3.10/site-packages/keras/src/saving/saving_api.py"", line 193, in load_model\r\n    raise ValueError(\r\nValueError: File format not supported: filepath=/tmp/**/model1. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(/tmp/**/model1, call_endpoint=\'serving_default\')` (note that your `call_endpoint` might have a different name).\r\n```\r\n\r\nAnd I tried `loaded3 = keras.layers.TFSMLayer(f""{path}/model3"", call_endpoint=\'serving_default\')`, but it didn\'t work either.\r\n```\r\nTraceback (most recent call last):\r\n  File ""test.py"", line 72, in <module>\r\n    loaded3 = keras.layers.TFSMLayer(f""{path}/model3"", call_endpoint=\'serving_default\')\r\n  File ""**/python3.10/site-packages/keras/src/export/export_lib.py"", line 731, in __init__\r\n    raise ValueError(\r\nValueError: The endpoint \'serving_default\' is neither an attribute of the reloaded SavedModel, nor an entry in the `signatures` field of the reloaded SavedModel. Select another endpoint via the `call_endpoint` argument. Available endpoints for this SavedModel: []\r\n```\r\n', 'I noticed that TensorFlow released version 2.17.0rc0 and gave it a try, the issue remains unresolved. 😕', ""@ian-huu There are two SavedModel formats: legacy and the new high-level format. The error message indicates you're dealing with the legacy format, which isn't compatible with load_model. Please refer this [guide](https://www.tensorflow.org/guide/saved_model) SavedModel format.\r\nThank you!"", '> @ian-huu There are two SavedModel formats: legacy and the new high-level format. The error message indicates you\'re dealing with the legacy format, which isn\'t compatible with load_model. Please refer this [guide](https://www.tensorflow.org/guide/saved_model) SavedModel format. Thank you!\r\n\r\nI believe the term ""legacy"" refers to the SavedModel itself. According to the [Keras 3 migration guide](https://keras.io/guides/migrating_to_keras_3/#saving-a-model-in-the-tf-savedmodel-format), support for SavedModel has been removed from the `tf.keras.models.save_model` API, resulting in an error:\r\n\r\n```\r\ntf.keras.models.save_model(model3, f""{path}/model3"")\r\n  File ""**/python3.10/site-packages/keras/src/saving/saving_api.py"", line 106, in save_model\r\n    raise ValueError(\r\nValueError: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=/tmp/**/model3\r\n```\r\n', ""The migration document suggests that I can use `model.export(filepath)` to save a SavedModel, and this method seems to work properly.\r\n\r\nHowever, I still need a new process to support fine-tuning of the SavedModel because this [guide](https://www.tensorflow.org/guide/saved_model#basic_fine-tuning) doesn't work anymore."", '@tilakrayal I was able to replicate the issue reported [here](https://colab.research.google.com/gist/sushreebarsa/888c6010aa9f9957f66b6503b5ee7f14/69307.ipynb). Please have a look at this issue.\r\nThank you!', 'The Keras team should triage the issue this week', ""Hi @ian-huu \r\n\r\nI'm from the Keras team!\r\n\r\nWould it be possible for you to fine-tune the model first and then export it?\r\n\r\nIn general, please use [keras.io guides](https://keras.io/guides/) if you're working with Keras 3.\r\n"", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69307"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69307"">No</a>\n', '@ian-huu , a fix has been pushed. You can get it by uninstalling `keras` and installing `keras-nightly`.\r\n\r\nNote that for whatever reason, TF changes the signature of the function. The inputs are flattened, made keyword arguments and called `inputs`, `inputs_0`, `inputs_1` etc.\r\n\r\n```python\r\noutputs = restored_model.signatures[""serving_default""](inputs=x, inputs_1=y)[""output_0""]\r\n```']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.16.1

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.1

### Mobile device

_No response_

### Python version

3.10.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

The code below illustrates that when a Keras model has multiple inputs, the tf.saved_model does not function correctly, resulting in an empty signatures field.

### Standalone code to reproduce the issue

```shell
import tempfile

import keras
import tensorflow as tf

path = tempfile.mkdtemp()

model1 = keras.models.Sequential([keras.layers.Dense(8), keras.layers.Dense(1)])
model1.build((None, 16))
tf.saved_model.save(model1, f""{path}/model1"")
loaded1 = tf.saved_model.load(f""{path}/model1"")
print(f""loaded1: {loaded1.signatures}"")


class Model2(keras.Model):
    def __init__(self):
        super().__init__()

        self.fc1 = keras.layers.Dense(8)
        self.fc2 = keras.layers.Dense(1)

    def call(self, inputs, **kwargs):
        out1 = self.fc1(inputs)
        out2 = self.fc2(out1)
        return out2


model2 = Model2()
model2.build((None, 16))
tf.saved_model.save(model2, f""{path}/model2"")
loaded2 = tf.saved_model.load(f""{path}/model2"")
print(f""loaded2: {loaded2.signatures}"")


class Model3(keras.Model):
    def __init__(self):
        super().__init__()

        self.fc1 = keras.layers.Dense(8)
        self.fc2 = keras.layers.Dense(1)

    def build(self, input_shape):
        self.fc1.build((None, sum([shape[1] for shape in input_shape])))
        self.fc2.build((None, 8))

    def call(self, inputs, **kwargs):
        concat_inputs = keras.ops.concatenate(inputs, axis=1)
        out1 = self.fc1(concat_inputs)
        out2 = self.fc2(out1)
        return out2


model3 = Model3()
model3.build([(None, 8), (None, 8)])
tf.saved_model.save(model3, f""{path}/model3"")

loaded3 = tf.saved_model.load(f""{path}/model3"")
print(f""loaded3: {loaded3.signatures}"")
```


### Relevant log output

```shell
loaded1: _SignatureMap({'serving_default': <ConcreteFunction (*, inputs: TensorSpec(shape=(None, 16), dtype=tf.float32, name='inputs')) -> Dict[['output_0', TensorSpec(shape=(None, 1), dtype=tf.float32, name='output_0')]] at 0x7A4E8429C8E0>})
python3.10/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'model2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
loaded2: _SignatureMap({'serving_default': <ConcreteFunction (*, inputs: TensorSpec(shape=(None, 16), dtype=tf.float32, name='inputs')) -> Dict[['output_0', TensorSpec(shape=(None, 1), dtype=tf.float32, name='output_0')]] at 0x7A4E841D4A00>})
loaded3: _SignatureMap({})
```
"
2339167973,69340,Title: TensorFlow/Keras Integration Error: A KerasTensor cannot be used as input to a TensorFlow function,closed,2024-06-06 21:16:12+00:00,2024-08-22T07:18:18Z,2024-06-25T01:51:06Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/69340,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'TF 2.13']","['@ShoumitroC Could you try to use  keras.layers.Lambda layer that allows you to define a custom function using a Python lambda expression that can operate on KerasTensors within the model building process?\r\nPlease upgrade to the latest TF version and if the issue still persists then kindly provide the standalone code to replicate this issue?\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69340"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69340"">No</a>\n', 'Can you please try disabling the eager execution?\r\n\r\n_from tensorflow.python.framework.ops import disable_eager_execution\r\ndisable_eager_execution()_\r\n\r\n']","### Issue type

Build/Install

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

Mac OS x86-64

### Mobile device

Macbook

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I'm working on an image processing project using InsightFace and OpenNSFW2. I'm encountering an error with TensorFlow and Keras integration. When I try to use tf.pad on a tensor, I get the following error:

ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:



### Standalone code to reproduce the issue

```shell
ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:

x = Input(...)
...
tf_fn(x)  # Invalid.


I've tried wrapping tf.pad in a custom layer as suggested, but I'm still getting the error. Here's the relevant code snippet:

class MyLayer(Layer):
    def call(self, x):
        return tf.pad(x, [[0, 0], [3, 3], [3, 3], [0, 0]], ""CONSTANT"")

# Usage
x = MyLayer()(x)


Could someone please help me understand what I'm doing wrong and how to fix it?

Thank you!
```


### Relevant log output

_No response_"
2341720647,69431,tflite model maker not install ,closed,2024-06-08 16:12:29+00:00,2024-11-25T22:47:49Z,2024-07-09T01:52:38Z,sawantkumar,,https://github.com/tensorflow/tensorflow/issues/69431,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'TFLiteModelMaker']","['Hi **@ALAZZURRI** ,\r\n- I was able to reproduce same issue. here i am providing screenshots for reference.\r\n<img width=""1495"" alt=""image"" src=""https://github.com/tensorflow/tensorflow/assets/147127861/3c23b9e9-799f-4de9-a4f7-4ef57b2adce0"">\r\n<img width=""1495"" alt=""image (2)"" src=""https://github.com/tensorflow/tensorflow/assets/147127861/b32a72fd-2822-442a-9e33-b95b7a31e50c"">\r\nThank you!', 'i am having the same issue please help urgently', 'Hi @ALAZZURRI , \r\n\r\nThis issue is unlikely to be resolved soon. However there are few option that you can explore like MediaPipe Model Maker.\r\nPlease look at [this](https://github.com/tensorflow/tensorflow/issues/62658) old issue for more details.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69431"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69431"">No</a>\n', ""I'm having the same issue installing tflite model maker on WSL2 windows 11. Has anyone found a solution?""]","i want install tflite-model-maker but i face issue when install 
i do this 

1. install python 3.12.4
2. create Virtual Environments and Activate  
3.  inside env use "" pip install tflite-model-maker""

env_name>pip install tflite-model-maker
Collecting tflite-model-maker
  Using cached tflite_model_maker-0.4.3-py3-none-any.whl.metadata (5.4 kB)
Collecting tf-models-official==2.3.0 (from tflite-model-maker)
  Using cached tf_models_official-2.3.0-py2.py3-none-any.whl.metadata (1.3 kB)
Collecting numpy<1.23.4,>=1.17.3 (from tflite-model-maker)
  Using cached numpy-1.23.3.tar.gz (10.7 MB)
  Installing build dependencies ... done
  Getting requirements to build wheel ... error
  error: subprocess-exited-with-error

  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [33 lines of output]
      Traceback (most recent call last):
        File ""C:\Users\aalrahahleh\AppData\Local\Programs\Python\Python312\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 353, in <module>
          main()
        File ""C:\Users\aalrahahleh\AppData\Local\Programs\Python\Python312\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 335, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        File ""C:\Users\aalrahahleh\AppData\Local\Programs\Python\Python312\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 112, in get_requires_for_build_wheel
          backend = _build_backend()
                    ^^^^^^^^^^^^^^^^
        File ""C:\Users\aalrahahleh\AppData\Local\Programs\Python\Python312\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py"", line 77, in _build_backend
          obj = import_module(mod_path)
                ^^^^^^^^^^^^^^^^^^^^^^^
        File ""C:\Users\aalrahahleh\AppData\Local\Programs\Python\Python312\Lib\importlib\__init__.py"", line 90, in import_module
          return _bootstrap._gcd_import(name[level:], package, level)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        File ""<frozen importlib._bootstrap>"", line 1387, in _gcd_import
        File ""<frozen importlib._bootstrap>"", line 1360, in _find_and_load
        File ""<frozen importlib._bootstrap>"", line 1310, in _find_and_load_unlocked
        File ""<frozen importlib._bootstrap>"", line 488, in _call_with_frames_removed
        File ""<frozen importlib._bootstrap>"", line 1387, in _gcd_import
        File ""<frozen importlib._bootstrap>"", line 1360, in _find_and_load
        File ""<frozen importlib._bootstrap>"", line 1331, in _find_and_load_unlocked
        File ""<frozen importlib._bootstrap>"", line 935, in _load_unlocked
        File ""<frozen importlib._bootstrap_external>"", line 995, in exec_module
        File ""<frozen importlib._bootstrap>"", line 488, in _call_with_frames_removed
        File ""C:\Users\aalrahahleh\AppData\Local\Temp\pip-build-env-e6sy9x22\overlay\Lib\site-packages\setuptools\__init__.py"", line 16, in <module>
          import setuptools.version
        File ""C:\Users\aalrahahleh\AppData\Local\Temp\pip-build-env-e6sy9x22\overlay\Lib\site-packages\setuptools\version.py"", line 1, in <module>
          import pkg_resources
        File ""C:\Users\aalrahahleh\AppData\Local\Temp\pip-build-env-e6sy9x22\overlay\Lib\site-packages\pkg_resources\__init__.py"", line 2172, in <module>
          register_finder(pkgutil.ImpImporter, find_on_path)
                          ^^^^^^^^^^^^^^^^^^^
      AttributeError: module 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?
      [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
"
2342401243,69448,AttributeError: 'ModelCheckpoint' object has no attribute '_implements_train_batch_hooks' in MoViNet Streaming Model Training,closed,2024-06-09 17:48:09+00:00,2024-06-25T01:51:06Z,2024-06-25T01:51:03Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/69448,"['stat:awaiting response', 'type:bug', 'stale', 'comp:model', 'TF 2.16']","['@yuvch98 Could you try creating a new virtual environment to avoid conflicts with existing project dependencies and if you still face the issue then please post this issue on [models](https://github.com/tensorflow/models/issues?q=is%3Aissue+is%3Aopen) repository for further assistance.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69448"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69448"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.16.1

### Custom code

No

### OS platform and distribution

Google Colab

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I encountered an AttributeError while trying to fit the model using the MoViNet Streaming Model Training and Inference notebook provided in the TensorFlow Model Garden repository. The specific error message is as follows:
![image](https://github.com/tensorflow/tensorflow/assets/109518434/6dd33b9e-4524-4031-b1bb-0576308bff6d)


in addition, there is a minor adjustment needed to be done in this code:
![image](https://github.com/tensorflow/tensorflow/assets/109518434/d597141d-6359-4e8d-a299-439fb75c458e)


### Standalone code to reproduce the issue

```shell
The issue can be reproduced using the notebook from the official TensorFlow Models GitHub repository:

https://github.com/tensorflow/models/blob/f9fdc4faef47af76351204b6d8df576f0e79baab/official/projects/movinet/movinet_streaming_model_training_and_inference.ipynb
```


### Relevant log output

```shell
AttributeError                            Traceback (most recent call last)
<ipython-input-18-49dc73e1e0f6> in <cell line: 1>()
----> 1 results = model.fit(train_ds,
      2                     validation_data=val_ds,
      3                     epochs=2,
      4                     validation_freq=1,
      5                     verbose=1,

1 frames
/usr/local/lib/python3.10/dist-packages/tf_keras/src/callbacks.py in <genexpr>(.0)
    243             getattr(cb, ""_supports_tf_logs"", False)
    244             for cb in self.callbacks
--> 245             if cb._implements_train_batch_hooks()
    246             or cb._implements_test_batch_hooks()
    247             or cb._implements_predict_batch_hooks()

AttributeError: 'ModelCheckpoint' object has no attribute '_implements_train_batch_hooks'
```
"
2343294184,69461,Segmentation fault (core dumped) in tf.raw_ops.FractionalMaxPoolGrad when col_pooling_sequence is a very small negative number,closed,2024-06-10 08:49:31+00:00,2024-07-04T01:51:37Z,2024-07-04T01:51:27Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/69461,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.16']","['@x0w3n I was able to replicate  the issue reported [here](https://colab.research.google.com/gist/sushreebarsa/e02cf76790a4b4e658a9844601ddf892/69461.ipynb).  One workaround could be to perform the forward FractionalMaxPool to get the correct pooling sequences, then using the obtained pooling sequences in the gradient operation. Please let us know if it helps?\r\nThank you!\r\n', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69461"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69461"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

tf.raw_ops.FractionalMaxPoolGrad triggers a crash when the col_pooling_sequence parameter is a very small negative number. Additionally, the same situation exists with the row_pooling_sequence parameter.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

overlapping = True
orig_input = tf.constant(100, shape=[1,4,7,1], dtype=tf.float32)
orig_output = tf.constant(.453409232, shape=[1,7,13,1], dtype=tf.float32)
out_backprop = tf.constant(.453409232, shape=[1,7,13,1], dtype=tf.float32)
# row_pooling_sequence = tf.constant(-1250999896764, shape=[5], dtype=tf.int64) # same
row_pooling_sequence = tf.constant(0, shape=[5], dtype=tf.int64) 
col_pooling_sequence = tf.constant(-1250999896764, shape=[5], dtype=tf.int64)
tf.raw_ops.FractionalMaxPoolGrad(orig_input=orig_input, orig_output=orig_output, out_backprop=out_backprop, row_pooling_sequence=row_pooling_sequence, col_pooling_sequence=col_pooling_sequence, overlapping=overlapping)
```


### Relevant log output

```shell
2024-06-10 08:49:22.910373: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Segmentation fault (core dumped)
```
"
2343848478,69470,Aborted (core dumped) in `tf.raw_ops.SparseReduceSum\tf.raw_ops.SparseReduceMax`,closed,2024-06-10 12:55:29+00:00,2024-07-06T01:49:31Z,2024-07-06T01:49:25Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/69470,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.16']","['@x0w3n,\r\nI tried to execute the mentioned code on tf-nightly and it was not aborted as above, and fails with the same error as the input is very long(Encountered overflow when multiplying). Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/af41845d49b59bc070b15e61faf5d0ad/untitled1948.ipynb).  Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', 'Thank you for your response. I found that this crash only triggers in tf version 2.16. Thanks. \r\nhere is gist: https://colab.research.google.com/drive/1IxrskRrvNvxuiObCry6LOUxPaKALSqNT?usp=sharing', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69470"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69470"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Under specific input, tf.raw_ops.SparseReduceSum\tf.raw_ops.SparseReduceMax encounters ""Aborted (core dumped)"".

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

input_dict = {
    'input_indices': tf.constant([[-3, 1, -3], [-2, -4, 2]], dtype=tf.int64),
    'input_values': tf.constant([1, 4], dtype=tf.float64),
    'input_shape': tf.constant([0, 1700000000000, 6000000], dtype=tf.int64),
    'reduction_axes': tf.constant([0], dtype=tf.int32),
    'keep_dims': False
}
# crash
tf.raw_ops.SparseReduceSum(
   **input_dict
)

# crash
# tf.raw_ops.SparseReduceMax(
#    **input_dict
# )
```


### Relevant log output

```shell
2024-06-10 12:47:47.733403: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-10 12:47:48.724820: F tensorflow/core/framework/tensor_shape.cc:201] Non-OK-status: InitDims(dim_sizes) status: INVALID_ARGUMENT: Encountered overflow when multiplying 1700000000000 with 6000000, result: -8246744073709551616
Aborted (core dumped)
```
"
2345558494,69510,YOLOv5n model does work on python tflite but not C++ tflite,closed,2024-06-11 06:57:11+00:00,2024-06-12T04:04:10Z,2024-06-12T04:04:07Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/69510,"['type:bug', 'comp:lite', 'TF 2.16']","['Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69510"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69510"">No</a>\n']","**System information**
Linux with tensorflow v2.16.1

**Standalone code to reproduce the issue**
I exported YOLOv5n integer quantized model from ultralytics.
I tested with python tflite code, and it worked fine.
But when I ported it to C++ tflite code, it did not work.
All the output score value is 0.
The output x,y,w,h value is not 0.

**Any other info / logs**
I attatched the exported YOLOv5n model.
https://1drv.ms/u/s!AnqHHtrBqwyUg8QHviF7T1KqPkXeog?e=c3fasi


The code I used it for C++ is as bellows.
```c++
std::unique_ptr<tflite::FlatBufferModel> model = tflite::FlatBufferModel::BuildFromFile(""yolov5nu_integer_quant.tflite"");

tflite::ops::builtin::BuiltinOpResolver resolver;
tflite::InterpreterBuilder builder(*model, resolver);
std::unique_ptr<tflite::Interpreter> interpreter;
builder(&interpreter);

interpreter->AllocateTensors();

TfLiteTensor* input_tensor_0 = interpreter->input_tensor(0);
TfLiteIntArray* input_dims = input_tensor_0->dims;
int input_height = input_dims->data[1];
int input_width = input_dims->data[2];
int input_channel = input_dims->data[3];

float * input_img_ptr = new float[input_height * input_width * input_channel];
memset(input_img_ptr, 0, input_height * input_width * input_channel * sizeof(float));

... //image decode and resize it as resize_img_ptr

for(int i = 0; i < resize_height; i++){
    for(int j = 0; j < resize_width; j++){
        int input_idx = i * input_width + j;
        int resize_idx = i * resize_width + j;

        input_img_ptr[3 * input_idx] = resize_img_ptr[3 * resize_idx] / 255.0;
        input_img_ptr[3 * input_idx + 1] = resize_img_ptr[3 * resize_idx + 1] / 255.0;
        input_img_ptr[3 * input_idx + 2] = resize_img_ptr[3 * resize_idx + 2] / 255.0;
    }
}

memcpy(interpreter->typed_input_tensor<float>(0), input_img_ptr, input_height * input_width * input_channel * sizeof(float));
delete input_img_ptr;

interpreter->Invoke();

float * output = interpreter->typed_output_tensor<float>(0);
float (*output_arr)[output_width] = (float(*)[output_width])output;

TfLiteTensor* output_tensor_0 = interpreter->output_tensor(0);
TfLiteIntArray* output_dims = output_tensor_0->dims;
int output_height = output_dims->data[1];
int output_width = output_dims->data[2];

for(int i = 0; i < output_width; i++){
    float x = output_arr[0][i];
    float y = output_arr[1][i];
    float w = output_arr[2][i];
    float h = output_arr[3][i];
    
    float xmin = (x - 0.5 * w) * input_width / scale_width ;
    float ymin = (y - 0.5 * h) * input_height / scale_height ;
    float width = w * input_width / scale_width;
    float height = h * input_height / scale_height;
    
    float max_score = 0;
    int max_class_id = 0;
    
    for(int j = 4; j < output_height; j++){
        float score = output_arr[j][i];
    
        int class_id = j - 4;
    
        if(score > max_score){
            max_score = score;
            max_class_id = class_id;
        }
    
        std::cout << i << "", ""<< j <<  "": class_id: "" << class_id << "", score: "" << score << "", xn: "" << x << "", y: "" << y << "", w: "" << w << "", h: ""<< h << std::endl;
 }
``` 
"
2348016628,69575,"tf.data.Dataset.save and load custom dataset throw ""DataLossError: Unable to parse tensor from stored proto""",closed,2024-06-12 07:21:42+00:00,2024-06-28T01:51:24Z,2024-06-28T01:51:20Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/69575,"['stat:awaiting response', 'type:bug', 'stale', 'comp:data', 'TF 2.16']","['@dunalduck0,\r\nAFAIK  the issue is with the tensor size which you are trying. Could you please try reducing the size of the tensor and test the code\r\nI have tested the sample code with a lower Tensor size and found no error/issue. The Error reported might be due to Higher size Input Tensor. Please refer to the [gist](https://colab.research.google.com/gist/SuryanarayanaY/7b0b9106c1cd26a97bf133ac878bfa71/45223.ipynb) with Lower size Tensor which works fine without any error.\r\n\r\nThank you!\r\n', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69575"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69575"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.16.1

### Custom code

No

### OS platform and distribution

Linux Ubuntu 22.04

### Mobile device

_No response_

### Python version

3.10.14

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I am processing a custom dataset from [link](https://colab.research.google.com/drive/1b4PPH4XGht4Jve2xPKMCh-AXXAQziNQa?usp=sharing#scrollTo=HuiDoQnHcNsE). The dataset is in google drive. A sample can be downloaded with `gsutil -m cp -r gs://gresearch/robotics/droid_100 <your_local_path>` and then loaded with `ds = tfds.load(""droid_100"", data_dir=<your_local_path>, split=""train"")`

The full data is too large for a single compute to handle. Thus, I need split the dataset into smaller batches, save to local drive and reload each batch for processing. I found no save API in tfds, but I find tf.data.Dataset.save() and load() promising. Unfortunately, after saving and reloading the same dataset, I am getting errors (see relevant log output)

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import tensorflow_datasets as tfds

data_dir = <your_local_path>
ds = tfds.load(""droid_100"", data_dir=data_dir, split=""train"").take(1)
ds.save(""/tmp/copycat"")
ds2 = tf.data.Dataset.load('/tmp/copycat')
for x in ds2:
    pass
```


### Relevant log output

```shell
2024-06-12 07:09:42.851470: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-12 07:09:43.816148: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-12 07:09:44.657802: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-06-12 07:09:45.022935: E tensorflow/core/framework/dataset.cc:109] The Encode() method is not implemented for DatasetVariantWrapper objects.
2024-06-12 07:09:45.150111: E tensorflow/core/framework/variant.cc:100] Could not decode variant with type_name: ""tensorflow::DatasetVariantWrapper"".  Perhaps you forgot to register a decoder via REGISTER_UNARY_VARIANT_DECODE_FUNCTION?
2024-06-12 07:09:45.150452: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: DATA_LOSS: Unable to parse tensor from stored proto in file: /tmp/copycat/8099738303123461199/00000000.shard/00000000.snapshot, record 307. TensorProto: dtype: DT_VARIANT tensor_shape { } tensor_content: ""#\n!tensorflow::DatasetVariantWrapper""
Traceback (most recent call last):
  File ""/home/meiyang/src/ceprojects/magma/error.py"", line 7, in <module>
    for x in ds2:
  File ""/home/meiyang/miniconda3/envs/magma/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 809, in __next__
    return self._next_internal()
  File ""/home/meiyang/miniconda3/envs/magma/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 772, in _next_internal
    ret = gen_dataset_ops.iterator_get_next(
  File ""/home/meiyang/miniconda3/envs/magma/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 3086, in iterator_get_next
    _ops.raise_from_not_ok_status(e, name)
  File ""/home/meiyang/miniconda3/envs/magma/lib/python3.10/site-packages/tensorflow/python/framework/ops.py"", line 5983, in raise_from_not_ok_status
    raise core._status_to_exception(e) from None  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.DataLossError: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unable to parse tensor from stored proto in file: /tmp/copycat/8099738303123461199/00000000.shard/00000000.snapshot, record 307. TensorProto: dtype: DT_VARIANT tensor_shape { } tensor_content: ""#\n!tensorflow::DatasetVariantWrapper"" [Op:IteratorGetNext] name:
```
"
2348681289,69595,tf.signal.rfftnd throws NotFoundError on CPU execution (GPU-behavior unknown),closed,2024-06-12 12:44:00+00:00,2024-08-18T01:57:02Z,2024-08-18T01:56:59Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/69595,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.16']","[""@MathiesW You could reinstall TensorFlow with CPU support explicitly enabled. Here's a general guideline build instructions for WSL Ubuntu 22.04 ; please follow the steps below and let us know?\r\na. Uninstall the current TensorFlow installation: pip uninstall tensorflow\r\nb. During the installation, use a flag or configuration option that specifies CPU support. For example, you might be able to use `pip install tensorflow-cpu.` \r\nThank you!"", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', '@sushreebarsa thanks for the recommendation. I tried your approach on Google Colab and the same error occurs: `NotFoundError: Could not find device for node: {{node RFFTND}} = RFFTND[Tcomplex=DT_COMPLEX64, Treal=DT_FLOAT]\r\nAll kernels registered for op RFFTND:\r\n  <no registered kernels>\r\n [Op:RFFTND] name: `\r\n\r\nsee my Colab the code here: https://colab.research.google.com/drive/16Y52PrW3eRBtTHOzw32chYgJ5sMZFgwq?usp=sharing\r\n\r\nI now opted to just use the existing FFT implementations in TF for 1, 2 and 3 dimensions as a workaround. However, they do not feature the `axes` argument, such that I have to transpose all my data from format `channels last` to format `channels first` before using the FFT. ', ""@MathiesW,\r\nHave you got the chance to have a look at the **fft_ops.py**, **rfftnd** and **irfftnd** API's are registered with the GPU and other 2d, 3d API's are registered with the CPU.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/fft_ops.cc#L1095\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/fft_ops.cc#L407\r\n\r\nThank you!"", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69595"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69595"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

tf 2.16.1

### Custom code

No

### OS platform and distribution

WSL Ubuntu 22.04

### Mobile device

_No response_

### Python version

3.11.8

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Tensorflow throws an NotFoundError when calling ```tf.signal.rfftnd```. It seems to me like TF wants to run the code on a GPU, which is not available since I am running on CPU only. I have no possibility of testing on a GPU atm.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
x = tf.random.normal([8, 8])
y = tf.signal.rfftnd(x)
```


### Relevant log output

```shell
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
Cell In[4], line 3
      1 import tensorflow as tf
      2 x = tf.random.normal([8, 8])
----> 3 y = tf.signal.rfftnd(x)

File ~/.pyenv/versions/3.11.8/envs/emess/lib/python3.11/site-packages/tensorflow/python/ops/signal/fft_ops.py:325, in _rfftn_wrapper.<locals>._rfftn(input_tensor, fft_length, axes, norm, name)
    323   elif norm == ""ortho"":
    324     input_tensor /= np.sqrt(n)  # should be sqrt(N)
--> 325 return rfft_n(
    326     input_tensor,
    327     fft_length,
    328     axes,
    329     Tcomplex=complex_dtype,
    330     name=name,
    331 )

File ~/.pyenv/versions/3.11.8/envs/emess/lib/python3.11/site-packages/tensorflow/python/ops/gen_spectral_ops.py:1744, in rfftnd(input, fft_length, axes, Tcomplex, name)
   1742   return _result
   1743 except _core._NotOkStatusException as e:
-> 1744   _ops.raise_from_not_ok_status(e, name)
   1745 except _core._FallbackException:
   1746   pass

File ~/.pyenv/versions/3.11.8/envs/emess/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5983, in raise_from_not_ok_status(e, name)
   5981 def raise_from_not_ok_status(e, name) -> NoReturn:
   5982   e.message += ("" name: "" + str(name if name is not None else """"))
-> 5983   raise core._status_to_exception(e) from None

NotFoundError: Could not find device for node: {{node RFFTND}} = RFFTND[Tcomplex=DT_COMPLEX64, Treal=DT_FLOAT]
All kernels registered for op RFFTND:
  device='GPU'
 [Op:RFFTND] name:
```
"
2351347130,69701,Aborted (core dumped) in `tf.raw_ops.BatchFunction`,closed,2024-06-13 14:46:23+00:00,2024-07-04T01:51:31Z,2024-07-04T01:51:25Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/69701,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.16']","['@x0w3n I was able to replicate the issue reported [here](https://colab.research.google.com/gist/sushreebarsa/95318cc9e4a8fc8a4c64eb0b59202fae/69701.ipynb#scrollTo=iPHVebaM13Us). One workaround could be to use tf.raw_ops.BatchFunction that offers low-level control, a simpler approach for batching a function might be using tf.data.Dataset.map with vectorization?\r\nCould you please let us know if it helps?\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69701"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69701"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When num_batch_threads is too large, tf.raw_ops.BatchFunction triggers crash.
![image](https://github.com/tensorflow/tensorflow/assets/165141765/fbeaa22a-f07e-4e53-9d55-4366b1dd77e0)


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

@tf.function
def simple_fn(x, y):
    return x + y

input_tensor = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)
captured_tensor = tf.constant([4.0], dtype=tf.float32)

def wrapped_fn(in_tensors, captured_tensors):
    return simple_fn(in_tensors[0], captured_tensors[0])

defun_func = tf.function(wrapped_fn).get_concrete_function([input_tensor], [captured_tensor])


result = tf.raw_ops.BatchFunction(
    in_tensors=[input_tensor],
    captured_tensors=[captured_tensor],
    f=defun_func,
    num_batch_threads=tf.constant(93389718, dtype=tf.int32),
    max_batch_size=10,
    batch_timeout_micros=1000,
    Tout=[tf.float32],
    max_enqueued_batches=10,
    allowed_batch_sizes=[5, 10],
    container='',
    shared_name='',
    batching_queue='',
    low_priority_max_batch_size=0,
    low_priority_batch_timeout_micros=0,
    low_priority_allowed_batch_sizes=[],
    low_priority_max_enqueued_batches=0,
    enable_large_batch_splitting=False,
    name=None
)

print(result)
```


### Relevant log output

```shell
2024-06-13 14:42:13.314670: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-13 14:42:19.076124: F external/local_tsl/tsl/platform/default/env.cc:74] Check failed: ret == 0 (11 vs. 0)Thread batch_threads_ creation via pthread_create() failed.
Aborted (core dumped)
```
"
2351753610,69718,Installing Tensorflow on Fedora 40,closed,2024-06-13 18:00:32+00:00,2024-06-18T06:19:59Z,2024-06-18T06:19:56Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/69718,"['stat:awaiting response', 'type:bug', 'TF 2.5', 'wsl2']","['I got it fixed with tensorflow nightly in docker containers, forget building from source!!!\r\n\r\nthis worked!!\r\n\r\nStep-by-Step Instructions\r\n\r\nEnsure Podman is Installed and Configured:\r\nIf Podman isn\'t installed or configured yet, follow these steps:\r\n\r\nsh\r\n\r\nsudo dnf install -y podman\r\n\r\nInstall NVIDIA Container Toolkit:\r\nInstall the NVIDIA Container Toolkit to enable GPU support in Podman.\r\n\r\nsh\r\n\r\ndistribution=$(. /etc/os-release;echo $ID$VERSION_ID)\r\ncurl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg\r\ncurl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | sudo tee /etc/yum.repos.d/nvidia-docker.repo\r\nsudo dnf install -y nvidia-container-toolkit\r\nsudo systemctl restart containerd\r\n\r\nConfigure Podman for NVIDIA Runtime:\r\nUpdate Podman’s configuration to use the NVIDIA runtime.\r\n\r\nsh\r\n\r\nmkdir -p ~/.config/containers\r\ncat < ~/.config/containers/containers.conf\r\n[engine]\r\nruntime = “nvidia”\r\nEOT\r\n\r\nRun TensorFlow Nightly GPU Container with Podman:\r\n\r\nUse Podman on your host system to run the TensorFlow nightly GPU container. The --runtime=nvidia flag ensures that GPU support is enabled.\r\n\r\nsh\r\n\r\npodman run --runtime=nvidia -it tensorflow/tensorflow:nightly-gpu bash\r\n\r\nIf the above command fails or --runtime is not recognized, use the --gpus all flag:\r\n\r\nsh\r\n\r\npodman run --gpus all -it tensorflow/tensorflow:nightly-gpu bash\r\n\r\nVerify TensorFlow GPU Support Inside the Container:\r\n\r\nOnce inside the container, verify that TensorFlow can access the GPU:\r\n\r\nsh\r\n\r\npython -c ""import tensorflow as tf; print(‘TensorFlow version:’, tf.version); prin\r\n\r\n\r\n[2m](https://discussion.fedoraproject.org/t/gpu-support-for-deep-learning-frameworks-pytorch-tensorflow/118038/12)\r\n$ podman run --gpus all -it tensorflow/tensorflow:nightly-gpu bash\r\nWARN[0000] Using cgroups-v1 which is deprecated in favor of cgroups-v2 with Podman v5 and will be removed in a future version. Set environment variable PODMAN_IGNORE_CGROUPSV1_WARNING to hide this warning.\r\n\r\n___ /________________________________ / /______ __\r\n__ / _ _ _ __ _ / __ _ / / __ / __ _ | /| / /\r\n_ / / / / / /( )/ // / / _ __/ _ / / // / |/ |/ /\r\n// ___/// //// _/// // // _/__/|__/\r\n\r\nWARNING: You are running this container as root, which can cause new files in\r\nmounted volumes to be created as the root user on your host machine.\r\n\r\nTo avoid this, run the container by specifying your user’s userid:\r\n\r\n$ docker run -u $(id -u):$(id -g) args…\r\n\r\n/sbin/ldconfig.real: /usr/lib/wsl/drivers/nvmdsi.inf_amd64_23a2cede5f1383ec/libnvidia-ml.so.1 is not a symbolic link\r\n\r\nroot@b24205da9419:/# python -c “import tensorflow as tf; print(‘TensorFlow version:’, tf.version); print(‘Num GPUs Available:’, len(tf.config.experimental.list_physical_devices(‘GPU’)))”\r\n2024-06-13 21:27:38.985917: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable TF_ENABLE_ONEDNN_OPTS=0.\r\n2024-06-13 21:27:39.009506: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\r\nTo enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\nTensorFlow version: 2.18.0-dev20240612\r\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\nI0000 00:00:1718314059.869098 17 cuda_executor.cc:990] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\nYour kernel may have been built without NUMA support.\r\nI0000 00:00:1718314059.872207 17 cuda_executor.cc:990] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\nYour kernel may have been built without NUMA support.\r\nI0000 00:00:1718314059.872254 17 cuda_executor.cc:990] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\nYour kernel may have been built without NUMA support.\r\nNum GPUs Available: 1', 'Hi @ludiusvox ,\r\n- Could you please upgrade your tensorflow version. And here there is version miss match also. Please go through this [documentation](https://www.tensorflow.org/install/source_windows) once.\r\n\r\nThank you!', 'Thank you!', 'I found a solution with an IDE 1 line of code.  Very useful\r\n\r\none line of code\r\n\r\nFound the solutions.\r\n\r\nhttps://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html\r\n\r\nFor example, you can use an image quay.io/jupyter/pytorch-notebook:cuda12-python-3.11.8 or quay.io/jupyter/tensorflow-notebook:cuda-latest\r\n\r\n`sudo podman pull quay.io/jupyter/tensorflow-notebook:cuda-latest`\r\n\r\nvery fast shortcut\r\n\r\none line of code fixed the problem ', 'Hi **@ludiusvox** ,\r\n- Glad to see this issue is resolved.  Please feel free to close the issue if it is resolved ? \r\n\r\nThank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69718"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69718"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.5

### Custom code

Yes

### OS platform and distribution

WSL Fedora 40

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.4

### GPU model and memory

4080RTX NVIDIA

### Current behavior?

I am trying to figure out how to build a wheel for Tensorflow 2.5+ for CUDA 12.4, I am having difficulty, the Fedora developers think they need Bazel, but I explained that Bazel is unneccesary, but I am looking for a procedure to install with CMAKE and build from source and upload a container.  

Pytorch is easy to install, and the team lead on Fedora 40 AI/ML is more interested in supporting ROCm so I am just coming in here see if I can get some advice.  I had completed a graduate thesis in TF and i am really comfortable with the Software, but it's limited pipeline support for all the distros is difficult.  

I would hate to have to spend $1000 on a new GPU I really like fedora and Pytorch works out of the box, can anything be done?

### Standalone code to reproduce the issue

```shell
Building TensorFlow with CMake

TensorFlow provides some support for building with CMake, primarily targeting Windows environments. Below are the steps for building TensorFlow using CMake on Linux. This process is more experimental and might not cover all features of TensorFlow.
Prerequisites

    Dependencies:
        CMake (version 3.16 or later)
        Python (3.6, 3.7, 3.8, or 3.9)
        TensorFlow dependencies: numpy, six, wheel, setuptools, h5py, keras_preprocessing
        GCC compiler (GCC 7.3 or later recommended)

    Install necessary packages:

    bash

    sudo apt-get update
    sudo apt-get install cmake python3-dev python3-pip gcc g++
    pip3 install numpy six wheel setuptools h5py keras_preprocessing

Steps to Build

    Clone TensorFlow Repository:

    bash

git clone https://github.com/tensorflow/tensorflow.git
cd tensorflow

Create Build Directory:

bash

mkdir build
cd build

Configure the Build with CMake:

bash

cmake .. -Dtensorflow_ENABLE_GPU=OFF -Dtensorflow_BUILD_PYTHON_BINDINGS=ON

    Adjust options as necessary. For example, set -Dtensorflow_ENABLE_GPU=ON if building with GPU support.

Build TensorFlow:

bash

cmake --build . --config Release

Build the Python Wheel:

    After building the main TensorFlow library, you need to build the Python package:

    bash

    cd ../tensorflow/tools/pip_package
    python3 build_pip_package.py --src .. --output .

    This script should generate a .whl file in the specified output directory.

Install the Wheel:

bash

pip3 install ./tensorflow-*.whl
```


### Relevant log output

```shell
--------------------------

Error here, I am stuck on python3-dev, and we expecting problems with keras_preprocessing
```
"
2351754385,69719,Rescaling Layer Issue when Loading .keras Model,closed,2024-06-13 18:00:53+00:00,2024-08-17T01:52:03Z,2024-08-17T01:52:00Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/69719,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'TF 2.16']","['@marcobornstein Could you try to use CustomRescaling layer that is defined to take a scaling vector as an input and scale the inputs accordingly. It overrides the get_config and from_config methods to ensure proper serialization and deserialization. For any further queries please raise the issue in [Keras](https://github.com/keras-team/keras/issues) repository. Thank you!', 'Sorry @sushreebarsa, I am a bit confused. I have not defined a CustomRescaling layer in the code above. Previously, this Rescaling layer would work. I have also tried to implement a custom Rescalying layer (which you may be mentioning), howeve**r I still get issues with the get_config and from_config even if I write those functions myself**. What other options exist?', ""@marcobornstein If the TensorFlow versions seem compatible, there's a chance the model saving format might have changed between them. Could you try saving the model with the same TensorFlow version you used previously. This might resolve the loading issue?\r\nThank you!"", '@sushreebarsa yes, the previous TensorFlow version does allow correct model saving of the Rescaling layers. My issue is that this no longer works in TensorFlow 2.16. Is it possible to have this bug fixed? I am hoping to continue usage of TensorFlow 2.16 for my work.', ""@marcobornstein By saving your model again using the exact same TensorFlow version you used for training, please ensure the model is saved in the format that version expects. When you then load the model with the same version, there's a much higher chance of successful loading because the format and information about the re-scaling layer will be consistent.\r\n\r\nThank you!"", '@sushreebarsa, I am training and reloading the model using the exact same TensorFlow method. This can be shown in the ""Standalone code to reproduce the issue"" section of my Issue. How can this issue be fixed?', '@marcobornstein Thank you for the update!\r\nIn TensorFlow/Keras, after you save and load a model, you need to recompile it before using it again.\r\n\r\nPlease follow the below code and let us know if it helps?\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n# Fake data\r\nX = np.random.rand(100, 10)\r\nY = np.random.rand(100, 5)\r\nr = np.random.rand(5)\r\n\r\n# Build/compile/fit model\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.layers.Dense(100, activation=""relu"", name=""layer1""),\r\n    tf.keras.layers.Dense(10, activation=""relu"", name=""layer2""),\r\n    tf.keras.layers.Dense(5, name=""layer3""),\r\n])\r\nmodel.compile(optimizer=""adam"", loss=""mse"")\r\nmodel.fit(X, Y, epochs=50)\r\n\r\n# Save model\r\nmodel.save(\'model.keras\')\r\n\r\n# Load model\r\nmodel = tf.keras.models.load_model(\'model.keras\')\r\n\r\n# Add rescaling layer after loading\r\nmodel.add(tf.keras.layers.Rescaling(r))\r\n\r\n# Test point\r\nx_tst = np.random.rand(1, 10)\r\n\r\n# Print prediction (should work after recompiling)\r\nprint(model(x_tst))\r\n\r\n# Summary of the model\r\nmodel.summary()\r\n\r\n```\r\n\r\nAfter loading the model, adding the Rescaling layer, and before using the model for prediction, we should recompile it:\r\n```\r\n# Recompile the model after adding Rescaling layer\r\nmodel.compile(optimizer=""adam"", loss=""mse"")\r\n\r\n# Now the prediction would run successful\r\nprint(model(x_tst))\r\n\r\n```\r\nPlease find the gist [here](https://colab.research.google.com/gist/sushreebarsa/3d58f048813281c815e58cb8c60a1d23/69719.ipynb) for reference.\r\nThank you!', 'Hello, the provided code above reloads the model and then adds in a scaling layer. **There is no error saving and reloading a model which does not use a rescaling layer**. When a model that uses a rescaling layer is saved, an error still occurs when it is reloaded. The code to produce this is shown below,\r\n\r\n```\r\n# fake data\r\nX = np.random.rand(100, 10)\r\nY = np.random.rand(100, 5)\r\nr = np.random.rand(5)\r\n\r\n# build/compile/fit model\r\nmodel = tf.keras.Sequential(\r\n    [\r\n        tf.keras.layers.Dense(100, activation=""relu"", name=""layer1""),\r\n        tf.keras.layers.Dense(10, activation=""relu"", name=""layer2""),\r\n        tf.keras.layers.Dense(5, name=""layer3""),\r\n    ]\r\n)\r\nmodel.compile(optimizer=""adam"", loss=""mse"")\r\nmodel.fit(X, Y, epochs=50)\r\n\r\n# add rescaling layer\r\nmodel.add(tf.keras.layers.Rescaling(r))\r\n\r\n# test point\r\nx_tst = np.random.rand(1, 10)\r\n\r\n# this works!\r\nprint(model(x_tst))\r\n\r\n# save model\r\nmodel.save(\'model.keras\')\r\n\r\n# load model now\r\nmodel = tf.keras.models.load_model(\'model.keras\')\r\n\r\n# Recompile the model after adding Rescaling layer\r\nmodel.compile(optimizer=""adam"", loss=""mse"")\r\n\r\n# error here!\r\nprint(model(x_tst))\r\n```\r\n\r\nThere needs to be a patch to fix the issue surrounding saving a TF model which uses a rescaling layer.', '@tilakrayal I was able to replicate the issue reported [here](https://colab.research.google.com/gist/sushreebarsa/75752a61ee9bc39acb6cf77b0994de92/69719.ipynb).\r\nThank you!', '@marcobornstein,\r\nApologies for the delay. Looks like this issue is more related to keras. Could you please raise the issue in the keras-team/keras repo for the quick resolution. Thank you!', '> @marcobornstein, Apologies for the delay. Looks like this issue is more related to keras. Could you please raise the issue in the keras-team/keras repo for the quick resolution. Thank you!\r\n\r\nThank you for the reply, [I opened an issue here!](https://github.com/keras-team/keras/issues/20072). Do I need to do anything else?', '@marcobornstein,\r\nCould you please feel free to move this issue to closed status, since it is already being tracked in the Keras repo? Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69719"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69719"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

v2.16.1-0-g5bc9d26649c 2.16.1

### Custom code

Yes

### OS platform and distribution

macOS Sonoma 14.5

### Mobile device

_No response_

### Python version

3.10.5

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I'm currently training an MLP, and after training I add on a rescaling layer (tf.keras.layers.Rescaling). The rescaling is needed to return to the normal label values (I scale them during training). Previously, on older versions of tensorflow (2.9 or so), I could add the rescaling layer and then load the .keras model without any issue. Now that I upgraded to 2.16.1 and keras 3.0+, I can no longer get the model to predict after loading the .keras model. It is important to note that **everything works great when I load in the weights via** `model.load_weights('model-weights.weights.h5')`. My error occurs only when performing `load_model` and then doing inference (I can load the model fine but errors pop up during inference).

### Standalone code to reproduce the issue

```shell
import numpy as np
import tensorflow as tf

# fake data
X = np.random.rand(100, 10)
Y = np.random.rand(100, 5)
r = np.random.rand(5)

# build/compile/fit model
model = tf.keras.Sequential(
    [
        tf.keras.layers.Dense(100, activation=""relu"", name=""layer1""),
        tf.keras.layers.Dense(10, activation=""relu"", name=""layer2""),
        tf.keras.layers.Dense(5, name=""layer3""),
    ]
)
model.compile(optimizer=""adam"", loss=""mse"")
model.fit(X, Y, epochs=50)

# add rescaling layer
model.add(tf.keras.layers.Rescaling(r))

# test point
x_tst = np.random.rand(1, 10)

# this works!
print(model(x_tst))

# save model
model.save('model.keras')

# load model now
model = tf.keras.models.load_model('model.keras')
model.summary()

# error here!
print(model(x_tst))
```


### Relevant log output

```shell
ValueError: Exception encountered when calling Rescaling.call().

Attempt to convert a value ({'class_name': '__numpy__', 'config': {'value': [0.5410176182754953, 0.03500206949958751, 0.6878430055707475, 0.8070027690483106, 0.2295546297709813], 'dtype': 'float64'}}) with an unsupported type (<class 'keras.src.utils.tracking.TrackedDict'>) to a Tensor.

Arguments received by Rescaling.call():
  • inputs=tf.Tensor(shape=(1, 5), dtype=float32)
```
"
2352050826,69734,Object Detection in Android using front camera: the detected bounding boxes are drawn incorrectly,closed,2024-06-13 20:55:44+00:00,2024-11-27T18:05:52Z,2024-11-27T18:05:49Z,arfaian,,https://github.com/tensorflow/tensorflow/issues/69734,"['stat:awaiting tensorflower', 'type:bug', 'comp:lite', 'Android']","['Hi, @roshni-warrantylife \r\n\r\nI apologize for the delayed response and thank you for bringing this issue to our attention, if possible could you please help us with your github repo (with changes made by you in this [example](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android)) which will be easy for us to replicate the same behaviour from our end and investigate this issue further ?\r\n\r\nThank you for your cooperation and patience.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', '> Hi, @roshni-warrantylife\r\n> \r\n> I apologize for the delayed response and thank you for bringing this issue to our attention, if possible could you please help us with your github repo (with changes made by you in this [example](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android)) which will be easy for us to replicate the same behaviour from our end and investigate this issue further ?\r\n> \r\n> Thank you for your cooperation and patience.\r\n\r\nThank you for your understanding. I’ve shared the GitHub repository link below, which includes the changes I made to the example. Please feel free to use it to replicate the behavior on your end and investigate the issue further:\r\n\r\nhttps://github.com/roshni-warrantylife/object-detection/tree/master/lite/examples/object_detection/android\r\n\r\nLet me know if you need any additional information, and I’ll be happy to assist. Thank you for your time and support!', ""Hi, @roshni-warrantylife\r\n\r\nI apologize for the delayed response, I was trying to replicate the same behavior from my end with your provided Github repo and I'm getting error messages please refer this error [log file](https://pastebin.com/juJnHENQ) so could you please try from your end and see is it working as expected or not ? it seems there might be some package versions compatibility or Gradle version mismatch ?\r\n\r\nThank you for your cooperation and patience.\r\n\r\n"", ""Thanks for sharing the error log. I've updated the code in the GitHub repo to address possible Gradle or package version issues. Please try again using this [link](https://github.com/roshni-warrantylife/object-detection/tree/master/lite/examples/object_detection/android) and let me know if it works as expected.\r\n\r\nIf the issue persists, feel free to share the updated logs for further review.\r\n\r\nThanks for your patience!\r\n\r\n"", ""Hi, @roshni-warrantylife\r\n\r\nThank you for providing the updated github repo, I'm able to build and run your project successfully with Android virtual device with `Pixel 5 API 35` but I'm getting below output so are you using actual device or AVD ( I gave permission to access  camera for device from AVD) ? or Am I missing something here ?\r\n\r\nThank you for your cooperation and patience.\r\n\r\n![image](https://github.com/user-attachments/assets/a33fb172-ed5c-4474-bff8-bd39e0509ffc)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n"", ""Thank you for your feedback and for successfully building and running the project on the Android Virtual Device (Pixel 5 API 35). To clarify, I am testing the project on an actual physical device. This might explain the difference in the output you're seeing. If possible, could you try running the app on an actual device to see if the output differs? \r\n\r\nThank you for your patience and cooperation as we troubleshoot this!\r\n"", 'Hi, @pkgoogle\r\nPlease take look into this issue. Thank you', 'Hi @arfaian, can you please take a look? Thanks.', ""Hi, @roshni-warrantylife \r\nThanks for raising this issue. Are you aware of the migration to [LiteRT](https://developers.googleblog.com/en/tensorflow-lite-is-now-litert/)? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/google-ai-edge/LiteRT/issues/59\r\n\r\nLet us know if you have any questions. Thanks.\r\n\r\n\r\n\r\n\r\n"", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69734"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69734"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

0.4.0

### Custom code

No

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When I move an object (initially placed at the center of the screen) from a far distance towards the camera lens, the left position of the bounding box gradually shifts to the right side of the screen instead of staying centered.

Here is the recording of the issue, https://drive.google.com/file/d/144zCu8yPXYSeVPKk4RjDTG40YOcbLAtX/view

This issue is reproducable in the https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android. 

I have changed the camera lens to ""LENS_FACING_FRONT"" in the CameraFragment class. Additionally, to resolve the issue with the inverted (mirrored) coordinates, I have flipped the coordinates horizontally by adding the following code in the OverlayView class.

`           
```
            val boundingBox = result.boundingBox

            val objectTop = boundingBox.top * scaleFactor
            val objectBottom = boundingBox.bottom * scaleFactor
            val objectOriginalLeft = boundingBox.left * scaleFactor
            val objectOriginalRight = boundingBox.right * scaleFactor
            val objectWidth = objectOriginalRight - objectOriginalLeft

             var objectLeft = width - objectOriginalLeft + objectWidth
             var objectRight = objectLeft + objectWidth
```

### Standalone code to reproduce the issue

```shell
https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android
```


### Relevant log output

_No response_"
2352384571,69753,CMake Error: could not find requested file BuildFlatBuffers when cmake the lite kernel test,closed,2024-06-14 02:55:33+00:00,2024-07-25T06:33:36Z,2024-07-04T01:51:24Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/69753,"['stat:awaiting response', 'type:bug', 'type:build/install', 'stale', 'comp:lite', 'TF 2.16']","['@zoghin Could you please make sure that FlatBuffers are installed and available on your system? Kindly ensure the paths to FlatBuffers scripts and modules are correct as well and let us know?\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69753"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69753"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

master

### Custom code

No

### OS platform and distribution

linux Ubuntu 20.0

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

cmake 

### CUDA/cuDNN version

_No response_

### GPU model and memory

yes

### Current behavior?

cmake command:
 cmake ../tensorflow/lite/ -DTFLITE_KERNEL_TEST=ON  -DTFLITE_ENABLE_GPU=ON -DTFLITE_ENABLE_INSTALL=ON 

erro info:
-- Found PythonInterp: /usr/bin/python (found version ""3.8.2"")
CMake Error at kernels/CMakeLists.txt:27 (include):
  include could not find requested file:

    BuildFlatBuffers


CMake Error at kernels/CMakeLists.txt:53 (build_flatbuffers):
  Unknown CMake command ""build_flatbuffers"".


### Standalone code to reproduce the issue

```shell
lite/kernels/CMakeLists.txt
 15 message(""==== cmake for lit kernel test==="")
 16 find_package(googletest REQUIRED)
 17 find_package(nsync REQUIRED)
 18 find_package(re2 REQUIRED)
 19
 20 # Generate the mutable schema_generated.h header for tests.
 21 set(SCHEMA_FILE ${TFLITE_SOURCE_DIR}/schema/schema.fbs)
 22 set(SCHEMA_GENERATED_ROOT ${CMAKE_CURRENT_BINARY_DIR}/schema)
 23 set(SCHEMA_GENERATED_PATH ${SCHEMA_GENERATED_ROOT}/tensorflow/lite/schema/mutable)
 24 set(SCHEMA_GENERATED_FILE ${SCHEMA_GENERATED_PATH}/schema_generated.h)
 25
 26 # Use the util function in flatbuffer to generate the schema header.
 27 include(BuildFlatBuffers)
 28
 29 # For cross-compilation purposes a natively compiled 'flatc' compiler is required
 30 if(${CMAKE_CROSSCOMPILING})
The file BuildFlatBuffers must be include as showed in the line 27, But it couldnot be found!
```


### Relevant log output

```shell
-- Found PythonInterp: /usr/bin/python (found version ""3.8.2"")
CMake Error at kernels/CMakeLists.txt:27 (include):
  include could not find requested file:

    BuildFlatBuffers


CMake Error at kernels/CMakeLists.txt:53 (build_flatbuffers):
  Unknown CMake command ""build_flatbuffers"".
```
"
2352384908,69754,CMake Error: could not find requested file BuildFlatBuffers when cmake the lite kernel test,closed,2024-06-14 02:55:57+00:00,2024-08-01T01:58:08Z,2024-08-01T01:57:59Z,sawantkumar,,https://github.com/tensorflow/tensorflow/issues/69754,"['stat:awaiting response', 'type:bug', 'type:build/install', 'stale', 'comp:lite']","['Hi @zoghin ,\r\n\r\nCan you please provide me more details regarding your installation, like what is your target platform ,also give me the detailed instructions that you are following. I will be able to debug quicker if you give me these details. ', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69754"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69754"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

master

### Custom code

No

### OS platform and distribution

linux Ubuntu 20.0

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

cmake 

### CUDA/cuDNN version

_No response_

### GPU model and memory

yes

### Current behavior?

cmake command:
 cmake ../tensorflow/lite/ -DTFLITE_KERNEL_TEST=ON  -DTFLITE_ENABLE_GPU=ON -DTFLITE_ENABLE_INSTALL=ON 

erro info:
-- Found PythonInterp: /usr/bin/python (found version ""3.8.2"")
CMake Error at kernels/CMakeLists.txt:27 (include):
  include could not find requested file:

    BuildFlatBuffers


CMake Error at kernels/CMakeLists.txt:53 (build_flatbuffers):
  Unknown CMake command ""build_flatbuffers"".


### Standalone code to reproduce the issue

```shell
lite/kernels/CMakeLists.txt
 15 message(""==== cmake for lit kernel test==="")
 16 find_package(googletest REQUIRED)
 17 find_package(nsync REQUIRED)
 18 find_package(re2 REQUIRED)
 19
 20 # Generate the mutable schema_generated.h header for tests.
 21 set(SCHEMA_FILE ${TFLITE_SOURCE_DIR}/schema/schema.fbs)
 22 set(SCHEMA_GENERATED_ROOT ${CMAKE_CURRENT_BINARY_DIR}/schema)
 23 set(SCHEMA_GENERATED_PATH ${SCHEMA_GENERATED_ROOT}/tensorflow/lite/schema/mutable)
 24 set(SCHEMA_GENERATED_FILE ${SCHEMA_GENERATED_PATH}/schema_generated.h)
 25
 26 # Use the util function in flatbuffer to generate the schema header.
 27 include(BuildFlatBuffers)
 28
 29 # For cross-compilation purposes a natively compiled 'flatc' compiler is required
 30 if(${CMAKE_CROSSCOMPILING})
The file BuildFlatBuffers must be include as showed in the line 27, But it couldnot be found!
```


### Relevant log output

```shell
-- Found PythonInterp: /usr/bin/python (found version ""3.8.2"")
CMake Error at kernels/CMakeLists.txt:27 (include):
  include could not find requested file:

    BuildFlatBuffers


CMake Error at kernels/CMakeLists.txt:53 (build_flatbuffers):
  Unknown CMake command ""build_flatbuffers"".
```
"
2353381662,69777,tf.py_function does not output ragged tensors,closed,2024-06-14 13:24:10+00:00,2024-12-29T02:06:59Z,2024-12-29T02:06:56Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/69777,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.15']","['Hi **@tirk999** ,\r\n- I tried to run your code on Colab using TF v2.16.1 and nightly faced the same issue. Please find the [gist](https://colab.research.google.com/gist/Venkat6871/8f69515c20611104a9d025639f3d697b/69777_2-16-1-nightly-v.ipynb) here for reference. \r\n- Thank you!', 'Hello @Venkat6871 , do you think that the issue will be solved?\r\nThank you!', ""Hi, @tirk999 \r\nI apologize for the delayed response, I have tried with lambda function something like below which is returning the `tf.RaggedTensor` please refer these similar issues https://github.com/tensorflow/tensorflow/issues/27679, https://github.com/tensorflow/tensorflow/issues/26453 which may help you to solve your issue.\r\n\r\n\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n# Using lambda with default return\r\nresult = tf.py_function(\r\n    lambda elements=None: tf.ragged.constant([\r\n    np.array([1., 2., 3.]).astype('float32'), \r\n    np.array([4., 5.]).astype('float32')\r\n    ]), \r\n    [], \r\n    Tout=tf.RaggedTensorSpec([2, None], tf.float32)\r\n)\r\nprint(result)\r\n```\r\n\r\n**Output** : `<tf.RaggedTensor [[1.0, 2.0, 3.0], [4.0, 5.0]]>`\r\n\r\nIf I have missed something here please let me know. Thank you for your cooperation and patience."", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69777"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69777"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.15

### Custom code

Yes

### OS platform and distribution

Windows

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Hello everyone,

I am having a problem with the function tf.py_function. I want it to output a ragged tensor but I cannot manage to make it happen.

The longer context is that I am training a neural network, YOLO, for object detection. I want to use some data augmentations techniques that do not support bounding boxes. Therefore, I moved to albumentations for data augmentation. The problem is that albuminations works on numpy arrays. I use tf.py_function to output my defined data augmentation but I would need the bounding boxes to be a ragged tensor. 

Reference code: https://keras.io/examples/vision/yolov8/
```python
# where map_augmentation is my function for augmentation. 
train_ds = train_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)
train_ds = train_ds.shuffle(BATCH_SIZE * 4)
train_ds = train_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)
train_ds = train_ds.map(map_augmentation, num_parallel_calls=tf.data.AUTOTUNE)
``` 
Inside of the map_augmentation function:
```python
augmented_images, augmented_classes, augmented_bboxes = tf.py_function(
            func=apply_augmentation,
            inp=[images[j,:,:,:], classes[j], bbox[j]],
            Tout=[tf.float32, tf.float32, tf.float32]
        )
``` 
I can modify the Tout in order to output a tf.TensorRaggedSpec but I always get errors.

Moreover, I tried to find a solution with this topic https://github.com/tensorflow/tensorflow/issues/26453 but I did not manage.
I manage to make this run:

```python
tf = tensorflow.compat.v2
def py_func():
  return tf.ragged.constant([[1., 2., 3.], [4., 5.]])

print(tf.py_function(py_func, [], Tout=tf.RaggedTensorSpec([2, None], tf.float32)))  # <tf.RaggedTensor [[1.0, 2.0, 3.0], [4.0, 5.0]]>
``` 

but I have the issue when I declare an input for py_func.

### Standalone code to reproduce the issue

```shell

elements=[np.array([1., 2., 3.]).astype('float32'), np.array([4., 5.]).astype('float32')]
def py_func(elements):
  return tf.ragged.constant([np.array([1., 2., 3.]).astype('float32'), np.array([4., 5.]).astype('float32')])

print(tf.py_function(py_func, [elements], Tout=tf.RaggedTensorSpec([2, None], tf.float32)))  


### Relevant log output

```shell
ValueError: Can't convert non-rectangular Python sequence to Tensor.
```
"
2353393875,69778,Aborted (core dumped) in `tf.raw_ops.CropAndResizeGradImage`,closed,2024-06-14 13:30:18+00:00,2024-07-04T01:51:25Z,2024-07-04T01:51:22Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/69778,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.16']","['@x0w3n I was able to replicate the issue reported [here](https://colab.research.google.com/gist/sushreebarsa/89cca63de4f64f2606aa6200f74f1cf5/69778.ipynb). The parameter T is incorrectly set to tf.float32. Could we set the data types as Python objects (dtype=tf.float32) rather than the type itself (T=tf.float32).\r\nThank You!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69778"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69778"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

On specific  inputs, tf.raw_ops.CropAndResizeGradImage triggers crash.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

tf.raw_ops.CropAndResizeGradImage(
    grads=tf.constant([], shape=(0, 2, 3, 1), dtype=tf.float32),
    boxes= tf.constant([[]], dtype=tf.float32),
    box_ind=tf.constant([], shape=(1, 0), dtype=tf.int32),
    image_size= tf.constant([1,1,1,1], shape=(4), dtype=tf.int32),
    T= tf.float32,
    method='bilinear',
    name=None
)
```


### Relevant log output

```shell
2024-06-14 13:28:05.614835: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-14 13:28:06.611621: F tensorflow/core/framework/tensor_shape.cc:45] Check failed: NDIMS == dims() (1 vs. 2)Asking for tensor of 1 dimensions from a tensor of 2 dimensions
Aborted (core dumped)
```
"
2353423687,69779,Crash in `tf.raw_ops.UnsortedSegmentJoin/UnsortedSegmentMin/UnsortedSegmentMax/UnsortedSegmentProd/UnsortedSegmentSum`,closed,2024-06-14 13:45:52+00:00,2024-07-02T01:51:41Z,2024-07-02T01:51:38Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/69779,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.16']","[""@x0w3n,\r\nFor UnsortedSegmentProd, we have below logic implemented and also reason for different implementation on CPU and GPU is:\r\nnum_segments should equal the number of distinct segment IDs.\r\nOn CPU, values in segment_ids are always validated to be less than num_segments, and an error is thrown\r\nfor out-of-bound indices.\r\nOn GPU, this does not throw an error for out-of-bound indices. On Gpu, out-of-bound indices result in safe but unspecified behavior, which may include ignoring out-of-bound indices or outputting a tensor with a 0 stored in the first\r\ndimension of its shape if num_segments is 0.\r\n\r\nAlso Your example is similar to malloc(a_huge_number) written by a programmer in their own code. This has exactly one effect: self-caused denial of service. Also, in this case, this is a user-caused DOS, not something that results from a very small input getting unpacked into something large (as it would be the case in a tar bomb for example, though even there we no longer care about these if they don't manifest in real world models)"", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69779"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69779"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

On specific input, These APIs will output ""The session crashed because it took up all available RAM.""
Furthermore，tf.raw_ops.UnsortedSegmentJoin triggered Aborted (core dumped). 

### Standalone code to reproduce the issue

```shell
https://colab.research.google.com/drive/14cpQrFAGZtNXXPvQzXGIYxOmJxIKhJ9q?usp=sharing
```


### Relevant log output

```shell
Jun 14, 2024, 9:37:23 PM	WARNING	WARNING:root:kernel 971d9681-81a9-4140-92f6-1ae620993b21 restarted
Jun 14, 2024, 9:37:23 PM	INFO	KernelRestarter: restarting kernel (1/5), keep random ports
Jun 14, 2024, 9:37:23 PM	WARNING	2024-06-14 13:37:23.763910: F tensorflow/core/framework/tensor_shape.cc:419] Check failed: 0 <= new_num_elements (0 vs. -1)
Jun 14, 2024, 9:37:16 PM	WARNING	2024-06-14 13:37:16.149795: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Jun 14, 2024, 9:37:14 PM	WARNING	To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Jun 14, 2024, 9:37:14 PM	WARNING	2024-06-14 13:37:14.046722: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
Jun 14, 2024, 9:31:38 PM	INFO	Kernel started: 971d9681-81a9-4140-92f6-1ae620993b21, name: python3
Jun 14, 2024, 9:23:53 PM	INFO	Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
Jun 14, 2024, 9:23:53 PM	INFO	http://172.28.0.12:9000/
Jun 14, 2024, 9:23:53 PM	INFO	Jupyter Notebook 6.5.5 is running at:
```
"
2353699328,69789,GCS gfile operations fail in TF 2.17.0rc0 and 2.18 nightly when not running in GCP,closed,2024-06-14 16:21:43+00:00,2024-07-10T13:18:02Z,2024-07-10T13:17:59Z,aaudiber,,https://github.com/tensorflow/tensorflow/issues/69789,"['stat:awaiting tensorflower', 'type:bug', 'comp:cloud', '2.17']","[""The only commit that comes to mind that might influence this is a4e3b786447042f4aa6ad5649a7fef9c4b40cee7, but I can't easily test this since tf-nightly wheels on pypi older than this date are not available."", '@learning-to-play , this is another regression in TF 2.17 RC0', 'Please consider filing an issue in TensorFlow IO. To my knowledge there are similar issues already reported to TensorFlow IO.\r\n\r\nFYI @yongtang @monicadsong @rtg0795 ', ""> Please consider filing an issue in TensorFlow IO. To my knowledge there are similar issues already reported to TensorFlow IO.\r\n\r\n@learning-to-play I already did at https://github.com/tensorflow/io/issues/2016.\r\nBut I'm not sure that it's related to TensorFlow IO since I can only reproduce this issue with TF 2.17 but not TF 2.16 even when both of them use the same `tensorflow_io_gcs_filesystem` package version."", '@aaudiber Could you PTAL and help route to the right person?', 'This is from tsl layer, not TF-IO.', ""Indeed, using a wheel from Feb 20 works:\r\n`gs://tensorflow-public-build-artifacts/prod/tensorflow/official/release/nightly/linux_x86_cpu/wheel_py311/391/20240220-042013/github/tensorflow/build_output/tf_nightly_cpu-2.17.0.dev20240220-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl`\r\n\r\n(there's more wheels in that bucket)\r\n\r\nI've been able to reproduce  this in one place, but it does work in a Docker container on a non-VM PC, so it's not necessarily VM-related.\r\n\r\nSo it does appear https://github.com/tensorflow/tensorflow/commit/a4e3b786447042f4aa6ad5649a7fef9c4b40cee7 is the cause.\r\nWe're looking into whether it can be rolled back"", 'Probably could be ""reverted"" via copybara', ""Thanks for looking into it and reproducing the issue. Also thanks for sharing the link to the older tf-nightly wheels, that's very useful to know."", 'This has been fixed in the latest nightly and on 2.17.0rc1 🎉 ', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69789"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69789"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.17.0rc0, 2.17.0-dev20240320, 2.17.0.dev20240528, 2.18.0.dev20240613, 2.18.0.dev20240617

### Custom code

No

### OS platform and distribution

Debian bookworm, macos 14.5

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When trying to run GCS operations with `tf.io.gfile` on nightly 2.17 or 2.18 anywhere outside of a GCP VM the command hangs and eventually fails after 10 retries with the error message as below.

I can't seem to reproduce this issue on either colab or a GCP VM. But it will consistently fail locally on my mac, inside a `python:3.11` docker container, on GitHub actions or inside a kaggle notebook. The same code works fine with TensorFlow 2.16 so I don't think this is due to my local setup.

It also seems like other people are running into this with the latest TF nightly: https://github.com/tensorflow/datasets/issues/5360

Would be great to get this fixed before the 2.17 stable release.

### Standalone code to reproduce the issue

```python
import tensorflow as tf

tf.io.gfile.exists(""gs://tfds-data/dataset_info/mnist/3.0.1/dataset_info.json"")
```


### Relevant log output

```shell
2024-06-14 15:45:30.081439: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""NOT_FOUND: Could not locate the credentials file."". Retrieving token from GCE failed with ""FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal"".
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.11/site-packages/tensorflow/python/lib/io/file_io.py"", line 290, in file_exists_v2
    _pywrap_file_io.FileExists(compat.path_to_bytes(path))
tensorflow.python.framework.errors_impl.AbortedError: All 10 retry attempts failed. The last failure: Error executing an HTTP request: HTTP response code 301 with body '<HTML><HEAD><meta http-equiv=""content-type"" content=""text/html;charset=utf-8"">
<TITLE>301 Moved</TITLE></HEAD><BODY>
<H1>301 Moved</H1>
The document has moved
<A HREF=""https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fmnist%2F3.0.1%2Fdataset_info.json?fields=size%2Cgeneration%2Cupdated"">here</A>.
</BODY></HTML>
'
	 when reading metadata of gs://tfds-data/dataset_info/mnist/3.0.1/dataset_info.json
```
"
2354365909,69811,Immediate Assistance Required: Issue with Converting Keras Model to TFLite,closed,2024-06-15 01:14:41+00:00,2024-07-06T01:49:28Z,2024-07-06T01:49:23Z,sawantkumar,,https://github.com/tensorflow/tensorflow/issues/69811,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'TFLiteConverter', 'TF 2.16']","['Hi @orikkwak ,\r\n\r\nI tried replicating your issue in colab, but it keeps crashing because i run out of VRAM while training on the Tesla T4 GPU . Can you please share me the saved model instead ?', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69811"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69811"">No</a>\n']","### 1. System information

- OS Platform and Distribution : Windows 10 / flutter 3.19.5 /dart 3.3.3 / python 3.12.4
- TensorFlow installation : pip package
- TensorFlow library : 2.16.1

### 2. Code
#### Option B: Paste your code here or provide a link to a custom end-to-end colab
import os
import tensorflow as tf
import tensorflow_datasets as tfds
import tensorflow_hub as hub
import warnings

# 경고 메시지 무시
warnings.filterwarnings(""ignore"", category=DeprecationWarning)
warnings.filterwarnings(""ignore"", category=FutureWarning)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # TensorFlow의 INFO 및 WARNING 메시지 무시

# 데이터 로드 및 전처리 함수
def load_data():
    def preprocess(image, label):
        try:
            image = tf.image.resize(image, (224, 224))
            image = image / 255.0  # 정규화
        except Exception as e:
            print(f""Error in preprocessing: {e}"")
            return None, None
        return image, label

    train_dataset, test_dataset = tfds.load('cifar10', split=['train', 'test'], as_supervised=True)
    train_dataset = train_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)
    train_dataset = train_dataset.filter(lambda x, y: x is not None)  # 예외 처리된 데이터 제외
    train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)

    test_dataset = test_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)
    test_dataset = test_dataset.filter(lambda x, y: x is not None)  # 예외 처리된 데이터 제외
    test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)

    return train_dataset, test_dataset

# 모델 클래스 정의
class EfficientNetLiteModel(tf.keras.layers.Layer):
    def __init__(self):
        super(EfficientNetLiteModel, self).__init__()
        effnet_lite_url = ""https://tfhub.dev/tensorflow/efficientnet/lite0/feature-vector/2""
        self.effnet_lite_layer = hub.KerasLayer(effnet_lite_url, trainable=False)
        self.dense_layer = tf.keras.layers.Dense(10)  # softmax 활성화 함수 제거

    def call(self, inputs):
        outputs = self.effnet_lite_layer(inputs)
        outputs = self.dense_layer(outputs)
        return outputs

# 모델 생성 함수
def build_model():
    model = tf.keras.Sequential([
        EfficientNetLiteModel()
    ])
    model.build(input_shape=(None, 224, 224, 3))
    model.compile(optimizer='adam',
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['accuracy'])
    return model


# 모델 학습 함수
def train_model(model_name):
    train_dataset, test_dataset = load_data()
    model = build_model()

    model.fit(train_dataset, epochs=3, validation_data=test_dataset)

    # 여러 최적화 옵션으로 모델 저장
    export_quantized_model(model, model_name, tf.lite.Optimize.DEFAULT, ""default"")
    export_quantized_model(model, model_name, tf.lite.Optimize.OPTIMIZE_FOR_LATENCY, ""latency"")
    export_quantized_model(model, model_name, tf.lite.Optimize.OPTIMIZE_FOR_SIZE, ""size"")

    # Keras 모델 저장
    model.save(f""{model_name}.h5"")

# 정량화된 TFLite 모델 내보내기
def export_quantized_model(model, model_name, optimization, suffix):
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.optimizations = [optimization]
    
    # 입력 형상 지정을 위한 대표 데이터셋 생성
    def representative_dataset():
        for images, _ in load_data()[0].take(100):
            data = tf.cast(images, tf.float32)
            yield [data]

    converter.representative_dataset = representative_dataset

    # 대표 데이터셋 생성자
    def representative_dataset_gen():
        for images, _ in load_data()[0].take(100):
            yield [images]
            
    converter.representative_dataset = representative_dataset_gen
    tflite_quant_model = converter.convert()

    tflite_model_file = f""{model_name}_quant_{suffix}.tflite""
    with open(tflite_model_file, 'wb') as f:
        f.write(tflite_quant_model)


# TFLite 모델 평가 함수
def evaluate_tflite_model(tflite_model_path, test_dataset):
    # TFLite 모델 로드
    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)
    interpreter.allocate_tensors()

    input_index = interpreter.get_input_details()[0]['index']
    output_index = interpreter.get_output_details()[0]['index']

    # 정확도 평가
    total_seen = 0
    num_correct = 0

    for images, labels in test_dataset:
        interpreter.set_tensor(input_index, images)
        interpreter.invoke()
        predictions = interpreter.get_tensor(output_index)

        predicted_labels = tf.argmax(predictions, axis=1)
        num_correct += tf.reduce_sum(tf.cast(predicted_labels == labels, tf.int32)).numpy()
        total_seen += images.shape[0]

    accuracy = num_correct / total_seen
    print(f""TFLite 모델 ({tflite_model_path}) 정확도: {accuracy:.4f}"")

# 메인 함수
def main():
    model_name = ""efficientnet-lite0""
    train_model(model_name)  # 여러 최적화된 모델 생성
    
    # 학습된 TFLite 모델 평가
    _, test_dataset = load_data()
    evaluate_tflite_model(f""{model_name}.tflite"", test_dataset)
    evaluate_tflite_model(f""{model_name}_quant_default.tflite"", test_dataset)
    evaluate_tflite_model(f""{model_name}_quant_latency.tflite"", test_dataset)
    evaluate_tflite_model(f""{model_name}_quant_size.tflite"", test_dataset)

if __name__ == ""__main__"":
    main()

### 3. Failure after conversion
2024-06-15 07:33:32.135707: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-15 07:33:33.475807: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING:tensorflow:From D:\getxgallery\myenv\Lib\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

Epoch 3/3
1563/1563 ━━━━━━━━━━━━━━━━━━━━ 0s 324ms/step - accuracy: 0.9128 - loss: 0.25622024-06-15 08:03:13.894773: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]
2024-06-15 08:05:09.110888: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]
1563/1563 ━━━━━━━━━━━━━━━━━━━━ 623s 398ms/step - accuracy: 0.9128 - loss: 0.2562 - val_accuracy: 0.8921 - val_loss: 0.3063
Traceback (most recent call last):
  File ""D:\getxgallery\model_training\gallery_model_training\test.py"", line 138, in <module>
    main()
  File ""D:\getxgallery\model_training\gallery_model_training\test.py"", line 128, in main
    train_model(model_name)  # 여러 최적화된 모델 생성
    ^^^^^^^^^^^^^^^^^^^^^^^
  File ""D:\getxgallery\model_training\gallery_model_training\test.py"", line 67, in train_model
    export_quantized_model(model, model_name, tf.lite.Optimize.DEFAULT, ""default"")
  File ""D:\getxgallery\model_training\gallery_model_training\test.py"", line 93, in export_quantized_model
    tflite_quant_model = converter.convert()
                         ^^^^^^^^^^^^^^^^^^^
  File ""D:\getxgallery\myenv\Lib\site-packages\tensorflow\lite\python\lite.py"", line 1175, in wrapper
    return self._convert_and_export_metrics(convert_func, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""D:\getxgallery\myenv\Lib\site-packages\tensorflow\lite\python\lite.py"", line 1129, in _convert_and_export_metrics  
    result = convert_func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""D:\getxgallery\myenv\Lib\site-packages\tensorflow\lite\python\lite.py"", line 1641, in convert
    self._freeze_keras_model()
  File ""D:\getxgallery\myenv\Lib\site-packages\tensorflow\lite\python\convert_phase.py"", line 215, in wrapper
    raise error from None  # Re-throws the exception.
    ^^^^^^^^^^^^^^^^^^^^^
  File ""D:\getxgallery\myenv\Lib\site-packages\tensorflow\lite\python\convert_phase.py"", line 205, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File ""D:\getxgallery\myenv\Lib\site-packages\tensorflow\lite\python\lite.py"", line 1582, in _freeze_keras_model
    input_signature = _model_input_signature(
                      ^^^^^^^^^^^^^^^^^^^^^^^
  File ""D:\getxgallery\myenv\Lib\site-packages\tensorflow\lite\python\tflite_keras_util.py"", line 84, in model_input_signature
    input_specs = model._get_save_spec(  # pylint: disable=protected-access
                  ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Sequential' object has no attribute '_get_save_spec'. Did you mean: '_set_save_spec'?"
2356808156,69851,cannot import name 'mean_squared_error' from 'tensorflow.keras.losses,closed,2024-06-17 09:06:08+00:00,2024-11-07T11:46:56Z,2024-06-25T07:15:06Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/69851,"['stat:awaiting response', 'type:bug', 'comp:apis', 'TF 2.16']","[""@GreatKampfstern I was able to import 'mean_squared_error' from 'tensorflow.keras.losses , please follow the correct commands as below;\r\n```\r\n!pip install pyod\r\nimport tensorflow as tf\r\nfrom pyod.models.auto_encoder import AutoEncoder\r\nfrom tensorflow.keras.losses import mean_squared_error\r\n\r\n```\r\nPlease find the gist [here](https://colab.research.google.com/gist/sushreebarsa/fc1d450185fd38628007e8e08de9540b/69851.ipynb#scrollTo=ZSzMQaR6-rwo) for your reference. Thank you!"", ""If I first execute \r\n```\r\n!pip install --upgrade pyod\r\n!pip install --upgrade tf-keras\r\n!pip install --upgrade tensorflow\r\n```\r\nand then do\r\n`from pyod.models.auto_encoder import AutoEncoder`\r\nI get the same error:\r\n\r\n> ImportError                               Traceback (most recent call last)\r\n> \r\n> [<ipython-input-10-16f16faeafae>](https://localhost:8080/#) in <cell line: 1>()\r\n> ----> 1 from pyod.models.auto_encoder import AutoEncoder\r\n> \r\n> [/usr/local/lib/python3.10/dist-packages/pyod/models/auto_encoder.py](https://localhost:8080/#) in <module>\r\n>      28     from tensorflow.keras.layers import Dense, Dropout\r\n>      29     from tensorflow.keras.regularizers import l2\r\n> ---> 30     from tensorflow.keras.losses import mean_squared_error\r\n>      31 \r\n>      32 \r\n> \r\n> ImportError: cannot import name 'mean_squared_error' from 'tensorflow.keras.losses' (/usr/local/lib/python3.10/dist-packages/keras/_tf_keras/keras/losses/__init__.py)\r\n\r\nSorry if the first three lines are stupid, I just thought (when I did it on my computer) that I first have to install and upgrade all packages. And as far as I know it should still work if I upgrade everything.\r\n[Gist for reference](https://colab.research.google.com/gist/GreatKampfstern/1d5085ba5d7623940d16c3367f1fc055/69851.ipynb)"", '@GreatKampfstern `keras.src.losses.losses` refers to an internal path within the Keras source code which is not recommended for use.  The following command is recommended for use;\r\n```\r\nfrom tensorflow.keras.losses import mean_squared_error\r\n\r\n```\r\nFirstly install pyod and then run the command for AutoEncoder as below;\r\n```\r\n!pip install pyod\r\n\r\nfrom pyod.models.auto_encoder import AutoEncoder\r\n\r\n```\r\nPlease have a look at this [gist](https://colab.research.google.com/gist/sushreebarsa/672cb0955efd4f879559646b22a9098d/69851.ipynb). Thank you!', ""> @GreatKampfstern `keras.src.losses.losses` refers to an internal path within the Keras source code which is not recommended for use. The following command is recommended for use;\r\n> \r\n> ```\r\n> from tensorflow.keras.losses import mean_squared_error\r\n> ```\r\nYeah I wasn't doing that.\r\n\r\nBut anyways thank you, you showed me that it's enough to just install pyod. So I uninstalled every tensorflow and keras module I had installed and now it works.\r\nAnd in my Gist in the comment above it now works, even tough I didn't change anything."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69851"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69851"">No</a>\n', 'The name is changed to MeanSquaredError.please replace mean_squared_error with MeanSquaredError. This Works for me thank you']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

tf 2.16.1

### Custom code

No

### OS platform and distribution

Linux Ubuntu 22.04.2

### Mobile device

_No response_

### Python version

3.10.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When I import auto_encoder I get following error:
```
    from tensorflow.keras.losses import mean_squared_error
ImportError: cannot import name 'mean_squared_error' from 'tensorflow.keras.losses'
```
This also happens on Windows Powershell, all modules are on the latest stable version

If I go into the file '/home/user/.local/lib/python3.10/site-packages/keras/_tf_keras/keras/losses/__init__.py' and change the line 
`from keras.src.losses.losses import mean_squared_error as mse` to
`from keras.src.losses.losses import mean_squared_error` it works

### Standalone code to reproduce the issue

```shell
from pyod.models.auto_encoder import AutoEncoder
```


### Relevant log output

```shell
On Bash:

2024-06-17 11:11:41.210014: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-17 11:11:42.147055: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/user/.local/lib/python3.10/site-packages/pyod/models/auto_encoder.py"", line 30, in <module>
    from tensorflow.keras.losses import mean_squared_error
ImportError: cannot import name 'mean_squared_error' from 'tensorflow.keras.losses' (/home/user/.local/lib/python3.10/site-packages/keras/_tf_keras/keras/losses/__init__.py)

In Jupyter Notebook:

---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
Cell In[3], line 1
----> 1 from pyod.models.auto_encoder import AutoEncoder

File ~/.local/lib/python3.10/site-packages/pyod/models/auto_encoder.py:30
     28     from tensorflow.keras.layers import Dense, Dropout
     29     from tensorflow.keras.regularizers import l2
---> 30     from tensorflow.keras.losses import mean_squared_error
     33 # noinspection PyUnresolvedReferences,PyPep8Naming,PyTypeChecker
     34 class AutoEncoder(BaseDetector):

ImportError: cannot import name 'mean_squared_error' from 'tensorflow.keras.losses' (/home/user/.local/lib/python3.10/site-packages/keras/_tf_keras/keras/losses/__init__.py)
```
"
2357302012,69869,`tf.debugging.enable_check_numerics` maximum recursion depth,closed,2024-06-17 13:04:20+00:00,2024-07-06T01:49:25Z,2024-07-06T01:49:22Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/69869,"['stat:awaiting response', 'type:bug', 'stale', 'TF 2.16']","['Hi **@johnlarkin1** ,\r\n- I reproduced the code shared but facing different error .Could you please share the colab gist with all the dependencies to analyze more of it.\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69869"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69869"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

v2.16.1-0-g5bc9d26649c 2.16.1

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS

### Mobile device

_No response_

### Python version

Python 3.11.0rc1

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I am trying to debug an incredibly annoying `nan/inf` issue in my Tensorflow model. I have tried to use the Tensorboard Debugger V2 but often it is unable to render when I specify `-1` for the max_buffer_size because it generates around like 80GB of logs which is also unfortunate. 

I'm trying to utilize `tf.debugging.enable_check_numerics()` so that I can find the first place that a `nan/inf` enters one of my Tensors and starts to corrupt it. 

### Standalone code to reproduce the issue

```shell
Here is the main entrypoint for the script that I'm executing: 


import os
from alphabet import ALPHABET_SIZE
from callbacks import (
    ExtendedModelCheckpoint,
    ModelCheckpointWithPeriod,
    PrintModelParametersCallback,
)
from loader import HandwritingDataLoader
from model.handwriting_models import (
    DeepHandwritingSynthesisModel,
)

import tensorflow as tf
import numpy as np
import datetime

from constants import (
    BATCH_SIZE,
    GRADIENT_CLIP_VALUE,
    LEARNING_RATE,
    NUM_BIVARIATE_GAUSSIAN_MIXTURE_COMPONENTS,
    NUM_ATTENTION_GAUSSIAN_COMPONENTS,
    NUM_EPOCH,
)

tf.keras.mixed_precision.set_global_policy('float32')
np.set_printoptions(threshold=10)

# Path logic for saved files
curr_directory = os.path.dirname(os.path.realpath(__file__))
model_name = ""handwriting_synthesis""
model_save_dir = f""{curr_directory}/saved/models/{model_name}/""
start_day = datetime.datetime.now().strftime(""%Y%m%d"")
log_dir = f""{curr_directory}/saved/logs/{model_name}/profile/{start_day}""
debugging_dir = f""{curr_directory}/saved/logs/{model_name}/debug/{start_day}""
os.makedirs(model_save_dir, exist_ok=True)
os.makedirs(log_dir, exist_ok=True)
os.makedirs(debugging_dir, exist_ok=True)
model_save_path = os.path.join(model_save_dir, ""best_model.keras"")
checkpoint_model_filepath = os.path.join(
    model_save_dir, ""model_{epoch:02d}_{val_loss:.2f}.keras""
)
model_save_path_final = os.path.join(model_save_dir, ""best_model_final.keras"")
epochs_info_path = os.path.join(model_save_dir, ""epochs_info.json"")

# Hyper parameters
num_mixture_components = NUM_BIVARIATE_GAUSSIAN_MIXTURE_COMPONENTS
num_attention_gaussians = NUM_ATTENTION_GAUSSIAN_COMPONENTS

# Training parameters
desired_epochs = 10_000
model_chkpt_period = 200


# Get the data
data_loader = HandwritingDataLoader()
data_loader.prepare_data()
combined_train_strokes, combined_train_lengths = (
    data_loader.combined_train_strokes,
    data_loader.combined_train_stroke_lengths,
)
combined_train_trans, combined_trans_lengths = (
    data_loader.combined_train_transcriptions,
    data_loader.combined_train_transcription_lengths,
)

if __name__ == ""__main__"":
    # Preparing the input and target data for training
    x_train = combined_train_strokes
    x_train_len = combined_train_lengths
    y_train = np.zeros_like(x_train)
    y_train[:, :-1, :] = x_train[:, 1:, :]
    y_train_len = x_train_len - 1

    # Preparing the transcription information
    char_seq = combined_train_trans
    char_seq_len = combined_trans_lengths

    best_loss = float(""inf"")
    batch_size = BATCH_SIZE
    print(f""Debugging info: {debugging_dir}"")
    #tf.debugging.set_log_device_placement(True)
    tf.config.set_soft_device_placement(True)
    tf.debugging.enable_check_numerics()
    tf.debugging.experimental.enable_dump_debug_info(
        debugging_dir, tensor_debug_mode=""FULL_HEALTH"", circular_buffer_size=10_000_000
    )

    dataset = tf.data.Dataset.from_tensor_slices(
        (
            {
                ""input_strokes"": x_train,
                ""input_stroke_lens"": x_train_len,
                ""input_chars"": char_seq,
                ""input_char_lens"": char_seq_len,
            },
            y_train,
        )
    ).batch(BATCH_SIZE)

    stroke_model = DeepHandwritingSynthesisModel(
        units=400,
        num_layers=3,
        num_mixture_components=num_mixture_components,
        num_chars=ALPHABET_SIZE,
        num_attention_gaussians=num_attention_gaussians,
        gradient_clip_value=GRADIENT_CLIP_VALUE,
    )
    learning_rate_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate=LEARNING_RATE,
        decay_steps=50_000,
        decay_rate=0.96,
        staircase=True,
    )
    stroke_model.compile(
        optimizer=tf.keras.optimizers.RMSprop(
            learning_rate=learning_rate_schedule,
            global_clipnorm=GRADIENT_CLIP_VALUE,
        ),
    )

    callbacks = [
        tf.keras.callbacks.TensorBoard(
            log_dir=log_dir, histogram_freq=1, profile_batch=""500,520""
        ),
        ModelCheckpointWithPeriod(model_name, period=200),
        ExtendedModelCheckpoint(model_name),
        PrintModelParametersCallback(),
    ]

    history = stroke_model.fit(dataset, epochs=desired_epochs, callbacks=callbacks)
    stroke_model.save(model_save_path)
    print(""Training completed."")
```


### Relevant log output

```shell
Debugging info: /root/code/src/saved/logs/handwriting_synthesis/debug/20240617
2024-06-17 12:56:20.745453: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
Traceback (most recent call last):
  File ""/root/code/src/train_handwriting_synthesis.py"", line 115, in <module>
    stroke_model.compile(
  File ""/root/code/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py"", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/root/code/venv/lib/python3.11/site-packages/tensorflow/dtensor/python/api.py"", line 64, in call_with_layout
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File ""/root/code/venv/lib/python3.11/site-packages/numpy/core/arrayprint.py"", line 1612, in _array_str_implementation
    return array2string(a, max_line_width, precision, suppress_small, ' ', """")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/root/code/venv/lib/python3.11/site-packages/numpy/core/arrayprint.py"", line 736, in array2string
    return _array2string(a, options, separator, prefix)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/root/code/venv/lib/python3.11/site-packages/numpy/core/arrayprint.py"", line 513, in wrapper
    return f(self, *args, **kwargs)
    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/root/code/venv/lib/python3.11/site-packages/numpy/core/arrayprint.py"", line 539, in _array2string
    format_function = _get_format_function(data, **options)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/root/code/venv/lib/python3.11/site-packages/numpy/core/arrayprint.py"", line 472, in _get_format_function
    return formatdict['float']()
           ^^^^^^^^^^^^^^^^^^^^^
  File ""/root/code/venv/lib/python3.11/site-packages/numpy/core/arrayprint.py"", line 411, in <lambda>
    'float': lambda: FloatingFormat(
                     ^^^^^^^^^^^^^^^
RecursionError: maximum recursion depth exceeded while calling a Python object
```
"
2358729650,69920,AttributeError: module 'tensorflow' has no attribute 'layers',closed,2024-06-18 02:34:44+00:00,2024-07-01T06:23:23Z,2024-06-18T02:35:17Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/69920,"['type:bug', 'comp:apis', 'TF 2.0']","['Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69920"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69920"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

self.pooled_output = tf.layers.dense(
            first_token_tensor,
            config.hidden_size,
            activation=tf.tanh,
            kernel_initializer=create_initializer(config.initializer_range))

### Standalone code to reproduce the issue

```shell
File ""BertSimilarity/modeling.py"", line 229, in __init__
    self.pooled_output = tf.layers.dense(
AttributeError: module 'tensorflow' has no attribute 'layers'
```


### Relevant log output

_No response_"
2359540974,69951,Build TensorFlow for raspberry pi failed by ): relocation truncated to fit: R_AARCH64_CALL26 against symbol ,closed,2024-06-18 10:41:41+00:00,2024-08-10T01:54:28Z,2024-08-10T01:54:25Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/69951,"['stat:awaiting response', 'type:bug', 'type:build/install', 'type:support', 'stale', 'comp:lite', 'TF 2.16']","[""I have tried to add -fPIC in the build flag, but it still reports the same issue.  I also tried change '-O2‘ to '-Os', it is the same. \r\nIf I add '-mcmodel=large' in the build flag, it will report confliction with '-fPIC' when build python _pywrap_snapshot_utils.cc."", ""Hi,\r\nI also tried the latest code, it still have the same issue.\r\n\r\nBuilding for the aarch64\r\nINFO: Reading 'startup' options from /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow/.bazelrc: --windows_enable_symlinks\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=122\r\nINFO: Reading rc options for 'build' from /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow/.bazelrc:\r\n  'build' options: --define framework_shared_object=true --define tsl_protobuf_header_only=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --features=-force_no_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=false --incompatible_enforce_config_setting_visibility\r\nINFO: Reading rc options for 'build' from /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3/dist-packages --python_path=/usr/bin/python3 --define=with_xla_support=false\r\nINFO: Found applicable config definition build:short_logs in file /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:elinux_aarch64 in file /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow/.bazelrc: --config=elinux --cpu=aarch64\r\nINFO: Found applicable config definition build:elinux in file /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow/.bazelrc: --crosstool_top=@local_config_embedded_arm//:toolchain --host_crosstool_top=@bazel_tools//tools/cpp:toolchain\r\nINFO: Found applicable config definition build:monolithic in file /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow/.bazelrc: --define framework_shared_object=false --define tsl_protobuf_header_only=false --experimental_link_static_libraries_once=false\r\nINFO: Found applicable config definition build:linux in file /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow/.bazelrc: --host_copt=-w --copt=-Wno-all --copt=-Wno-extra --copt=-Wno-deprecated --copt=-Wno-deprecated-declarations --copt=-Wno-ignored-attributes --copt=-Wno-array-bounds --copt=-Wunused-result --copt=-Werror=unused-result --copt=-Wswitch --copt=-Werror=switch --copt=-Wno-error=unused-but-set-variable --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++17 --host_cxxopt=-std=c++17 --config=dynamic_kernels --experimental_guard_against_concurrent_changes\r\nINFO: Found applicable config definition build:dynamic_kernels in file /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nINFO: Analyzed 4 targets (299 packages loaded, 18526 targets configured).\r\nINFO: Found 4 targets...\r\nERROR: /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow/tensorflow/BUILD:1318:21: Linking tensorflow/libtensorflow_cc.so.2.18.0 failed: (Exit 1): aarch64-none-linux-gnu-gcc failed: error executing command (from target //tensorflow:libtensorflow_cc.so.2.18.0)\r\n  (cd /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow/build/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python3 \\\r\n    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n  /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow/build/external/aarch64_linux_toolchain/bin/aarch64-none-linux-gnu-gcc @bazel-out/aarch64-opt/bin/tensorflow/libtensorflow_cc.so.2.18.0-2.params)\r\n# Configuration: f86a22a88103843b2f048db8d142631a85f0eddbce9df51d51c468ebb4786d1f\r\n# Execution platform: @local_execution_config_platform//:platform\r\nbazel-out/aarch64-opt/bin/tensorflow/c/experimental/gradients/libmath_grad.pic.a(math_grad.pic.o): in function `tsl::core::RefCounted::Unref() const [clone .constprop.0]':\r\nmath_grad.cc:(.text.unlikely._ZNK3tsl4core10RefCounted5UnrefEv.constprop.0+0x14): relocation truncated to fit: R_AARCH64_CALL26 against symbol `__aarch64_ldadd8_acq_rel' defined in .text section in /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow/build/external/aarch64_linux_toolchain/bin/../lib/gcc/aarch64-none-linux-gnu/11.3.1/libgcc.a(ldadd_8_4.o)\r\nbazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/python/libjax_to_tfl_flatbuffer.pic.a(jax_to_tfl_flatbuffer.pic.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <absl::lts_20230802::Status, 0>(absl::lts_20230802::Status const&) [clone .isra.0]':\r\njax_to_tfl_flatbuffer.cc:(.text.unlikely._ZN4absl12lts_2023080212log_internal10LogMessagelsINS0_6StatusELi0EEERS2_RKT_.isra.0+0x1c): relocation truncated to fit: R_AARCH64_CALL26 against symbol `absl::lts_20230802::log_internal::LogMessage::OstreamView::OstreamView(absl::lts_20230802::log_internal::LogMessage::LogMessageData&)' defined in .text._ZN4absl12lts_2023080212log_internal10LogMessage11OstreamViewC2ERNS2_14LogMessageDataE section in bazel-out/aarch64-opt/bin/external/com_google_absl/absl/log/internal/liblog_message.pic.a(log_message.pic.o)\r\njax_to_tfl_flatbuffer.cc:(.text.unlikely._ZN4absl12lts_2023080212log_internal10LogMessagelsINS0_6StatusELi0EEERS2_RKT_.isra.0+0x24): relocation truncated to fit: R_AARCH64_CALL26 against symbol `absl::lts_20230802::log_internal::LogMessage::OstreamView::stream()' defined in .text._ZN4absl12lts_2023080212log_internal10LogMessage11OstreamView6streamEv section in bazel-out/aarch64-opt/bin/external/com_google_absl/absl/log/internal/liblog_message.pic.a(log_message.pic.o)\r\njax_to_tfl_flatbuffer.cc:(.text.unlikely._ZN4absl12lts_2023080212log_internal10LogMessagelsINS0_6StatusELi0EEERS2_RKT_.isra.0+0x2c): relocation truncated to fit: R_AARCH64_CALL26 against symbol `absl::lts_20230802::operator<<(std::ostream&, absl::lts_20230802::Status const&)' defined in .text._ZN4absl12lts_20230802lsERSoRKNS0_6StatusE section in bazel-out/aarch64-opt/bin/external/com_google_absl/absl/status/libstatus.pic.a(status.pic.o)\r\njax_to_tfl_flatbuffer.cc:(.text.unlikely._ZN4absl12lts_2023080212log_internal10LogMessagelsINS0_6StatusELi0EEERS2_RKT_.isra.0+0x34): relocation truncated to fit: R_AARCH64_CALL26 against symbol `absl::lts_20230802::log_internal::LogMessage::OstreamView::~OstreamView()' defined in .text._ZN4absl12lts_2023080212log_internal10LogMessage11OstreamViewD2Ev section in bazel-out/aarch64-opt/bin/external/com_google_absl/absl/log/internal/liblog_message.pic.a(log_message.pic.o)\r\njax_to_tfl_flatbuffer.cc:(.text.unlikely._ZN4absl12lts_2023080212log_internal10LogMessagelsINS0_6StatusELi0EEERS2_RKT_.isra.0+0x50): relocation truncated to fit: R_AARCH64_CALL26 against symbol `absl::lts_20230802::log_internal::LogMessage::OstreamView::~OstreamView()' defined in .text._ZN4absl12lts_2023080212log_internal10LogMessage11OstreamViewD2Ev section in bazel-out/aarch64-opt/bin/external/com_google_absl/absl/log/internal/liblog_message.pic.a(log_message.pic.o)\r\nbazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/libtf_to_tfl_flatbuffer.pic.a(tf_to_tfl_flatbuffer.pic.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <absl::lts_20230802::Status, 0>(absl::lts_20230802::Status const&) [clone .isra.0]':\r\ntf_to_tfl_flatbuffer.cc:(.text.unlikely._ZN4absl12lts_2023080212log_internal10LogMessagelsINS0_6StatusELi0EEERS2_RKT_.isra.0+0x1c): relocation truncated to fit: R_AARCH64_CALL26 against symbol `absl::lts_20230802::log_internal::LogMessage::OstreamView::OstreamView(absl::lts_20230802::log_internal::LogMessage::LogMessageData&)' defined in .text._ZN4absl12lts_2023080212log_internal10LogMessage11OstreamViewC2ERNS2_14LogMessageDataE section in bazel-out/aarch64-opt/bin/external/com_google_absl/absl/log/internal/liblog_message.pic.a(log_message.pic.o)\r\ntf_to_tfl_flatbuffer.cc:(.text.unlikely._ZN4absl12lts_2023080212log_internal10LogMessagelsINS0_6StatusELi0EEERS2_RKT_.isra.0+0x24): relocation truncated to fit: R_AARCH64_CALL26 against symbol `absl::lts_20230802::log_internal::LogMessage::OstreamView::stream()' defined in .text._ZN4absl12lts_2023080212log_internal10LogMessage11OstreamView6streamEv section in bazel-out/aarch64-opt/bin/external/com_google_absl/absl/log/internal/liblog_message.pic.a(log_message.pic.o)\r\ntf_to_tfl_flatbuffer.cc:(.text.unlikely._ZN4absl12lts_2023080212log_internal10LogMessagelsINS0_6StatusELi0EEERS2_RKT_.isra.0+0x2c): relocation truncated to fit: R_AARCH64_CALL26 against symbol `absl::lts_20230802::operator<<(std::ostream&, absl::lts_20230802::Status const&)' defined in .text._ZN4absl12lts_20230802lsERSoRKNS0_6StatusE section in bazel-out/aarch64-opt/bin/external/com_google_absl/absl/status/libstatus.pic.a(status.pic.o)\r\ntf_to_tfl_flatbuffer.cc:(.text.unlikely._ZN4absl12lts_2023080212log_internal10LogMessagelsINS0_6StatusELi0EEERS2_RKT_.isra.0+0x34): relocation truncated to fit: R_AARCH64_CALL26 against symbol `absl::lts_20230802::log_internal::LogMessage::OstreamView::~OstreamView()' defined in .text._ZN4absl12lts_2023080212log_internal10LogMessage11OstreamViewD2Ev section in bazel-out/aarch64-opt/bin/external/com_google_absl/absl/log/internal/liblog_message.pic.a(log_message.pic.o)\r\ntf_to_tfl_flatbuffer.cc:(.text.unlikely._ZN4absl12lts_2023080212log_internal10LogMessagelsINS0_6StatusELi0EEERS2_RKT_.isra.0+0x50): additional relocation overflows omitted from the output\r\ncollect2: error: ld returned 1 exit status\r\nERROR: /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow/tensorflow/tools/pip_package/BUILD:266:9 Action tensorflow/tools/pip_package/wheel_house failed: (Exit 1): aarch64-none-linux-gnu-gcc failed: error executing command (from target //tensorflow:libtensorflow_cc.so.2.18.0)\r\n  (cd /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow/build/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python3 \\\r\n    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n  /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow/build/external/aarch64_linux_toolchain/bin/aarch64-none-linux-gnu-gcc @bazel-out/aarch64-opt/bin/tensorflow/libtensorflow_cc.so.2.18.0-2.params)\r\n# Configuration: f86a22a88103843b2f048db8d142631a85f0eddbce9df51d51c468ebb4786d1f\r\n# Execution platform: @local_execution_config_platform//:platform\r\nINFO: Elapsed time: 758.820s, Critical Path: 625.27s\r\nINFO: 6123 processes: 721 internal, 5402 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n\r\n"", 'Hi,\r\n\r\nAdd more info when I debug it. This issue ONLY happens at build the target --//tensorflow/tools/pip_package:build_pip_package\r\nWhich should be the python package.\r\n\r\nWillen', ""I met with a similar problem when running `bazel build //tensorflow/tools/pip_package:build_pip_package` with tensorflow version r2.13, GCC 9.4.0. It is on a Jetson Orin NX Jetpack 5.1. \r\n\r\nThe bazel build always failed at `Linking tensorflow/libtensorflow_cc.so.2.13.1`. I believe it is because the size of this lib file is too large for a normal ARM jumping instruction to jump somewhere inside/to this lib. There was a similar issue #48919 on an x86-64 platform, resulting from a `--dbg` flag generating way more debugging information in the lib. \r\n\r\nOf course it should be not so easy to shrink the lib size. I used to find some sources that mentioned the `-mcmodel` and `-fPIC` compilation flags. Maybe I am gonna report the result here after I try them.\r\n\r\nHere is my error logs.\r\n```\r\nERROR: /home/user/tensorflow/tensorflow/BUILD:1272:21: Linking tensorflow/libtensorflow_cc.so.2.13.1 failed: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc @bazel-out/aarch64-opt/bin/tensorflow/libtensorflow_cc.so.2.13.1-2.params\r\n/home/user/.cache/bazel/_bazel_user/b0c16afcd5d9b574b1ee2f726ab4799c/execroot/org_tensorflow/external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc:44: DeprecationWarning: 'pipes' is deprecated and slated for removal in Python 3.13\r\n  import pipes\r\nbazel-out/aarch64-opt/bin/tensorflow/compiler/aot/libtfcompile_lib.pic.a(compile.pic.o): in function `llvm::object_creator<std::function<absl::lts_20230125::Status (tensorflow::tf2xla::Config const&, xla::XlaComputation*)> >::call()':\r\ncompile.cc:(.text._ZN4llvm14object_creatorISt8functionIFN4absl12lts_202301256StatusERKN10tensorflow6tf2xla6ConfigEPN3xla14XlaComputationEEEE4callEv[_ZN4llvm14object_creatorISt8functionIFN4absl12lts_202301256StatusERKN10tensorflow6tf2xla6ConfigEPN3xla14XlaComputationEEEE4callEv]+0xc): relocation truncated to fit: R_AARCH64_CALL26 against symbol `operator new(unsigned long)@@GLIBCXX_3.4' defined in .text section in /usr/lib/gcc/aarch64-linux-gnu/9/libstdc++.so\r\nbazel-out/aarch64-opt/bin/tensorflow/compiler/aot/libtfcompile_lib.pic.a(compile.pic.o): in function `tensorflow::tfcompile::InitializeTargets()':\r\ncompile.cc:(.text._ZN10tensorflow9tfcompileL17InitializeTargetsEv+0x14): relocation truncated to fit: R_AARCH64_CALL26 against symbol `LLVMInitializeAArch64AsmParser' defined in .text.LLVMInitializeAArch64AsmParser section in bazel-out/aarch64-opt/bin/external/llvm-project/llvm/libAArch64AsmParser.pic.a(AArch64AsmParser.pic.o)\r\ncompile.cc:(.text._ZN10tensorflow9tfcompileL17InitializeTargetsEv+0x34): relocation truncated to fit: R_AARCH64_CALL26 against symbol `LLVMInitializePowerPCTargetInfo' defined in .text.LLVMInitializePowerPCTargetInfo section in bazel-out/aarch64-opt/bin/external/llvm-project/llvm/libPowerPCInfo.pic.a(PowerPCTargetInfo.pic.o)\r\ncompile.cc:(.text._ZN10tensorflow9tfcompileL17InitializeTargetsEv+0x40): relocation truncated to fit: R_AARCH64_CALL26 against symbol `LLVMInitializePowerPCAsmPrinter' defined in .text.LLVMInitializePowerPCAsmPrinter section in bazel-out/aarch64-opt/bin/external/llvm-project/llvm/libPowerPCCodeGen.pic.a(PPCAsmPrinter.pic.o)\r\ncompile.cc:(.text._ZN10tensorflow9tfcompileL17InitializeTargetsEv+0x50): relocation truncated to fit: R_AARCH64_CALL26 against symbol `LLVMInitializeX86AsmParser' defined in .text.LLVMInitializeX86AsmParser section in bazel-out/aarch64-opt/bin/external/llvm-project/llvm/libX86AsmParser.pic.a(X86AsmParser.pic.o)\r\ncompile.cc:(.text._ZN10tensorflow9tfcompileL17InitializeTargetsEv+0x58): relocation truncated to fit: R_AARCH64_JUMP26 against symbol `LLVMInitializeX86AsmPrinter' defined in .text.LLVMInitializeX86AsmPrinter section in bazel-out/aarch64-opt/bin/external/llvm-project/llvm/libX86CodeGen.pic.a(X86AsmPrinter.pic.o)\r\nbazel-out/aarch64-opt/bin/tensorflow/compiler/aot/libtfcompile_lib.pic.a(compile.pic.o): in function `tensorflow::tfcompile::ReadProtoFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, google::protobuf::Message*)':\r\ncompile.cc:(.text._ZN10tensorflow9tfcompileL13ReadProtoFileERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPN6google8protobuf7MessageE+0x58): relocation truncated to fit: R_AARCH64_CALL26 against symbol `tsl::ReadBinaryProto(tsl::Env*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, google::protobuf::MessageLite*)' defined in .text._ZN3tsl15ReadBinaryProtoEPNS_3EnvERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPN6google8protobuf11MessageLiteE section in bazel-out/aarch64-opt/bin/tensorflow/tsl/platform/default/libenv.pic.a(env.pic.o)\r\ncompile.cc:(.text._ZN10tensorflow9tfcompileL13ReadProtoFileERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPN6google8protobuf7MessageE+0x90): relocation truncated to fit: R_AARCH64_CALL26 against symbol `tsl::ReadTextProto(tsl::Env*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, google::protobuf::Message*)' defined in .text._ZN3tsl13ReadTextProtoEPNS_3EnvERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEPN6google8protobuf7MessageE section in bazel-out/aarch64-opt/bin/tensorflow/tsl/platform/default/libenv.pic.a(env.pic.o)\r\nbazel-out/aarch64-opt/bin/tensorflow/compiler/aot/libtfcompile_lib.pic.a(compile.pic.o): in function `tensorflow::tfcompile::RegisterQuantizeFn(std::function<absl::lts_20230125::Status (tensorflow::tf2xla::Config const&, xla::XlaComputation*)> const&)':\r\ncompile.cc:(.text._ZN10tensorflow9tfcompile18RegisterQuantizeFnERKSt8functionIFN4absl12lts_202301256StatusERKNS_6tf2xla6ConfigEPN3xla14XlaComputationEEE+0x140): relocation truncated to fit: R_AARCH64_CALL26 against symbol `__stack_chk_fail@@GLIBC_2.17' defined in .text section in /lib/aarch64-linux-gnu/libc.so.6\r\nbazel-out/aarch64-opt/bin/tensorflow/compiler/aot/libtfcompile_lib.pic.a(compile.pic.o): in function `absl::lts_20230125::Status tsl::errors::Unknown<char const*, std::basic_string_view<char, std::char_traits<char> > >(char const*, std::basic_string_view<char, std::char_traits<char> >)':\r\ncompile.cc:(.text._ZN3tsl6errors7UnknownIJPKcSt17basic_string_viewIcSt11char_traitsIcEEEEEN4absl12lts_202301256StatusEDpT_[_ZN3tsl6errors7UnknownIJPKcSt17basic_string_viewIcSt11char_traitsIcEEEEEN4absl12lts_202301256StatusEDpT_]+0x3c): relocation truncated to fit: R_AARCH64_CALL26 against symbol `strlen@@GLIBC_2.17' defined in .text section in /lib/aarch64-linux-gnu/libc.so.6\r\ncompile.cc:(.text._ZN3tsl6errors7UnknownIJPKcSt17basic_string_viewIcSt11char_traitsIcEEEEEN4absl12lts_202301256StatusEDpT_[_ZN3tsl6errors7UnknownIJPKcSt17basic_string_viewIcSt11char_traitsIcEEEEEN4absl12lts_202301256StatusEDpT_]+0x7c): additional relocation overflows omitted from the output\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n```"", 'The solution seems to be using clang instead of GCC.', 'Hi @pkgoogle ,\r\n\r\nI got the below error while replicating this issue. can you please take a look?\r\n\r\n`INFO: Reading \'startup\' options from /home/sawantkumar/work/tensorflow/.bazelrc: --windows_enable_symlinks\r\nINFO: Options provided by the client:\r\n  Inherited \'common\' options: --isatty=1 --terminal_columns=217\r\nINFO: Reading rc options for \'build\' from /home/sawantkumar/work/tensorflow/.bazelrc:\r\n  Inherited \'common\' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for \'build\' from /home/sawantkumar/work/tensorflow/.bazelrc:\r\n  \'build\' options: --define framework_shared_object=true --define tsl_protobuf_header_only=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --features=-force_no_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=false --incompatible_enforce_config_setting_visibility\r\nINFO: Reading rc options for \'build\' from /home/sawantkumar/work/tensorflow/.tf_configure.bazelrc:\r\n  \'build\' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3.11 --action_env PYTHON_LIB_PATH=/usr/lib/python3.11/site-packages --python_path=/usr/bin/python3.11 --define=with_xla_support=false --action_env CLANG_COMPILER_PATH=/usr/lib/llvm-10/bin/clang --repo_env=CC=/usr/lib/llvm-10/bin/clang --repo_env=BAZEL_COMPILER=/usr/lib/llvm-10/bin/clang\r\nINFO: Found applicable config definition build:short_logs in file /home/sawantkumar/work/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /home/sawantkumar/work/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:elinux_aarch64 in file /home/sawantkumar/work/tensorflow/.bazelrc: --config=elinux --cpu=aarch64\r\nINFO: Found applicable config definition build:elinux in file /home/sawantkumar/work/tensorflow/.bazelrc: --crosstool_top=@local_config_embedded_arm//:toolchain --host_crosstool_top=@bazel_tools//tools/cpp:toolchain\r\nINFO: Found applicable config definition build:monolithic in file /home/sawantkumar/work/tensorflow/.bazelrc: --define framework_shared_object=false --define tsl_protobuf_header_only=false --experimental_link_static_libraries_once=false\r\nINFO: Found applicable config definition build:linux in file /home/sawantkumar/work/tensorflow/.bazelrc: --host_copt=-w --copt=-Wno-all --copt=-Wno-extra --copt=-Wno-deprecated --copt=-Wno-deprecated-declarations --copt=-Wno-ignored-attributes --copt=-Wno-array-bounds --copt=-Wunused-result --copt=-Werror=unused-result --copt=-Wswitch --copt=-Werror=switch --copt=-Wno-error=unused-but-set-variable --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++17 --host_cxxopt=-std=c++17 --config=dynamic_kernels --experimental_guard_against_concurrent_changes\r\nINFO: Found applicable config definition build:dynamic_kernels in file /home/sawantkumar/work/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nDEBUG: /root/.cache/bazel/_bazel_root/d4b0d2249c66f1993f1bdd593c2da087/external/local_xla/third_party/py/python_repo.bzl:109:10: Using hermetic Python 3.11\r\nERROR: Skipping \'//tensorflow/tools/pip_package:build_pip_package\': no such target \'//tensorflow/tools/pip_package:build_pip_package\': target \'build_pip_package\' not declared in package \'tensorflow/tools/pip_package\' defined by /home/sawantkumar/work/tensorflow/tensorflow/tools/pip_package/BUILD (did you mean \'build_pip_package.py\'? Tip: use `query ""//tensorflow/tools/pip_package:*""` to see all the targets in that package)\r\nERROR: no such target \'//tensorflow/tools/pip_package:build_pip_package\': target \'build_pip_package\' not declared in package \'tensorflow/tools/pip_package\' defined by /home/sawantkumar/work/tensorflow/tensorflow/tools/pip_package/BUILD (did you mean \'build_pip_package.py\'? Tip: use `query ""//tensorflow/tools/pip_package:*""` to see all the targets in that package)\r\nINFO: Elapsed time: 13.876s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (3 packages loaded)`', 'Hi @willendzw, please use Clang 17.0.6 as specified in our Tested build configurations: https://www.tensorflow.org/install/source#tested_build_configurations and as @sclarkson noted. While sometimes other configuration combinations do work, these are more or less guaranteed to work -- let me know if that helps. Thanks.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69951"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69951"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16.1

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.11

### Bazel version

6.5.0

### GCC/compiler version

aarch64

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Build successfully for raspberry PI 4

### Standalone code to reproduce the issue

```shell
1. Clone the code:
git clone https://github.com/tensorflow/tensorflow.git

cd tensorflow
./tensorflow/tools/ci_build/pi/build_raspberry_pi.sh AARCH64
```


### Relevant log output

```shell
ERROR: /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow-2.16.1/tensorflow/BUILD:1314:21: Linking tensorflow/libtensorflow_cc.so.2.16.1 failed: (Exit 1): aarch64-none-linux-gnu-gcc failed: error executing command (from target //tensorflow:libtensorflow_cc.so.2.16.1)
  (cd /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow-2.16.1/build/execroot/org_tensorflow && \
  exec env - \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python3 \
    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \
    TF2_BEHAVIOR=1 \
  /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow-2.16.1/build/external/aarch64_linux_toolchain/bin/aarch64-none-linux-gnu-gcc @bazel-out/aarch64-opt/bin/tensorflow/libtensorflow_cc.so.2.16.1-2.params)
# Configuration: f86a22a88103843b2f048db8d142631a85f0eddbce9df51d51c468ebb4786d1f
# Execution platform: @local_execution_config_platform//:platform
bazel-out/aarch64-opt/bin/tensorflow/c/experimental/gradients/libmath_grad.pic.a(math_grad.pic.o): in function `tsl::core::RefCounted::Unref() const [clone .constprop.0]':
math_grad.cc:(.text.unlikely._ZNK3tsl4core10RefCounted5UnrefEv.constprop.0+0x14): relocation truncated to fit: R_AARCH64_CALL26 against symbol `__aarch64_ldadd8_acq_rel' defined in .text section in /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow-2.16.1/build/external/aarch64_linux_toolchain/bin/../lib/gcc/aarch64-none-linux-gnu/11.3.1/libgcc.a(ldadd_8_4.o)
bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/python/libjax_to_tfl_flatbuffer.pic.a(jax_to_tfl_flatbuffer.pic.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <absl::lts_20230802::Status, 0>(absl::lts_20230802::Status const&) [clone .isra.0]':
jax_to_tfl_flatbuffer.cc:(.text.unlikely._ZN4absl12lts_2023080212log_internal10LogMessagelsINS0_6StatusELi0EEERS2_RKT_.isra.0+0x1c): relocation truncated to fit: R_AARCH64_CALL26 against symbol `absl::lts_20230802::log_internal::LogMessage::OstreamView::OstreamView(absl::lts_20230802::log_internal::LogMessage::LogMessageData&)' defined in .text._ZN4absl12lts_2023080212log_internal10LogMessage11OstreamViewC2ERNS2_14LogMessageDataE section in bazel-out/aarch64-opt/bin/external/com_google_absl/absl/log/internal/liblog_message.pic.a(log_message.pic.o)
jax_to_tfl_flatbuffer.cc:(.text.unlikely._ZN4absl12lts_2023080212log_internal10LogMessagelsINS0_6StatusELi0EEERS2_RKT_.isra.0+0x2c): relocation truncated to fit: R_AARCH64_CALL26 against symbol `absl::lts_20230802::operator<<(std::ostream&, absl::lts_20230802::Status const&)' defined in .text._ZN4absl12lts_20230802lsERSoRKNS0_6StatusE section in bazel-out/aarch64-opt/bin/external/com_google_absl/absl/status/libstatus.pic.a(status.pic.o)
bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/libtf_to_tfl_flatbuffer.pic.a(tf_to_tfl_flatbuffer.pic.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <absl::lts_20230802::Status, 0>(absl::lts_20230802::Status const&) [clone .isra.0]':
tf_to_tfl_flatbuffer.cc:(.text.unlikely._ZN4absl12lts_2023080212log_internal10LogMessagelsINS0_6StatusELi0EEERS2_RKT_.isra.0+0x1c): relocation truncated to fit: R_AARCH64_CALL26 against symbol `absl::lts_20230802::log_internal::LogMessage::OstreamView::OstreamView(absl::lts_20230802::log_internal::LogMessage::LogMessageData&)' defined in .text._ZN4absl12lts_2023080212log_internal10LogMessage11OstreamViewC2ERNS2_14LogMessageDataE section in bazel-out/aarch64-opt/bin/external/com_google_absl/absl/log/internal/liblog_message.pic.a(log_message.pic.o)
tf_to_tfl_flatbuffer.cc:(.text.unlikely._ZN4absl12lts_2023080212log_internal10LogMessagelsINS0_6StatusELi0EEERS2_RKT_.isra.0+0x2c): relocation truncated to fit: R_AARCH64_CALL26 against symbol `absl::lts_20230802::operator<<(std::ostream&, absl::lts_20230802::Status const&)' defined in .text._ZN4absl12lts_20230802lsERSoRKNS0_6StatusE section in bazel-out/aarch64-opt/bin/external/com_google_absl/absl/status/libstatus.pic.a(status.pic.o)
bazel-out/aarch64-opt/bin/external/com_google_absl/absl/log/libdie_if_null.pic.a(die_if_null.pic.o): in function `absl::lts_20230802::log_internal::DieBecauseNull(char const*, int, char const*)':
die_if_null.cc:(.text.unlikely._ZN4absl12lts_2023080212log_internal14DieBecauseNullEPKciS3_+0x5c): relocation truncated to fit: R_AARCH64_CALL26 against symbol `absl::lts_20230802::log_internal::LogMessage::AtLocation(std::basic_string_view<char, std::char_traits<char> >, int)' defined in .text._ZN4absl12lts_2023080212log_internal10LogMessage10AtLocationESt17basic_string_viewIcSt11char_traitsIcEEi section in bazel-out/aarch64-opt/bin/external/com_google_absl/absl/log/internal/liblog_message.pic.a(log_message.pic.o)
die_if_null.cc:(.text.unlikely._ZN4absl12lts_2023080212log_internal14DieBecauseNullEPKciS3_+0xb4): relocation truncated to fit: R_AARCH64_CALL26 against symbol `absl::lts_20230802::StrCat[abi:cxx11](absl::lts_20230802::AlphaNum const&, absl::lts_20230802::AlphaNum const&, absl::lts_20230802::AlphaNum const&)' defined in .text._ZN4absl12lts_202308026StrCatB5cxx11ERKNS0_8AlphaNumES3_S3_ section in bazel-out/aarch64-opt/bin/external/com_google_absl/absl/strings/libstrings.pic.a(str_cat.pic.o)
bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/quantization/tensorflow/libpasses.pic.lo(insert_main_function.pic.o): in function `llvm::StringMap<llvm::SmallVector<mlir::quant::(anonymous namespace)::OutputInfo, 3u>, llvm::MallocAllocator>::~StringMap()':
insert_main_function.cc:(.text.unlikely._ZN4llvm9StringMapINS_11SmallVectorIN4mlir5quant12_GLOBAL__N_110OutputInfoELj3EEENS_15MallocAllocatorEED2Ev+0x74): relocation truncated to fit: R_AARCH64_CALL26 against symbol `llvm::deallocate_buffer(void*, unsigned long, unsigned long)' defined in .text._ZN4llvm17deallocate_bufferEPvmm section in bazel-out/aarch64-opt/bin/external/llvm-project/llvm/libSupport.pic.a(MemAlloc.pic.o)
bazel-out/aarch64-opt/bin/tensorflow/core/data/service/snapshot/libsnapshot_manager.pic.a(snapshot_manager.pic.o): in function `tensorflow::data::SnapshotManager::Start(tensorflow::data::SnapshotRequest const&)':
snapshot_manager.cc:(.text.unlikely._ZN10tensorflow4data15SnapshotManager5StartERKNS0_15SnapshotRequestE+0x5c): relocation truncated to fit: R_AARCH64_CALL26 against symbol `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)' defined in .text._ZN4absl12lts_2023080212log_internal10LogMessage19CopyToEncodedBufferILNS2_10StringTypeE0EEEvSt17basic_string_viewIcSt11char_traitsIcEE[_ZN4absl12lts_2023080212log_internal10LogMessage19CopyToEncodedBufferILNS2_10StringTypeE0EEEvSt17basic_string_viewIcSt11char_traitsIcEE] section in bazel-out/aarch64-opt/bin/external/com_google_absl/absl/log/internal/liblog_message.pic.a(log_message.pic.o)
snapshot_manager.cc:(.text.unlikely._ZN10tensorflow4data15SnapshotManager5StartERKNS0_15SnapshotRequestE+0x248): relocation truncated to fit: R_AARCH64_CALL26 against symbol `__aarch64_ldadd4_relax' defined in .text section in /home/bcmwrt/data/Tensorflow/tf_aarch64/tensorflow-2.16.1/build/external/aarch64_linux_toolchain/bin/../lib/gcc/aarch64-none-linux-gnu/11.3.1/libgcc.a(ldadd_4_1.o)
snapshot_manager.cc:(.text.unlikely._ZN10tensorflow4data15SnapshotManager5StartERKNS0_15SnapshotRequestE+0x2ac): additional relocation overflows omitted from the output
collect2: error: ld returned 1 exit status
INFO: Elapsed time: 1271.228s, Critical Path: 890.84s
INFO: 13379 processes: 86 internal, 13293 local.
FAILED: Build did NOT complete successfully
```
"
2360192110,69967,Tensorflow.keras cannot be resolved,closed,2024-06-18 15:52:36+00:00,2024-07-04T13:12:25Z,2024-07-04T13:12:22Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/69967,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'TF 2.16']","['@ninjaguardian Please ensure that TensorFlow is correctly installed in your Python environment. You can verify this by running the following command in your terminal or command prompt:\r\n```\r\n\r\npip show tensorflow\r\n\r\n```\r\nI was able to run the command successfully, please find the [gist](https://colab.research.google.com/gist/sushreebarsa/6d0e55fd394e93200200fb9dfc538d5a/69967.ipynb) here. Thank you!', ""Tensorflow works, just vscode's autocorrect is not working with it and giving those errors. Tensorflow is correctly installed."", 'I have the same problem', ""@ninjaguardian Since the core issue is with VS Code's autocorrection, could you try disabling it for TensorFlow modules?\r\nThen again restart the VS code and try it. I tried it and wasn't able to face the reported issue.\r\n![unnamed](https://github.com/tensorflow/tensorflow/assets/84765720/46aea51e-faa7-429b-b815-89c6610dd136)\r\nThank you!"", ""How do I disable it for certain modules? And other people like https://github.com/tensorflow/tensorflow/issues/56231 have this issue and their fixes aren't working."", ""@ninjaguardian There's no direct way to disable TensorFlow.keras for specific modules in VS Code. TensorFlow.keras is a core part of TensorFlow 2.6 and later, and VS Code relies on language features provided by the installed libraries to offer features like code completion and linting.\r\n\r\nFor any further queries please post this issue in TF [forum](https://discuss.tensorflow.org/). Thank you!"", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69967"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69967"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16.1, tf-intel 2.16.1

### Custom code

Yes

### OS platform and distribution

Windows 10

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Vscode says ‘Import tensorflow.keras could not be resolved’ 

and ‘keras is unknown import symbol’

### Standalone code to reproduce the issue

```shell
from tensorflow import keras
```


### Relevant log output

_No response_"
2360475177,69981,Deprecation warning when importing tensorflow,closed,2024-06-18 18:41:32+00:00,2024-07-12T01:51:46Z,2024-07-12T01:51:38Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/69981,"['stat:awaiting response', 'type:bug', 'stale', 'TF 2.12']","['Hi **@chiamp** ,\r\n- I tried to reproduce this error in Cloud VM with ubuntu- 20.04, Tensorflow 2.12, python 3.10 & jax0.4.30 and observed that there was no issue/error as mentioned above.\r\n- Please find the screenshot for reference.\r\n<img width=""1495"" alt=""image (5)"" src=""https://github.com/tensorflow/tensorflow/assets/147127861/8835a242-a476-413f-8689-f2eb8c34046a"">\r\n\r\n- Could you please let me know in which environment you are facing the issue? So that i will try to replicate in the same.', ""In my case, the warning arises only when using `pytest` (on Ubuntu 22.04):\r\n\r\n```shell\r\n$ echo 'import tensorflow' >v.py\r\n$ pytest v.py\r\n============================= test session starts ==============================\r\nplatform linux -- Python 3.10.12, pytest-8.2.2, pluggy-1.5.0\r\nrootdir: /home/hhoppe/tmp\r\nplugins: anyio-3.6.1\r\ncollected 0 items\r\n\r\n=============================== warnings summary ===============================\r\n../.local/lib/python3.10/site-packages/tensorflow/lite/python/util.py:51\r\n../.local/lib/python3.10/site-packages/tensorflow/lite/python/util.py:51\r\n  /home/hhoppe/.local/lib/python3.10/site-packages/tensorflow/lite/python/util.py:51: DeprecationWarning: jax.xla_computation is deprecated. Please use the AOT APIs.\r\n    from jax import xla_computation as _xla_computation\r\n\r\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\r\n============================= 2 warnings in 3.17s ==============================\r\n$ pip list | grep -E 'tensorflow|pytest|jax'\r\njax                           0.4.30\r\njaxlib                        0.4.28\r\npytest                        8.2.2\r\ntensorflow-cpu                2.16.1\r\ntensorflow-datasets           4.9.5\r\ntensorflow-io-gcs-filesystem  0.36.0\r\ntensorflow-metadata           1.15.0\r\n```\r\n\r\n\r\n"", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69981"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69981"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.12.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

A [deprecation warning](https://github.com/google/flax/actions/runs/9570186063/job/26384406675?pr=4001#step:8:336) is raised when trying to import tensorflow. This occurred after JAX [deprecated](https://github.com/google/jax/pull/21923) the `xla_computation` API.

### Standalone code to reproduce the issue

```shell
Importing tensorflow causes the error:

`import tensorflow as tf`
```


### Relevant log output

```shell
tests/jax_utils_test.py:22: in <module>
    import tensorflow as tf
venv/lib/python3.10/site-packages/tensorflow/__init__.py:51: in <module>
    from tensorflow._api.v2 import compat
venv/lib/python3.10/site-packages/tensorflow/_api/v2/compat/__init__.py:8: in <module>
    from tensorflow._api.v2.compat import v1
venv/lib/python3.10/site-packages/tensorflow/_api/v2/compat/v1/__init__.py:30: in <module>
    from tensorflow._api.v2.compat.v1 import compat
venv/lib/python3.10/site-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py:8: in <module>
    from tensorflow._api.v2.compat.v1.compat import v1
venv/lib/python3.10/site-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py:47: in <module>
    from tensorflow._api.v2.compat.v1 import lite
venv/lib/python3.10/site-packages/tensorflow/_api/v2/compat/v1/lite/__init__.py:9: in <module>
    from tensorflow._api.v2.compat.v1.lite import experimental
venv/lib/python3.10/site-packages/tensorflow/_api/v2/compat/v1/lite/experimental/__init__.py:8: in <module>
    from tensorflow._api.v2.compat.v1.lite.experimental import authoring
venv/lib/python3.10/site-packages/tensorflow/_api/v2/compat/v1/lite/experimental/authoring/__init__.py:8: in <module>
    from tensorflow.lite.python.authoring.authoring import compatible # line: 265
venv/lib/python3.10/site-packages/tensorflow/lite/python/authoring/authoring.py:43: in <module>
    from tensorflow.lite.python import convert
venv/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:30: in <module>
    from tensorflow.lite.python import util
venv/lib/python3.10/site-packages/tensorflow/lite/python/util.py:51: in <module>
    from jax import xla_computation as _xla_computation
<frozen importlib._bootstrap>:1075: in _handle_fromlist
    ???
venv/lib/python3.10/site-packages/jax/_src/deprecations.py:53: in getattr
    warnings.warn(message, DeprecationWarning, stacklevel=2)
E   DeprecationWarning: jax.xla_computation is deprecated. Please use the AOT APIs.
```
"
2360499166,69984,Issues in Tensorflow model training ,closed,2024-06-18 18:56:48+00:00,2024-08-23T01:54:47Z,2024-08-23T01:54:44Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/69984,"['stat:awaiting response', 'type:bug', 'stale', 'comp:dist-strat', 'TF 2.16']","[""@myh1234567 \r\nCould you please verify that all input data (x, y, etc.) passed to your model is of the correct type (tf.float32, tf.float64, etc.) as expected by the model's architecture and the loss function ? Also, in order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thank you!"", '> @myh1234567 Could you please verify that all input data (x, y, etc.) passed to your model is of the correct type (tf.float32, tf.float64, etc.) as expected by the model\'s architecture and the loss function ? Also, in order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thank you!\r\n\r\nthe following is the code snippent, \r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport scipy.sparse as sp\r\nimport keras\r\nfrom keras.utils import to_categorical\r\n\r\nphysical_device = tf.config.list_physical_devices(""GPU"")\r\nprint(""===================================== num gpu:"", len(physical_device))\r\n\r\n\r\ndef convert_sparse_matrix_to_sparse_tensor(X) -> tf.SparseTensor:\r\n    """""" Convert a scipy sparse matrix to a SparseTensor.""""""\r\n    coo = X.tocoo()\r\n    indices = np.mat([coo.row, coo.col]).transpose()\r\n    return tf.sparse.SparseTensor(indices, coo.data, coo.shape)\r\n\r\nX_transformed_train_db = sp.rand(100, 1000, density=0.1, format=\'coo\')\r\nX_train_db = convert_sparse_matrix_to_sparse_tensor(X_transformed_train_db)\r\nX_train_db = tf.sparse.reorder(X_train_db)\r\ny_train_db = np.random.randint(0, 3, size=(100,))  # Let\'s assume 3 classes\r\ny_train_db_ = to_categorical(y_train_db)\r\n\r\ngpus = tf.config.list_logical_devices(""GPU"")\r\nstrategy = tf.distribute.MirroredStrategy(gpus)\r\n\r\nwith strategy.scope():\r\n    opti = keras.optimizers.Adam(learning_rate=0.0001)\r\n    input_dimension = X_transformed_train_db.shape[1]\r\n    model_db = keras.Sequential()\r\n    model_db.add(keras.layers.Dense(1000, kernel_initializer=keras.initializers.HeNormal(seed=1), activation=\'relu\', input_dim=input_dimension))\r\n    model_db.add(keras.layers.Dropout(0.1))\r\n    model_db.add(keras.layers.Dense(500, kernel_initializer=keras.initializers.HeNormal(seed=2), activation=\'relu\'))\r\n    model_db.add(keras.layers.Dropout(0.1))\r\n    model_db.add(keras.layers.Dense(200, kernel_initializer=keras.initializers.HeNormal(), activation=\'relu\'))\r\n    model_db.add(keras.layers.Dropout(0.1))\r\n    model_db.add(keras.layers.Dense(y_train_db_.shape[1], kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=4), activation=\'softmax\'))\r\n    model_db.compile(optimizer=opti, loss=\'categorical_crossentropy\',metrics=[\'accuracy\'])\r\n\r\nhistory_db = model_db.fit(X_transformed_train_db, y_train_db_, epochs=3)\r\n\r\n\r\ntensorflow                2.16.1\r\nkeras                     3.3.3\r\nscipy                     1.13.1\r\nnumpy                     1.26.4\r\n\r\nthank you ', '@myh1234567 ,\r\nI tried to execute the code and faced the indentation errors. Could you please provide colab gist or the executable way. And also could you please confirm this issue is happening with tensorflow 2.15 as well because, 2.15 contains keras2.0 and 2.16 contains keras3.0. Thank you!', '> @myh1234567 , I tried to execute the code and faced the indentation errors. Could you please provide colab gist or the executable way. And also could you please confirm this issue is happening with tensorflow 2.15 as well because, 2.15 contains keras2.0 and 2.16 contains keras3.0. Thank you!\r\n\r\nhttps://colab.research.google.com/gist/myh1234567/a83605d7c47314f6a9a5ced2807f4fde/63362.ipynb\r\n', ""@myh1234567,\r\nI tried to execute the mentioned code on the colab and couldn't find any issue/error during the execution. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/23238db0730137f2429dc576f146ec2c/untitled2052.ipynb). Thank you!"", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69984"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/69984"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.16.1

### Custom code

Yes

### OS platform and distribution

linux 

### Mobile device

x86_64

### Python version

3.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

With the same code and the same data, I had no issues training under Python 3.9 with TensorFlow 2.11. 
However, after updating to Python 3.12 with TensorFlow 2.16, I encountered errors. 

The error messages are as follows:
Traceback (most recent call last):
  File ""/home/train_model"", line 379, in <module>
    history_db = model_db.fit(X_transformed_train_db, y_train_db_, epochs=3)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/miniconda3/lib/python3.12/site-packages/keras/utils/traceback_utils.py"", line 123, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/home/miniconda3/lib/python3.12/site-packages/keras/trainers/data_adapters/__init__.py"", line 113, in get_data_adapter
    raise ValueError(f""Unrecognized data type: x={x} (of type {type(x)})"")
ValueError: Unrecognized data type: x=SparseTensor(indices=tf.Tensor(
[[      0   11068]
 [      0   16849]
 [      0   35681]
 ...
 [8563599   29603]
 [8563599   31778]
 [8563599   38279]], shape=(41839230, 2), dtype=int64), values=tf.Tensor([0.52680086 0.59266628 0.42937609 ... 0.27554394 0.25317136 0.33879793], shape=(41839230,), dtype=float64), dense_shape=tf.Tensor([8563600   40000], shape=(2,), dtype=int64)) (of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>)

### Standalone code to reproduce the issue

```shell
n/a
```


### Relevant log output

_No response_"
2361443964,70029,Reduce TensorFlow Lite binary size,closed,2024-06-19 06:33:03+00:00,2024-08-01T01:58:05Z,2024-08-01T01:57:58Z,sawantkumar,,https://github.com/tensorflow/tensorflow/issues/70029,"['stat:awaiting response', 'type:bug', 'type:build/install', 'stale', 'comp:lite', 'TF 2.16']","['I used the docker compilation from the official website。https://ai.google.dev/edge/lite/build/android?hl=zh-cn', 'Hi @hui-li-xf ,\r\n\r\nCan you provide me the tflite model also that you used ?', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70029"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70029"">No</a>\n']","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux 
- TensorFlow installed from (source or binary): git 
- TensorFlow version (or github SHA if from source): laset 

I use the following command: sh /host_dir/tensorflow/tensorflow/lite/tools/build_aar.sh --input_models=/host_dir/dan_encoder.tflite --src_dir=/host_dir/tensorflow --target_archs=arm64-v8a,armeabi-v7a ， to build the tf lite version。

The following error occurs：
INFO: Analyzed target //tmp:tensorflow-lite (160 packages loaded, 13820 targets configured).
INFO: Found 1 target...
ERROR: /tensorflow_src/tensorflow/lite/kernels/BUILD:505:11: Compiling tensorflow/lite/kernels/stablehlo_elementwise.cc failed: (Exit 1): clang failed: error executing command (from target //tensorflow/lite/kernels:stablehlo_elementwise) external/androidndk/toolchains/llvm/prebuilt/linux-x86_64/bin/clang -no-canonical-prefixes '--target=aarch64-linux-android30' -fdiagnostics-color -Wa,--noexecstack -fno-exceptions '-std=gnu++17' ... (remaining 138 arguments skipped)
In file included from tensorflow/lite/kernels/stablehlo_elementwise.cc:15:
In file included from ./tensorflow/lite/kernels/stablehlo_elementwise.h:21:
In file included from external/eigen_archive/Eigen/Core:172:
external/eigen_archive/Eigen/src/Core/util/Memory.h:1300:12: error: no member named 'construct_at' in namespace 'std'
using std::construct_at;
      ~~~~~^
In file included from tensorflow/lite/kernels/stablehlo_elementwise.cc:15:
In file included from ./tensorflow/lite/kernels/stablehlo_elementwise.h:21:
In file included from external/eigen_archive/Eigen/Core:296:
external/eigen_archive/Eigen/src/Core/CoreEvaluators.h:1673:15: error: no member named 'construct_at' in namespace 'Eigen::internal'
    internal::construct_at<Base>(this, m_result);
    ~~~~~~~~~~^
external/eigen_archive/Eigen/src/Core/CoreEvaluators.h:1673:28: error: unexpected type name 'Base': expected expression
    internal::construct_at<Base>(this, m_result);
                           ^
external/eigen_archive/Eigen/src/Core/CoreEvaluators.h:1677:79: error: no member named 'construct_at' in namespace 'Eigen::internal'
  EIGEN_DEVICE_FUNC evaluator(const ArgType& arg) : m_result(arg) { internal::construct_at<Base>(this, m_result); }
                                                                    ~~~~~~~~~~^
external/eigen_archive/Eigen/src/Core/CoreEvaluators.h:1677:92: error: unexpected type name 'Base': expected expression
  EIGEN_DEVICE_FUNC evaluator(const ArgType& arg) : m_result(arg) { internal::construct_at<Base>(this, m_result); }
                                                                                           ^
In file included from tensorflow/lite/kernels/stablehlo_elementwise.cc:15:
In file included from ./tensorflow/lite/kernels/stablehlo_elementwise.h:21:
In file included from external/eigen_archive/Eigen/Core:311:
external/eigen_archive/Eigen/src/Core/ReturnByValue.h:103:15: error: no member named 'construct_at' in namespace 'Eigen::internal'
    internal::construct_at<Base>(this, m_result);
    ~~~~~~~~~~^
external/eigen_archive/Eigen/src/Core/ReturnByValue.h:103:28: error: unexpected type name 'Base': expected expression
    internal::construct_at<Base>(this, m_result);
                           ^
In file included from tensorflow/lite/kernels/stablehlo_elementwise.cc:15:
In file included from ./tensorflow/lite/kernels/stablehlo_elementwise.h:21:
In file included from external/eigen_archive/Eigen/Core:327:
external/eigen_archive/Eigen/src/Core/Ref.h:189:5: error: no template named 'construct_at' in namespace 'Eigen::internal'; did you mean 'construct'?
    internal::construct_at<Base>(this, expr.data(), rows, cols);
    ^~~~~~~~~~~~~~~~~~~~~~
    construct
external/eigen_archive/Eigen/src/Core/Ref.h:111:26: note: 'construct' declared here
  EIGEN_DEVICE_FUNC bool construct(Expression& expr) {
                         ^
external/eigen_archive/Eigen/src/Core/Ref.h:189:5: error: no template named 'construct' in namespace 'Eigen::internal'; did you mean simply 'construct'?
    internal::construct_at<Base>(this, expr.data(), rows, cols);
    ^~~~~~~~~~~~~~~~~~~~~~
    construct
external/eigen_archive/Eigen/src/Core/Ref.h:111:26: note: 'construct' declared here
  EIGEN_DEVICE_FUNC bool construct(Expression& expr) {
                         ^
external/eigen_archive/Eigen/src/Core/Ref.h:189:15: error: cannot refer to member 'construct' in 'RefBase<Derived>' with '->'
    internal::construct_at<Base>(this, expr.data(), rows, cols);
              ^
external/eigen_archive/Eigen/src/Core/Ref.h:111:26: note: member 'construct' declared here
  EIGEN_DEVICE_FUNC bool construct(Expression& expr) {
                         ^
external/eigen_archive/Eigen/src/Core/Ref.h:190:15: error: no member named 'construct_at' in namespace 'Eigen::internal'
    internal::construct_at(&m_stride, (StrideType::OuterStrideAtCompileTime == 0) ? 0 : outer_stride,
    ~~~~~~~~~~^
In file included from tensorflow/lite/kernels/stablehlo_elementwise.cc:15:
In file included from ./tensorflow/lite/kernels/stablehlo_elementwise.h:21:
In file included from external/eigen_archive/Eigen/Core:343:
external/eigen_archive/Eigen/src/Core/Solve.h:114:15: error: no member named 'construct_at' in namespace 'Eigen::internal'
    internal::construct_at<Base>(this, m_result);
    ~~~~~~~~~~^
external/eigen_archive/Eigen/src/Core/Solve.h:114:28: error: unexpected type name 'Base': expected expression
    internal::construct_at<Base>(this, m_result);
                           ^
In file included from tensorflow/lite/kernels/stablehlo_elementwise.cc:15:
In file included from ./tensorflow/lite/kernels/stablehlo_elementwise.h:21:
In file included from external/eigen_archive/Eigen/Core:344:
external/eigen_archive/Eigen/src/Core/Inverse.h:96:15: error: no member named 'construct_at' in namespace 'Eigen::internal'
    internal::construct_at<Base>(this, m_result);
    ~~~~~~~~~~^
external/eigen_archive/Eigen/src/Core/Inverse.h:96:28: error: unexpected type name 'Base': expected expression
    internal::construct_at<Base>(this, m_result);
                           ^
In file included from tensorflow/lite/kernels/stablehlo_elementwise.cc:15:
In file included from ./tensorflow/lite/kernels/stablehlo_elementwise.h:21:
In file included from external/eigen_archive/Eigen/Core:355:
external/eigen_archive/Eigen/src/Core/ProductEvaluators.h:97:15: error: no member named 'construct_at' in namespace 'Eigen::internal'
    internal::construct_at<Base>(this, m_result);
    ~~~~~~~~~~^
external/eigen_archive/Eigen/src/Core/ProductEvaluators.h:97:28: error: unexpected type name 'Base': expected expression
    internal::construct_at<Base>(this, m_result);
                           ^
17 errors generated.
Target //tmp:tensorflow-lite failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 489.011s, Critical Path: 8.66s
INFO: 624 processes: 419 internal, 205 local.
FAILED: Build did NOT complete successfully

"
2362484652,70050,Compiling doesn't change learning rate of reloaded model. Instead changes learning-rate of optimizer,closed,2024-06-19 14:07:34+00:00,2024-06-26T13:58:11Z,2024-06-26T13:58:08Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/70050,"['type:bug', 'comp:keras', 'TF 2.15']","['@kindaTall,\r\nThank you for the issue. We also observed the same behavior. Could you please allow some time to deep dive and investigate the same behavior. Also could you please try and let  me know if you are facing the same in the keras3.0 version, Tensorflow v2.16. Thank you!', ""This seems to be indeed fixed by 2.16\r\n\r\n```Console\r\nTensorFlow version: 2.16.1\r\nPython version: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\r\nOptimizer's learning rate of the loaded model: 1.000000e-04\r\nOptimizer's learning rate of the loaded model: 1.000000e-04\r\n```\r\n\r\nToo bad for me, I am currently restricted to a Windows machine, which doesn't seem to have GPU support post 2.10."", '@kindaTall,\r\nGlad the issue is resolved in tensorflow 2.16.1. Could you please feel free to move this issue to closed status and TensorFlow 2.10 was the last TensorFlow release that supported GPU on native-Windows. Starting with TensorFlow 2.11, you will need to install [TensorFlow in WSL2](https://tensorflow.org/install/pip#windows-wsl2), or install tensorflow or tensorflow-cpu and, optionally, try the [TensorFlow-DirectML-Plugin](https://github.com/microsoft/tensorflow-directml-plugin#tensorflow-directml-plugin-)\r\n\r\nThank you!', 'Thank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70050"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70050"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.15.0

### Custom code

Yes

### OS platform and distribution

Google Colab

### Mobile device

_No response_

### Python version

3.10.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I expected the compiled model to have the learning rate I was trying to set. Instead it kept the original learning rate.
When repeated twice, this didn't occure.

### Standalone code to reproduce the issue

[https://colab.research.google.com/drive/1JNQmWZc9OYa39h1xfZaz2Fa8CDhte94n?usp=sharing](https://colab.research.google.com/drive/1JNQmWZc9OYa39h1xfZaz2Fa8CDhte94n?usp=sharing) 
```shell


import sys

from pathlib import Path

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense


def create_model():
    model = Sequential([
        Dense(64, activation='relu', input_shape=(10,)),
        Dense(1, activation='sigmoid')
    ])
    return model

def compile_model(model, learning_rate):
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                  loss='binary_crossentropy')


def save_model_(model, log_dir, struct_only=False):
    log_dir = Path(log_dir)
    log_dir.mkdir(parents=True, exist_ok=True)
    with open(log_dir / 'model.json', 'w') as f:
        f.write(model.to_json())
    model.save_weights(log_dir / 'weights/weights')


def load_model_(log_dir):
    log_dir = Path(log_dir)
    with open(log_dir / 'model.json', 'r') as f:
        model_json = f.read()
    model = tf.keras.models.model_from_json(model_json)
    model.load_weights(log_dir / 'weights/weights')
    return model


if __name__ == ""__main__"":
    print(f""TensorFlow version: {tf.__version__}"")
    print(f""Python version: {sys.version}"")

    model = create_model()
    initial_learning_rate = 0.001
    compile_model(model, initial_learning_rate)

    model_path = 'my_model'
    save_model_(model, model_path)
    loaded_model = load_model_(model_path)

    new_learning_rate = 0.0001
    compile_model(loaded_model, new_learning_rate)
    print(f""Optimizer's learning rate of the loaded model: {loaded_model.optimizer.learning_rate.numpy():e}"")
    # 1e-3
    compile_model(loaded_model, new_learning_rate)
    print(f""Optimizer's learning rate of the loaded model: {loaded_model.optimizer.learning_rate.numpy():e}"")
    # 1e-4
```


### Relevant log output

```shell
TensorFlow version: 2.15.0
Python version: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]
Optimizer's learning rate of the loaded model: 1.000000e-03
Optimizer's learning rate of the loaded model: 1.000000e-04
```
"
2364770897,70116,`tf.data.Dataset.load()` cannot load from a folder with bracket in the name,closed,2024-06-20 15:50:06+00:00,2024-07-19T01:52:37Z,2024-07-19T01:52:33Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/70116,"['stat:awaiting response', 'type:bug', 'stale', 'comp:data', 'TF 2.16']","['@yanncalec,\r\nI tried to execute the mentioned code on Tensorflow v2.16.1 and it was executed without any issue. Kindly find the [gist](https://colab.research.google.com/gist/tilakrayal/01623d46cb0c5e741662781f326e93f7/untitled1977.ipynb) and screenshot for the reference. Could you please let me know in which environment you are trying to execute the code. \r\n\r\n![image](https://github.com/tensorflow/tensorflow/assets/81610181/c003ed46-f8bf-4a18-868d-42ab615029ef)\r\n\r\nThank you!', ""Thanks for your reply. I run your notebook and can still confirm the behavior: when the folder's name contains a bracket nothing is printed, meaning that the variable `new_dataset` is empty:\r\n![image](https://github.com/tensorflow/tensorflow/assets/3247670/8ece4418-0d6f-4b58-815d-7e2303bf20a8)\r\n\r\nCompare this to the folder name without bracket:\r\n![image](https://github.com/tensorflow/tensorflow/assets/3247670/045211af-3c5a-4278-b642-2840d73eeea5)\r\n"", 'I executed your gist online. Otherwise I work under Linux with tf 2.16.1.', '@yanncalec,\r\nI guess the problem is when we are using [] to save and load the file. Whenever I tried to use [] and the other like () or {} or ({}), the file was able to save, load and also the output is also able to display. AFAIK the problem is with [].\r\nKindly find the [gist](https://colab.research.google.com/gist/tilakrayal/3e8520335984a579fc390a51db6b9b02/untitled1988.ipynb) for the reference.\r\n\r\n![image](https://github.com/tensorflow/tensorflow/assets/81610181/2f21c324-bab4-448c-8f1e-a9453d7debb0)\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70116"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70116"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When save and reload a dataset, the reloaded dataset seems empty if the folder contains a bracket '[ ]'.
The dataset is however effectively saved.


### Standalone code to reproduce the issue

```shell
import os
path = os.path.expanduser(""~/tmp/folder"")
# path = os.path.expanduser(""~/tmp/folder[1]"")  # this won't work
os.makedirs(path, exist_ok=True)

# Save a dataset
dataset = tf.data.Dataset.range(2)
tf.data.Dataset.save(dataset, path)
# Check that dataset is effectively saved
assert os.path.exists(os.path.join(path, ""snapshot.metadata""))

new_dataset = tf.data.Dataset.load(path)
for elem in new_dataset:
    print(elem)
```


### Relevant log output

_No response_"
2365540051,70164,ValueError: Only instances of `keras.Layer` can be added to a Sequential model. Received: <tensorflow_probability.python.layers.dense_variational_v2.DenseVariational object at 0x000001C67AF5B4D0> (of type <class 'tensorflow_probability.python.layers.dense_variational_v2.DenseVariational'>),closed,2024-06-21 01:48:13+00:00,2024-07-07T01:55:39Z,2024-07-07T01:55:36Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/70164,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'TF 2.16']","['Hi **@Suryansh-patidar** ,\r\n- Please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999).\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70164"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70164"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.15.0 /2.16.1

### Custom code

Yes

### OS platform and distribution

Jupyter notebook/ Kaggle/ Google Collab

### Mobile device

Windows

### Python version

3.11.3

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

It should have been ran normally and started should have made the model as specified 

### Standalone code to reproduce the issue

```shell
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
import keras_tuner
import tensorflow_probability as tfp
from tensorflow_probability import distributions as tfd
from tensorflow.keras.models import Model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dropout,Input,Dense
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam
from keras import layers
from keras import regularizers

best_model_2 = tf.keras.Sequential([
    layers.Dense(181,activation='relu',input_shape=(21,)),
    tfp.layers.DenseVariational(181,activation='relu',make_posterior_fn=posterior_mean_field,
                                        make_prior_fn=prior_trainable,
                                        kl_weight=1/train_size,),
    layers.Dense(1,activation='linear')
])
```


### Relevant log output

```shell
ValueError                                Traceback (most recent call last)
Cell In[42], line 7
      1 # tf.__version__
      2 # %pip uninstall tensorflow
      3 # import tensorflow
      4 # %pip install tensorflow==2.14
      5 # keras.__version__
----> 7 best_model_2 = tf.keras.Sequential([
      8     layers.Dense(181,activation='relu',input_shape=(21,)),
      9     tfp.layers.DenseVariational(181,activation='relu',make_posterior_fn=posterior_mean_field,
     10                                         make_prior_fn=prior_trainable,
     11                                         kl_weight=1/train_size,),
     12     layers.Dense(1,activation='linear')
     13 ])

File ~\anaconda3\Lib\site-packages\keras\src\models\sequential.py:73, in Sequential.__init__(self, layers, trainable, name)
     71 if layers:
     72     for layer in layers:
---> 73         self.add(layer, rebuild=False)
     74     self._maybe_rebuild()

File ~\anaconda3\Lib\site-packages\keras\src\models\sequential.py:95, in Sequential.add(self, layer, rebuild)
     93         layer = origin_layer
     94 if not isinstance(layer, Layer):
---> 95     raise ValueError(
     96         ""Only instances of `keras.Layer` can be ""
     97         f""added to a Sequential model. Received: {layer} ""
     98         f""(of type {type(layer)})""
     99     )
    100 if not self._is_layer_name_unique(layer):
    101     raise ValueError(
    102         ""All layers added to a Sequential model ""
    103         f""should have unique names. Name '{layer.name}' is already ""
    104         ""the name of a layer in this model. Update the `name` argument ""
    105         ""to pass a unique name.""
    106     )

ValueError: Only instances of `keras.Layer` can be added to a Sequential model. Received: <tensorflow_probability.python.layers.dense_variational_v2.DenseVariational object at 0x000001C663D64350> (of type <class 'tensorflow_probability.python.layers.dense_variational_v2.DenseVariational'>)
```
"
2366549804,70196,Failure loading saved model (with tf2onnx),closed,2024-06-21 13:26:14+00:00,2024-07-12T01:51:43Z,2024-07-12T01:51:36Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/70196,"['stat:awaiting response', 'type:bug', 'stale', 'comp:apis']","['@kupix Could you please ensure that any environment variables required for TensorFlow compatibility are set properly?\r\nPlease make sure you are using compatible versions of TensorFlow and tf2onnx. Kindly use the latest TF v2.16 as the nightly builds might cause some issues.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70196"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70196"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

tf 2.18

### Custom code

No

### OS platform and distribution

Linux Ubuntu 22.04

### Mobile device

_No response_

### Python version

3.10.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Current behaviour: TF is unable to load a previously saved model, reporting ""AttributeError: '_UserObject' object has no attribute 'add_slot'"".
Expected behaviour: TF loads the previously saved model and converts it to ONNX. 
See also similar, also unresolved issue: https://github.com/tensorflow/tensorflow/issues/61972

### Standalone code to reproduce the issue

```shell
git clone https://vcgit.hhi.fraunhofer.de/jvet-ahg-nnvc/VVCSoftware_VTM
cd VVCSoftware_VTM
git checkout VTM-11.0_nnvc
cd training/training_scripts/NN_Post_Filtering/scripts/resources/orig_base_models/

python3 -m pip install tf-nightly onnx
python3 -m tf2onnx.convert --saved-model ./model1
```


### Relevant log output

```shell
2024-06-21 14:24:04.004487: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-21 14:24:04.004758: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-21 14:24:04.007946: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-21 14:24:04.048536: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-21 14:24:04.658015: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour
  warn(RuntimeWarning(msg))
2024-06-21 14:24:05,131 - WARNING - '--tag' not specified for saved_model. Using --tag serve
Traceback (most recent call last):
  File ""/usr/lib/python3.10/runpy.py"", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File ""/usr/lib/python3.10/runpy.py"", line 86, in _run_code
    exec(code, run_globals)
  File ""/home/john/venv/lib/python3.10/site-packages/tf2onnx/convert.py"", line 714, in <module>
    main()
  File ""/home/john/venv/lib/python3.10/site-packages/tf2onnx/convert.py"", line 242, in main
    graph_def, inputs, outputs, initialized_tables, tensors_to_rename = tf_loader.from_saved_model(
  File ""/home/john/venv/lib/python3.10/site-packages/tf2onnx/tf_loader.py"", line 636, in from_saved_model
    _from_saved_model_v2(model_path, input_names, output_names,
  File ""/home/john/venv/lib/python3.10/site-packages/tf2onnx/tf_loader.py"", line 570, in _from_saved_model_v2
    imported = tf.saved_model.load(model_path, tags=tag)  # pylint: disable=no-value-for-parameter
  File ""/home/john/venv/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py"", line 912, in load
    result = load_partial(export_dir, None, tags, options)[""root""]
  File ""/home/john/venv/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py"", line 1042, in load_partial
    loader = Loader(object_graph_proto, saved_model_proto, export_dir,
  File ""/home/john/venv/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py"", line 223, in __init__
    self._load_all()
  File ""/home/john/venv/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py"", line 320, in _load_all
    self._load_nodes()
  File ""/home/john/venv/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py"", line 529, in _load_nodes
    slot_variable = optimizer_object.add_slot(
AttributeError: '_UserObject' object has no attribute 'add_slot'
```
"
2368450567,70261,whenever I try fitting a sequential model it doesn't work,closed,2024-06-23 08:47:54+00:00,2024-07-01T20:06:10Z,2024-07-01T14:06:24Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/70261,"['type:bug', 'comp:apis', 'TF 2.16']","['@yousifj129 Could you please share the dependencies here to run the shared script?\r\nI tried to revise the code below, please let us know if it helps?\r\n\r\n```\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nfrom sklearn.preprocessing import StandardScaler\r\nfrom imblearn.over_sampling import RandomOverSampler\r\nfrom sklearn.model_selection import train_test_split\r\nimport tensorflow as tf\r\n\r\n# Load dataset\r\ncols = [""flength"", ""fwidth"", ""fsize"", ""fconc"", ""fconc1"", ""fasym"", ""fm3long"", ""fm3trans"", ""falpha"", ""fdist"", ""class""]\r\ndf = pd.read_csv(""./ML/gamma ray stuff/magic04.data"", names=cols)\r\n\r\n# Convert class to binary integer\r\ndf[""class""] = (df[""class""] == ""g"").astype(int)\r\n\r\n# Split dataset into train, validation, test sets\r\ntrain, test = train_test_split(df, test_size=0.2, random_state=42)\r\ntrain, valid = train_test_split(train, test_size=0.25, random_state=42)  # 60% train, 20% valid\r\n\r\n# Function to scale dataset and optionally oversample\r\ndef scale_dataset(dataframe, oversample=False):\r\n    X = dataframe[dataframe.columns[:-1]].values\r\n    y = dataframe[dataframe.columns[-1]].values\r\n\r\n    scalar = StandardScaler()\r\n    X = scalar.fit_transform(X)\r\n\r\n    if oversample:\r\n        ros = RandomOverSampler()\r\n        X, y = ros.fit_resample(X, y)\r\n    \r\n    return X, y\r\n\r\n# Preprocess datasets\r\nx_train, y_train = scale_dataset(train, oversample=True)\r\nx_valid, y_valid = scale_dataset(valid, oversample=False)\r\nx_test, y_test = scale_dataset(test, oversample=False)\r\n\r\n# Define neural network model\r\nnn_model = tf.keras.Sequential([\r\n    tf.keras.layers.Dense(32, activation=\'relu\', input_shape=(x_train.shape[1],)),\r\n    tf.keras.layers.Dense(32, activation=\'relu\'),\r\n    tf.keras.layers.Dense(1, activation=\'sigmoid\')\r\n])\r\n\r\n# Compile model\r\nnn_model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\r\n                 loss=\'binary_crossentropy\',\r\n                 metrics=[\'accuracy\'])\r\n\r\n# Train model with callbacks for early stopping and model checkpoint\r\ncallbacks = [\r\n    tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\r\n    tf.keras.callbacks.ModelCheckpoint(\'model_best.h5\', save_best_only=True)\r\n]\r\n\r\nhistory = nn_model.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=callbacks)\r\n\r\n# Evaluate model on train, validation, and test sets\r\neval_train = nn_model.evaluate(x_train, y_train)\r\neval_valid = nn_model.evaluate(x_valid, y_valid)\r\neval_test = nn_model.evaluate(x_test, y_test)\r\n\r\nprint(""Train Accuracy:"", eval_train[1])\r\nprint(""Validation Accuracy:"", eval_valid[1])\r\nprint(""Test Accuracy:"", eval_test[1])\r\n\r\n```\r\n\r\nThank you!', 'I tried the code but I dont have the file model_best.h5:\r\nValueError: The filepath provided must end in `.keras` (Keras model format). Received: filepath=model_best.h5\r\n\r\nabsl-py==2.1.0\r\nasgiref==3.8.1\r\nasttokens==2.4.1\r\nastunparse==1.6.3\r\ncachetools==5.3.3\r\ncertifi==2024.6.2\r\nchardet==5.2.0\r\ncharset-normalizer==2.1.1\r\ncolorama==0.4.6\r\ncomm==0.2.2\r\ncontourpy==1.2.1\r\ncycler==0.12.1\r\ndebugpy==1.8.2\r\ndecorator==5.1.1\r\nDjango==5.0.6\r\nexecuting==2.0.1\r\nflatbuffers==24.3.25\r\nfonttools==4.53.0\r\ngast==0.5.4\r\ngensim==4.3.2\r\ngoogle-auth==2.30.0\r\ngoogle-auth-oauthlib==1.2.0\r\ngoogle-pasta==0.2.0\r\ngrpcio==1.64.1\r\ngspread==5.6.0\r\nh5py==3.11.0\r\nidna==3.7\r\nimbalanced-learn==0.12.3\r\nimblearn==0.0\r\nipykernel==6.29.4\r\nipython==8.25.0\r\njedi==0.19.1\r\njoblib==1.4.2\r\njupyter_client==8.6.2\r\njupyter_core==5.7.2\r\nkeras==3.4.0\r\nkeras-nightly==3.3.3.dev2024062303\r\nkiwisolver==1.4.5\r\nlibclang==18.1.1\r\nMarkdown==3.6\r\nmarkdown-it-py==3.0.0\r\nMarkupSafe==2.1.5\r\nmatplotlib==3.9.0\r\nmatplotlib-inline==0.1.7\r\nmdurl==0.1.2\r\nml-dtypes==0.3.2\r\nMouseInfo==0.1.3\r\nnamex==0.0.8\r\nnest-asyncio==1.6.0\r\nnumpy==1.26.4\r\noauthlib==3.2.2\r\nopt-einsum==3.3.0\r\noptree==0.11.0\r\npackaging==24.1\r\npandas==2.2.2\r\nparso==0.8.4\r\npillow==10.3.0\r\nplatformdirs==4.2.2\r\nprompt_toolkit==3.0.47\r\nprotobuf==4.25.3\r\npsutil==6.0.0\r\npure-eval==0.2.2\r\npyasn1==0.6.0\r\npyasn1_modules==0.4.0\r\nPyAutoGUI==0.9.54\r\npygame==2.6.0\r\nPyGetWindow==0.0.9\r\nPygments==2.18.0\r\nPyMsgBox==1.0.9\r\npyparsing==3.1.2\r\npyperclip==1.9.0\r\nPyRect==0.2.0\r\nPyScreeze==0.1.30\r\nPySide6==6.7.2\r\nPySide6_Addons==6.7.2\r\nPySide6_Essentials==6.7.2\r\npython-dateutil==2.9.0.post0\r\npython-dotenv==0.21.0\r\npytweening==1.2.0\r\npytz==2024.1\r\npywin32==306\r\npyzmq==26.0.3\r\nreportlab==4.2.2\r\nrequests==2.32.3\r\nrequests-oauthlib==1.3.1\r\nrich==13.7.1\r\nrsa==4.9\r\nschedule==1.1.0\r\nscikit-learn==1.5.0\r\nscipy==1.12.0\r\nsetuptools==70.1.0\r\nshiboken6==6.7.2\r\nsix==1.16.0\r\nsmart-open==7.0.4\r\nsqlparse==0.5.0\r\nstack-data==0.6.3\r\ntb-nightly==2.18.0a20240616\r\ntensorboard==2.16.2\r\ntensorboard-data-server==0.7.2\r\ntensorflow==2.16.1\r\ntensorflow-intel==2.16.1\r\ntermcolor==2.4.0\r\ntf-nightly==2.18.0.dev20240620\r\ntf_nightly_intel==2.18.0.dev20240620\r\nthreadpoolctl==3.5.0\r\ntornado==6.4.1\r\ntraitlets==5.14.3\r\ntweepy==4.10.1\r\ntyping_extensions==4.12.2\r\ntzdata==2024.1\r\nurllib3==1.26.19\r\nwcwidth==0.2.13\r\nWerkzeug==3.0.3\r\nwheel==0.43.0\r\nwrapt==1.16.0', '@yousifj129 I tried to replicate the issue reported [here](https://colab.research.google.com/gist/sushreebarsa/414af12a513fd6aef5499bd97702fd47/70261.ipynb), could you please share the dependencies? Thank you!', 'i am not sure what do you mean by ""dependencies"" cause i sent you all the packages, but just in case you meant the data:\r\n[magic04.csv](https://github.com/user-attachments/files/16026277/magic04.csv)\r\n', ""Check if your environment is set to UTF-8 coding or not.\r\nin your terminal write these commands for checking environment coding:\r\n\r\nimport locale\r\nlocale.getpreferredencoding()\r\n\r\nand then and explicitly set encoding\r\nrun this in your terminal:\r\nset PYTHONIOENCODING=utf-8\r\n\r\nor you can try to redirect the output to a file to avoid any issues with terminal encoding\r\n\r\nimport sys\r\nsys.stdout = open ('output.txt', 'w', encoding='utf-8')\r\n\r\nnn_model.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\r\n\r\nIf the issue is related to the verbose output during the training process, you can set the verbosity level to 0 or 1\r\n\r\nif this also doesn't work, check latest version of tensor flow is installed.\r\n\r\n\r\n"", '@yousifj129 Could you refer to the above comment and let us know?\r\nThank you!', ""I tried to do it, but it doesn't change it\r\nset PYTHONIOENCODING=utf-8\r\nand\r\nexport PYTHONIOENCODING=utf-8\r\nin bash, tried different methods but it kept giving me:\r\n>>> import locale\r\n>>> locale.getpreferredencoding() \r\n'cp1252'\r\n\r\nit doesn't change to UTF-8"", 'it didnt change it after I did \r\nset PYTHONIOENCODING=utf-8\r\n\r\nbut then searched around and found a solution that worked:\r\nLocale can be set in windows globally to UTF-8, if you so desire, as follows:\r\n\r\nControl panel -> Clock and Region -> Region -> Administrative -> Change system locale -> Check Beta: Use Unicode UTF-8 ...\r\n\r\n', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70261"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70261"">No</a>\n', '> it didnt change it after I did set PYTHONIOENCODING=utf-8\r\n> \r\n> but then searched around and found a solution that worked: Locale can be set in windows globally to UTF-8, if you so desire, as follows:\r\n> \r\n> Control panel -> Clock and Region -> Region -> Administrative -> Change system locale -> Check Beta: Use Unicode UTF-8 ...\r\n\r\nso problem was with utf-8 only, I 1st time contributed to a problem in github']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.16.1

### Custom code

Yes

### OS platform and distribution

Windows 11

### Mobile device

_No response_

### Python version

3.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

release 12.4, V12.4.131

### GPU model and memory

_No response_

### Current behavior?

I can't use the fit function, I tried it everytime, even when I am using the code examples in the tensorflow website and documentation, it just doesn't seem to work

### Standalone code to reproduce the issue

```shell
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import RandomOverSampler
import tensorflow as tf


cols = [""flength"", ""fwidth"", ""fsize"", ""fconc"", ""fconc1"", ""fasym"", ""fm3long"", ""fm3trans"", ""falpha"", ""fdist"", ""class""]

df = pd.read_csv(""./ML/gamma ray stuff/magic04.data"", names=cols)
df.head()

df[""class""] = (df[""class""] == ""g"").astype(int)
print(df)

# for label in cols[:-1]:  # Exclude the last element (""class"")
#     plt.hist(df[df[""class""] == 1][label], color='blue', label=""gamma"", alpha=0.7, density=True)
#     plt.hist(df[df[""class""] == 0][label], color='red', label=""hadron"", alpha=0.7, density=True)
#     plt.title(label)
#     plt.ylabel(""probability"")
#     plt.xlabel(label)
#     plt.legend()
#     plt.show()

train, valid, test = np.split(df.sample(frac=1), [int(0.6*len(df)), int(0.8*len(df))])

def scale_dataset(dataframe, oversample =False):
    X = dataframe[dataframe.columns[:-1]].values
    y = dataframe[dataframe.columns[-1]].values

    scalar = StandardScaler()

    X = scalar.fit_transform(X)

    if oversample:
        ros = RandomOverSampler()
        X,y = ros.fit_resample(X,y)
    
    data = np.hstack((X,np.reshape(y, (-1,1))))

    return data, X, y


train, x_train, y_train = scale_dataset(train,oversample=True)
valid, x_valid, y_valid = scale_dataset(valid,oversample=False)
test, x_test, y_test = scale_dataset(test,oversample=False)

nn_model = tf.keras.Sequential(
    [
        tf.keras.layers.Dense(32, activation='relu', input_shape= (10,)),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dense(1, activation='sigmoid')
    ]
)

nn_model.compile(
    optimizer=tf.keras.optimizers.Adam(0.001),
      loss='binary_crossentropy',
        metrics=['accuracy']
)

nn_model.fit(x_train,y_train, epochs=100, batch_size=32, validation_split=0.2)
```


### Relevant log output

```shell
C:\Users\PCMR\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2024-06-23 11:43:50.343214: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/100
Traceback (most recent call last):
  File ""d:\Developer\Python\testing territory\ML\gamma ray stuff\main.py"", line 100, in <module>
    nn_model.fit(x_train,y_train, epochs=100, batch_size=32, validation_split=0.2)
  File ""C:\Users\PCMR\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\keras\src\utils\traceback_utils.py"", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.12_3.12.1264.0_x64__qbz5n2kfra8p0\Lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode characters in position 23-42: character maps to <undefined>
```
"
2368601059,70263,Can't load my model.h5,closed,2024-06-23 14:54:42+00:00,2024-06-24T07:15:15Z,2024-06-24T07:15:12Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/70263,"['type:bug', 'comp:apis', 'TF 2.15']","['@manswad The error message persists, indicating the issue with loading your model is related to a missing function named ""mae"". Could you please locate the source of it? Kindly check the loading path and also please make sure you are training and loading the model in the same TF version. Thank you!', '> @manswad The error message persists, indicating the issue with loading your model is related to a missing function named ""mae"". Could you please locate the source of it? Kindly check the loading path and also please make sure you are training and loading the model in the same TF version. Thank you!\n\nOh my bad, I used loss=\'mae\', it was causing the problem, then I tried loss=\'mean_absolute_error\'\nAnd it WORKED\n\nThankss', '@manswad Thank you for the update. Please let us know if we can move this issue to closed status as it is resolved?\r\nThank you!', ""> @manswad Thank you for the update. Please let us know if we can move this issue to closed status as it is resolved?\n> Thank you!\n\nYes, Thanks a lot. Sir/Ma'am"", '@manswad Thank you! Closing this ticket.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70263"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70263"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.15.0

### Custom code

Yes

### OS platform and distribution

Kaggle NoteBook

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

My model got saved without any problem. But is showing some kind of error afterwards. 

Here is the link to my Kaggle Notebook if you would like to see my full code: https://www.kaggle.com/code/manswad/house-prices-advanced-regression-techniques



### Standalone code to reproduce the issue

```shell
from tensorflow.keras.models import load_model

model = load_model('/kaggle/working/model.h5')
```


### Relevant log output

```shell
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[47], line 3
      1 from tensorflow.keras.models import load_model
----> 3 model = load_model('/kaggle/working/model.h5')

File /opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_api.py:183, in load_model(filepath, custom_objects, compile, safe_mode)
    176     return saving_lib.load_model(
    177         filepath,
    178         custom_objects=custom_objects,
    179         compile=compile,
    180         safe_mode=safe_mode,
    181     )
    182 if str(filepath).endswith(("".h5"", "".hdf5"")):
--> 183     return legacy_h5_format.load_model_from_hdf5(
    184         filepath, custom_objects=custom_objects, compile=compile
    185     )
    186 elif str(filepath).endswith("".keras""):
    187     raise ValueError(
    188         f""File not found: filepath={filepath}. ""
    189         ""Please ensure the file is an accessible `.keras` ""
    190         ""zip file.""
    191     )

File /opt/conda/lib/python3.10/site-packages/keras/src/legacy/saving/legacy_h5_format.py:155, in load_model_from_hdf5(filepath, custom_objects, compile)
    151 training_config = json_utils.decode(training_config)
    153 # Compile model.
    154 model.compile(
--> 155     **saving_utils.compile_args_from_training_config(
    156         training_config, custom_objects
    157     )
    158 )
    159 saving_utils.try_build_compiled_arguments(model)
    161 # Set optimizer weights.

File /opt/conda/lib/python3.10/site-packages/keras/src/legacy/saving/saving_utils.py:143, in compile_args_from_training_config(training_config, custom_objects)
    141 loss_config = training_config.get(""loss"", None)
    142 if loss_config is not None:
--> 143     loss = _deserialize_nested_config(losses.deserialize, loss_config)
    144     # Ensure backwards compatibility for losses in legacy H5 files
    145     loss = _resolve_compile_arguments_compat(loss, loss_config, losses)

File /opt/conda/lib/python3.10/site-packages/keras/src/legacy/saving/saving_utils.py:202, in _deserialize_nested_config(deserialize_fn, config)
    200     return None
    201 if _is_single_object(config):
--> 202     return deserialize_fn(config)
    203 elif isinstance(config, dict):
    204     return {
    205         k: _deserialize_nested_config(deserialize_fn, v)
    206         for k, v in config.items()
    207     }

File /opt/conda/lib/python3.10/site-packages/keras/src/losses/__init__.py:144, in deserialize(name, custom_objects)
    131 @keras_export(""keras.losses.deserialize"")
    132 def deserialize(name, custom_objects=None):
    133     """"""Deserializes a serialized loss class/function instance.
    134 
    135     Args:
   (...)
    142         A Keras `Loss` instance or a loss function.
    143     """"""
--> 144     return serialization_lib.deserialize_keras_object(
    145         name,
    146         module_objects=ALL_OBJECTS_DICT,
    147         custom_objects=custom_objects,
    148     )

File /opt/conda/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py:575, in deserialize_keras_object(config, custom_objects, safe_mode, **kwargs)
    573             return config
    574         if isinstance(module_objects[config], types.FunctionType):
--> 575             return deserialize_keras_object(
    576                 serialize_with_public_fn(
    577                     module_objects[config], config, fn_module_name
    578                 ),
    579                 custom_objects=custom_objects,
    580             )
    581         return deserialize_keras_object(
    582             serialize_with_public_class(
    583                 module_objects[config], inner_config=inner_config
    584             ),
    585             custom_objects=custom_objects,
    586         )
    588 if isinstance(config, PLAIN_TYPES):

File /opt/conda/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py:678, in deserialize_keras_object(config, custom_objects, safe_mode, **kwargs)
    676 if class_name == ""function"":
    677     fn_name = inner_config
--> 678     return _retrieve_class_or_fn(
    679         fn_name,
    680         registered_name,
    681         module,
    682         obj_type=""function"",
    683         full_config=config,
    684         custom_objects=custom_objects,
    685     )
    687 # Below, handling of all classes.
    688 # First, is it a shared object?
    689 if ""shared_object_id"" in config:

File /opt/conda/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py:812, in _retrieve_class_or_fn(name, registered_name, module, obj_type, full_config, custom_objects)
    809     if obj is not None:
    810         return obj
--> 812 raise TypeError(
    813     f""Could not locate {obj_type} '{name}'. ""
    814     ""Make sure custom classes are decorated with ""
    815     ""`@keras.saving.register_keras_serializable()`. ""
    816     f""Full object config: {full_config}""
    817 )

TypeError: Could not locate function 'mae'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mae', 'registered_name': 'mae'}
```
"
2369096630,70267,AttributeError: module 'keras.src.backend' has no attribute 'convert_to_numpy',closed,2024-06-24 03:07:06+00:00,2024-07-13T01:51:52Z,2024-07-13T01:51:49Z,sushreebarsa,,https://github.com/tensorflow/tensorflow/issues/70267,"['stat:awaiting response', 'type:bug', 'stale', 'comp:apis', 'TF 2.16']","['@weebao I tried to modify the code , could you please have a look at the gist [here](https://colab.research.google.com/gist/sushreebarsa/2cc350a77f8a705082d80805c8e81cd5/70267.ipynb) and let us know if it helps?\r\nThank you!', ""Hi @sushreebarsa! Thanks for your time! I guess it does work on Colab but when I run the .ipynb file locally it returns the following error:\r\n\r\n```console\r\nFile c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\__init__.py:30\r\n...\r\n---> [32](file:///C:/Users/baoro/AppData/Local/Programs/Python/Python311/Lib/site-packages/tensorflow/_api/v2/compat/v1/data/experimental/__init__.py:32) from tensorflow.python.data.experimental.ops.iterator_ops import get_model_proto # line: 103\r\n     [33](file:///C:/Users/baoro/AppData/Local/Programs/Python/Python311/Lib/site-packages/tensorflow/_api/v2/compat/v1/data/experimental/__init__.py:33) from tensorflow.python.data.experimental.ops.iterator_ops import make_saveable_from_iterator # line: 41\r\n     [34](file:///C:/Users/baoro/AppData/Local/Programs/Python/Python311/Lib/site-packages/tensorflow/_api/v2/compat/v1/data/experimental/__init__.py:34) from tensorflow.python.data.experimental.ops.lookup_ops import DatasetInitializer # line: 54\r\n\r\nImportError: cannot import name 'get_model_proto' from 'tensorflow.python.data.experimental.ops.iterator_ops' (c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\iterator_ops.py)\r\n```\r\n\r\nI have installed the latest version of all libraries so I'm not sure how to resolve this..."", ""@weebao On your local machine please check the following;\r\n```\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\n\r\n```\r\nIf the version doesn't match then you can install the same version manually;\r\n```\r\npip install tensorflow==<version_number>\r\n\r\n```\r\nOtherwise you could use a virtual environment to isolate dependencies and avoid conflicts. \r\n```\r\n# Create a virtual environment\r\npython -m venv myenv\r\n\r\n# Activate the virtual environment\r\n# On Windows\r\nmyenv\\Scripts\\activate\r\n# On macOS/Linux\r\nsource myenv/bin/activate\r\n\r\n\r\n```\r\nThank you!"", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70267"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70267"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.16.1

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I am following up on #66966, which seems to not be really resolved yet. I am also running the `fit` function on a Sequential object from keras and I tried it on both python file and .ipynb file. Apparently this works when running with Python but not on a .ipynb file, which confuses me. Is there any way I can go around this? Thanks!

### Standalone code to reproduce the issue

```shell
import nltk
from nltk.tokenize import word_tokenize
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
import numpy as np
from keras.models import Sequential
from keras.layers import Embedding, LSTM, Dense

nltk.download('punkt')

corpus = [
    ""Hello, how are you?"",
    ""I am fine, thank you!"",
    ""What are you doing today?"",
    ""I am working on a project.""
]

# Tokenize the text
corpus_tokens = [word_tokenize(doc.lower()) for doc in corpus]

# Flatten the list of token lists into a single list of tokens
all_tokens = [token for sublist in corpus_tokens for token in sublist]

tokenizer = Tokenizer()
tokenizer.fit_on_texts(all_tokens)
total_words = len(tokenizer.word_index) + 1

# Convert text to sequences of tokens
input_sequences = []
for line in corpus_tokens:
    token_list = tokenizer.texts_to_sequences([line])[0]
    for i in range(1, len(token_list)):
        n_gram_sequence = token_list[:i+1]
        input_sequences.append(n_gram_sequence)

max_sequence_len = max([len(x) for x in input_sequences])
input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))

predictors, label = input_sequences[:,:-1], input_sequences[:,-1]
label = to_categorical(label, num_classes=total_words)

# Build model
def build_model(max_sequence_len, total_words):
    model = Sequential()
    model.add(Embedding(total_words, 10, input_length=max_sequence_len - 1))
    model.add(LSTM(150))
    model.add(Dense(total_words, activation='softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

model = build_model(max_sequence_len, total_words)

# Training model
model.fit(predictors, label, epochs=1, verbose=1)  # Reduced epochs for demonstration

# Predict function
def predict_next_word(model, tokenizer, text, k):
    sequence = word_tokenize(text.lower())
    token_list = tokenizer.texts_to_sequences([sequence])[0]
    token_list = pad_sequences([token_list], maxlen=k, padding='pre')
    predicted = model.predict(token_list, verbose=0)
    output_word = """"
    for word, index in tokenizer.word_index.items():
        if index == np.argmax(predicted):
            output_word = word
            break
    return output_word

print(predict_next_word(model, tokenizer, ""I am"", k=2))
```


### Relevant log output

_No response_"
2369598955,70273,Loading model error 'No such file or directory: 'model.weights.h5',closed,2024-06-24 08:34:43+00:00,2024-06-28T10:01:35Z,2024-06-28T10:01:32Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/70273,"['stat:awaiting response', 'type:bug', 'comp:keras', 'TF 2.16']","['@WeichenXu123,\r\nWeights can be saved to disk by calling **model.save_weights(filepath)**. The filename should end in **.weights.h5**. While loading the weights, Could you please try using **load_weights(""my_model.weights.h5"")**\r\n\r\n\r\n```python\r\nsequential_model.save_weights(""my_model.weights.h5"")\r\nsequential_model.load_weights(""my_model.weights.h5"")\r\n```\r\n\r\nhttps://keras.io/guides/serialization_and_saving/#how-to-save-and-load-a-model\r\n\r\nThank you!', 'Thanks ! But I think `tensorflow.keras.models.load_model` should also work. In tensorflow released version it works.\r\n\r\nAnd note that I saved the model as `.keras` format, I don\'t want to save it as `.weights.h5` format. \r\n\r\nThe expected behavior should be:\r\n\r\n`model.save(""model_file.keras"")` # generates a `model_file.keras` file.\r\n\r\nand in a new python process, we can do\r\n`loaded_model = tensorflow.keras.models.load_model(""model_file.keras"")`\r\n\r\nIn released version above code works well. But now it becomes buggy.', 'I can reproduce the error. I tried python 3.10, and it won\'t generate ""model.weights.h5"" file, and loads well.', ""In my case, I got this error with my code (using mulitprocessing module in python to load keras model in each child process) running in a docker image on AWS. But I can't reproduce the error when running the same code locally. Very confusing. "", 'The error occurs in Tensorflow 2.16.1 too. :) ', '@WeichenXu123,\r\nThe default keras version in tensorflow v2.16.1 is the keras3.0 version which might be the reason for the change. While loading the weights,  please try using load_weights(""my_model.weights.h5""). While tensorflow 2.15 version contains tf-keras 2.15(keras2). \r\n\r\nAnd for more Keras related issues, please feel free to raise the issue in  [keras-team/keras](https://github.com/keras-team/keras/issues) repo for quick resolution.\r\nThank you!', 'thanks!', '@WeichenXu123,\r\nCould you please feel free to close this issue. Thank you!', '@WeichenXu123 , This issue has been fixed in the commit here https://github.com/keras-team/keras/pull/19924 and it will be available in the Keras 3.4.1 release which should be available tomorrow. \r\nFeel free to close the issue.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70273"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70273"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.18.0-dev20240623

### Custom code

No

### OS platform and distribution

Ubuntu 22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

If I launches multiple concurrency processes to load tensorflow model from one saved model file, error occurs like:

```
  File ""/tmp/tfm2/t1.py"", line 13, in <module>
    tensorflow.keras.models.load_model(model_file_path, custom_objects=custom_objects)
  File ""/home/weichen.xu/miniconda3/envs/mlflow/lib/python3.9/site-packages/keras/src/saving/saving_api.py"", line 182, in load_model
    return saving_lib.load_model(
  File ""/home/weichen.xu/miniconda3/envs/mlflow/lib/python3.9/site-packages/keras/src/saving/saving_lib.py"", line 229, in load_model
    return _load_model_from_fileobj(
  File ""/home/weichen.xu/miniconda3/envs/mlflow/lib/python3.9/site-packages/keras/src/saving/saving_lib.py"", line 353, in _load_model_from_fileobj
    weights_file_path.unlink()
  File ""/home/weichen.xu/miniconda3/envs/mlflow/lib/python3.9/pathlib.py"", line 1354, in unlink
    self._accessor.unlink(self)

```

### Standalone code to reproduce the issue

```shell
(1) Create the following python script `tf-save.py` to generate model file:


import os.path

import pandas as pd
import numpy as np
from sklearn import datasets
from tensorflow.keras.layers import Concatenate, Dense, Input, Lambda
from tensorflow.keras.saving import register_keras_serializable
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.optimizers import SGD
import cloudpickle
import sys

save_path = sys.argv[1]

iris = datasets.load_iris()
data = pd.DataFrame(
    data=np.c_[iris[""data""], iris[""target""]], columns=iris[""feature_names""] + [""target""]
)
y = data[""target""]
x = data.drop(""target"", axis=1)

input_a = Input(shape=(2, 3), name=""a"")
input_b = Input(shape=(2, 5), name=""b"")


@register_keras_serializable(name=""f2"")
def f2(z):
    from tensorflow.keras import backend as K

    return K.mean(z, axis=2)


input_a_sum = Lambda(f2)(input_a)
input_b_sum = Lambda(f2)(input_b)

output = Dense(1)(Dense(3, input_dim=4)(Concatenate()([input_a_sum, input_b_sum])))
model = Model(inputs=[input_a, input_b], outputs=output)
model.compile(loss=""mean_squared_error"", optimizer=SGD())
model.fit(
    [
        np.repeat(x.values[:, :2, np.newaxis], 3, axis=2),
        np.repeat(x.values[:, -2:, np.newaxis], 5, axis=2),
    ],
    y,
)

from tensorflow.keras.saving import get_custom_objects

global_custom_objects = get_custom_objects()

with open(os.path.join(save_path, ""global_custom_objects.cloudpickle""), ""wb"") as out_f:
    cloudpickle.dump(global_custom_objects, out_f)

model_file_path = f""{save_path}/model.keras""
model.save(model_file_path)

```
then run shell command:

```
python tf-save.py .
```

It generates the following files in current directory:

```
global_custom_objects.cloudpickle  model.keras  model.weights.h5
```
One strange thing is it shouldn't generate `model.weights.h5` file. We only save model weights to `model.keras` file

then create a `tf-load.py` file containing:
```
import os.path
import sys
import cloudpickle
import tensorflow.keras

model_path = sys.argv[1]

custom_obj_path = os.path.join(model_path, ""global_custom_objects.cloudpickle"")
with open(custom_obj_path, ""rb"") as f:
    custom_objects = cloudpickle.load(f)

model_file_path = os.path.join(model_path, ""model.keras"")
tensorflow.keras.models.load_model(model_file_path, custom_objects=custom_objects)
```

then create a bash script `run.sh` like:

```
python tf-load.py . &
python tf-load.py . &
python tf-load.py . &
python tf-load.py . &

wait
```

then execute shell command
```
. run.sh 
```

error occurs:
```
Traceback (most recent call last):
  File ""/tmp/tfm2/tf-load.py"", line 13, in <module>
    tensorflow.keras.models.load_model(model_file_path, custom_objects=custom_objects)
  File ""/home/weichen.xu/miniconda3/envs/mlflow/lib/python3.9/site-packages/keras/src/saving/saving_api.py"", line 182, in load_model
    return saving_lib.load_model(
  File ""/home/weichen.xu/miniconda3/envs/mlflow/lib/python3.9/site-packages/keras/src/saving/saving_lib.py"", line 229, in load_model
    return _load_model_from_fileobj(
  File ""/home/weichen.xu/miniconda3/envs/mlflow/lib/python3.9/site-packages/keras/src/saving/saving_lib.py"", line 353, in _load_model_from_fileobj
    weights_file_path.unlink()
  File ""/home/weichen.xu/miniconda3/envs/mlflow/lib/python3.9/pathlib.py"", line 1354, in unlink
    self._accessor.unlink(self)
FileNotFoundError: [Errno 2] No such file or directory: 'model.weights.h5'
```
and we found after executing `run.sh`, the `model.weights.h5` file is deleted.



### Relevant log output

_No response_"
2371316059,70316,[TFLite] TfLiteInterpreterInvoke has memory leak and increasing duration time,closed,2024-06-24 23:46:57+00:00,2024-11-26T02:06:19Z,2024-11-26T02:06:16Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/70316,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'type:performance', 'TF 2.15']","[""@kkk-jpeg Could you please make sure that you're properly allocating and deallocating memory for tensors used with the interpreter. Please consider optimizing your TFLite model using tools like the TFLite Converter with optimizations like quantization and pruning. Kindly let us know if you are facing this issue in TF latest version?\r\nThank you!"", '@sushreebarsa \r\nI commented out ""TfLiteInterperterInvoke"", and this problem doesn\'t happen.\r\nI made sure input and output buffer treat currectly.\r\n\r\nTfliteInterpreter.close won\'t work.\r\nand after using ""TfLiteInterpreterDelete(mTFLInterpreter)"" doesn\'t change increased time.\r\nIf this function work right, the increased time will back to normal.\r\n\r\nPlease give me any suggestion.\r\n\r\n>if you are facing this issue in TF latest version?\u3000\u3000\r\n\r\nyes.\r\n\r\n', 'https://github.com/android/camera-samples/blob/42f76c4aab7c7c2d41110c3c127c20c08882e079/CameraXTfLite/app/src/main/java/com/example/android/camerax/tflite/CameraActivity.kt#L89\r\n\r\nThis sample app also increase duration time. It started 10fps but 7fps after 5 mins.', '@kkk-jpeg Could you please verify that the interpreter (mTFLInterpreter) is initialized correctly with your model and input parameters. Any incomplete or incorrect initialization can lead to undefined behavior, including memory leaks?\r\nPlease provide the standalone code to replicate the issue reported here.\r\nThank you!\r\n', ""@sushreebarsa \r\nThank you for your kindly answer. I'm checking if my code using model in right way.\r\nNow I found this error. Do you think this related to memory leak?\r\n![image](https://github.com/tensorflow/tensorflow/assets/103484905/51c76bc5-f5e9-4cc4-b7ab-886f455b9461)\r\n"", '@sushreebarsa \r\nI would like to make sure to convert .tflite file to .h file.\r\nIf I do wrong convert, this also let memory leak happen.\r\n\r\n```\r\nimport numpy as np\r\nimport os\r\n\r\ndef convert_tflite_to_header(tflite_path, output_header_path):\r\n\r\nwith open(tflite_path, \'rb\') as tflite_file:\r\n    tflite_content = tflite_file.read()\r\n\r\n\r\nhex_lines = [\', \'.join([f\'0x{byte:02x}\' for byte in tflite_content[i:i+12]]) for i in range(0, len(tflite_content), 12)]\r\n\r\n\r\nhex_array = \',\\n  \'.join(hex_lines)\r\n\r\n\r\nwith open(output_header_path, \'w\') as header_file:\r\n    \r\n    header_file.write(\'const unsigned char model[] = {\\n  \')\r\n    header_file.write(f\'{hex_array}\\n\')\r\n    header_file.write(\'};\\n\\n\')\r\n    \r\nif __name__ == ""__main__"":\r\n    tflite_path = \'model.tflite\'\r\n    output_header_path = \'model.h\'\r\n\r\n    convert_tflite_to_header(tflite_path, output_header_path)\r\n    convert_tflite_to_header(tflite_path, output_header_path)\r\n```', 'I recognized my output tensor index is 337 in .tflite file, but I have to use index 0 when using C API.\r\nThis means something made wrong converting .tflite to hex array in C file?', '@sawantkumar please give me any suggestions?', 'Hi @kkk-jpeg ,\r\n\r\nCan you please share your tflite model file if possible ?', ""@sawantkumar \r\nI can't put tflite model here. could you tell me your e-mail?"", 'Hi @kkk-jpeg ,\r\n\r\nYou can upload your model to your google drive and share a link here or you can mail me at sawantkumar@google.com.', 'meet the same problem while using metal delegate with iOS', ""@sawantkumar \r\nI've sent you e-mail. could you check please?"", 'Hi @kkk-jpeg ,\r\n\r\nI forgot to ask but can you also provide me the complete code required to replicate this issue ?\r\n\r\n', '@sawantkumar I have a demo which can reproduce the leak problem using ios metal delegate, will that be useful to you? If so, I can share it with you.', 'Hi @zhanghuicuc ,\r\n\r\nSure, you can share it .', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', '@zhanghuicuc @sawantkumar \r\nIf you have any findings, could you share with me?', 'Hi, @pkgoogle \r\n\r\nPlease take look into this issue. Thank you', ""Hi @kkk-jpeg, delete[] is not valid in C, is this a C++ issue or a C issue?, I'm not seeing where your init() or release() is being called. Can you maybe give me more of your code or give me a standalone reproducible example?"", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70316"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70316"">No</a>\n', '@pkgoogle \r\nsorry for late reply.\r\nI\'m using this C API of tflite in C++ extension. that makes memory leak problem?\r\n(When I use malloc/free does\'t change this problem)\r\nXcode function ""leaks"" mentioned TfLiteInterpreterCreate memory leaks.\r\n\r\nThanks.', 'Hi @kkk-jpeg, I am unable to reproduce with the given code thus far. Can you provide more context on how to reproduce this? If you have code in a github repo, that may be easiest. But please share as much as you can.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70316"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70316"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.15.0

### Custom code

Yes

### OS platform and distribution

Android/iOS mobile platform

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I found memory and duration time increasing when I  use tflite C API code in below.
The duration time increase 10 msec in just 10 minitues.


```
TfLiteStatus init(){
    // create model 
    mTFLModel = TfLiteModelCreate(dst_buf, dlc_size);

    mTFLInterpreter = TfLiteInterpreterCreate(mTFLModel, NULL);
    // Allocate tensor buffers.　
    mStatus = TfLiteInterpreterAllocateTensors(mTFLInterpreter);
    // output buffer
    mdnnOutputDataBuffer = new float[OutputSize.width * OutputSize.height];
    memset(mdnnOutputDataBuffer, 0, sizeof(float) * OutputSize.width * OutputSize.height );
    return mStatus;
}

void release(){
    if (mdnnOutputDataBuffer != NULL) delete[] mdnnOutputDataBuffer;
    if (mTFLInterpreter != NULL) {
        TfLiteInterpreterDelete(mTFLInterpreter);
        mTFLInterpreter = NULL;
    }
    if (mTFLModel != NULL) {
        TfLiteModelDelete(mTFLModel);
        mTFLModel = NULL;
    }
}

TfLiteStatus main(const float* input, uint8_t* intValues) {

        TfLiteTensor* input_tensor = TfLiteInterpreterGetInputTensor(mTFLInterpreter,0);
        //
        mStatus = TfLiteTensorCopyFromBuffer(input_tensor, input, TfLiteTensorByteSize(input_tensor));
        //
        mStatus = TfLiteInterpreterInvoke(mTFLInterpreter);

        const TfLiteTensor* output_tensor =
                TfLiteInterpreterGetOutputTensor(mTFLInterpreter, 0);
        
        TfLiteTensorCopyToBuffer(output_tensor, mdnnOutputDataBuffer,
                                 TfLiteTensorByteSize(output_tensor));

}
```


Now I know is ..
・Not depending on tf version(I tried both 2.9.0 and 2.16.1)
・Not depenging on iOS/android(both happen)
・Low resolution input/output model slightly better
・Not depending on device(I tried sevaral devices)

I checked similar mention, but those problem are about NNapi or GPU delegate option.
I don't use delegate option and doesen't work for me.

- https://github.com/tensorflow/tensorflow/issues/55503
- https://github.com/tensorflow/tflite-support/issues/269
- https://github.com/tensorflow/tensorflow/issues/66736

### Standalone code to reproduce the issue

```shell
…
```


### Relevant log output

_No response_"
2372211496,70340,Strange issue File already exists in database,closed,2024-06-25 09:46:27+00:00,2024-07-14T03:25:42Z,2024-07-14T03:25:39Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/70340,"['type:bug', 'type:build/install', 'TF 2.16']","['@tomneo2004,\r\nCould you please confirm the sequence of steps. Tf2.16v supports protobuf >=3.20.3 versions as per [source](https://github.com/tensorflow/tensorflow/blob/v2.16.1/tensorflow/tools/pip_package/setup.py#L101) where as it seems protobuf 3.19v has been installed.\r\n\r\nThank you!', '> @tomneo2004, Could you please confirm the sequence of steps. Tf2.16v supports protobuf >=3.20.3 versions as per [source](https://github.com/tensorflow/tensorflow/blob/v2.16.1/tensorflow/tools/pip_package/setup.py#L101) where as it seems protobuf 3.19v has been installed.\r\n> \r\n> Thank you!\r\n\r\n![Screenshot from 2024-06-27 03-05-03](https://github.com/tensorflow/tensorflow/assets/921838/4544b843-7fd3-4eb0-ab25-cd2c2e83627b)\r\n\r\nv4.25.3 protobuf was installed along side with tensorflow 2.16', 'I end up switching to ONNX Runtime instead of Tensorflow for my model inference to solve problem.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70340"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70340"">No</a>\n']","### Issue type

Others

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Pop os 22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

My project use tensorflow library and work fine when application run from python script. When I make bundle of application for distribution and run the application an error pop up. The main issue is this only happen in Linux system. I also try in Ubuntu but is the same error.

Error is following
```
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:642] File already exists in database: tensorflow/core/protobuf/replay_log.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1986] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
Aborted (core dumped)
```

Library I use to bundle  the application is [cx_Freeze](https://cx-freeze.readthedocs.io/en/stable/). I think above error related to protobuf  in tensorflow.

### Standalone code to reproduce the issue

```shell
1. Clone my project  [here](https://github.com/NPMachineLearning/SmartTrainer.git)

2. Follow the steps here [here](https://github.com/NPMachineLearning/SmartTrainer#steps) to produce an executable application

3. Run app under directory qt_app/build/exe.linux-x86_64-3.9/
```


### Relevant log output

_No response_"
2375878939,70456,"Unable to use tf and its modules including keras and etc,  where the tensorflow==2.15.1 and keras==2.15.0",closed,2024-06-26 17:12:12+00:00,2024-07-03T16:58:16Z,2024-07-03T16:58:13Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/70456,"['stat:awaiting response', 'type:bug', 'comp:keras', 'TF 2.15']","['Saved a model using a Jupyter Notebook and later when tried to load the model inside my project the model is not able to load throws error.', 'Hi **@arpanptnk85** ,\r\n- I reproduced the code shared but facing different error .Could you please share the colab gist with all the dependencies to analyze more of it.\r\nThank you!', ""Hey @Venkat6871,\r\n\r\n- Thanks for reaching out. I've encountered issues with importing submodules from TensorFlow. Below, I have explained the import issues in detail:\r\n\r\n## Problematic Imports\r\n```\r\n# These imports are causing issues depending on the TensorFlow version 2.15.1\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n```\r\n\r\n## Working Solution\r\n```\r\n# Importing the tensorflow.keras as keras worked out.\r\nimport tensorflow.keras as keras\r\n```\r\n\r\nCould you help me understand why the direct import method suddenly stopped working?"", ""Hi **@arpanptnk85** ,\r\n- Thanks for provided information. I tried to run your code on Colab using TF v2.15 and i don't faced any issue. Please find the [gist](https://colab.research.google.com/gist/Venkat6871/7b283bcf7bd2d55893d7647da69a0840/70456_2-15-v.ipynb) here for reference. \r\n\r\nThank you!"", 'Thanks ', 'Hi **@arpanptnk85** ,\r\n- Could you please confirm if this issue is resolved for you ? Please feel free to close the issue if it is resolved ? \r\n\r\nThank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70456"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70456"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

v2.15.0-11-g63f5a65c7cd 2.15.1

### Custom code

No

### OS platform and distribution

Mac OS Sonoma

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?



import tensorflow as tf
model = tf.keras.models.load_model(model_path)

tf.keras =>(module) tf

Top-level module of TensorFlow. By convention, we refer to this module as tf instead of tensorflow, following the common practice of importing TensorFlow via the command import tensorflow as tf.

The primary function of this module is to import all of the public TensorFlow interfaces into a single place. The interfaces themselves are located in sub-modules, as described below.

Note that the file __init__.py in the TensorFlow source code tree is actually only a placeholder to enable test cases to run. The TensorFlow build replaces
this file with a file generated from [api_template.__init__.py](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/api_template.__init__.py)


### Standalone code to reproduce the issue

```shell
import tensorflow as tf



# Save the model
model.save('model.keras')

# Load the model
model = tf.keras.models.load_model('model.keras')
```


### Relevant log output

```shell
[Error]-[loading model]: Could not deserialize class 'Functional' because its parent module keras.src.engine.functional cannot be imported.
```
"
2377580800,70502,LSTM model conversion failed from 'from_keras_model',closed,2024-06-27 09:01:51+00:00,2024-07-25T01:53:08Z,2024-07-25T01:53:05Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/70502,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'TFLiteConverter', 'TF 2.12']","[""@KarenMars,\r\n\r\nAdd `tf.lite.OpsSet.SELECT_TF_OPS`  to the converter's target spec: \r\n\r\n``` python \r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS] \r\n```\r\n\r\nto expand the range of supported operations. \r\n\r\nAlso could you please try to change the following lines of code:\r\n\r\n   ```python\r\n    converter = tf.lite.TFLiteConverter.from_keras_model( enc_model )\r\n    buffer = converter.convert()\r\n    open( 'enc_model.tflite' , 'wb' ).write( buffer ) \r\n```\r\nto \r\n\r\n```python\r\nconverter = tf.lite.TFLiteConverter.from_keras_model( enc_model )\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.experimental_new_converter=True\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,*tf.lite.OpsSet.SELECT_TF_OPS]\r\nbuffer = converter.convert()\r\nopen( 'enc_model.tflite' , 'wb' ).write( buffer ). \r\n```\r\n\r\nThank you!"", 'Hi,\r\n\r\nThank you very much for the help, when I added the code you provided, the conversion from `from_keras_model` can work.\r\n\r\nHowever, when I visualize these tflite models from `from_saved_model` and `from_keras_model`, it can be seen that the tflite model from `from_keras_model` uses many extra operators for the LSTM opertator. I assume that is because of the settings of `converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,*tf.lite.OpsSet.SELECT_TF_OPS]`. I wonder why the conversion from the keras model cannot support the lstm operators. And whether these extra operators will have different computation efficiency compared with a single lstm operator. Looking forward to your reply, and thank you very much.\r\n\r\n![image](https://github.com/tensorflow/tensorflow/assets/32601780/ee6bd31f-77f0-4eee-9a81-d57aa2cfba80)\r\n\r\n![image](https://github.com/tensorflow/tensorflow/assets/32601780/a2209c75-eea2-4f63-ab62-c807fdf8aa03)\r\n\r\n', 'Hi, do we have any updates of this issue, thank you very much ~', ""Hi @KarenMars can you provide your current script which produces the non-optimal tflite model. You can skip the training steps since we're mainly focusing on the architectural issues w/ the conversion and not the value of the weights. I would say this is likely an optimization bug... have you tried seeing what the performance/efficiency differences are? I suspect they are different but it'll be interesting if the converted version is actually more performant than the correct tflite op. Which would mean it converts to a more optimal form -- I don't think this is a the case but in that case I would actually not call it a bug. Thanks for your help."", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70502"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70502"">No</a>\n']","### Issue
Hi, I am trying to convert my lstm-based model into tflite format, and I am using the [official lstm conversion code](https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/experimental_new_converter/Keras_LSTM_fusion_Codelab.ipynb) from the tensorflow colab. In the code given in the colab, the conversion works fine with `from_saved_model`, however, when I using the `from_keras_model` for the conversion, the conversion is failed. Please check the below code and logs for more information, thank you for any help : )

### 1. System information

- OS Platform and Distribution: 22.04.1
- TensorFlow installation: pip package
- TensorFlow library: 2.12.1

### 2. Code
```python
import numpy as np
import tensorflow as tf

model = tf.keras.models.Sequential([
    tf.keras.layers.Input(shape=(28, 28), name='input'),
    tf.keras.layers.LSTM(20, time_major=False, return_sequences=True),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(10, activation=tf.nn.softmax, name='output')
])
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
model.summary()

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
x_train = x_train.astype(np.float32)
x_test = x_test.astype(np.float32)

_FAST_TRAINING = True
_EPOCHS = 5
if _FAST_TRAINING:
  _EPOCHS = 1
  _TRAINING_DATA_COUNT = 1000
  x_train = x_train[:_TRAINING_DATA_COUNT]
  y_train = y_train[:_TRAINING_DATA_COUNT]

model.fit(x_train, y_train, epochs=_EPOCHS)
model.evaluate(x_test, y_test, verbose=0)

run_model = tf.function(lambda x: model(x))
# This is important, let's fix the input size.
BATCH_SIZE = 1
STEPS = 28
INPUT_SIZE = 28
concrete_func = run_model.get_concrete_function(
    tf.TensorSpec([BATCH_SIZE, STEPS, INPUT_SIZE], model.inputs[0].dtype))

# model directory.
MODEL_DIR = ""keras_lstm""
model.save(MODEL_DIR, save_format=""tf"", signatures=concrete_func)

# from saved model
converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)
tflite_model = converter.convert()
open(""saved_lstm_model.tflite"", ""wb"").write(tflite_model)
print('convert from saved model successfully!')
# from keras model
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
open(""keras_lstm_model.tflite"", ""wb"").write(tflite_model)

```

### 3. logs
```
// the conversion is failed by 'from_keras_model'
Model: ""sequential""
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm (LSTM)                 (None, 28, 20)            3920      
                                                                 
 flatten (Flatten)           (None, 560)               0         
                                                                 
 output (Dense)              (None, 10)                5610      
                                                                 
=================================================================
Total params: 9,530
Trainable params: 9,530
Non-trainable params: 0
_________________________________________________________________

 1/32 [..............................] - ETA: 26s - loss: 2.3000 - accuracy: 0.0625
10/32 [========>.....................] - ETA: 0s - loss: 2.2685 - accuracy: 0.1688 
14/32 [============>.................] - ETA: 0s - loss: 2.2432 - accuracy: 0.2165
19/32 [================>.............] - ETA: 0s - loss: 2.2064 - accuracy: 0.2730
24/32 [=====================>........] - ETA: 0s - loss: 2.1691 - accuracy: 0.3190
30/32 [===========================>..] - ETA: 0s - loss: 2.1254 - accuracy: 0.3646
32/32 [==============================] - 1s 10ms/step - loss: 2.1139 - accuracy: 0.3760
convert from saved model successfully!

WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.
WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.
loc(callsite(callsite(callsite(fused[""TensorListReserve:"", callsite(""TensorArrayV2_1@__inference_standard_lstm_17957""(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1276:0) at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1240:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1283:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py"":205:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1353:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1373:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":940:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":962:0 at ""/Github_repo/draft/save_lstm_model.py"":50:0))))))))] at fused[""PartitionedCall:"", callsite(""sequential/lstm/PartitionedCall@__inference__wrapped_model_18239""(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1276:0) at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1240:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1283:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py"":205:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1353:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1373:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":940:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":962:0 at ""/Github_repo/draft/save_lstm_model.py"":50:0))))))))]) at fused[""StatefulPartitionedCall:"", callsite(""StatefulPartitionedCall@__inference_signature_wrapper_20177""(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1276:0) at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1240:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1283:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py"":205:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1353:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1373:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":940:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":962:0 at ""/Github_repo/draft/save_lstm_model.py"":50:0))))))))]) at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall""])): error: 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass
loc(callsite(callsite(callsite(fused[""TensorListReserve:"", callsite(""TensorArrayV2_1@__inference_standard_lstm_17957""(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1276:0) at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1240:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1283:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py"":205:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1353:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1373:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":940:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":962:0 at ""/Github_repo/draft/save_lstm_model.py"":50:0))))))))] at fused[""PartitionedCall:"", callsite(""sequential/lstm/PartitionedCall@__inference__wrapped_model_18239""(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1276:0) at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1240:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1283:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py"":205:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1353:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1373:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":940:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":962:0 at ""/Github_repo/draft/save_lstm_model.py"":50:0))))))))]) at fused[""StatefulPartitionedCall:"", callsite(""StatefulPartitionedCall@__inference_signature_wrapper_20177""(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1276:0) at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1240:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1283:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py"":205:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1353:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1373:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":940:0 at callsite(""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":962:0 at ""/Github_repo/draft/save_lstm_model.py"":50:0))))))))]) at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall""])): error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal
error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n converter._experimental_lower_tensor_list_ops = False
Traceback (most recent call last):
  File ""/Github_repo/draft/save_lstm_model.py"", line 50, in <module>
    tflite_model = converter.convert()
  File ""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"", line 962, in wrapper
    return self._convert_and_export_metrics(convert_func, *args, **kwargs)
  File ""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"", line 940, in _convert_and_export_metrics
    result = convert_func(self, *args, **kwargs)
  File ""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"", line 1373, in convert
    saved_model_convert_result = self._convert_as_saved_model()
  File ""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"", line 1356, in _convert_as_saved_model
    self).convert(graph_def, input_tensors, output_tensors)
  File ""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"", line 1166, in convert
    result = _convert_graphdef(
  File ""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py"", line 212, in wrapper
    raise converter_error from None  # Re-throws the exception.
  File ""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py"", line 205, in wrapper
    return func(*args, **kwargs)
  File ""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/convert.py"", line 817, in convert_graphdef
    data = convert(
  File ""/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/lite/python/convert.py"", line 322, in convert
    raise converter_error
tensorflow.lite.python.convert_phase.ConverterError: /Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py:1276:0: error: 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass
<unknown>:0: note: loc(fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall""]): called from
/Github_repo/temp_folder/backend/venv/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py:1276:0: error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal
<unknown>:0: note: loc(fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall""]): called from
<unknown>:0: error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n converter._experimental_lower_tensor_list_ops = False
```
"
2378524034,70520,tfm.nlp.layers.RelativePositionEmbedding ,closed,2024-06-27 15:50:37+00:00,2024-08-13T01:55:41Z,2024-08-13T01:55:35Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/70520,"['stat:awaiting response', 'type:bug', 'stale', 'comp:model', 'TF 2.16']","['@Leo-Lifeblood I was able to replicate the output reported [here](https://colab.research.google.com/gist/sushreebarsa/c573727f8cf0f77be2dc13af243567a4/70520.ipynb), could you please share the error you are encountering ?\r\nThank you!', 'The error is that the batch dimension in this case 32 is being deleted. This breaks any training loop. ', '@Leo-Lifeblood,\r\nThank you for reporting the issue. tfm.nlp.layers.RelativePositionEmbedding API is more related to tf-models. Could you please raise the issue on the TensorFlow/tf-models [repo](https://github.com/tensorflow/models/issues) for the quick response.\r\n\r\n\r\nhttps://github.com/tensorflow/models/blob/master/official/nlp/modeling/layers/position_embedding.py\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70520"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70520"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.16.1

### Custom code

Yes

### OS platform and distribution

google colab

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

<img width=""727"" alt=""Screenshot 2024-06-27 at 17 49 59"" src=""https://github.com/tensorflow/tensorflow/assets/174037709/021a5a0a-aff2-4b07-8e1d-dba1972b99ee"">


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import tensorflow_models as tfm

input_tensor = tf.random.normal((32, 87, 128))


position_emb = tfm.nlp.layers.RelativePositionEmbedding(hidden_size=128)


output_tensor = position_emb(input_tensor)
 

print(output_tensor.shape)
```


### Relevant log output

_No response_"
2382244491,70659,TensorFlow Lite label_image fails to build with cmake,closed,2024-06-30 12:59:31+00:00,2024-08-07T06:48:03Z,2024-08-07T06:48:00Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/70659,"['awaiting review', 'type:bug', 'comp:lite', '2.17']","[""The problem is that `tensorflow/lite/profiling/proto/profiling_info.pb.h` is generated under `CMAKE_BINARY_DIR`, but there is no include_directories setting.\r\n\r\nAdding the following modification to `tensorflow/lite/examples/label_image/CMakeLists.txt` will resolve the error, \r\n```bash\r\n$ git diff tensorflow/lite/examples/label_image/CMakeLists.txt\r\ndiff --git a/tensorflow/lite/examples/label_image/CMakeLists.txt b/tensorflow/lite/examples/label_image/CMakeLists.txt\r\nindex 9874801f34f..5acbae31565 100644\r\n--- a/tensorflow/lite/examples/label_image/CMakeLists.txt\r\n+++ b/tensorflow/lite/examples/label_image/CMakeLists.txt\r\n@@ -61,6 +61,11 @@ if(TFLITE_ENABLE_EXTERNAL_DELEGATE)\r\n           ${TFLITE_SOURCE_DIR}/tools/delegates/external_delegate_provider.cc)\r\n endif()\r\n \r\n+include_directories(label_image\r\n+  PUBLIC\r\n+  ${CMAKE_BINARY_DIR}\r\n+)\r\n+\r\n add_executable(label_image\r\n   ${TFLITE_LABEL_IMAGE_SRCS}\r\n )\r\n```\r\n\r\nbut a new error will occur.\r\n```bash\r\n/usr/bin/ld: CMakeFiles/label_image.dir/__/__/profiling/profile_summary_formatter.cc.o: in function `tflite::profiling::ProfileSummaryProtoFormatter::GenerateOpProfileDataFromDetail(tsl::StatsCalculator::Detail const*, tsl::StatsCalculator const*, tflite::profiling::OpProfileData*) const [clone .part.0]':\r\nprofile_summary_formatter.cc:(.text+0x9c): undefined reference to `google::protobuf::internal::ArenaStringPtr::Set(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, google::protobuf::Arena*)'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x218): undefined reference to `google::protobuf::internal::ArenaStringPtr::Set(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, google::protobuf::Arena*)'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x2e8): undefined reference to `tflite::profiling::OpProfilingStat* google::protobuf::Arena::CreateMaybeMessage<tflite::profiling::OpProfilingStat>(google::protobuf::Arena*)'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x304): undefined reference to `tflite::profiling::OpProfilingStat* google::protobuf::Arena::CreateMaybeMessage<tflite::profiling::OpProfilingStat>(google::protobuf::Arena*)'\r\n/usr/bin/ld: CMakeFiles/label_image.dir/__/__/profiling/profile_summary_formatter.cc.o: in function `tflite::profiling::ProfileSummaryProtoFormatter::GenerateSubGraphProfilingData(tsl::StatsCalculator const*, int, std::map<unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::less<unsigned int>, std::allocator<std::pair<unsigned int const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > > const&, tflite::profiling::SubGraphProfilingData*) const':\r\nprofile_summary_formatter.cc:(.text+0x3748): undefined reference to `google::protobuf::internal::ArenaStringPtr::Set(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, google::protobuf::Arena*)'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x384c): undefined reference to `tflite::profiling::OpProfileData* google::protobuf::Arena::CreateMaybeMessage<tflite::profiling::OpProfileData>(google::protobuf::Arena*)'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x3858): undefined reference to `google::protobuf::internal::RepeatedPtrFieldBase::AddOutOfLineHelper(void*)'\r\n/usr/bin/ld: CMakeFiles/label_image.dir/__/__/profiling/profile_summary_formatter.cc.o: in function `tflite::profiling::ProfileSummaryProtoFormatter::GenerateDelegateProfilingData(tsl::StatsCalculator const*, tflite::profiling::DelegateProfilingData*) const':\r\nprofile_summary_formatter.cc:(.text+0x3a24): undefined reference to `tflite::profiling::OpProfileData* google::protobuf::Arena::CreateMaybeMessage<tflite::profiling::OpProfileData>(google::protobuf::Arena*)'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x3a30): undefined reference to `google::protobuf::internal::RepeatedPtrFieldBase::AddOutOfLineHelper(void*)'\r\n/usr/bin/ld: CMakeFiles/label_image.dir/__/__/profiling/profile_summary_formatter.cc.o: in function `tflite::profiling::ProfileSummaryProtoFormatter::GetOutputString(std::map<unsigned int, std::unique_ptr<tsl::StatsCalculator, std::default_delete<tsl::StatsCalculator> >, std::less<unsigned int>, std::allocator<std::pair<unsigned int const, std::unique_ptr<tsl::StatsCalculator, std::default_delete<tsl::StatsCalculator> > > > > const&, tsl::StatsCalculator const&, std::map<unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::less<unsigned int>, std::allocator<std::pair<unsigned int const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > > const&) const':\r\nprofile_summary_formatter.cc:(.text+0x3ab8): undefined reference to `tflite::profiling::ModelProfilingData::ModelProfilingData(google::protobuf::Arena*, bool)'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x3b2c): undefined reference to `tflite::profiling::SubGraphProfilingData* google::protobuf::Arena::CreateMaybeMessage<tflite::profiling::SubGraphProfilingData>(google::protobuf::Arena*)'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x3b38): undefined reference to `google::protobuf::internal::RepeatedPtrFieldBase::AddOutOfLineHelper(void*)'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x3b8c): undefined reference to `google::protobuf::MessageLite::SerializeAsString[abi:cxx11]() const'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x3b94): undefined reference to `tflite::profiling::ModelProfilingData::~ModelProfilingData()'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x3bbc): undefined reference to `tflite::profiling::DelegateProfilingData* google::protobuf::Arena::CreateMaybeMessage<tflite::profiling::DelegateProfilingData>(google::protobuf::Arena*)'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x3bc8): undefined reference to `google::protobuf::internal::RepeatedPtrFieldBase::AddOutOfLineHelper(void*)'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x3bdc): undefined reference to `tflite::profiling::ModelProfilingData::~ModelProfilingData()'\r\n/usr/bin/ld: CMakeFiles/label_image.dir/__/__/profiling/profile_summary_formatter.cc.o: in function `tflite::profiling::ProfileSummaryProtoFormatter::HandleOutput(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) const':\r\nprofile_summary_formatter.cc:(.text+0x3cf4): undefined reference to `tflite::profiling::BenchmarkProfilingData::BenchmarkProfilingData(google::protobuf::Arena*, bool)'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x3d18): undefined reference to `google::protobuf::MessageLite::SerializeToOstream(std::ostream*) const'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x3d28): undefined reference to `tflite::profiling::BenchmarkProfilingData::~BenchmarkProfilingData()'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x3dc0): undefined reference to `google::protobuf::MessageLite::ParseFromString(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x3de4): undefined reference to `google::protobuf::MessageLite::ParseFromString(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x3f28): undefined reference to `google::protobuf::Message::DebugString[abi:cxx11]() const'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x3f7c): undefined reference to `tflite::profiling::ModelProfilingData* google::protobuf::Arena::CreateMaybeMessage<tflite::profiling::ModelProfilingData>(google::protobuf::Arena*)'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x3f94): undefined reference to `tflite::profiling::ModelProfilingData* google::protobuf::Arena::CreateMaybeMessage<tflite::profiling::ModelProfilingData>(google::protobuf::Arena*)'\r\n/usr/bin/ld: profile_summary_formatter.cc:(.text+0x3fc4): undefined reference to `tflite::profiling::BenchmarkProfilingData::~BenchmarkProfilingData()'\r\ncollect2: error: ld returned 1 exit status\r\ngmake[3]: *** [examples/label_image/CMakeFiles/label_image.dir/build.make:409: examples/label_image/label_image] Error 1\r\ngmake[2]: *** [CMakeFiles/Makefile2:7751: examples/label_image/CMakeFiles/label_image.dir/all] Error 2\r\ngmake[1]: *** [CMakeFiles/Makefile2:7758: examples/label_image/CMakeFiles/label_image.dir/rule] Error 2\r\ngmake: *** [Makefile:2600: label_image] Error 2"", ""`tensorflow/lite/profiling/proto/profiling_info.pb.cc` and the link of the `libprotobuf` library are missing from label_image's `CMakeLists.txt`.\r\n\r\nI was able to confirm that label_image can be built successfully with the following corrections.\r\n```bash\r\n git diff tensorflow/lite/examples/label_image/CMakeLists.txt\r\ndiff --git a/tensorflow/lite/examples/label_image/CMakeLists.txt b/tensorflow/lite/examples/label_image/CMakeLists.txt\r\nindex 9874801f34f..4e3cf86daf6 100644\r\n--- a/tensorflow/lite/examples/label_image/CMakeLists.txt\r\n+++ b/tensorflow/lite/examples/label_image/CMakeLists.txt\r\n@@ -31,6 +31,7 @@ list(APPEND TFLITE_LABEL_IMAGE_SRCS\r\n   ${TFLITE_SOURCE_DIR}/tools/delegates/delegate_provider.cc\r\n   ${TFLITE_SOURCE_DIR}/tools/evaluation/utils.cc\r\n   ${TFLITE_SOURCE_DIR}/tools/tool_params.cc\r\n+  ${CMAKE_BINARY_DIR}/tensorflow/lite/profiling/proto/profiling_info.pb.cc\r\n )\r\n \r\n if(TFLITE_ENABLE_XNNPACK)\r\n@@ -61,6 +62,11 @@ if(TFLITE_ENABLE_EXTERNAL_DELEGATE)\r\n           ${TFLITE_SOURCE_DIR}/tools/delegates/external_delegate_provider.cc)\r\n endif()\r\n \r\n+include_directories(label_image\r\n+  PUBLIC\r\n+  ${CMAKE_BINARY_DIR}\r\n+)\r\n+\r\n add_executable(label_image\r\n   ${TFLITE_LABEL_IMAGE_SRCS}\r\n )\r\n@@ -78,4 +84,5 @@ target_compile_options(label_image\r\n )\r\n target_link_libraries(label_image\r\n   tensorflow-lite\r\n+  ${CMAKE_BINARY_DIR}/_deps/protobuf-build/libprotobuf.a\r\n )\r\n\r\n```"", ""\r\nI'm not sure if modifying label_image's CMakeLists.txt is the correct approach, but I have confirmed that it can be built with the following modifications.\r\n```bash\r\n$ git diff tensorflow/lite/examples/label_image/CMakeLists.txt\r\ndiff --git a/tensorflow/lite/examples/label_image/CMakeLists.txt b/tensorflow/lite/examples/label_image/CMakeLists.txt\r\nindex 9874801f34f..2fcb09ce96e 100644\r\n--- a/tensorflow/lite/examples/label_image/CMakeLists.txt\r\n+++ b/tensorflow/lite/examples/label_image/CMakeLists.txt\r\n@@ -61,6 +61,11 @@ if(TFLITE_ENABLE_EXTERNAL_DELEGATE)\r\n           ${TFLITE_SOURCE_DIR}/tools/delegates/external_delegate_provider.cc)\r\n endif()\r\n \r\n+include_directories(label_image\r\n+  PUBLIC\r\n+  ${CMAKE_BINARY_DIR}\r\n+)\r\n+\r\n add_executable(label_image\r\n   ${TFLITE_LABEL_IMAGE_SRCS}\r\n )\r\n@@ -78,4 +83,6 @@ target_compile_options(label_image\r\n )\r\n target_link_libraries(label_image\r\n   tensorflow-lite\r\n+  profiling_info_proto\r\n+  protobuf\r\n )\r\n```"", 'The latest commit (775c84d11596da38120a9443dca87ca5d7930ead) still gives the error I reported.', 'Hi @pkgoogle , \r\n\r\nI replicate the issue and i got the same error , can you please take a look ?\r\n\r\n`Scanning dependencies of target label_image\r\n[100%] Building CXX object examples/label_image/CMakeFiles/label_image.dir/bitmap_helpers.cc.o\r\n[100%] Building CXX object examples/label_image/CMakeFiles/label_image.dir/label_image.cc.o\r\n[100%] Building CXX object examples/label_image/CMakeFiles/label_image.dir/home/sawantkumar/tensorflow/third_party/xla/xla/tsl/util/stats_calculator.cc.o\r\n[100%] Building CXX object examples/label_image/CMakeFiles/label_image.dir/__/__/profiling/memory_info.cc.o\r\n[100%] Building CXX object examples/label_image/CMakeFiles/label_image.dir/__/__/profiling/profile_summarizer.cc.o\r\nIn file included from /home/sawantkumar/tensorflow/tensorflow/lite/profiling/profile_summarizer.h:28,\r\n                 from /home/sawantkumar/tensorflow/tensorflow/lite/profiling/profile_summarizer.cc:16:\r\n/home/sawantkumar/tensorflow/tensorflow/lite/profiling/profile_summary_formatter.h:31:10: fatal error: tensorflow/lite/profiling/proto/profiling_info.pb.h: No such file or directory\r\n   31 | #include ""tensorflow/lite/profiling/proto/profiling_info.pb.h""\r\n      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ncompilation terminated.\r\nmake[3]: *** [examples/label_image/CMakeFiles/label_image.dir/build.make:115: examples/label_image/CMakeFiles/label_image.dir/__/__/profiling/profile_summarizer.cc.o] Error 1\r\nmake[2]: *** [CMakeFiles/Makefile2:8102: examples/label_image/CMakeFiles/label_image.dir/all] Error 2\r\nmake[1]: *** [CMakeFiles/Makefile2:8109: examples/label_image/CMakeFiles/label_image.dir/rule] Error 2\r\nmake: *** [Makefile:2595: label_image] Error 2`', ""The PR looks correct to me, let's wait for a review."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70659"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70659"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

v2.17.0-rc0

### Custom code

No

### OS platform and distribution

Linux (Raspberry Pi OS)

### Mobile device

Raspberry Pi 4

### Python version

3.11.2

### Bazel version

_No response_

### GCC/compiler version

12.2.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I get the error 
> tensorflow/lite/profiling/proto/profiling_info.pb.h: No such file or directory.


### Standalone code to reproduce the issue

```shell
$ git clone -b v2.17.0-rc0 https://github.com/tensorflow/tensorflow
$ mkdir tflite_build && tflite_build
$ cmake ../tensorflow/tensorflow/lite/
$ cmake --build . -j3
$ cmake --build . -t label_image
In file included from /home/pi/tensorflow/tensorflow/lite/profiling/profile_summarizer.h:28,
                 from /home/pi/tensorflow/tensorflow/lite/profiling/profile_summarizer.cc:16:
/home/pi/tensorflow/tensorflow/lite/profiling/profile_summary_formatter.h:31:10: fatal error: tensorflow/lite/profiling/proto/profiling_info.pb.h: No such file or directory
   31 | #include ""tensorflow/lite/profiling/proto/profiling_info.pb.h""
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
compilation terminated.

```
```


### Relevant log output

_No response_"
2383379342,70682,Tflite inference with multiple inputs and outputs on Android,closed,2024-07-01 09:53:11+00:00,2024-09-27T17:44:25Z,2024-09-27T17:44:22Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/70682,"['type:bug', 'comp:lite', '2.6.0', 'Android']","['Hi @panhu ,\r\nPlease take a look at this [link](https://www.tensorflow.org/lite/guide/inference#android_platform) and let me know if this what you are looking for.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', 'Hi, @pkgoogle \r\nPlease take look into this issue. Thank you', ""No description, I'm assuming this is spam, if there is a real issue please create a new one with a description. Thanks."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70682"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70682"">No</a>\n']",
2385504088,70726,Tflite(C++) for saving fine tuned models,closed,2024-07-02 07:49:11+00:00,2024-10-24T02:02:06Z,2024-10-24T02:02:04Z,haozha111,,https://github.com/tensorflow/tensorflow/issues/70726,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'TF 2.9']","['@Sachi-27,\r\nCould you please provide the complete code to reproduce and the tensorflow version you are trying  which helps to debug the issue. Thank you!', 'Tensorflow version : 2.9.1\r\nI have used the same code as in [here](https://www.tensorflow.org/lite/examples/on_device_training/overview#build_a_model_for_on-device_training) to convert the .h5 model to .tflite with signatures.\r\n\r\nI have made changes to the tensorflow/tlite/examples/minimal/minimal.cc code.\r\n```\r\n#include <cstdio>\r\n#include <iostream>\r\n#include <fstream>\r\n#include <sys/time.h>\r\n#include ""tensorflow/lite/interpreter.h""\r\n#include ""tensorflow/lite/kernels/register.h""\r\n#include ""tensorflow/lite/model.h""\r\n#include ""tensorflow/lite/optional_debug_tools.h""\r\n#include ""tensorflow/lite/signature_runner.h""\r\n#include ""tensorflow/lite/kernels/internal/tensor_ctypes.h""\r\n\r\n#define TFLITE_MINIMAL_CHECK(x)                              \\\r\n  if (!(x)) {                                                \\\r\n    fprintf(stderr, ""Error at %s:%d\\n"", __FILE__, __LINE__); \\\r\n    exit(1);                                                 \\\r\n  }\r\nint main(int argc, char* argv[]) {\r\n  if (argc != 2) {\r\n    fprintf(stderr, ""minimal <tflite model>\\n"");\r\n     return 1;\r\n  }\r\n\r\n  const char* filename = argv[1];\r\n\r\n  // Load model\r\n  std::unique_ptr<tflite::FlatBufferModel> model =\r\n      tflite::FlatBufferModel::BuildFromFile(filename);\r\n  TFLITE_MINIMAL_CHECK(model != nullptr);\r\n\r\n  // Build the interpreter with the InterpreterBuilder.\r\n  // Note: all Interpreters should be built with the InterpreterBuilder,\r\n  // which allocates memory for the Interpreter and does various set up\r\n  // tasks so that the Interpreter can read the provided model.\r\n  tflite::ops::builtin::BuiltinOpResolver resolver;\r\n  tflite::InterpreterBuilder builder(*model, resolver);\r\n  std::unique_ptr<tflite::Interpreter> interpreter;\r\n  builder(&interpreter);\r\n  TFLITE_MINIMAL_CHECK(interpreter != nullptr);\r\n  \r\nint batch_sz = 10;\r\n  std::vector<const std::string*> signature_defs = interpreter->signature_keys();\r\n tflite::SignatureRunner* save_runner = interpreter->GetSignatureRunner(signature_defs[2]->c_str());\r\n  if(!save_runner){\r\n    std::cerr << ""Cannot obtain save signature"" << std::endl; \r\n  }\r\nconst std::vector<const char*>& input_names_ = save_runner->input_names();\r\n  const std::vector<const char*>& output_names_ = save_runner->output_names();\r\n  std::cout << ""input_names.size() = "" << input_names_.size() << std::endl;\r\n  std::cout << input_names_[0] << std::endl;\r\n  std::cout << ""output_names.size() = "" << output_names_.size() << std::endl;\r\n  std::cout << output_names_[0] << std::endl;\r\n\r\n  TFLITE_MINIMAL_CHECK(save_runner->AllocateTensors() == kTfLiteOk);\r\n  TfLiteTensor* input_tensor_ = save_runner->input_tensor(""checkpoint_path"");\r\n  TFLITE_MINIMAL_CHECK(input_tensor_ != nullptr);\r\n  std::string* input_ = tflite::GetTensorData<std::string>(input_tensor_);\r\n  std::cout << ""About to set input_ value"" << std::endl;\r\n  std::cout << ""TFLITE TYPE: "" << input_tensor_->type << std::endl;\r\n    *input_ = ""model.ckpt"";\r\n  \r\n  std::cout << ""Setting input_ to: "" << input_tensor->data.raw << std::endl;\r\n\r\n  TFLITE_MINIMAL_CHECK(save_runner->Invoke() == kTfLiteOk);\r\n  std::cout << ""Invoked"" << std::endl;\r\n  const TfLiteTensor* output_tensor_ = save_runner->output_tensor(""checkpoint_path"");\r\n  std::cout << ""Obtained output_tensor_"" << std::endl;\r\n  std::cout << ""OUTPUT checkpoint path: ""<< output_tensor->data.raw << std::endl;\r\n\r\n  interpreter.reset();\r\n  return 0;\r\n}\r\n```\r\n\r\n\r\n\r\nCOMMAND TO RUN:\r\n`./minimal demo.tflite`\r\n\r\nOUTPUT:\r\n1\r\ncheckpoint_path\r\n1\r\ncheckpoint_path\r\nAbout to set input_ value\r\nTFLITE TYPE: 5\r\nSegmentation Fault\r\n\r\n\r\n\r\nQUERY:\r\nI would like to basically know how to pass in tf.string input correctly. I have also tried doing the following instead:\r\n`input_tensor_->data.raw = ""model.ckpt"";`\r\nBut i get Segmentation fault when `save_runner->Invoke()` is called', 'Hi @pkgoogle ,\r\n\r\nI also got the same error, can you please look into it \r\n\r\n```\r\nroot@tflite-issue-replication:/home/sawantkumar/work/c_plus/tensorflow/bazel-bin/tensorflow/lite/examples/minimal# ./minimal /home/sawantkumar/work/c_plus/tensorflow/tensorflow/lite/examples/minimal/demo1.tflite\r\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\r\ninput_names.size() = 1\r\ncheckpoint_path\r\noutput_names.size() = 1\r\ncheckpoint_path\r\nAbout to set input_ value\r\nTFLITE TYPE: 5\r\nSegmentation fault (core dumped)\r\n```', 'Hi @Sachi-27, do you absolutely need to do on device training? -- if not I can recommend other methods which may work better.', 'Yes @pkgoogle. I am working on developing on-device real-time training.', ""So that tutorial is very old, I think we should at the very least update everything to work with the latest version. Here's a [gist](https://colab.sandbox.google.com/gist/pkgoogle/12c0c38408514a5b840c920373754cb1/odt_tutorial.ipynb) showing how far I got on nightly. @haozha111 can you please take a look? Thanks."", ""@pkgoogle It seems you haven't given the access rights. Can you change the share permissions? Thankyou"", ""> @pkgoogle It seems you haven't given the access rights. Can you change the share permissions? Thankyou\r\n\r\nAhh wrong link, it should be updated now."", ""@Sachi-27 i think the way you set string tensor for the tflite save signature is a bit problematic. TF Lite's string tensor has a different encoding format with the std::string, so we can't just copy the `std:string` into TF Lite. Can you try something like:\r\n\r\n`def run_save():\r\n    save_signature = interpreter.get_signature_runner('save')\r\n    ckpt = '/tmp/model.ckpt'\r\n    output = save_signature(checkpoint_path=np.array(ckpt, dtype=np.string_))\r\n`"", 'Hi, @Sachi-27 \r\n\r\nCould you please try above [workaround](https://github.com/tensorflow/tensorflow/issues/70726#issuecomment-2277297493) and see is it resolving your issue or not ? Thank you', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70726"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70726"">No</a>\n']","I have used the reference [here](https://www.tensorflow.org/lite/examples/on_device_training/overview#build_a_model_for_on-device_training) to enable on-device learning by adding four signatures (infer, train, restore and save) same as given in the reference. I now use C++ TFLite API, which takes as input <tflite_model_path> and <input_data> and performs inference and can also train the model using the tflite::SignatureRunner. I am unable to perform saving and restoring of weights. 

Following is my attempt. I get Error: Memory Allocation failed. 

`tflite::SignatureRunner* save_runner = interpreter->GetSignatureRunner(signature_defs[2]->c_str());`
`if(!save_runner){
  std::cerr << ""Cannot obtain save signature"" << std::endl; 
}`

`TFLITE_MINIMAL_CHECK(save_runner->AllocateTensors() == kTfLiteOk);`
`TfLiteTensor* input_tensor_ = save_runner->input_tensor(""checkpoint_path"");`
`TFLITE_MINIMAL_CHECK(input_tensor_ != nullptr);`
`std::string* input_ = tflite::GetTensorData<std::string>(input_tensor_);`
`if(input_){
  *input_ = ""model.ckpt"";
}`
`else{
  std::cerr << ""Error: Memory allocation failed"" << std::endl; exit(1);
}`

`TFLITE_MINIMAL_CHECK(save_runner->Invoke() == kTfLiteOk);`
`TfLiteTensor* output_tensor_ = save_runner->input_tensor(""checkpoint_path"");`
`std::string* output = tflite::GetTensorData<std::string>(output_tensor_);`
`std::cout << ""OUTPUT checkpoint path: ""<< *output << std::endl;`

`interpreter.reset();`
`return 0;`

Why is the input_ variable not allocated any memory. Following is the function signature corresponding to ""save"".
`@tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])`
`  def save(self, checkpoint_path):`
`    tensor_names = [weight.name for weight in self.model.weights]`
`    tensors_to_save = [weight.read_value() for weight in self.model.weights]`
`    tf.raw_ops.Save(`
`        filename=checkpoint_path, tensor_names=tensor_names,`
`        data=tensors_to_save, name='save')`
`    return {`
`        ""checkpoint_path"": checkpoint_path`
`    }`"
2386437695,70744,Issue: TensorFlow API Installation and Integration with Website Failing on Laptop,closed,2024-07-02 14:34:20+00:00,2024-07-24T01:53:20Z,2024-07-24T01:53:16Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/70744,"['stat:awaiting response', 'type:bug', 'stale', 'subtype:windows', 'TF 2.16']","['@SakshiFadnavis2003,\r\nCould you please provide the steps you have followed to install the tensorflow and also provide the error log which you are facing during the process.\r\n\r\nAlso please try to follow the steps mentioned which are available in the official document.\r\nhttps://www.tensorflow.org/install/pip#step-by-step_instructions\r\n\r\nThank you!\r\n', '@tilakrayal ,\r\nTensorflow is installed but the API needed to integrating the tensorflow models into the website are not installing like the  one tensorflow API', '@SakshiFadnavis2003,\r\nCould you please let me know the details of the tensorflow API which you are trying to install the website which helps to debug the issue. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70744"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70744"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

v2.16.0-rc0-18-g5bc9d26649c 2.16.1

### Custom code

Yes

### OS platform and distribution

 Microsoft Windows 11 Home Single Language

### Mobile device

_No response_

### Python version

Python 3.9.18

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I am facing issues installing the TensorFlow API and integrating TensorFlow models into my website. Despite following various guides and tutorials available on YouTube and Google, I have been unable to resolve the installation issues on my laptop.

### Standalone code to reproduce the issue

```shell
I currently do not have specific code to reproduce the issue as I have been running commands in the bash shell and facing installation problems. However, I have attempted every possible solution and guide available online through Google and YouTube, and none have resolved the installation issues I’m experiencing.
```


### Relevant log output

_No response_"
2386516403,70747,TFLite in C++ causes Segmentation Fault,closed,2024-07-02 15:08:12+00:00,2024-07-03T13:32:34Z,2024-07-03T13:32:31Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/70747,"['type:bug', 'comp:lite']","[""Static dimensions (including batch size) are required apparently, though I didn't see it anywhere in documentation?\r\ntf.keras.Sequential([tf.keras.Input(batch_shape=[1, 224, 449, 3]), model])\r\n\r\nClosing the issue as I've opened a new one with the rest of the bugs."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70747"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70747"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No (different bug)

### Source

source

### TensorFlow version

2.13.1 (described below)
2.15.1 behaves similarly
2.16.1 cannot even produce the tflite model (something similar to this issue: https://github.com/tensorflow/tensorflow/issues/65012)
tf-nightly cannot build libtensorflowlite.so (gcc: error: unrecognized command-line option '-mavx512fp16'; did you mean '-mavx512bf16'?)

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.4 LTS

### Mobile device

_No response_

### Python version

3.10.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I have a model which I wish to run on RPi-4 in C++, however, I am currently facing issues with converting the model to TFLite and running it in C++ on the native machine. I made a dummy model which demonstrates the bug. Here's the code for generating the model:

```
model = tf.keras.Sequential([
    tf.keras.layers.Dense(32, activation=""relu""),
    tf.keras.layers.Dense(5, activation=""softmax"")
])

model.build(input_shape=(1, 224, 449, 3))

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
with open(""converted_model.tflite"", ""wb"") as f:
    f.write(tflite_model)
```

Note however that THIS solves the issue for this dummy model:
```
class WrappedModel(tf.keras.Model):
    def __init__(self, baseModel):
        super().__init__()
        self.baseModel = baseModel

    def call(self, x, training=False):
        x = tf.reshape(x, [1, 224, 449, 3])
        return self.baseModel(x)

model = tf.keras.Sequential([
    tf.keras.layers.Dense(32, activation=""relu""),
    tf.keras.layers.Dense(5, activation=""softmax"")
])

model.build(input_shape=(1, 224, 449, 3))

wrapped_model = WrappedModel(model)

# Calling wrapped_model.build(...) doesn't work here for some reason, looks like another bug.
wrapped_model.compute_output_shape(
    input_shape=[1, 224 * 449 * 3]
)

converter = tf.lite.TFLiteConverter.from_keras_model(wrapped_model)
tflite_model = converter.convert()
with open(""converted_model.tflite"", ""wb"") as f:
    f.write(tflite_model)
```
but it doesn't work with my real model (which includes some pretrained models, several branched layers, etc.).
When I run TFLite interpreter from Python everything works as expected.

Thanks!

### Standalone code to reproduce the issue

```shell
#include <memory>
#include <iostream>
#include ""tensorflow/lite/core/interpreter.h""
#include ""tensorflow/lite/core/model_builder.h""
#include ""tensorflow/lite/kernels/register.h""
#include ""tensorflow/lite/core/c/common.h""
#include ""tensorflow/lite/optional_debug_tools.h""
#include ""flatbuffers/flatbuffers.h""

std::unique_ptr<tflite::Interpreter> Initialize()
{
    const std::string model_path = ""converted_model.tflite"";
    std::unique_ptr<tflite::FlatBufferModel> model =
        tflite::FlatBufferModel::BuildFromFile(model_path.c_str());

    tflite::ops::builtin::BuiltinOpResolver resolver;
    std::unique_ptr<tflite::Interpreter> model_interpreter;
    tflite::InterpreterBuilder(*model, resolver)(&model_interpreter);
    if (model_interpreter->AllocateTensors() != kTfLiteOk)
    {
        std::cerr << ""Failed to allocate tensors."" << std::endl;
    }

    return model_interpreter;
}

int main()
{
    std::unique_ptr<tflite::Interpreter> interpreter = Initialize();

    std::cout << ""Acquiring input buffer"" << std::endl;

    float *input_buff = interpreter->typed_input_tensor<float>(0);

    for (int i = 0; i < 224*449*3; i++)
    {
        input_buff[i] = 0.2;
    }

    std::cout << ""Filled input buffer"" << std::endl;

    interpreter->Invoke();

    std::cout << ""Done with Invoke"" << std::endl;

    float *output = interpreter->typed_output_tensor<float>(0);
    std::cout << ""Output: "" << output[0] << std::endl;

    return 0;
}
```


### Relevant log output
```
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
Acquiring input buffer
Filled input buffer
Segmentation fault (core dumped)
```"
2386777948,70757,Issue with Loading Sequential Models,closed,2024-07-02 17:23:24+00:00,2024-08-20T14:34:58Z,2024-08-03T01:57:17Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/70757,"['stat:awaiting response', 'type:bug', 'comp:model', 'TF 2.16']","['Experiencing the same issue in tensorflow 2.16.1.', '@tilakrayal I was able to replicate the issue in TF[v2.16](https://colab.research.google.com/gist/sushreebarsa/0c319b7455efb0deb9f2e79d99dd18f7/notebook-for-error.ipynb#scrollTo=DdP3-O33ypGO) and tf-[nightly](https://colab.research.google.com/gist/sushreebarsa/35d0ea64c077c3fa55a6976eea53279a/notebook-for-error.ipynb#scrollTo=r84tJyfxykjb) but it is not reproducible in TF [2.15](https://colab.research.google.com/gist/sushreebarsa/e38f5797c21a185db2ac276d7994bef3/notebook-for-error.ipynb#scrollTo=kPo0jdaRx_D0).\r\nThank you!', '@RaulCastillo547,\r\nI tried to execute the mentioned using **!pip install tf-keras==2.17.0rc0**, and executed the official time series forecasting document and it was executed without fail. By default Tensorflow v2.16 contains the keras3.0 version which might be the reason for the issue/error/fail. Kindly find the gist of it [here](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb).\r\n\r\nThank you!', '@tilakrayal,\r\nI tried using !pip install tf-keras==2.17.0rc0 and tried to save and load the CNN multi-step model on both the official time series forecasting document and my google collab notebook. However, the same error pops up when I load the model.', '@RaulCastillo547,\r\nThank you for reporting the issue. I was able to reproduce the issue on TensorFlow 2.15, keras2.0 and tf-nightly keras3.0 as well. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/e1188571488b381ebce4ab6708593739/notebook_for_error.ipynb).\r\n\r\nAs this issue is more related to keras, could you please try to raise the issue in the keras-team/keras [repo](https://github.com/keras-team/keras/issues) for the quick resolution. Thank you!', 'Hello, reporting the same issue with pip version 2.17. Thanks', 'Could you please feel free to move this issue to closed status, since it is already being tracked in the Keras repo? Thank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70757"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70757"">No</a>\n', ""In my case, the issue was caused by my use of the `tf.keras.layers.Lambda` class within the `tf.keras.Sequential` model. The lambda function I was using was `lambda x: tf.reshape(x, [...])` which I suppose changed the tuple shape representation to a list representation. I believe this comparison subsequently failed downstream when loading the model. My solution was to use the `tf.keras.layers.Reshape` class instead of the Lambda class as you're supposed to. P.S. This might not be the exact reason the tutorial code is failing.""]","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.16.2

### Custom code

Yes

### OS platform and distribution

Windows 10 Home

### Mobile device

_No response_

### Python version

3.12.0

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I am trying to train a Sequential model based off the Single Shot CNN model found in the Tensorflow [time series forecasting tutorial](https://www.tensorflow.org/tutorials/structured_data/time_series).

The compiling, testing, predicting, and saving operations all work fine; however, loading the model gives me this error - `ValueError: Sequential model 'sequential' has already been configured to use input shape (None, 10, 4). You cannot build it with input_shape [None, 10, 4]`.

This happens with version 2.16.2, but if I were to use version 2.15.0 from a Google Colab notebook, I would get no errors. This difference between versions and the oddity between two identical shapes not equaling causes me to believe that this is a bug.

I also [posted on the Tensorflow Forums](https://discuss.tensorflow.org/t/issue-with-identical-input-shapes-not-equalling/25585) about this issue, and another user replied that they too have similar issues.


### Standalone code to reproduce the issue

This is a link to a Colab notebook that reproduces the error:
https://colab.research.google.com/drive/1ivDScvFR9oJOKVg31oIc0BbGux7WGEEM?usp=sharing

This is a link to the csv file that I used (place it in the content folder):
https://drive.google.com/file/d/1gpG0SN6ayCnemssI9XdnLB5VOxfV-xzc/view?usp=sharing


### Relevant log output

```shell
/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py in build(self, input_shape)
    164         if isinstance(self._layers[0], InputLayer):
    165             if self._layers[0].batch_shape != input_shape:
--> 166                 raise ValueError(
    167                     f""Sequential model '{self.name}' has already been ""
    168                     ""configured to use input shape ""

ValueError: Sequential model 'sequential' has already been configured to use input shape (None, 10, 4). You cannot build it with input_shape [None, 10, 4]
```
"
2388515632,70796,cannot import name 'mean_absolute_error' from 'tensorflow.keras.losses',closed,2024-07-03 12:34:06+00:00,2024-07-21T01:56:00Z,2024-07-21T01:55:57Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/70796,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'TF 2.16']","[""@dwang6524,\r\nAFAIK the issue is tensorflow v2.16 contains keras3.0 which might be the reason for the issue/error. As a workaround could you please try to below code before executing the import statement.\r\n\r\n```python\r\n!pip install tf-keras\r\nimport os\r\nos.environ['TF_USE_LEGACY_KERAS'] = '1'\r\n```\r\n\r\nKindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/efa6769300cb9365313856205da78e7f/untitled1990.ipynb)\r\n\r\nThank you!"", 'This issue can be solved by changing two files (both files need to be changed): site-packages/neurite/tf/metrics.py (lines 33 and 34) and site-packages/neurite/tf/losses.py (lines 32 and 33). Tensorflow version==2.16.1, voxelmorph version==0.2\r\n\r\nChange from these: \r\n\r\n```python\r\nfrom tensorflow.keras.losses import mean_absolute_error as l1\r\nfrom tensorflow.keras.losses import mean_squared_error as l2\r\n```\r\nTo these: \r\n```python\r\nfrom tensorflow.keras.losses import MAE as l1\r\nfrom tensorflow.keras.losses import MSE as l2\r\n```\r\n', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70796"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70796"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

v2.16.1-19-g810f233968c 2.16.2

### Custom code

No

### OS platform and distribution

macOS Sonoma 14.5

### Mobile device

_No response_

### Python version

Python 3.10.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When i import neurite or voxelmorph it spits out

ImportError: cannot import name 'mean_absolute_error' from 'tensorflow.keras.losses' (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/_tf_keras/keras/losses/__init__.py)


I see someone had a similar issue here but the answers did not help me: https://github.com/tensorflow/tensorflow/issues/69851




### Standalone code to reproduce the issue

```shell
import voxelmorph as vxm
```


### Relevant log output

```shell
----> 6 import voxelmorph as vxm
      7 import neurite as ne

File /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/voxelmorph/__init__.py:12
      9 from packaging import version
     11 # ensure valid neurite version is available
---> 12 import neurite
     13 minv = '0.2'
     14 curv = getattr(neurite, '__version__', None)

File /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/neurite/__init__.py:50
     47 except ImportError:
     48     raise ImportError('Please install tensorflow to use this neurite backend')
---> 50 from . import tf
     51 from .tf import *

File /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/neurite/tf/__init__.py:5
      3 from . import generators
      4 from . import callbacks
----> 5 from . import metrics
      6 from . import losses
      7 from . import models

File /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/neurite/tf/metrics.py:33
     31 from tensorflow.keras import losses
     32 # simple metrics renamed mae -> l1, mse -> l2
---> 33 from tensorflow.keras.losses import mean_absolute_error as l1
     34 from tensorflow.keras.losses import mean_squared_error as l2
     36 # local

ImportError: cannot import name 'mean_absolute_error' from 'tensorflow.keras.losses' (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/_tf_keras/keras/losses/__init__.py)
```
"
2388643236,70802,TFLite in C++ causes Segmentation Fault for MobileNet,closed,2024-07-03 13:30:53+00:00,2024-09-19T02:00:28Z,2024-09-19T02:00:26Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/70802,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'TF 2.16']","['Hi @damjandakic93 ,\r\n\r\nCan you please provide me the tflite file if possible ?', 'Sure, though you have the code to generate it above.\r\nHere it is attached.\r\n[converted_model.tflite.zip](https://github.com/user-attachments/files/16264096/converted_model.tflite.zip)\r\nThanks!', 'Hi @pkgoogle ,\r\n\r\nI tried several times but i keep getting the below error where it says it cannot find the interpreter.h even though its present at that location, , can you please take a look?\r\n\r\n```\r\nCMake Generate step failed.  Build files cannot be regenerated correctly.\r\nroot@tflite-issue-replication:/home/sawantkumar/work/tflite_program/build# cd ..\r\nroot@tflite-issue-replication:/home/sawantkumar/work/tflite_program# nano CMakeLists.txt \r\nroot@tflite-issue-replication:/home/sawantkumar/work/tflite_program# cd build/\r\nroot@tflite-issue-replication:/home/sawantkumar/work/tflite_program/build# cmake ..\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/sawantkumar/work/tflite_program/build\r\nroot@tflite-issue-replication:/home/sawantkumar/work/tflite_program/build# make\r\nScanning dependencies of target tflite_program\r\n[ 50%] Building CXX object CMakeFiles/tflite_program.dir/model_runner.cpp.o\r\n/home/sawantkumar/work/tflite_program/model_runner.cpp:3:10: fatal error: tensorflow/lite/core/interpreter.h: No such file or directory\r\n    3 | #include ""tensorflow/lite/core/interpreter.h""\r\n      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ncompilation terminated.\r\nmake[2]: *** [CMakeFiles/tflite_program.dir/build.make:63: CMakeFiles/tflite_program.dir/model_runner.cpp.o] Error 1\r\nmake[1]: *** [CMakeFiles/Makefile2:76: CMakeFiles/tflite_program.dir/all] Error 2\r\nmake: *** [Makefile:84: all] Error 2\r\n```', 'Hi @damjandakic93, are you willing to switch to a different workflow? Using [AI-Edge-Torch](https://github.com/google-ai-edge/ai-edge-torch) and our [minimal C++ example](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/minimal), I was able to successfully run this model:\r\n\r\nconversion:\r\n```py\r\nimport ai_edge_torch\r\nimport torch\r\nimport torchvision\r\n\r\n\r\norig_model = torchvision.models.mobilenet_v3_small()\r\nsample_input = (torch.randn(1, 3, 224, 224),)\r\n\r\nedge_model = ai_edge_torch.convert(orig_model.eval(), sample_input)\r\nedge_model.export(""mobilenet_v3_small.tflite"")\r\n```\r\n\r\nexecution:\r\n```sh\r\ngit clone https://github.com/tensorflow/tensorflow.git tensorflow_src\r\nmkdir minimal_build\r\ncd minimal_build\r\ncmake ../tensorflow_src/tensorflow/lite/examples/minimal\r\ncmake --build . -j\r\n./minimal <path/to/mobilenet_v3_small.tflite> #wherever you saved it\r\n```\r\n\r\nexample output:\r\n```\r\n./minimal xxxxxxxx/issues/tflite/70802/mobilenet_v3_small.tflite\r\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\r\n=== Pre-invoke Interpreter State ===\r\nInterpreter has 1 subgraphs.\r\n\r\n-----------Subgraph-0 has 316 tensors and 132 nodes------------\r\n1 Inputs: [0] -> 602112B (0.57MB)\r\n1 Outputs: [222] -> 4000B (0.00MB)\r\n\r\nTensor  ID Name                      Type            AllocType          Size (Bytes/MB)    Shape      MemAddr-Offset  \r\nTensor   0 serving_default_args_0:0  kTfLiteFloat32  kTfLiteArenaRw     602112   / 0.57 [1,3,224,224] [0, 602112)\r\nTensor   1 arith.constant            kTfLiteFloat32  kTfLiteMmapRo      2359296  / 2.25 [1024,576] [7758680, 10117976)\r\nTensor   2 arith.constant1           kTfLiteFloat32  kTfLiteMmapRo      221184   / 0.21 [576,1,1,96] [7537476, 7758660)\r\nTensor   3 arith.constant2           kTfLiteFloat32  kTfLiteMmapRo      221184   / 0.21 [96,1,1,576] [7316280, 7537464)\r\nTensor   4 arith.constant3           kTfLiteFloat32  kTfLiteMmapRo      57600    / 0.05 [1,5,5,576] [7258668, 7316268)\r\nTensor   5 arith.constant4           kTfLiteFloat32  kTfLiteMmapRo      221184   / 0.21 [576,1,1,96] [7037472, 7258656)\r\nTensor   6 arith.constant5           kTfLiteFloat32  kTfLiteMmapRo      221184   / 0.21 [96,1,1,576] [6816276, 7037460)\r\nTensor   7 arith.constant6           kTfLiteFloat32  kTfLiteMmapRo      57600    / 0.05 [1,5,5,576] [6758664, 6816264)\r\nTensor   8 arith.constant7           kTfLiteFloat32  kTfLiteMmapRo      2304     / 0.00 [576] [6756348, 6758652)\r\nTensor   9 arith.constant8           kTfLiteFloat32  kTfLiteMmapRo      221184   / 0.21 [576,1,1,96] [6535152, 6756336)\r\nTensor  10 arith.constant9           kTfLiteFloat32  kTfLiteMmapRo      110592   / 0.11 [96,1,1,288] [6424548, 6535140)\r\nTensor  11 arith.constant10          kTfLiteFloat32  kTfLiteMmapRo      28800    / 0.03 [1,5,5,288] [6395736, 6424536)\r\n...\r\n...\r\n...\r\nNode 127 Operator Builtin Code  74 SUM (delegated by node 131)\r\n  2 Input Tensors:[218,59] -> 0B (0.00MB)\r\n  1 Output Tensors:[219] -> 0B (0.00MB)\r\n  4 Temporary Tensors:[259-262] -> 0B (0.00MB)\r\nNode 128 Operator Builtin Code   9 FULLY_CONNECTED (delegated by node 131)\r\n  3 Input Tensors:[219,1,-1] -> 0B (0.00MB)\r\n  1 Output Tensors:[220] -> 0B (0.00MB)\r\nNode 129 Operator Builtin Code 117 HARD_SWISH (delegated by node 131)\r\n  1 Input Tensors:[220] -> 0B (0.00MB)\r\n  1 Output Tensors:[221] -> 0B (0.00MB)\r\nNode 130 Operator Builtin Code   9 FULLY_CONNECTED (delegated by node 131)\r\n  3 Input Tensors:[221,58,-1] -> 0B (0.00MB)\r\n  1 Output Tensors:[222] -> 0B (0.00MB)\r\nNode 131 Operator Custom Name TfLiteXNNPackDelegate \r\n  92 Input Tensors:[0-91] -> 10719000B (10.22MB)\r\n  1 Output Tensors:[222] -> 4000B (0.00MB)\r\n\r\nExecution plan as the list of 1 nodes invoked in-order: [131]\r\nAmong these nodes in the execution plan:\r\n  Node 131 is a TfLiteXNNPackDelegate node (0x555e556d2f20), which has delegated 131 nodes: [0-130]\r\n--------------Subgraph-0 dump has completed--------------\r\n\r\n--------------Memory Arena Status Start--------------\r\nTotal memory usage: 606112 bytes (0.578 MB)\r\n- Total arena memory usage: 606112 bytes (0.578 MB)\r\n- Total dynamic memory usage: 0 bytes (0.000 MB)\r\n\r\nSubgraph#0   Arena (Normal)         606112 (100.00%)\r\n--------------Memory Arena Status End--------------\r\n\r\n```', ""@pkgoogle Wow, this seems interesting, thanks! I actually had a significant amount of work to switch from PyTorch I was working with to TensorFlow as I was unaware of this tool. The reason I had to switch was because ultimately I wish to run the model on a Coral device. Does this workflow support running models on Coral?\r\n\r\nAlso, my model is not a simple mobilenet like in this example but a custom model which relies on the mobilenet as a backbone (so mobilenet + some fully connected layers in several branches with regression outputs at the end), does this sound like something I'd be able to get running on Coral with AI-Edge-Torch?"", ""Hi @damjandakic93, ideally it should work with any model you can define in PyTorch, in practice this is probably not 100% true -- if it isn't, that team would love to hear from you :) so we can make the product even better. The produced tflite model is not particularly special/not-special so the produced model should run on Coral.\r\n\r\nExample custom model conversion: https://github.com/tensorflow/tensorflow/issues/65769#issuecomment-2159237894"", ""Managed to convert the model (it seems v2.functional.rotate isn't supported but I've removed it for the sake of getting anything to work).\r\nHowever, once I try to run it in tflite (C++, natively without TPU) it causes SegmentationFault on Invoke (same inference code as above, I've just commented-out the filling of the input buffer).\r\nNow I cannot share with you this specific model (due to NDA). I can tell you that it contains MobileNet, slicing, concatenation, torch.nn.Linear and torch.nn.functional.silu which are all fairly simple operators.\r\n\r\nAny hints on how to debug this futher? Thanks!"", 'Btw, custom matmul (""my_mat_mul.tflite"") from the example conversion you linked above works properly so the issue is model-specific.', 'Actually, let me rephrase my question.\r\nSince I cannot give you the whole model, how do you suggest I proceed with the debug?\r\nI an start from simple mobilenet and butcher my model until it starts working to see which op causes the segfault, or is there a better way? Thanks!', ""Hi @damjandakic93 What you are suggesting will work to isolate where the situation is happening though there is a risk that the system together is what causing the issue, but you will answer that as you try to isolate the issue. From there you will have a minimally reproducible model which will help you in the next step.\r\n\r\nI'm guessing you have a program that is running the model in C++. You have to compile TF from source with debug symbols, so follow https://www.tensorflow.org/install/source and add this option when using Bazel: `--config=dbg`, install the version of TF you want to debug (I recommend starting with nightly as that represents the latest code, in case your issue is actually resolved already)\r\n\r\nChoose your favorite debugger (usually this means gdb or lldb), use it with your program i.e. if you would execute your program like: `./your_program`, do `gdb ./your_program`\r\n\r\nIf you are unfamiliar with a debugger, well then it's time to start but I would look up a cheat sheet online and just start stepping through the code."", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""I'll need some time (other priorities) before I dive into this debug (as it will take some time most likely).\r\nI'll leave the issue as stale (and then closed) and will reopen it once I have an update."", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70802"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70802"">No</a>\n', 'Hi @pkgoogle,\r\n\r\nSo, I came back back to this issue. I\'ve relaxed my requirements to supporting Python as well (so no need for C++ anymore, it\'s too much of a hassle, I\'ll do it inter-process).\r\nI start with a simple vanilla Mobilenet model:\r\n\r\n`model = torchvision.models.get_model(""mobilenet_v3_small"", weights=""DEFAULT"")`\r\n\r\nI convert it via aiedge:\r\n\r\n```\r\nmodel = ai_edge_torch.to_channel_last_io(model, args=[0])\r\n_args = (\r\n    torch.randn((1, 224, 224, 3), dtype=torch.float32),\r\n)\r\n\r\nedge_model = ai_edge_torch.convert(model, _args)\r\nedge_model.export(""edge_model.tflite"")\r\n```\r\n\r\nWhen I try to run it through edgetpu_compiler via CLI I get the following:\r\n\r\n> edgetpu_compiler edge_model.tflite \r\n> /bin/bash: /home/ddakic/anaconda3/envs/aiedge/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n> Edge TPU Compiler version 16.0.384591198\r\n> ERROR: Op builtin_code out of range: 204. Are you using old TFLite binary with newer model?\r\n> ERROR: Registration failed.\r\n> \r\n> Invalid model: edge_model.tflite\r\n> Model could not be parsed\r\n\r\nIs there a way to control the opset version during the conversion (I guess that would be a reasonable path to start debugging)?\r\n\r\nMy TF version is 2.17.0 (also tried with tf-nightly, with it I get ""Didn\'t find op for builtin opcode \'MUL\' version \'7\'."").\r\nPyTorch version is 2.4.0.\r\nPython version 3.11 (also tried with 3.9).\r\n\r\nThanks!', 'Hi @damjandakic93, this looks like an edgetpu_compiler issue... is there a more relevant repo for that particular piece? Perhaps this? https://github.com/google-coral/libedgetpu/issues', ""I'll try to debug it with them as well.\r\nThought this might also be the place to mention this as the same model implemented in TensorFlow and converted directly through TFLite converter works properly with the edgetpu_compiler. Let me try to work it out with them first then, in case you get some ideas on your side let me know please. Thanks!"", ""Hi @damjandakic93, then .. it may be an ai-edge-torch issue: https://github.com/google-ai-edge/ai-edge-torch/issues, I do think they can perhaps identify root cause better, if there's an issue w/ the converted .tflite file then route it to AI-Edge-Torch (i.e. it converted something improperly). But digging into why edgetpu_compiler is failing with it will be better handled by that repo for now."", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70802"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70802"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.13.1
2.15.1 behaves similarly
2.16.1 cannot even produce the tflite model (something similar to this issue: https://github.com/tensorflow/tensorflow/issues/65012)
tf-nightly cannot build libtensorflowlite.so (gcc: error: unrecognized command-line option '-mavx512fp16'; did you mean '-mavx512bf16'?)

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.4 LTS

### Mobile device

_No response_

### Python version

3.10.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I make a simple MobileNet model in TF, convert it to TFLite and attempt to run it in C++. It causes Segmentation Fault. Running TFLite Interpreter in Python works properly. I have created a minimal repro case:

```
import tensorflow as tf

def main():
    model = tf.keras.Sequential([
        tf.keras.Input(batch_shape=[1, 224, 224, 3]),
        tf.keras.applications.MobileNetV3Small(
            input_shape=[224, 224, 3],
            alpha=1.0,
            minimalistic=False,
            include_top=False,
            weights=""imagenet"",
            pooling=""max"",
            dropout_rate=0.2,
            classifier_activation=None,
            include_preprocessing=True,
        )
    ])

    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    tflite_model = converter.convert()
    with open(""converted_model.tflite"", ""wb"") as f:
        f.write(tflite_model)


if __name__ == ""__main__"":
    main()
```

### Standalone code to reproduce the issue

```shell
#include <memory>
#include <iostream>
#include ""tensorflow/lite/core/interpreter.h""
#include ""tensorflow/lite/core/model_builder.h""
#include ""tensorflow/lite/kernels/register.h""
#include ""tensorflow/lite/core/c/common.h""
#include ""tensorflow/lite/optional_debug_tools.h""
#include ""flatbuffers/flatbuffers.h""

std::unique_ptr<tflite::Interpreter> Initialize()
{
    const std::string model_path = ""converted_model.tflite"";
    std::unique_ptr<tflite::FlatBufferModel> model =
        tflite::FlatBufferModel::BuildFromFile(model_path.c_str());

    tflite::ops::builtin::BuiltinOpResolver resolver;
    std::unique_ptr<tflite::Interpreter> model_interpreter;
    tflite::InterpreterBuilder(*model, resolver)(&model_interpreter);
    if (model_interpreter->AllocateTensors() != kTfLiteOk)
    {
        std::cerr << ""Failed to allocate tensors."" << std::endl;
    }

    return model_interpreter;
}

int main()
{
    std::unique_ptr<tflite::Interpreter> interpreter = Initialize();

    std::cout << ""Acquiring input buffer"" << std::endl;

    float *input_buff = interpreter->typed_input_tensor<float>(0);

    for (int i = 0; i < 224*224*3; i++)
    {
        input_buff[i] = 0.2;
    }

    std::cout << ""Filled input buffer"" << std::endl;

    interpreter->Invoke();

    std::cout << ""Done with Invoke"" << std::endl;

    float *output = interpreter->typed_output_tensor<float>(0);
    std::cout << ""Output: "" << output[0] << std::endl;

    return 0;
}
```


### Relevant log output

```shell
INFO: Initialized TensorFlow Lite runtime.
INFO: Applying 1 TensorFlow Lite delegate(s) lazily.
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
VERBOSE: Replacing 109 out of 110 node(s) with delegate (TfLiteXNNPackDelegate) node, yielding 2 partitions for the whole graph.
Note (XNNPACK): fuse Constant Pad Node #5 into Depthwise Convolution 2D Node #4
Note (XNNPACK): fuse Constant Pad Node #14 into Depthwise Convolution 2D Node #13
Note (XNNPACK): fuse Constant Pad Node #23 into Depthwise Convolution 2D Node #22
Note (XNNPACK): fuse Constant Pad Node #77 into Depthwise Convolution 2D Node #76
INFO: Successfully applied the default TensorFlow Lite delegate indexed at 0.
 *NOTE*: because a delegate has been applied, the precision of computations should be unchanged, but the exact output tensor values may have changed. If such output values are checked in your code, like in your tests etc., please consider increasing error tolerance for the check.
Acquiring input buffer
Filled input buffer
Segmentation fault (core dumped)
```
"
2388820824,70803,TFLite initializes Coral device but still runs inference on CPU,closed,2024-07-03 14:43:23+00:00,2024-07-04T12:42:38Z,2024-07-04T12:42:35Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/70803,"['stat:awaiting response', 'type:bug', 'comp:lite', 'TF 2.13']","['@damjandakic93,\r\nCould you please check and confirm if you are facing the same issue with the latest tensorflow versions 2.15 and 2.16?\r\nThank you!', ""I actually made a mistake, I ran the edgetpu-compiler but copied the wrong file (so no ops were intended for TPU).\r\nI have another issue where I get segfault upon calling Invoke, I guess I'll open a new Issue for that?"", '@damjandakic93,\r\nIn that scenario, could you please feel free to move this issue to closed status? Thank you!', 'Agreed, thanks.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70803"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70803"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.13.1

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I have a model which I wish to run on RPi-4 with Coral USB device connected to it. I've set the context manager verbosity to max. I can see that the library is communicating with the device, however, in the end, it still runs inference on CPU. I have verified this by measuring time and checking the CPU utilization.

Notice: ""INFO: Created TensorFlow Lite XNNPACK delegate for CPU."" in the middle of the logs.

### Standalone code to reproduce the issue

```shell
#include <memory>
#include <iostream>
#include ""tensorflow/lite/core/interpreter.h""
#include ""tensorflow/lite/core/model_builder.h""
#include ""tensorflow/lite/kernels/register.h""
#include ""tflite/public/edgetpu.h""
#include ""flatbuffers/flatbuffers.h""
#include <chrono>

using namespace std::chrono;

std::unique_ptr<tflite::Interpreter> BuildEdgeTpuInterpreter(
    const tflite::FlatBufferModel &model,
    edgetpu::EdgeTpuContext *edgetpu_context)
{
    tflite::ops::builtin::BuiltinOpResolver resolver;
    resolver.AddCustom(edgetpu::kCustomOp, edgetpu::RegisterCustomOp());
    std::unique_ptr<tflite::Interpreter> interpreter;
    if (tflite::InterpreterBuilder(model, resolver)(&interpreter) != kTfLiteOk)
    {
        std::cerr << ""Failed to build interpreter."" << std::endl;
    }
    // Bind given context with interpreter.
    interpreter->SetExternalContext(kTfLiteEdgeTpuContext, edgetpu_context);
    interpreter->SetNumThreads(-1);
    if (interpreter->AllocateTensors() != kTfLiteOk)
    {
        std::cerr << ""Failed to allocate tensors."" << std::endl;
    }
    return interpreter;
}

std::unique_ptr<tflite::Interpreter> Initialize()
{
    const std::string model_path = ""converted_model.tflite"";
    std::unique_ptr<tflite::FlatBufferModel> model =
        tflite::FlatBufferModel::BuildFromFile(model_path.c_str());

    edgetpu::EdgeTpuManager::GetSingleton()->SetVerbosity(10);

    std::shared_ptr<edgetpu::EdgeTpuContext> edgetpu_context =
        edgetpu::EdgeTpuManager::GetSingleton()->OpenDevice();

    std::unique_ptr<tflite::Interpreter> model_interpreter =
        BuildEdgeTpuInterpreter(*model, edgetpu_context.get());

    return model_interpreter;
}

int main()
{
    std::cout << ""Hello world!"" << std::endl;
    std::unique_ptr<tflite::Interpreter> interpreter = Initialize();
    // Fill `input`

    auto start = high_resolution_clock::now();

    interpreter->Invoke();

    auto stop = high_resolution_clock::now();
    auto duration = duration_cast<microseconds>(stop - start);
    std::cout << duration.count() << std::endl;
    float *output = interpreter->typed_output_tensor<float>(0);
    std::cout << output[0] << std::endl;

    return 0;
}
```


### Relevant log output

```shell
Hello world!
I tflite/edgetpu_manager_direct.cc:453] No matching device is already opened for shared ownership.
I driver/driver_factory_default.cc:31] Failed to open /sys/class/apex: No such file or directory
I driver/usb/local_usb_device.cc:944] EnumerateDevices: vendor:0x1a6e, product:0x89a
I driver/usb/local_usb_device.cc:979] EnumerateDevices: checking bus[2] port[0]
I driver/usb/local_usb_device.cc:979] EnumerateDevices: checking bus[1] port[2]
I driver/usb/local_usb_device.cc:979] EnumerateDevices: checking bus[1] port[1]
I driver/usb/local_usb_device.cc:979] EnumerateDevices: checking bus[1] port[4]
I driver/usb/local_usb_device.cc:979] EnumerateDevices: checking bus[1] port[3]
I driver/usb/local_usb_device.cc:979] EnumerateDevices: checking bus[1] port[3]
I driver/usb/local_usb_device.cc:979] EnumerateDevices: checking bus[1] port[2]
I driver/usb/local_usb_device.cc:979] EnumerateDevices: checking bus[1] port[1]
I driver/usb/local_usb_device.cc:979] EnumerateDevices: checking bus[1] port[0]
I driver/usb/local_usb_device.cc:944] EnumerateDevices: vendor:0x18d1, product:0x9302
I driver/usb/local_usb_device.cc:979] EnumerateDevices: checking bus[2] port[0]
I driver/usb/local_usb_device.cc:979] EnumerateDevices: checking bus[1] port[2]
I driver/usb/local_usb_device.cc:979] EnumerateDevices: checking bus[1] port[1]
I driver/usb/local_usb_device.cc:979] EnumerateDevices: checking bus[1] port[4]
I driver/usb/local_usb_device.cc:979] EnumerateDevices: checking bus[1] port[3]
I driver/usb/local_usb_device.cc:998] EnumerateDevices: found [/sys/bus/usb/devices/1-1.3.3]
I driver/usb/local_usb_device.cc:979] EnumerateDevices: checking bus[1] port[3]
I driver/usb/local_usb_device.cc:979] EnumerateDevices: checking bus[1] port[2]
I driver/usb/local_usb_device.cc:979] EnumerateDevices: checking bus[1] port[1]
I driver/usb/local_usb_device.cc:979] EnumerateDevices: checking bus[1] port[0]
I driver/beagle/beagle_usb_driver_provider.cc:225] Enumerate: adding path [/sys/bus/usb/devices/1-1.3.3]
I tflite/edgetpu_manager_direct.cc:471] No device of type Apex (PCIe) is available.
I tflite/edgetpu_context_direct.cc:106] USB always DFU: False (default)
I tflite/edgetpu_context_direct.cc:147] USB bulk-in queue capacity: 8
I tflite/edgetpu_context_direct.cc:63] Performance expectation: High when USB connected EdgeTpu is throttled
I driver/usb/usb_driver.cc:1383] Open device and check if DFU is needed
I driver/usb/local_usb_device.cc:1013] OpenDevice: [/sys/bus/usb/devices/1-1.3.3]
I driver/usb/local_usb_device.cc:1050] OpenDevice: checking bus[2] port[0]
I driver/usb/local_usb_device.cc:1050] OpenDevice: checking bus[1] port[2]
I driver/usb/local_usb_device.cc:1050] OpenDevice: checking bus[1] port[1]
I driver/usb/local_usb_device.cc:1050] OpenDevice: checking bus[1] port[4]
I driver/usb/local_usb_device.cc:1050] OpenDevice: checking bus[1] port[3]
I driver/usb/local_usb_device.cc:1081] OpenDevice: device opened 0x55b429dd60
I driver/usb/local_usb_device.cc:184] LocalUsbDevice
I driver/usb/usb_standard_commands.cc:36] UsbStandardCommands
I driver/usb/usb_dfu_commands.cc:37] UsbDfuCommands
I driver/usb/usb_standard_commands.cc:43] GetDeviceDescriptor
I driver/usb/local_usb_device.cc:398] GetDescriptor
I driver/usb/usb_standard_commands.cc:78] Vender ID: 0x18d1
I driver/usb/usb_standard_commands.cc:79] Product ID: 0x9302
I driver/usb/usb_driver.cc:1410] Device is already in application mode, skipping DFU
I driver/usb/usb_driver.cc:1422] Resetting device
I driver/usb/local_usb_device.cc:243] Close: closing device 0x55b429dd60 
I driver/usb/local_usb_device.cc:216] DoCancelAllTransfers: cancelling 0 async transfers
I driver/usb/local_usb_device.cc:224] DoCancelAllTransfers: waiting for all async transfers to complete
I driver/usb/local_usb_device.cc:234] DoCancelAllTransfers: all async transfers have completed
I driver/usb/local_usb_device.cc:276] Close: releasing 0 transfer buffers
I driver/usb/local_usb_device.cc:289] Close: performing graceful reset
I driver/usb/local_usb_device.cc:322] Close: final clean up completed
I driver/usb/usb_driver.cc:1364] Opening device expecting application mode
I driver/usb/local_usb_device.cc:1013] OpenDevice: [/sys/bus/usb/devices/1-1.3.3]
I driver/usb/local_usb_device.cc:1050] OpenDevice: checking bus[2] port[0]
I driver/usb/local_usb_device.cc:1050] OpenDevice: checking bus[1] port[2]
I driver/usb/local_usb_device.cc:1050] OpenDevice: checking bus[1] port[1]
I driver/usb/local_usb_device.cc:1050] OpenDevice: checking bus[1] port[4]
I driver/usb/local_usb_device.cc:1050] OpenDevice: checking bus[1] port[3]
I driver/usb/local_usb_device.cc:1081] OpenDevice: device opened 0x55b42ba410
I driver/usb/local_usb_device.cc:184] LocalUsbDevice
I driver/usb/usb_standard_commands.cc:36] UsbStandardCommands
I driver/usb/usb_ml_commands.cc:47] UsbMlCommands
I driver/usb/usb_dfu_commands.cc:40] ~UsbDfuCommands
I driver/usb/usb_standard_commands.cc:39] ~UsbStandardCommands
I driver/usb/local_usb_device.cc:196] ~LocalUsbDevice
I driver/usb/local_usb_device.cc:243] Close: closing device (nil) 
I driver/usb/local_usb_device.cc:352] ClaimInterface
I driver/usb/usb_ml_commands.cc:80] ReadRegister32 offset 0x1a30c
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:110] ReadRegister32 [0x1A30C] == 0xF0059
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A30C] := 0xF0059
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:80] ReadRegister32 offset 0x1a314
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:110] ReadRegister32 [0x1A314] == 0x110000
I driver/usb/usb_ml_commands.cc:80] ReadRegister32 offset 0x1a318
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:110] ReadRegister32 [0x1A318] == 0x50C50258
I driver/usb/usb_ml_commands.cc:80] ReadRegister32 offset 0x1a318
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:110] ReadRegister32 [0x1A318] == 0x50C50258
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A318] := 0x50850258
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:80] ReadRegister32 offset 0x1a318
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:110] ReadRegister32 [0x1A318] == 0x50850000
I driver/usb/usb_ml_commands.cc:117] ReadRegister64 offset 0x44018
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:147] ReadRegister64 [0x44018] == 0x0
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x4A000] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x48788] := 0x7F
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:117] ReadRegister64 offset 0x48788
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:147] ReadRegister64 [0x48788] == 0x7F
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x40020] := 0x1E02
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:80] ReadRegister32 offset 0x1a314
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:110] ReadRegister32 [0x1A314] == 0x110000
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A314] := 0x150000
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:80] ReadRegister32 offset 0x1a000
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:110] ReadRegister32 [0x1A000] == 0x219089A
I driver/usb/usb_driver.cc:321] e-fuse programming revision: 2
I driver/usb/usb_driver.cc:328] InitializeChip Enabling only sc host interrupt descriptors
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x4C148] := 0xF0
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_driver.cc:341] InitializeChip Enabling single EP mode
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x4C160] := 0x0
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_driver.cc:355] InitializeChip Setting 256B chunk for USB 2 High Speed
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x4C058] := 0x20
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x44018] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x44158] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x44198] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x441D8] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x44218] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x48788] := 0x7F
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:117] ReadRegister64 offset 0x48788
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:147] ReadRegister64 [0x48788] == 0x7F
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x400C0] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x40150] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x40110] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x40250] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x40298] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x402E0] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x40328] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x40190] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x401D0] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x40210] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x4C060] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x4C070] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x4C080] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x4C090] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x4C0A0] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:80] ReadRegister32 offset 0x1a0d4
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:110] ReadRegister32 [0x1A0D4] == 0x1
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A0D4] := 0x80000001
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:80] ReadRegister32 offset 0x1a704
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:110] ReadRegister32 [0x1A704] == 0x70007F
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A704] := 0x7F
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:80] ReadRegister32 offset 0x1a33c
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:110] ReadRegister32 [0x1A33C] == 0xC003F
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A33C] := 0x3F
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A500] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A600] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A558] := 0x3
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A658] := 0x3
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:80] ReadRegister32 offset 0x1a0d8
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:110] ReadRegister32 [0x1A0D8] == 0x0
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A0D8] := 0x80000000
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_driver.cc:1575] Reducing bulk-in request size to 256 bytes for USB2
I tflite/edgetpu_context_direct.cc:174] Opening device at /sys/bus/usb/devices/1-1.3.3
I driver/usb/usb_driver.cc:1155] WorkerThreadFunc starting worker thread
I driver/usb/usb_driver.cc:1174] WorkerThreadFunc dispatching 0 callback events in worker thread
I driver/usb/usb_driver.cc:1210] WorkerThreadFunc Re-installing event reader
I driver/usb/local_usb_device.cc:748] AsyncBulkInTransfer
I driver/usb/local_usb_device.cc:761] ASYNC IN 2 begin
I driver/usb/usb_driver.cc:1232] WorkerThreadFunc Re-installing interrupt reader
I driver/usb/local_usb_device.cc:785] AsyncInterruptInTransfer
I driver/usb/local_usb_device.cc:798] ASYNC IN 3 begin
I driver/usb/usb_driver.cc:1260] WorkerThreadFunc Installing bulk-in reader. buffer index [0]
I driver/usb/local_usb_device.cc:748] AsyncBulkInTransfer
I driver/usb/local_usb_device.cc:761] ASYNC IN 1 begin
I driver/usb/usb_driver.cc:1260] WorkerThreadFunc Installing bulk-in reader. buffer index [1]
I driver/usb/local_usb_device.cc:748] AsyncBulkInTransfer
I driver/usb/local_usb_device.cc:761] ASYNC IN 1 begin
I driver/usb/usb_driver.cc:1260] WorkerThreadFunc Installing bulk-in reader. buffer index [2]
I driver/usb/local_usb_device.cc:748] AsyncBulkInTransfer
I driver/usb/local_usb_device.cc:761] ASYNC IN 1 begin
I driver/usb/usb_driver.cc:1260] WorkerThreadFunc Installing bulk-in reader. buffer index [3]
I driver/usb/local_usb_device.cc:748] AsyncBulkInTransfer
I driver/usb/local_usb_device.cc:761] ASYNC IN 1 begin
I driver/usb/usb_driver.cc:1260] WorkerThreadFunc Installing bulk-in reader. buffer index [4]
I driver/usb/local_usb_device.cc:748] AsyncBulkInTransfer
I driver/usb/local_usb_device.cc:761] ASYNC IN 1 begin
I driver/usb/usb_driver.cc:1260] WorkerThreadFunc Installing bulk-in reader. buffer index [5]
I driver/usb/local_usb_device.cc:748] AsyncBulkInTransfer
I driver/usb/local_usb_device.cc:761] ASYNC IN 1 begin
I driver/usb/usb_driver.cc:1260] WorkerThreadFunc Installing bulk-in reader. buffer index [6]
I driver/usb/local_usb_device.cc:748] AsyncBulkInTransfer
I driver/usb/local_usb_device.cc:761] ASYNC IN 1 begin
I driver/usb/usb_driver.cc:1260] WorkerThreadFunc Installing bulk-in reader. buffer index [7]
I driver/usb/local_usb_device.cc:748] AsyncBulkInTransfer
I driver/usb/local_usb_device.cc:761] ASYNC IN 1 begin
I driver/usb/usb_driver.cc:1317] WorkerThreadFunc waiting on state change
I driver/usb/usb_driver.cc:91] Unlocks both mutex
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
I tflite/edgetpu_manager_direct.cc:226] Releasing Edge TPU device at /sys/bus/usb/devices/1-1.3.3
I tflite/edgetpu_context_direct.cc:180] Closing Edge TPU device at /sys/bus/usb/devices/1-1.3.3
I driver/usb/local_usb_device.cc:216] DoCancelAllTransfers: cancelling 10 async transfers
I driver/usb/usb_driver.cc:86] lock (does nothing)
I driver/usb/usb_driver.cc:1322] WorkerThreadFunc driver state change detected
I driver/usb/local_usb_device.cc:672] ASYNC IN 1 end
I driver/usb/local_usb_device.cc:97] ConvertLibUsbTransferStatus: USB transfer error 3 [LibUsbDataInCallback]
I driver/usb/local_usb_device.cc:642] UnregisterCompletedTransfer
I driver/usb/local_usb_device.cc:224] DoCancelAllTransfers: waiting for all async transfers to complete
I driver/usb/local_usb_device.cc:672] ASYNC IN 1 end
I driver/usb/local_usb_device.cc:97] ConvertLibUsbTransferStatus: USB transfer error 3 [LibUsbDataInCallback]
I driver/usb/local_usb_device.cc:642] UnregisterCompletedTransfer
I driver/usb/local_usb_device.cc:672] ASYNC IN 1 end
I driver/usb/local_usb_device.cc:97] ConvertLibUsbTransferStatus: USB transfer error 3 [LibUsbDataInCallback]
I driver/usb/local_usb_device.cc:642] UnregisterCompletedTransfer
I driver/usb/local_usb_device.cc:672] ASYNC IN 1 end
I driver/usb/local_usb_device.cc:97] ConvertLibUsbTransferStatus: USB transfer error 3 [LibUsbDataInCallback]
I driver/usb/local_usb_device.cc:642] UnregisterCompletedTransfer
I driver/usb/local_usb_device.cc:672] ASYNC IN 1 end
I driver/usb/local_usb_device.cc:97] ConvertLibUsbTransferStatus: USB transfer error 3 [LibUsbDataInCallback]
I driver/usb/local_usb_device.cc:642] UnregisterCompletedTransfer
I driver/usb/local_usb_device.cc:672] ASYNC IN 1 end
I driver/usb/local_usb_device.cc:97] ConvertLibUsbTransferStatus: USB transfer error 3 [LibUsbDataInCallback]
I driver/usb/local_usb_device.cc:642] UnregisterCompletedTransfer
I driver/usb/local_usb_device.cc:672] ASYNC IN 1 end
I driver/usb/local_usb_device.cc:97] ConvertLibUsbTransferStatus: USB transfer error 3 [LibUsbDataInCallback]
I driver/usb/local_usb_device.cc:642] UnregisterCompletedTransfer
I driver/usb/local_usb_device.cc:672] ASYNC IN 3 end
I driver/usb/local_usb_device.cc:97] ConvertLibUsbTransferStatus: USB transfer error 3 [LibUsbDataInCallback]
I driver/usb/local_usb_device.cc:642] UnregisterCompletedTransfer
I driver/usb/local_usb_device.cc:672] ASYNC IN 1 end
I driver/usb/local_usb_device.cc:97] ConvertLibUsbTransferStatus: USB transfer error 3 [LibUsbDataInCallback]
I driver/usb/local_usb_device.cc:642] UnregisterCompletedTransfer
I driver/usb/local_usb_device.cc:672] ASYNC IN 2 end
I driver/usb/local_usb_device.cc:97] ConvertLibUsbTransferStatus: USB transfer error 3 [LibUsbDataInCallback]
I driver/usb/local_usb_device.cc:642] UnregisterCompletedTransfer
I driver/usb/local_usb_device.cc:234] DoCancelAllTransfers: all async transfers have completed
I driver/usb/usb_driver.cc:1174] WorkerThreadFunc dispatching 10 callback events in worker thread
I driver/usb/usb_driver.cc:466] HandleInterrupt cancelled, ignore.
I driver/usb/usb_driver.cc:404] HandleEvent cancelled, ignore.
I driver/usb/usb_driver.cc:1194] All bulk-in buffers are available
I driver/usb/usb_driver.cc:1201] Driver is closing, and all async operations have completed.
I driver/usb/usb_driver.cc:1330] WorkerThreadFunc leaving worker thread
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x4C070] := 0x0
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x4C080] := 0x0
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x4C090] := 0x0
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x4C0A0] := 0x0
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:80] ReadRegister32 offset 0x1a0d4
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:110] ReadRegister32 [0x1A0D4] == 0x80000001
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A0D4] := 0x1
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:80] ReadRegister32 offset 0x1a704
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:110] ReadRegister32 [0x1A704] == 0x7F
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A704] := 0x70007F
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:80] ReadRegister32 offset 0x1a33c
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:110] ReadRegister32 [0x1A33C] == 0x3F
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A33C] := 0xC003F
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A500] := 0x0
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A600] := 0x0
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A558] := 0x0
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A658] := 0x0
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:80] ReadRegister32 offset 0x1a0d8
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:110] ReadRegister32 [0x1A0D8] == 0x80000000
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A0D8] := 0x0
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x4C060] := 0x0
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x44018] := 0x2
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x44158] := 0x2
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x44198] := 0x2
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x441D8] := 0x2
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x44218] := 0x2
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x48788] := 0x7F
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:117] ReadRegister64 offset 0x48788
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:147] ReadRegister64 [0x48788] == 0x7F
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x400C0] := 0x2
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x40150] := 0x2
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x40110] := 0x2
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x40250] := 0x2
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x40298] := 0x2
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x402E0] := 0x2
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x40328] := 0x2
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x40190] := 0x2
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x401D0] := 0x2
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:178] WriteRegister64 [0x40210] := 0x2
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:80] ReadRegister32 offset 0x1a318
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:110] ReadRegister32 [0x1A318] == 0x50850008
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1A318] := 0x50C50008
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:80] ReadRegister32 offset 0x1a318
I driver/usb/local_usb_device.cc:514] SendControlCommandWithDataIn
I driver/usb/local_usb_device.cc:521] SYNC CTRL WITH DATA IN begin
I driver/usb/local_usb_device.cc:538] SYNC CTRL WITH DATA IN end
I driver/usb/usb_ml_commands.cc:110] ReadRegister32 [0x1A318] == 0x50C50258
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1907C] := 0xF
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:153] WriteRegister32 [0x1907C] := 0x0
I driver/usb/local_usb_device.cc:475] SendControlCommandWithDataOut
I driver/usb/local_usb_device.cc:482] SYNC CTRL WITH DATA OUT begin
I driver/usb/local_usb_device.cc:499] SYNC CTRL WITH DATA OUT end
I driver/usb/usb_ml_commands.cc:50] ~UsbMlCommands
I driver/usb/usb_standard_commands.cc:39] ~UsbStandardCommands
I driver/usb/local_usb_device.cc:196] ~LocalUsbDevice
I driver/usb/local_usb_device.cc:243] Close: closing device 0x55b42ba410 
I driver/usb/local_usb_device.cc:263] Close: releasing claimed interface 0
I driver/usb/local_usb_device.cc:216] DoCancelAllTransfers: cancelling 0 async transfers
I driver/usb/local_usb_device.cc:224] DoCancelAllTransfers: waiting for all async transfers to complete
I driver/usb/local_usb_device.cc:234] DoCancelAllTransfers: all async transfers have completed
I driver/usb/local_usb_device.cc:276] Close: releasing 0 transfer buffers
I driver/usb/local_usb_device.cc:322] Close: final clean up completed
37329476
0.001
```
"
2389372791,70825,Importing tensorflow_model_optimization causes error,closed,2024-07-03 20:04:27+00:00,2024-07-24T01:53:18Z,2024-07-24T01:53:14Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/70825,"['stat:awaiting response', 'type:bug', 'stale', 'ModelOptimizationToolkit', 'TF 2.16']","['@Leo-Lifeblood,\r\nI tried with the alternative approach using the latest tensorflow version and it was working as expected without any error. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/e38f358afad1d9ca788988a0e20a38e5/untitled1992.ipynb) for the reference. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70825"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70825"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.16.1

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

A100

### Current behavior?

on running:

import pandas as pd
import numpy as np
import tensorflow as tf
import keras_nlp as knlp
from tensorflow_model_optimization.quantization.keras import quantize_model

I get:

AttributeError: module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'

### Standalone code to reproduce the issue

```shell
!pip install tensorflow
!pip install keras-nlp datasets huggingface_hub transformers tensorflow-model-optimization

import pandas as pd
import numpy as np
import tensorflow as tf
import keras_nlp as knlp
from tensorflow_model_optimization.quantization.keras import quantize_model
```


### Relevant log output

```shell
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-6-1ccfaf353d00> in <cell line: 6>()
      4 import keras_nlp as knlp
      5 from keras.preprocessing.sequence import pad_sequences
----> 6 from tensorflow_model_optimization.quantization.keras import quantize_model

20 frames
/usr/local/lib/python3.10/dist-packages/tensorflow_model_optimization/__init__.py in <module>
     84 from tensorflow_model_optimization.python.core import version
     85 
---> 86 from tensorflow_model_optimization.python.core.api import clustering
     87 from tensorflow_model_optimization.python.core.api import experimental
     88 from tensorflow_model_optimization.python.core.api import quantization

/usr/local/lib/python3.10/dist-packages/tensorflow_model_optimization/python/core/api/__init__.py in <module>
     14 # ==============================================================================
     15 """"""Import API modules for Tensorflow Model Optimization.""""""
---> 16 from tensorflow_model_optimization.python.core.api import clustering
     17 from tensorflow_model_optimization.python.core.api import experimental
     18 from tensorflow_model_optimization.python.core.api import quantization

/usr/local/lib/python3.10/dist-packages/tensorflow_model_optimization/python/core/api/clustering/__init__.py in <module>
     14 # ==============================================================================
     15 """"""Module containing code for clustering.""""""
---> 16 from tensorflow_model_optimization.python.core.api.clustering import keras

/usr/local/lib/python3.10/dist-packages/tensorflow_model_optimization/python/core/api/clustering/keras/__init__.py in <module>
     17 from tensorflow_model_optimization.python.core.clustering.keras import experimental
     18 
---> 19 from tensorflow_model_optimization.python.core.clustering.keras.cluster import cluster_scope
     20 from tensorflow_model_optimization.python.core.clustering.keras.cluster import cluster_weights
     21 from tensorflow_model_optimization.python.core.clustering.keras.cluster import strip_clustering

/usr/local/lib/python3.10/dist-packages/tensorflow_model_optimization/python/core/clustering/keras/cluster.py in <module>
     20 
     21 from tensorflow_model_optimization.python.core.clustering.keras import cluster_config
---> 22 from tensorflow_model_optimization.python.core.clustering.keras import cluster_wrapper
     23 from tensorflow_model_optimization.python.core.clustering.keras import clustering_centroids
     24 from tensorflow_model_optimization.python.core.keras.compat import keras

/usr/local/lib/python3.10/dist-packages/tensorflow_model_optimization/python/core/clustering/keras/cluster_wrapper.py in <module>
     21 from tensorflow_model_optimization.python.core.clustering.keras import cluster_config
     22 from tensorflow_model_optimization.python.core.clustering.keras import clusterable_layer
---> 23 from tensorflow_model_optimization.python.core.clustering.keras import clustering_centroids
     24 from tensorflow_model_optimization.python.core.clustering.keras import clustering_registry
     25 from tensorflow_model_optimization.python.core.keras.compat import keras

/usr/local/lib/python3.10/dist-packages/tensorflow_model_optimization/python/core/clustering/keras/clustering_centroids.py in <module>
     20 from tensorflow.python.ops import clustering_ops
     21 from tensorflow_model_optimization.python.core.clustering.keras import cluster_config
---> 22 from tensorflow_model_optimization.python.core.keras.compat import keras
     23 
     24 

/usr/local/lib/python3.10/dist-packages/tensorflow_model_optimization/python/core/keras/compat.py in <module>
     39 
     40 
---> 41 keras = _get_keras_instance()
     42 
     43 def assign(ref, value, name=None):

/usr/local/lib/python3.10/dist-packages/tensorflow_model_optimization/python/core/keras/compat.py in _get_keras_instance()
     33   version_fn = getattr(tf.keras, 'version', None)
     34   if version_fn and version_fn().startswith('3.'):
---> 35     import tf_keras as keras_internal  # pylint: disable=g-import-not-at-top,unused-import
     36   else:
     37     keras_internal = tf.keras

/usr/local/lib/python3.10/dist-packages/tf_keras/__init__.py in <module>
      1 """"""AUTOGENERATED. DO NOT EDIT.""""""
      2 
----> 3 from tf_keras import __internal__
      4 from tf_keras import activations
      5 from tf_keras import applications

/usr/local/lib/python3.10/dist-packages/tf_keras/__internal__/__init__.py in <module>
      4 from tf_keras.__internal__ import layers
      5 from tf_keras.__internal__ import losses
----> 6 from tf_keras.__internal__ import models
      7 from tf_keras.__internal__ import optimizers
      8 from tf_keras.__internal__ import utils

/usr/local/lib/python3.10/dist-packages/tf_keras/__internal__/models/__init__.py in <module>
      1 """"""AUTOGENERATED. DO NOT EDIT.""""""
      2 
----> 3 from tf_keras.src.models.cloning import clone_and_build_model
      4 from tf_keras.src.models.cloning import in_place_subclassed_model_state_restoration

/usr/local/lib/python3.10/dist-packages/tf_keras/src/__init__.py in <module>
     19 """"""
     20 
---> 21 from tf_keras.src import applications
     22 from tf_keras.src import distribute
     23 from tf_keras.src import models

/usr/local/lib/python3.10/dist-packages/tf_keras/src/applications/__init__.py in <module>
     16 
     17 
---> 18 from tf_keras.src.applications.convnext import ConvNeXtBase
     19 from tf_keras.src.applications.convnext import ConvNeXtLarge
     20 from tf_keras.src.applications.convnext import ConvNeXtSmall

/usr/local/lib/python3.10/dist-packages/tf_keras/src/applications/convnext.py in <module>
     31 from tf_keras.src import utils
     32 from tf_keras.src.applications import imagenet_utils
---> 33 from tf_keras.src.engine import sequential
     34 from tf_keras.src.engine import training as training_lib
     35 

/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/sequential.py in <module>
     22 from tf_keras.src import layers as layer_module
     23 from tf_keras.src.engine import base_layer
---> 24 from tf_keras.src.engine import functional
     25 from tf_keras.src.engine import input_layer
     26 from tf_keras.src.engine import training

/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/functional.py in <module>
     31 from tf_keras.src.engine import input_spec
     32 from tf_keras.src.engine import node as node_module
---> 33 from tf_keras.src.engine import training as training_lib
     34 from tf_keras.src.engine import training_utils
     35 from tf_keras.src.saving import serialization_lib

/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py in <module>
     46 from tf_keras.src.optimizers import optimizer_v1
     47 from tf_keras.src.saving import pickle_utils
---> 48 from tf_keras.src.saving import saving_api
     49 from tf_keras.src.saving import saving_lib
     50 from tf_keras.src.saving import serialization_lib

/usr/local/lib/python3.10/dist-packages/tf_keras/src/saving/saving_api.py in <module>
     23 
     24 from tf_keras.src.saving import saving_lib
---> 25 from tf_keras.src.saving.legacy import save as legacy_sm_saving_lib
     26 from tf_keras.src.utils import io_utils
     27 

/usr/local/lib/python3.10/dist-packages/tf_keras/src/saving/legacy/save.py in <module>
     25 from tf_keras.src.saving.legacy import serialization
     26 from tf_keras.src.saving.legacy.saved_model import load as saved_model_load
---> 27 from tf_keras.src.saving.legacy.saved_model import load_context
     28 from tf_keras.src.saving.legacy.saved_model import save as saved_model_save
     29 from tf_keras.src.saving.legacy.saved_model.utils import keras_option_scope

/usr/local/lib/python3.10/dist-packages/tf_keras/src/saving/legacy/saved_model/load_context.py in <module>
     66 
     67 
---> 68 tf.__internal__.register_load_context_function(in_load_context)
     69 

AttributeError: module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'
```
"
2389428704,70827,TPU unresolvable on google colab,closed,2024-07-03 20:38:11+00:00,2024-12-26T14:02:21Z,2024-08-06T01:53:39Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/70827,"['stat:awaiting response', 'type:bug', 'stale', 'comp:tpus', 'TF 2.16']","['@Leo-Lifeblood Please make sure to run this code in an environment that supports TPU, such as Google Colab with TPU runtime enabled?  I tried to run the code by modifying it, please have a look at this [gist](https://colab.research.google.com/gist/sushreebarsa/6ec53a5b175b0fe441087b43094d304b/70827.ipynb).\r\nThank you!', 'I did run it on a colander runtime with TPU enabled that’s how I got the error in the first place, I’m writing this now on my phone so I can’t check your code but what did you change to make it work? Any obvious thing I did wrong?', '@Leo-Lifeblood Please try restarting the runtime and let us know?\r\nThank you!', ""I have the same issue:\r\n\r\n- on Google Colab TPU (yes it is selected, restarted etc)\r\n- listing devices with both `tf.config.list_logical_devices('TPU')` and `tf.config.list_physical_devices('TPU')`\r\n\r\nThe notebook you linked cannot find any logical nor physical TPU either.\r\n\r\nAlso installing `tensorflow-tpu` fails because of a dependency conflic:\r\n\r\n```\r\nThe conflict is caused by:\r\n    tensorflow-tpu 2.16.2 depends on libtpu==2.16.0rc0\r\n    tensorflow-tpu 2.16.1 depends on libtpu==2.16.0rc0\r\n```\r\n\r\nI have run many successful model training with TF 2.15 on TPUs in Google Colab.\r\nNow that I turn to Keras 3 which requires tensorflow 2.16 it fails."", '@Leo-Lifeblood \r\nLooks like the issue is caused by ""pip install tf-models-official"". TPUs are found without a problem if not installing the package. This doesn\'t seem to be an issue with tf.distribute. Kindly recheck and raise the issue on tensorflow/models repo. Thank you!', '@Leo-Lifeblood please see the previous comment -- it was actually meant for you, not for me. ', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70827"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70827"">No</a>\n', 'In Colab the TPU runtimes are still using Tensorflow 2.15 and Keras 2.15, any attempt to use Keras 3 will fail.\r\nPer this issue listing in colab repo, the last native upgrade for both TF and Keras supports only CPU and GPU runtimes.\r\nhttps://github.com/googlecolab/colabtools/issues/4744']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.16.1

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

when trying to run:
tpu = tf.distribute.cluster_resolver.TPUClusterResolver()

I get:
ValueError: Please provide a TPU Name to connect to.

Im getting this while running on a colab TPU instance.
documentation states:
""A string corresponding to the TPU to use. It can be the TPU name or TPU worker gRPC address. If not set, it will try automatically resolve the TPU address on Cloud TPUs. If set to ""local"", it will assume that the TPU is directly connected to the VM instead of over the network.""
- https://www.tensorflow.org/api_docs/python/tf/distribute/cluster_resolver/TPUClusterResolver



P.S. Please help me Ive been dealing with OOMs for the last 5 months because of things like this please end my suffering


### Standalone code to reproduce the issue

```shell
!pip install datasets huggingface_hub transformers tf-models-official

import pandas as pd
import numpy as np
import tensorflow as tf
#import keras_nlp as knlp
import tensorflow_models as tfm

tpu = tf.distribute.cluster_resolver.TPUClusterResolver()

tf.config.experimental_connect_to_cluster(tpu)
tf.tpu.experimental.initialize_tpu_system(tpu)

strategy = tf.distribute.TPUStrategy(tpu)


print(f""Available number of replicas: {strategy.num_replicas_in_sync}"")
```


### Relevant log output

```shell
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-10-ae74ec612ba0> in <cell line: 1>()
----> 1 tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')
      2 
      3 tf.config.experimental_connect_to_cluster(tpu)
      4 tf.tpu.experimental.initialize_tpu_system(tpu)
      5 

1 frames
/usr/local/lib/python3.10/dist-packages/cloud_tpu_client/client.py in __init__(self, tpu, zone, project, credentials, service, discovery_url)
    137 
    138     if tpu is None:
--> 139       raise ValueError('Please provide a TPU Name to connect to.')
    140 
    141     self._tpu = _as_text(tpu)

ValueError: Please provide a TPU Name to connect to.
```
"
2389918850,70841,movenet = Movenet('movenet_thunder') not working,closed,2024-07-04 04:36:05+00:00,2024-07-18T10:55:36Z,2024-07-18T10:55:33Z,sawantkumar,,https://github.com/tensorflow/tensorflow/issues/70841,"['stat:awaiting response', 'type:bug', 'comp:lite', 'TF 2.15']","['@durgas4,\r\nCould you please provide the complete code or the colab gist to reproduce the issue which helps to debug the issue in an effective way. Thank you!', 'The code is here-\r\nhttps://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/hub/tutorials/movenet.ipynb#scrollTo=SYFdK-JHYhrv\r\n\r\nThis part-\r\nLoad Model from TF hub', ' Hi @durgas4 ,\r\n\r\nI ran the notebook from this same link but it worked fine. Can you please retry and let me know if it works?', ""Working fine, thanks!  i forgot the following code line -\r\n# Download model from TF Hub and check out inference code from GitHub\r\n!wget -q -O movenet_thunder.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/thunder/tflite/float16/4?lite-format=tflite\r\n!git clone https://github.com/tensorflow/examples.git\r\npose_sample_rpi_path = os.path.join(os.getcwd(), 'examples/lite/examples/pose_estimation/raspberry_pi')\r\nsys.path.append(pose_sample_rpi_path)\r\n\r\nAnd directly went to this :)\r\n# Load MoveNet Thunder model\r\nimport utils\r\nfrom data import BodyPart\r\nfrom ml import Movenet\r\nmovenet = Movenet('movenet_thunder')"", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70841"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70841"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.15.0

### Custom code

Yes

### OS platform and distribution

google ocllab

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When am trying to use the Movnet model, it is showing some error - 
movenet = Movenet('movenet_thunder')

### Standalone code to reproduce the issue

```shell
Used movnet for pose estimation , but the model is failing -
# Load MoveNet Thunder model
import utils
from data import BodyPart
from ml import Movenet
movenet = Movenet('movenet_thunder')
```


### Relevant log output

```shell
ValueError                                Traceback (most recent call last)
<ipython-input-16-85ae69c878c7> in <cell line: 11>()
      9 from data import BodyPart
     10 from ml import Movenet
---> 11 movenet = Movenet('movenet_thunder')
     12 
     13 # Define function to run pose estimation using MoveNet Thunder.

1 frames
/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/interpreter.py in __init__(self, model_path, model_content, experimental_delegates, num_threads, experimental_op_resolver_type, experimental_preserve_all_tensors, experimental_disable_delegate_clustering)
    462           x for x in self._custom_op_registerers if not isinstance(x, str)
    463       ]
--> 464       self._interpreter = _interpreter_wrapper.CreateWrapperFromFile(
    465           model_path,
    466           op_resolver_id,

ValueError: Mmap of '41' at offset '0' failed with error '22'.
```
"
2389965883,70842,TFlite on xtensa lx7,closed,2024-07-04 05:22:18+00:00,2024-08-17T01:51:59Z,2024-08-17T01:51:56Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/70842,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'comp:micro', 'TF 2.16']","[""Hi **@devapriyas2001** ,\r\nThe error you are facing is due to compatibility issue between EDK version of your device and TFLite. Could you please make sure the EDK version is compatible with the TFLite version you're targeting and the build includes the necessary header files in the path from Xtensa libraries and TFLite. For faster resolution could you please post this issue on [tflite/micro](https://github.com/tensorflow/tflite-micro).\r\n\r\nThank You!\r\n\r\n\r\n"", ""Hi @Venkat6871 ,\r\nHow to find the compatible EDK version for the device and TFlite?\r\nI posted the query on https://github.com/tensorflow/tflite-micro but didn't get the desired response.\r\nThanks!"", 'Hi @devapriyas2001, do you have a link to your query & response so that we may gain better context on what the issue may be?', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70842"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70842"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Linux, ubuntu 22.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Hi,
I need to compile tensorflow lite on xtensa lx7 platform. Currently, I used cross compilation information from tflite documentation but build errors (file not found errors, undefined references, syntax errors) are generated.
Please provide instruction on the build steps.




### Standalone code to reproduce the issue

```shell
cross compilation :
cmake   -DCMAKE_C_COMPILER=${XTENSA_PREFIX}/clang   -DCMAKE_CXX_COMPILER=${XTENSA_PREFIX}/clang++   -DCMAKE_C_FLAGS=""${XTENSA_FLAGS}""   -DCMAKE_CXX_FLAGS=""${XTENSA_FLAGS}""   -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON   -DCMAKE_SYSTEM_NAME=Linux   -DCMAKE_SYSTEM_PROCESSOR=xtensa   -DCMAKE_THREAD_LIBS_INIT=""-lpthread""   -DCMAKE_HAVE_THREADS_LIBRARY=1   -DCMAKE_USE_PTHREADS_INIT=1   -DTHREADS_PREFER_PTHREAD_FLAG=ON   
../tensorflow_src/tensorflow/lite

build:
cmake --build . -j
```


### Relevant log output

_No response_"
2390053135,70845,"TensorFlow is not detecting the GPU, whereas PyTorch is successfully identifying it.",closed,2024-07-04 06:27:38+00:00,2024-07-24T13:59:04Z,2024-07-24T13:59:01Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/70845,"['type:bug', 'comp:gpu', 'TF 2.16']","['@buttaRahul I was able to detect the GPU in Google colab, please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/3ee5f24e7acfdcd8c21c83e0b92a85bc/70845.ipynb).\r\nThank you!', 'Thank you for the response, but tesorflow is unable to detect GPU in my local device\r\nmy tensorflow version : 2.14.0, CUDA version: 11.8, cuDNN version 8.7.0.0 These versions are compatible as per [https://www.tensorflow.org/install/source#gpu](https://www.tensorflow.org/install/source#gpu) I would like to know what might be the issue in my device.', 'I have the same issue on my device with cuDNN 9 (also tested with version 8.7), CUDA 12.3 and tensorflow 2.16.1. Installation works fine with pytorch, but tensorflow can not detect the GPU. \r\n\r\nI see that the installation with pip is installing nvidia libraries, including some related to cuDNN, which may not have the same version as the one installed on the device, could this be a lead?', ""@buttaRahul  Could you please verify if your system recognizes the GPU using the NVIDIA System Management Interface:\r\n\r\n```\r\nnvidia-smi\r\n```\r\nPlease ensure that CUDA is correctly installed and the paths are set correctly:\r\n```\r\nnvcc --version\r\n\r\n```\r\nalso verify the cudnn version:\r\n```\r\ncat /usr/local/cuda/include/cudnn_version.h | grep CUDNN_MAJOR -A 2\r\n\r\n```\r\n\r\n```\r\npip uninstall tensorflow tensorflow-gpu\r\npip install tensorflow==2.14.0\r\n```\r\nthen install TF GPU and let us know?\r\n\r\n@FrejaThoresen Yes, the installation of NVIDIA libraries via pip that differ from your system's installed versions of CUDA and cuDNN could be causing conflicts. This is a common issue when there are mismatched versions. Please refer [TensorFlow compatibility guide](https://www.tensorflow.org/install/source#gpu) for the same. \r\nThank you!"", 'Please use TF 2.17, see #63362', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', 'I can confirm it works with Python 3.12, Tensorflow 2.17, Cuda 12.3, and cuDNN 8.9.7. I suspect the issue was caused by a mismatch between the pip versions of Nvidia cudnn installations and the cuDNN installation.\r\n\r\nTensorflow finding the GPU\r\n```\r\n>> python3 -c ""import tensorflow as tf; print(tf.config.list_physical_devices(\'GPU\'))""\r\n2024-07-24 15:06:12.214574: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n2024-07-24 15:06:12.223961: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n2024-07-24 15:06:12.226778: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n2024-07-24 15:06:12.233782: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\r\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2024-07-24 15:06:12.794225: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\r\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\nI0000 00:00:1721826373.167169  141358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\r\nI0000 00:00:1721826373.187865  141358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\r\nI0000 00:00:1721826373.188006  141358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\r\n[PhysicalDevice(name=\'/physical_device:GPU:0\', device_type=\'GPU\')]\r\n(tf_py12) freya@agora-linux-ai:~/Documents/Code/thin-slice-classifier$ nvcc --version\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2023 NVIDIA Corporation\r\nBuilt on Wed_Nov_22_10:17:15_PST_2023\r\nCuda compilation tools, release 12.3, V12.3.107\r\nBuild cuda_12.3.r12.3/compiler.33567101_0\r\n```\r\n\r\ncuDNN version\r\n```\r\n>> cat /usr/include/x86_64-linux-gnu/cudnn_v*.h | \r\ngrep CUDNN_MAJOR -A 2\r\n#define CUDNN_MAJOR 8\r\n#define CUDNN_MINOR 9\r\n#define CUDNN_PATCHLEVEL 7\r\n--\r\n#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\r\n\r\n/* cannot use constexpr here since this is a C-only file */\r\n```\r\n\r\npip nvidia libraries\r\n```\r\n>> pip list | grep nvidia\r\nnvidia-cublas-cu12       12.3.4.1\r\nnvidia-cuda-cupti-cu12   12.3.101\r\nnvidia-cuda-nvcc-cu12    12.3.107\r\nnvidia-cuda-nvrtc-cu12   12.3.107\r\nnvidia-cuda-runtime-cu12 12.3.101\r\nnvidia-cudnn-cu12        8.9.7.29\r\nnvidia-cufft-cu12        11.0.12.1\r\nnvidia-curand-cu12       10.3.4.107\r\nnvidia-cusolver-cu12     11.5.4.101\r\nnvidia-cusparse-cu12     12.2.0.103\r\nnvidia-nccl-cu12         2.19.3\r\nnvidia-nvjitlink-cu12    12.3.101\r\n```\r\n\r\npip tensorflow\r\n```\r\npip list | grep tensor\r\ntensorboard              2.17.0\r\ntensorboard-data-server  0.7.2\r\ntensorflow               2.17.0\r\n```\r\n\r\nDriver version\r\n```\r\n>> nvidia-smi\r\nWed Jul 24 15:11:31 2024       \r\n+-----------------------------------------------------------------------------------------+\r\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\r\n|-----------------------------------------+------------------------+----------------------+\r\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n|                                         |                        |               MIG M. |\r\n|=========================================+========================+======================|\r\n|   0  NVIDIA GeForce GTX 1660 ...    On  |   00000000:01:00.0  On |                  N/A |\r\n| 29%   31C    P8              6W /  125W |     126MiB /   6144MiB |      0%      Default |\r\n|                                         |                        |                  N/A |\r\n+-----------------------------------------+------------------------+----------------------+\r\n                                                                                         \r\n+-----------------------------------------------------------------------------------------+\r\n| Processes:                                                                              |\r\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n|        ID   ID                                                               Usage      |\r\n|=========================================================================================|\r\n|    0   N/A  N/A      1255      G   /usr/lib/xorg/Xorg                            116MiB |\r\n|    0   N/A  N/A      1303      G   /usr/bin/gnome-shell                            6MiB |\r\n+-----------------------------------------------------------------------------------------+\r\n```', 'Since it works on 2.17, moving towards closing this issue. Thank you @FrejaThoresen ', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70845"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70845"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.14.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

CUDA version: 11.8, cuDNN version: 8.7.0.0

### GPU model and memory

NVIDIA GeForce RTX 4060,  8188MiB

### Current behavior?

tensorflow unable to detect GPU, 


### Standalone code to reproduce the issue

```shell
tf.config.list_physical_devices()
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]

device = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")
print(f""Using device: {device}"")
Using device: cuda
```


### Relevant log output

_No response_"
2390194942,70851,Cannot build the TensorFlow Lite installation package (C++),closed,2024-07-04 07:51:03+00:00,2024-07-27T01:51:45Z,2024-07-27T01:51:42Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/70851,"['stat:awaiting response', 'type:bug', 'type:build/install', 'stale', 'comp:lite', 'TF 2.16']","[""Hi @WojciechRynczuk those instructions are supposed to be used with find_package in another cmake project. So after building, your project which integrates TFLite should include the `find_package(tensorflow-lite CONFIG)` line in your project's CMakeLists.txt file. I do not believe these instructions are meant to be used with `cmake --install`. Your CMakeLists.txt file will probably need more to work properly, but that is likely project dependent. Does that answer your question? Thanks."", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70851"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70851"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

v2.16.2

### Custom code

No

### OS platform and distribution

Linux

### Mobile device

Ubuntu 22.04

### Python version

3.10.12

### Bazel version

6.5.0

### GCC/compiler version

11.4.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I'd like to build the installable package of TensorFlow so as to be able to build standalone C++ applications using TensorFlow. They would be built using cmake. I followed the instructions provided [here](https://www.tensorflow.org/lite/guide/build_cmake#build_installable_package). Cmake fails.

Please notice that building the TensorFlow lib itself (not installable) succeeds. The issue only is applicable to the installable package.

I would expect the cmake to complete so as I would be able to execute 'cmake --install .' and install the TensorFlow library along with all necessary packages. If I am wrong here with my assumptions please advise me on installing the Tensorflow C++ runtime to be able to build standalone cmake based applications (x86 and ARM targets).

### Standalone code to reproduce the issue

```shell
cmake ../tensorflow/tensorflow/lite -DTFLITE_ENABLE_INSTALL=ON \
  -DCMAKE_FIND_PACKAGE_PREFER_CONFIG=ON \
  -DSYSTEM_FARMHASH=ON \
  -DSYSTEM_PTHREADPOOL=ON \
  -Dabsl_DIR=/usr/lib/cmake/absl \
  -DEigen3_DIR=/usr/share/eigen3/cmake \
  -DFlatBuffers_DIR=/usr/lib/cmake/flatbuffers \
  -Dgemmlowp_DIR=/usr/lib/cmake/gemmlowp \
  -DNEON_2_SSE_DIR=/usr/lib/cmake/NEON_2_SSE \
  -Dcpuinfo_DIR=/usr/share/cpuinfo \
  -Druy_DIR=/usr/lib/cmake/ruy
```


### Relevant log output

```shell
-- Configuring done (125.8s)
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_flags"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_hash"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_status"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_strings"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_synchronization"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_variant"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""ruy"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""pthreadpool"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""xnnpack-delegate"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""XNNPACK"" that is not in any export set.
CMake Error at /usr/local/lib/cmake/gemmlowp/gemmlowp-config.cmake:69 (set_target_properties):
  The link interface of target ""gemmlowp::eight_bit_int_gemm"" contains:

    Threads::Threads

  but the target was not found.  Possible reasons include:

    * There is a typo in the target name.
    * A find_package call is missing for an IMPORTED target.
    * An ALIAS target is missing.

Call Stack (most recent call first):
  CMakeLists.txt:171 (find_package)


-- Generating done (1.1s)
CMake Generate step failed.  Build files cannot be regenerated correctly.
```
"
2390743891,70866,Can't load model from model 2.15 in tensorflow 2.15?,closed,2024-07-04 12:21:48+00:00,2024-08-13T09:50:24Z,2024-07-05T09:37:09Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/70866,"['type:bug', 'comp:model', 'TF 2.15']","['Hi **@hotamago** ,\r\n- Could please provide a full code snippet to reproduce the issue reported here. I tried with another example, It works fine for me. Here i providing [gist](https://colab.research.google.com/gist/Venkat6871/59a99843d1abcfc2cd62686afd401fbc/70866_nightly-v.ipynb) for reference.\r\n\r\nThank you!\r\n', '> Hi **@hotamago** ,\r\n> \r\n> * Could please provide a full code snippet to reproduce the issue reported here. I tried with another example, It works fine for me. Here i providing [gist](https://colab.research.google.com/gist/Venkat6871/59a99843d1abcfc2cd62686afd401fbc/70866_nightly-v.ipynb) for reference.\r\n> \r\n> Thank you!\r\n\r\nOh, I tried my code in tf-nightly and get this error:\r\n![image](https://github.com/tensorflow/tensorflow/assets/24850901/38db6037-95c1-49d5-bb84-e3da2d1cc0c1)\r\n\r\nThank you for your help!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70866"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/70866"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.15

### Custom code

No

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I use model.save(""model.keras"") in kaggle using tf 2.15

then I load model in ubuntu 22.0 with python 3.10.12 using tensorflow 2.15
`tf.keras.models.load_model(
        os.path.join('model', 'model.keras'),
        safe_mode=False
    )`

result
`TypeError: Could not deserialize class 'Functional' because its parent module keras.src.models.functional cannot be imported. Full object config: {'module': 'keras.src.models.functional', 'class_name': 'Functional', 'config': {'name': 'functional_1', 'trainable': True, 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': [None, 16, 256, 1], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer'}, 'registered_name': None, 'name': 'input_layer', 'inbound_nodes': []}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 16, 256, 1]}, 'name': 'conv2d', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 16, 256, 1], 'dtype': 'float32', 'keras_history': ['input_layer', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 16, 256, 64]}, 'name': 'batch_normalization', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 16, 256, 64], 'dtype': 'float32', 'keras_history': ['conv2d', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 16, 256, 64]}, 'name': 're_lu', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 16, 256, 64], 'dtype': 'float32', 'keras_history': ['batch_normalization', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 16, 256, 64]}, 'name': 'conv2d_1', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 16, 256, 64], 'dtype': 'float32', 'keras_history': ['re_lu', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 16, 256, 64]}, 'name': 'batch_normalization_1', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 16, 256, 64], 'dtype': 'float32', 'keras_history': ['conv2d_1', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_1', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 16, 256, 64]}, 'name': 're_lu_1', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 16, 256, 64], 'dtype': 'float32', 'keras_history': ['batch_normalization_1', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': [2, 2], 'padding': 'valid', 'strides': [2, 2], 'data_format': 'channels_last'}, 'registered_name': None, 'build_config': {'input_shape': [None, 16, 256, 64]}, 'name': 'max_pooling2d', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 16, 256, 64], 'dtype': 'float32', 'keras_history': ['re_lu_1', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 8, 128, 64]}, 'name': 'conv2d_2', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 8, 128, 64], 'dtype': 'float32', 'keras_history': ['max_pooling2d', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 8, 128, 128]}, 'name': 'batch_normalization_2', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 8, 128, 128], 'dtype': 'float32', 'keras_history': ['conv2d_2', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_2', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 8, 128, 128]}, 'name': 're_lu_2', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 8, 128, 128], 'dtype': 'float32', 'keras_history': ['batch_normalization_2', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 8, 128, 128]}, 'name': 'conv2d_3', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 8, 128, 128], 'dtype': 'float32', 'keras_history': ['re_lu_2', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 8, 128, 128]}, 'name': 'batch_normalization_3', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 8, 128, 128], 'dtype': 'float32', 'keras_history': ['conv2d_3', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_3', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 8, 128, 128]}, 'name': 're_lu_3', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 8, 128, 128], 'dtype': 'float32', 'keras_history': ['batch_normalization_3', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': [2, 2], 'padding': 'valid', 'strides': [2, 2], 'data_format': 'channels_last'}, 'registered_name': None, 'build_config': {'input_shape': [None, 8, 128, 128]}, 'name': 'max_pooling2d_1', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 8, 128, 128], 'dtype': 'float32', 'keras_history': ['re_lu_3', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 4, 64, 128]}, 'name': 'conv2d_4', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 4, 64, 128], 'dtype': 'float32', 'keras_history': ['max_pooling2d_1', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 4, 64, 256]}, 'name': 'batch_normalization_4', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 4, 64, 256], 'dtype': 'float32', 'keras_history': ['conv2d_4', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_4', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 4, 64, 256]}, 'name': 're_lu_4', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 4, 64, 256], 'dtype': 'float32', 'keras_history': ['batch_normalization_4', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 4, 64, 256]}, 'name': 'conv2d_5', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 4, 64, 256], 'dtype': 'float32', 'keras_history': ['re_lu_4', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 4, 64, 256]}, 'name': 'batch_normalization_5', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 4, 64, 256], 'dtype': 'float32', 'keras_history': ['conv2d_5', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_5', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 4, 64, 256]}, 'name': 're_lu_5', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 4, 64, 256], 'dtype': 'float32', 'keras_history': ['batch_normalization_5', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': [2, 2], 'padding': 'valid', 'strides': [2, 2], 'data_format': 'channels_last'}, 'registered_name': None, 'build_config': {'input_shape': [None, 4, 64, 256]}, 'name': 'max_pooling2d_2', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 4, 64, 256], 'dtype': 'float32', 'keras_history': ['re_lu_5', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 512, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 2, 32, 256]}, 'name': 'conv2d_6', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 2, 32, 256], 'dtype': 'float32', 'keras_history': ['max_pooling2d_2', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 2, 32, 512]}, 'name': 'batch_normalization_6', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 2, 32, 512], 'dtype': 'float32', 'keras_history': ['conv2d_6', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_6', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 2, 32, 512]}, 'name': 're_lu_6', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 2, 32, 512], 'dtype': 'float32', 'keras_history': ['batch_normalization_6', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 512, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 2, 32, 512]}, 'name': 'conv2d_7', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 2, 32, 512], 'dtype': 'float32', 'keras_history': ['re_lu_6', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 2, 32, 512]}, 'name': 'batch_normalization_7', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 2, 32, 512], 'dtype': 'float32', 'keras_history': ['conv2d_7', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_7', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 2, 32, 512]}, 'name': 're_lu_7', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 2, 32, 512], 'dtype': 'float32', 'keras_history': ['batch_normalization_7', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': [2, 2], 'padding': 'valid', 'strides': [2, 2], 'data_format': 'channels_last'}, 'registered_name': None, 'build_config': {'input_shape': [None, 2, 32, 512]}, 'name': 'max_pooling2d_3', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 2, 32, 512], 'dtype': 'float32', 'keras_history': ['re_lu_7', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 1024, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 1, 16, 512]}, 'name': 'conv2d_8', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 1, 16, 512], 'dtype': 'float32', 'keras_history': ['max_pooling2d_3', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 1, 16, 1024]}, 'name': 'batch_normalization_8', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 1, 16, 1024], 'dtype': 'float32', 'keras_history': ['conv2d_8', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_8', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 1, 16, 1024]}, 'name': 're_lu_8', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 1, 16, 1024], 'dtype': 'float32', 'keras_history': ['batch_normalization_8', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 1024, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 1, 16, 1024]}, 'name': 'conv2d_9', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 1, 16, 1024], 'dtype': 'float32', 'keras_history': ['re_lu_8', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 1, 16, 1024]}, 'name': 'batch_normalization_9', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 1, 16, 1024], 'dtype': 'float32', 'keras_history': ['conv2d_9', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_9', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 1, 16, 1024]}, 'name': 're_lu_9', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 1, 16, 1024], 'dtype': 'float32', 'keras_history': ['batch_normalization_9', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2DTranspose', 'config': {'name': 'conv2d_transpose', 'trainable': True, 'dtype': 'float32', 'filters': 512, 'kernel_size': [2, 2], 'strides': [2, 2], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 1, 16, 1024]}, 'name': 'conv2d_transpose', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 1, 16, 1024], 'dtype': 'float32', 'keras_history': ['re_lu_9', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Concatenate', 'config': {'name': 'concatenate', 'trainable': True, 'dtype': 'float32', 'axis': -1}, 'registered_name': None, 'build_config': {'input_shape': [[None, 2, 32, 512], [None, 2, 32, 512]]}, 'name': 'concatenate', 'inbound_nodes': [{'args': [[{'class_name': '__keras_tensor__', 'config': {'shape': [None, 2, 32, 512], 'dtype': 'float32', 'keras_history': ['conv2d_transpose', 0, 0]}}, {'class_name': '__keras_tensor__', 'config': {'shape': [None, 2, 32, 512], 'dtype': 'float32', 'keras_history': ['re_lu_7', 0, 0]}}]], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 512, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 2, 32, 1024]}, 'name': 'conv2d_10', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 2, 32, 1024], 'dtype': 'float32', 'keras_history': ['concatenate', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_10', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 2, 32, 512]}, 'name': 'batch_normalization_10', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 2, 32, 512], 'dtype': 'float32', 'keras_history': ['conv2d_10', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_10', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 2, 32, 512]}, 'name': 're_lu_10', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 2, 32, 512], 'dtype': 'float32', 'keras_history': ['batch_normalization_10', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 512, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 2, 32, 512]}, 'name': 'conv2d_11', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 2, 32, 512], 'dtype': 'float32', 'keras_history': ['re_lu_10', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_11', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 2, 32, 512]}, 'name': 'batch_normalization_11', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 2, 32, 512], 'dtype': 'float32', 'keras_history': ['conv2d_11', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_11', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 2, 32, 512]}, 'name': 're_lu_11', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 2, 32, 512], 'dtype': 'float32', 'keras_history': ['batch_normalization_11', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2DTranspose', 'config': {'name': 'conv2d_transpose_1', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': [2, 2], 'strides': [2, 2], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 2, 32, 512]}, 'name': 'conv2d_transpose_1', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 2, 32, 512], 'dtype': 'float32', 'keras_history': ['re_lu_11', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Concatenate', 'config': {'name': 'concatenate_1', 'trainable': True, 'dtype': 'float32', 'axis': -1}, 'registered_name': None, 'build_config': {'input_shape': [[None, 4, 64, 256], [None, 4, 64, 256]]}, 'name': 'concatenate_1', 'inbound_nodes': [{'args': [[{'class_name': '__keras_tensor__', 'config': {'shape': [None, 4, 64, 256], 'dtype': 'float32', 'keras_history': ['conv2d_transpose_1', 0, 0]}}, {'class_name': '__keras_tensor__', 'config': {'shape': [None, 4, 64, 256], 'dtype': 'float32', 'keras_history': ['re_lu_5', 0, 0]}}]], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 4, 64, 512]}, 'name': 'conv2d_12', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 4, 64, 512], 'dtype': 'float32', 'keras_history': ['concatenate_1', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_12', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 4, 64, 256]}, 'name': 'batch_normalization_12', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 4, 64, 256], 'dtype': 'float32', 'keras_history': ['conv2d_12', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_12', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 4, 64, 256]}, 'name': 're_lu_12', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 4, 64, 256], 'dtype': 'float32', 'keras_history': ['batch_normalization_12', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 4, 64, 256]}, 'name': 'conv2d_13', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 4, 64, 256], 'dtype': 'float32', 'keras_history': ['re_lu_12', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_13', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 4, 64, 256]}, 'name': 'batch_normalization_13', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 4, 64, 256], 'dtype': 'float32', 'keras_history': ['conv2d_13', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_13', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 4, 64, 256]}, 'name': 're_lu_13', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 4, 64, 256], 'dtype': 'float32', 'keras_history': ['batch_normalization_13', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2DTranspose', 'config': {'name': 'conv2d_transpose_2', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': [2, 2], 'strides': [2, 2], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 4, 64, 256]}, 'name': 'conv2d_transpose_2', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 4, 64, 256], 'dtype': 'float32', 'keras_history': ['re_lu_13', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Concatenate', 'config': {'name': 'concatenate_2', 'trainable': True, 'dtype': 'float32', 'axis': -1}, 'registered_name': None, 'build_config': {'input_shape': [[None, 8, 128, 128], [None, 8, 128, 128]]}, 'name': 'concatenate_2', 'inbound_nodes': [{'args': [[{'class_name': '__keras_tensor__', 'config': {'shape': [None, 8, 128, 128], 'dtype': 'float32', 'keras_history': ['conv2d_transpose_2', 0, 0]}}, {'class_name': '__keras_tensor__', 'config': {'shape': [None, 8, 128, 128], 'dtype': 'float32', 'keras_history': ['re_lu_3', 0, 0]}}]], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 8, 128, 256]}, 'name': 'conv2d_14', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 8, 128, 256], 'dtype': 'float32', 'keras_history': ['concatenate_2', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_14', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 8, 128, 128]}, 'name': 'batch_normalization_14', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 8, 128, 128], 'dtype': 'float32', 'keras_history': ['conv2d_14', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_14', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 8, 128, 128]}, 'name': 're_lu_14', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 8, 128, 128], 'dtype': 'float32', 'keras_history': ['batch_normalization_14', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 8, 128, 128]}, 'name': 'conv2d_15', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 8, 128, 128], 'dtype': 'float32', 'keras_history': ['re_lu_14', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_15', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 8, 128, 128]}, 'name': 'batch_normalization_15', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 8, 128, 128], 'dtype': 'float32', 'keras_history': ['conv2d_15', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_15', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 8, 128, 128]}, 'name': 're_lu_15', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 8, 128, 128], 'dtype': 'float32', 'keras_history': ['batch_normalization_15', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2DTranspose', 'config': {'name': 'conv2d_transpose_3', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': [2, 2], 'strides': [2, 2], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 8, 128, 128]}, 'name': 'conv2d_transpose_3', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 8, 128, 128], 'dtype': 'float32', 'keras_history': ['re_lu_15', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Concatenate', 'config': {'name': 'concatenate_3', 'trainable': True, 'dtype': 'float32', 'axis': -1}, 'registered_name': None, 'build_config': {'input_shape': [[None, 16, 256, 64], [None, 16, 256, 64]]}, 'name': 'concatenate_3', 'inbound_nodes': [{'args': [[{'class_name': '__keras_tensor__', 'config': {'shape': [None, 16, 256, 64], 'dtype': 'float32', 'keras_history': ['conv2d_transpose_3', 0, 0]}}, {'class_name': '__keras_tensor__', 'config': {'shape': [None, 16, 256, 64], 'dtype': 'float32', 'keras_history': ['re_lu_1', 0, 0]}}]], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 16, 256, 128]}, 'name': 'conv2d_16', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 16, 256, 128], 'dtype': 'float32', 'keras_history': ['concatenate_3', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_16', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 16, 256, 64]}, 'name': 'batch_normalization_16', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 16, 256, 64], 'dtype': 'float32', 'keras_history': ['conv2d_16', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_16', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 16, 256, 64]}, 'name': 're_lu_16', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 16, 256, 64], 'dtype': 'float32', 'keras_history': ['batch_normalization_16', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 16, 256, 64]}, 'name': 'conv2d_17', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 16, 256, 64], 'dtype': 'float32', 'keras_history': ['re_lu_16', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_17', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 16, 256, 64]}, 'name': 'batch_normalization_17', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 16, 256, 64], 'dtype': 'float32', 'keras_history': ['conv2d_17', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_17', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 16, 256, 64]}, 'name': 're_lu_17', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 16, 256, 64], 'dtype': 'float32', 'keras_history': ['batch_normalization_17', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 1, 'kernel_size': [1, 1], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 16, 256, 64]}, 'name': 'conv2d_18', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 16, 256, 64], 'dtype': 'float32', 'keras_history': ['re_lu_17', 0, 0]}}], 'kwargs': {}}]}], 'input_layers': [['input_layer', 0, 0]], 'output_layers': [['conv2d_18', 0, 0]]}, 'registered_name': 'Functional', 'build_config': {'input_shape': None}, 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'Adam', 'config': {'name': 'adam', 'learning_rate': 9.999999747378752e-05, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': {'module': 'builtins', 'class_name': 'function', 'config': 'sp_custom_loss', 'registered_name': 'function'}, 'loss_weights': None, 'metrics': [{'module': 'keras.metrics', 'class_name': 'CosineSimilarity', 'config': {'name': 'cosine', 'dtype': 'float32'}, 'registered_name': None}, {'module': 'keras.metrics', 'class_name': 'MeanAbsoluteError', 'config': {'name': 'MAE', 'dtype': 'float32'}, 'registered_name': None}, {'module': 'keras.metrics', 'class_name': 'MeanSquaredError', 'config': {'name': 'MSE', 'dtype': 'float32'}, 'registered_name': None}], 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': True}}`

### Standalone code to reproduce the issue

```shell
model.save
tf.keras.models.load_model(os.path.join('model', 'model.keras'),safe_mode=False)
```


### Relevant log output

_No response_"
2397700446,71180,TFLite Podspecs haven't been updated after v2.14,closed,2024-07-09 09:48:42+00:00,2024-11-26T18:08:48Z,2024-11-26T18:08:44Z,yishuangP,,https://github.com/tensorflow/tensorflow/issues/71180,"['stat:awaiting tensorflower', 'type:bug', 'comp:lite', 'TF 2.16']","['This seems correct: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/ios/TensorFlowLiteC.podspec\r\n\r\n@yishuangP, can you please take a look? Thanks.', ""Hi, @guillaume-tgl \r\nThanks for raising this issue. Are you aware of the migration to [LiteRT](https://developers.googleblog.com/en/tensorflow-lite-is-now-litert/)? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/google-ai-edge/LiteRT/issues/47\r\n\r\nLet us know if you have any questions. Thanks."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71180"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71180"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.16.2

### Custom code

No

### OS platform and distribution

iOS

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

TensorflowLiteC podspec still uses the 2.14 binary and hasn't been updated since v2.14. It's necessary to be able to integrate the latest versions with the C API for iOS.

### Standalone code to reproduce the issue

```shell
N/A
```


### Relevant log output

_No response_"
2397722015,71184,Missing C headers in AAR,closed,2024-07-09 09:57:38+00:00,2024-07-18T18:25:36Z,2024-07-18T07:20:58Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/71184,"['stat:awaiting response', 'type:bug', 'type:build/install', 'comp:lite', 'Android', 'TF 2.16']","['Hi @guillaume-tgl, in the documentation it states: \r\n> You must include the four header files in the `headers/tensorflow/lite/`\r\n\r\nour interpretation of this is that you would manually add all these headers. So I believe it is working as intended. Thanks.', ""> our interpretation of this is that you would manually add all these headers. So I believe it is working as intended. Thanks.\r\n\r\nSorry, maybe my description was not clear enough. The headers embedded in the AAR are not enough to be able to compile a project depending on TFLite. I had to copy the missing headers directly from the Tensorflow repository for my project to compile.\r\nA similar issue was reported a few months ago and it was resolved by including the missing headers in the AAR: https://github.com/tensorflow/tensorflow/issues/59026\r\nDon't you think a similar solution can be implemented?"", 'Hi @guillaume-tgl, apologies for the misunderstanding, so if I\'m understanding correctly there are more than the 4 header files documented needed to use the C API now and those 2 files are: \r\n> ""tensorflow/lite/core/async/c/types.h""\r\n> ""tensorflow/lite/core/c/registration_external.h""\r\n\r\nWould you say these headers are needed more generally i.e. for most cases or do you feel they are specific for your project use cases? For either... can you provide any example project that shows this so that I may test it (Like a hello world version of what you did)? Thanks.', '@pkgoogle These two headers are needed in the general case since they are included by one of the 4 public headers: https://github.com/tensorflow/tensorflow/blob/v2.16.1/tensorflow/lite/core/c/c_api.h', 'Hi @guillaume-tgl, master/nightly is actually synchronous for their requirements: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/java/BUILD#L142, that being said, you are correct branch/release 2.16 is not consistent, let me look into see how I can update that branch. Thanks for your help.', '@guillaume-tgl Did you add the ``TFLITE_IN_GMSCORE`` define? I am assuming that you have not, since this define changes the include paths, ie\r\n```c\r\n#if TFLITE_IN_GMSCORE\r\n#include ""tensorflow/lite/abi/c/c_api_types.h""  // IWYU pragma: export\r\n#else\r\n#include ""tensorflow/lite/core/c/c_api_types.h""  // IWYU pragma: export\r\n#endif\r\n```\r\n\r\nI assume GMS stands for google mobile services, since tensorflow is now part of google play services thingy.\r\n\r\nAlso, you may stumble with the initialization of tensorflow (I sure did). Tensorflow will crash upon any function call and will output a message saying ""You need to initialize Tensorflow with a call to GmsTfLiteInitialize"" or something like that. This function (GmsTfLiteInitialize) expects some weird  \'internal native handle\' of type jobject. Absolutely no idea how to obtain that, or what it is. \r\nThe only solution (that I\'ve found) is to call `TfLiteNative.initialize` in java/kotlin. And the entire TfLiteNative class is not available in 2.16.1. You need to move to 2.16.2-beta02 to have it available. \r\n\r\nThis is the extend of my knowledge, I stumbled upon this same problem last week and this is all I\'ve got. Most of it is mentioned in the [docs](https://www.tensorflow.org/lite/android/native), but there is no explanation for what GMS is or why TfLiteNative is not available in 2.16.1, and how to do thing prior to 2.16.2. Or why is the official documentation advising the use of a beta release...', ""> @guillaume-tgl Did you add the TFLITE_IN_GMSCORE define?\r\n\r\nNo, I don't have this flag enabled. I use the regular way to embed TensorflowLite."", '> Hi @guillaume-tgl, master/nightly is actually synchronous for their requirements: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/java/BUILD#L142, that being said, you are correct branch/release 2.16 is not consistent, let me look into see how I can update that branch. Thanks for your help.\r\n\r\nI wanted to try v2.17 to see if the problem is still there but it looks like this version is not present on [Maven](https://central.sonatype.com/artifact/org.tensorflow/tensorflow-lite) 🤔 Any idea why?', ""Hey All. Apologies @guillaume-tgl, there's no more expected patches for 2.16 and unfortunately this issue is not big enough to warrant a new patch unless there's a security issue or such things. Please use the work around for now until a new version is out. I don't know exactly why v2.17 is not out yet on Maven, I'm guessing there are issues around the release process (maybe a similar issue like this for another platform). Thanks for your help."", ""Thanks.\r\n\r\n> I don't know exactly why v2.17 is not out yet on Maven, I'm guessing there are issues around the release process (maybe a similar issue like this for another platform).\r\n\r\nShould I open another ticket for this?"", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71184"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71184"">No</a>\n', 'Hi @guillaume-tgl, hmm yeah it seems reasonable, I suppose it will create some pressure to release it -- but largely I think they already know that. It will provide me more data/information to create more pressure for it if we feel there is a large demand.']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.16.1

### Custom code

Yes

### OS platform and distribution

Android

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I am using the approach described here to integrate C Api for tensorflow lite: https://www.tensorflow.org/lite/android/development#tools_for_building_with_c_and_c

According to the description I should do the following:

> Using this API is the recommended approach for developers using the NDK. Download the TensorFlow Lite AAR hosted at MavenCentral file, rename to tensorflow-lite-*.zip, and unzip it. You must include the four header files in the headers/tensorflow/lite/ and headers/tensorflow/lite/c/ folders and the relevant libtensorflowlite_jni.so dynamic library in the jni/ folder in your NDK project.
> 
> The c_api.h header file contains basic documentation about using the TFLite C API.

This approach works for previous versions of TFLite. When I try to upgrade to a v2.16.1 I get the following error:

```
In file included from ***/tflite/include/tensorflow/lite/c/c_api.h:24:
***/tflite/include/tensorflow/lite/core/c/c_api.h:29:10: fatal error: 'tensorflow/lite/core/async/c/types.h' file not found
```

The AAR is missing the following two headers:
""tensorflow/lite/core/async/c/types.h""
""tensorflow/lite/core/c/registration_external.h""

After manually adding these 2 headers, I was able to compile my project.

### Standalone code to reproduce the issue

```shell
Follow the guidelines described in the TFLite C API and use the 2.16.1 version AAR from Maven Central.
```


### Relevant log output

_No response_"
2400681527,71570,ValueError: Trying to load a model of incompatible/unknown type.,closed,2024-07-10 12:51:58+00:00,2024-08-01T11:20:40Z,2024-07-26T01:52:45Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/71570,"['stat:awaiting response', 'type:bug', 'stale', 'TF 2.16']","['@hanan454,\r\nTo avoid the issue of TF-Hub looking in temp directory for cached models, you can customise the download location to home directory by by setting the environment variable TFHUB_CACHE_DIR (recommended) or by passing the command-line flag --tfhub_cache_dir. Users who prefer persistent caching across system reboots can instead set TFHUB_CACHE_DIR to a location in their home directory. When using a persistent location, be aware that there is no automatic cleanup.\r\n\r\nI would recommend you to download the model from tfhub.dev with assets, variables and .pb checkpoint file and save it to your home directory and specify the downloaded model folder path in the hub.load() to load the model from local storage instead of looking in temp directory.\r\n\r\n```python\r\nmodel = hub.load(""/Users/tilak/Downloads/universal-sentence-encoder-multilingual-large_3/"")\r\n```\r\nThe other way would be to instruct the tensorflow_hub library to directly read models from remote storage (GCS) instead of downloading the models locally. This way, no caching directory is needed.\r\n\r\nRef: [Caching model downloads from TF Hub](https://www.tensorflow.org/hub/caching). \r\n\r\nAlso [tfhub.dev](http://tfhub.dev/) has been converged with Kaggle Model hub. You can refer [this](https://www.kaggle.com/discussions/product-feedback/448425) for update. Future improvements will be driven by Kaggle team. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71570"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71570"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.16.2

### Custom code

Yes

### OS platform and distribution

Widows

### Mobile device

_No response_

### Python version

3

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Although my code was work perfectly for months, but yesterday suddenly I get this error when I run my code: ValueError: Trying to load a model of incompatible/unknown type. 'C:\Users\me\AppData\Local\Temp\tfhub_modules\230e8287a3b3f30e3824b066c9ee9c839533b009' contains neither 'saved_model.pb' nor 'saved_model.pbtxt

### Standalone code to reproduce the issue

```shell
bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8' 
#bert_model_name = 'bert_en_uncased_L-12_H-768_A-12'

map_name_to_handle = {
    'bert_en_uncased_L-12_H-768_A-12':
        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',
    'bert_en_cased_L-12_H-768_A-12':
        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',
    'bert_multi_cased_L-12_H-768_A-12':
        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',
    'small_bert/bert_en_uncased_L-2_H-128_A-2':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',
    'small_bert/bert_en_uncased_L-2_H-256_A-4':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',
    'small_bert/bert_en_uncased_L-2_H-512_A-8':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',
    'small_bert/bert_en_uncased_L-2_H-768_A-12':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',
    'small_bert/bert_en_uncased_L-4_H-128_A-2':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',
    'small_bert/bert_en_uncased_L-4_H-256_A-4':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',
    'small_bert/bert_en_uncased_L-4_H-512_A-8':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',
    'small_bert/bert_en_uncased_L-4_H-768_A-12':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',
    'small_bert/bert_en_uncased_L-6_H-128_A-2':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',
    'small_bert/bert_en_uncased_L-6_H-256_A-4':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',
    'small_bert/bert_en_uncased_L-6_H-512_A-8':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',
    'small_bert/bert_en_uncased_L-6_H-768_A-12':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',
    'small_bert/bert_en_uncased_L-8_H-128_A-2':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',
    'small_bert/bert_en_uncased_L-8_H-256_A-4':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',
    'small_bert/bert_en_uncased_L-8_H-512_A-8':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',
    'small_bert/bert_en_uncased_L-8_H-768_A-12':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',
    'small_bert/bert_en_uncased_L-10_H-128_A-2':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',
    'small_bert/bert_en_uncased_L-10_H-256_A-4':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',
    'small_bert/bert_en_uncased_L-10_H-512_A-8':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',
    'small_bert/bert_en_uncased_L-10_H-768_A-12':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',
    'small_bert/bert_en_uncased_L-12_H-128_A-2':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',
    'small_bert/bert_en_uncased_L-12_H-256_A-4':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',
    'small_bert/bert_en_uncased_L-12_H-512_A-8':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',
    'small_bert/bert_en_uncased_L-12_H-768_A-12':
        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',
    'albert_en_base':
        'https://tfhub.dev/tensorflow/albert_en_base/2',
    'electra_small':
        'https://tfhub.dev/google/electra_small/2',
    'electra_base':
        'https://tfhub.dev/google/electra_base/2',
    'experts_pubmed':
        'https://tfhub.dev/google/experts/bert/pubmed/2',
    'experts_wiki_books':
        'https://tfhub.dev/google/experts/bert/wiki_books/2',
    'talking-heads_base':
        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',
}

map_model_to_preprocess = {
    'bert_en_uncased_L-12_H-768_A-12':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'bert_en_cased_L-12_H-768_A-12':
        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/1',
    'small_bert/bert_en_uncased_L-2_H-128_A-2':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-2_H-256_A-4':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-2_H-512_A-8':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-2_H-768_A-12':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-4_H-128_A-2':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-4_H-256_A-4':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-4_H-512_A-8':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-4_H-768_A-12':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-6_H-128_A-2':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-6_H-256_A-4':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-6_H-512_A-8':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-6_H-768_A-12':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-8_H-128_A-2':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-8_H-256_A-4':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-8_H-512_A-8':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-8_H-768_A-12':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-10_H-128_A-2':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-10_H-256_A-4':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-10_H-512_A-8':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-10_H-768_A-12':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-12_H-128_A-2':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-12_H-256_A-4':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-12_H-512_A-8':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'small_bert/bert_en_uncased_L-12_H-768_A-12':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'bert_multi_cased_L-12_H-768_A-12':
        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/1',
    'albert_en_base':
        'https://tfhub.dev/tensorflow/albert_en_preprocess/1',
    'electra_small':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'electra_base':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'experts_pubmed':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'experts_wiki_books':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
    'talking-heads_base':
        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1',
}

tfhub_handle_encoder = map_name_to_handle[bert_model_name]
tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]
bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)
```


### Relevant log output

```shell
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[290], line 1
----> 1 bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)

File ~\Anaconda\lib\site-packages\tensorflow_hub\keras_layer.py:157, in KerasLayer.__init__(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)
    153   self._output_shape = data_structures.NoDependency(
    154       _convert_nest_to_shapes(output_shape))
    156 self._load_options = load_options
--> 157 self._func = load_module(handle, tags, self._load_options)
    158 self._is_hub_module_v1 = getattr(self._func, ""_is_hub_module_v1"", False)
    160 # Update with the defaults when using legacy TF1 Hub format.

File ~\Anaconda\lib\site-packages\tensorflow_hub\keras_layer.py:459, in load_module(handle, tags, load_options)
    457     except ImportError:  # Expected before TF2.4.
    458       set_load_options = load_options
--> 459 return module_v2.load(handle, tags=tags, options=set_load_options)

File ~\Anaconda\lib\site-packages\tensorflow_hub\module_v2.py:107, in load(handle, tags, options)
    102 saved_model_pbtxt_path = os.path.join(
    103     tf.compat.as_bytes(module_path),
    104     tf.compat.as_bytes(tf.saved_model.SAVED_MODEL_FILENAME_PBTXT))
    105 if (not tf.io.gfile.exists(saved_model_path) and
    106     not tf.io.gfile.exists(saved_model_pbtxt_path)):
--> 107   raise ValueError(""Trying to load a model of incompatible/unknown type. ""
    108                    ""'%s' contains neither '%s' nor '%s'."" %
    109                    (module_path, tf.saved_model.SAVED_MODEL_FILENAME_PB,
    110                     tf.saved_model.SAVED_MODEL_FILENAME_PBTXT))
    112 if options:
    113   if not hasattr(getattr(tf, ""saved_model"", None), ""LoadOptions""):

ValueError: Trying to load a model of incompatible/unknown type. 'C:\Users\me\AppData\Local\Temp\tfhub_modules\230e8287a3b3f30e3824b066c9ee9c839533b009' contains neither 'saved_model.pb' nor 'saved_model.pbtxt'.
```
"
2401053553,71577,Tensorflow Metal Plugin produces different results with CPU for Conv1D,closed,2024-07-10 15:18:35+00:00,2024-09-06T01:57:58Z,2024-09-06T01:57:55Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/71577,"['stat:awaiting response', 'type:bug', 'stale', 'comp:apis', 'TF 2.16']","['@hguandl,\r\nWhen I tried to check in the colab which was having Linux in the background which was executed and observed that the results are also similar. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/6907eed04ea3b9cec404e0a753cb74a4/untitled2024.ipynb). I will check in Macos as well and provide more info on this. Meanwhile could you please check with tf-nightly and provide the update if you are facing the same. Thank you!', '@tilakrayal \r\nThank you for the information! When I tried tf-nightly, the program reported a library error:\r\n```\r\nTraceback (most recent call last):\r\n  File ""/Users/hguandl/Desktop/Workspace/ml-transfer/pt-129207-tf-report.py"", line 1, in <module>\r\n    import tensorflow as tf\r\n  File ""/Users/hguandl/Library/micromamba/envs/tf-new/lib/python3.9/site-packages/tensorflow/__init__.py"", line 434, in <module>\r\n    _ll.load_library(_plugin_dir)\r\n  File ""/Users/hguandl/Library/micromamba/envs/tf-new/lib/python3.9/site-packages/tensorflow/python/framework/load_library.py"", line 151, in load_library\r\n    py_tf.TF_LoadLibrary(lib)\r\ntensorflow.python.framework.errors_impl.NotFoundError: dlopen(/Users/hguandl/Library/micromamba/envs/tf-new/lib/python3.9/site-packages/tensorflow-plugins/libmetal_plugin.dylib, 0x0006): Symbol not found: __ZN3tsl8internal10LogMessageC1EPKcii\r\n  Referenced from: <D2EF42E3-3A7F-39DD-9982-FB6BCDC2853C> /Users/hguandl/Library/micromamba/envs/tf-new/lib/python3.9/site-packages/tensorflow-plugins/libmetal_plugin.dylib\r\n  Expected in:     <FE39B172-55AE-3F24-B912-DE28E355BE70> /Users/hguandl/Library/micromamba/envs/tf-new/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n```\r\nI guess tf-nightly does not work with the [PluggableDevice](https://developer.apple.com/metal/tensorflow-plugin/) well.', ""@hguandl,\r\nApologies for the delay. I tried to execute the mentioned code using multiple environments like windows, wsl2, linux and others as well and couldn't find the different results with the CPU for Conv1D. So please raise the issue in the Apple forum for the quick resolution. Thank you!"", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71577"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71577"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

tensorflow 2.16.1
tensorflow-metal 1.1.0

### Custom code

Yes

### OS platform and distribution

macOS 14.5

### Mobile device

macOS 14.5

### Python version

3.9.19

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

If we create Conv1D layer with 65537 layers, the results are different.

On macOS (`pip install tensorflow-metal`), the results are:
```
y_cpu: [[[ 0.00041509 -0.00370452 -0.00212137 ... -0.00374832 -0.00753052
   -0.00895449]]]
y_gpu: [[[-0.00895449 -0.00370452 -0.00212137 ... -0.00374832 -0.00753052
    0.        ]]]
Equal: False
```

On Linux (`pip install tensorflow-gpu`), the results are:
```
y_cpu: [[[ 0.00225602  0.01136317  0.00391667 ... -0.0028112   0.00243109
   -0.00492344]]]
y_gpu: [[[ 0.00225602  0.01136317  0.00391667 ... -0.0028112   0.00243109
   -0.00492344]]]
Equal: True
```

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

tf.random.set_seed(0)

conv = tf.keras.layers.Conv1D(filters=65537, kernel_size=3, padding='same')

x = tf.ones([1, 1, 3])

with tf.device('/CPU:0'):
    y_cpu = conv(x)

with tf.device('/GPU:0'):
    y_gpu = conv(x)

print(""y_cpu:"", y_cpu.numpy())
print(""y_gpu:"", y_gpu.numpy())
print(""Equal:"", np.allclose(y_cpu.numpy(), y_gpu.numpy()))
```


### Relevant log output

_No response_"
2401346789,71587,TFLite-Model-Maker running error: AttributeError: module 'numpy' has no attribute 'object'.,closed,2024-07-10 17:51:55+00:00,2024-08-07T01:54:25Z,2024-08-07T01:54:21Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/71587,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'TF 2.9', 'TFLiteModelMaker']","[""@libofei2004,\r\nThis issue is the known issue, Could you please use [mediapipe model maker](https://developers.google.com/mediapipe/solutions/model_maker) instead for now. Here is also a [gist](https://colab.sandbox.google.com/gist/pkgoogle/93fb7581fab1ea14728c61adf584ca13/media_pipe_example.ipynb) that runs through some image classification examples with mediapipe model maker, including quantization: gist. If you can't accomplish your goals with mediapipe-model-maker please let us know and we'll see if there is a way to accomplish your goals.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/60431\r\n\r\nThank you!"", '@tilakrayal Thank you, now I have installed mediapipe_model_maker, but when I run my code, the error occured:\r\nTraceback (most recent call last):\r\n  File ""<frozen importlib._bootstrap>"", line 1007, in _find_and_load\r\n  File ""<frozen importlib._bootstrap>"", line 986, in _find_and_load_unlocked\r\n  File ""<frozen importlib._bootstrap>"", line 680, in _load_unlocked\r\n  File ""<frozen importlib._bootstrap_external>"", line 790, in exec_module\r\n  File ""<frozen importlib._bootstrap>"", line 228, in _call_with_frames_removed\r\n  File ""C:\\Users\\libof\\env1\\lib\\site-packages\\mediapipe_model_maker\\__init__.py"", line 17, in <module>\r\n    from mediapipe_model_maker.python.vision import image_classifier\r\n  File ""C:\\Users\\libof\\env1\\lib\\site-packages\\mediapipe_model_maker\\python\\vision\\image_classifier\\__init__.py"", line 16, in <module>\r\n    from mediapipe_model_maker.python.vision.image_classifier import dataset\r\n  File ""C:\\Users\\libof\\env1\\lib\\site-packages\\mediapipe_model_maker\\python\\vision\\image_classifier\\dataset.py"", line 21, in <module>\r\n    import tensorflow_datasets as tfds\r\n  File ""C:\\Users\\libof\\env1\\lib\\site-packages\\tensorflow_datasets\\__init__.py"", line 43, in <module>\r\n    import tensorflow_datasets.core.logging as _tfds_logging\r\n  File ""C:\\Users\\libof\\env1\\lib\\site-packages\\tensorflow_datasets\\core\\__init__.py"", line 22, in <module>\r\n    from tensorflow_datasets.core import community\r\n  File ""C:\\Users\\libof\\env1\\lib\\site-packages\\tensorflow_datasets\\core\\community\\__init__.py"", line 18, in <module>\r\n    from tensorflow_datasets.core.community.huggingface_wrapper import mock_builtin_to_use_gfile\r\n  File ""C:\\Users\\libof\\env1\\lib\\site-packages\\tensorflow_datasets\\core\\community\\huggingface_wrapper.py"", line 31, in <module>\r\n    from tensorflow_datasets.core import dataset_builder\r\n  File ""C:\\Users\\libof\\env1\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py"", line 34, in <module>\r\n    from tensorflow_datasets.core import dataset_info\r\n  File ""C:\\Users\\libof\\env1\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_info.py"", line 47, in <module>\r\n    from tensorflow_datasets.core import file_adapters\r\n  File ""C:\\Users\\libof\\env1\\lib\\site-packages\\tensorflow_datasets\\core\\file_adapters.py"", line 29, in <module>\r\n    from array_record.python import array_record_module\r\nImportError: cannot import name \'array_record_module\' from \'array_record.python\' (C:\\Users\\libof\\env1\\lib\\site-packages\\array_record\\python\\__init__.py)\r\n\r\nmy code is:\r\n`import os\r\nos.environ[\'CUDA_VISIBLE_DEVICES\'] = \'-1\'\r\n \r\nfrom mediapipe_model_maker import object_detector\r\n\r\ntrain_dataset_path = \'C:\\\\workspace\\\\imgupload\\\\img\\\\selected1\\\\bt3\\\\train\\\\shot\'\r\nvalidation_dataset_path = \'C:\\\\workspace\\\\imgupload\\\\img\\\\selected1\\\\bt3\\\\train\\\\shot\'\r\ncache_dir = \'C:\\\\workspace\\\\imgupload\\\\img\\\\selected1\\\\tmp\'\r\n\r\ntrain_data = object_detector.Dataset.from_pascal_voc_folder(\r\n    train_dataset_path,\r\n    cache_dir=cache_dir)\r\n \r\nvalidate_data = object_detector.Dataset.from_pascal_voc_folder(\r\n    validation_dataset_path,\r\n    cache_dir=cache_dir)\r\n\r\nhparams = object_detector.HParams(batch_size=8, learning_rate=0.3, epochs=50, export_dir=\'exported_model\')\r\noptions = object_detector.ObjectDetectorOptions(\r\n    supported_model=object_detector.SupportedModels.MOBILENET_V2,\r\n    hparams=hparams)\r\n\r\nmodel = object_detector.ObjectDetector.create(\r\n    train_data=train_data,\r\n    validation_data=validate_data,\r\n    options=options)\r\n\r\nloss, coco_metrics = model.evaluate(validate_data, batch_size=4)\r\nprint(f""Validation loss: {loss}"")\r\nprint(f""Validation coco metrics: {coco_metrics}"")\r\n\r\nmodel.export_model(\'dogs.tflite\')`\r\n\r\n![image](https://github.com/user-attachments/assets/b4efb490-ef13-41e3-8c4c-f8f36e419aa6)\r\n', 'Hi @libofei2004 ,\r\n\r\nI am not able to replicate this issue since i keep getting the below error, can you please upload a jupyter notebook with the code and the dataset so that i will be able to replicate this issue ?\r\n\r\n`    return cache_files.TFRecordCacheFiles(\r\n  File ""<string>"", line 6, in __init__\r\n  File ""/home/sawantkumar/work/python_wor/myenv/lib/python3.9/site-packages/mediapipe_model_maker/python/core/data/cache_files.py"", line 53, in __post_init__\r\n    raise ValueError(\r\nValueError: num_shards must be greater than 0, got 0`', '@sawantkumar  my code is shown above. I think the problem is caused by conflicting versions of dependencies.', '@tilakrayal I use ""pip3 install mediapipe-model-maker“ to install mediapipe-model-maker,  my version is 0.1.0.1,  but the latest version is 0.2.1.4 in https://pypi.org/project/mediapipe-model-maker/, if I use  pip3 install mediapipe_model_maker==0.2.1.4  to update, the error occured:\r\nERROR: Could not find a version that satisfies the requirement mediapipe_model_maker==0.2.1.4 (from versions: none)\r\nERROR: No matching distribution found for mediapipe_model_maker==0.2.1.4\r\n\r\nI don\'t know why?', 'Hi @libofei2004, there is probably some weird conflict w/ your previous installation.. can you try with a fresh conda environment or a fresh venv python environment? Let us know what happens.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71587"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71587"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

tf2.9.3

### Custom code

Yes

### OS platform and distribution

windows11

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I installed TFLite-Model-Maker with command : pip3 install tflite-model-maker , 
and run my code:

```
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
import numpy as np
print(""numpy version:"", np.__version__)
import os
import tensorflow as tf
from tflite_model_maker import model_spec
from tflite_model_maker import object_detector
from tflite_model_maker.object_detector import DataLoader

data_dir = 'C:\\workspace\\imgupload\\img\\selected1\\bt3\\train\\shot'

data_loader = DataLoader.from_pascal_voc(data_dir)

train_data, validation_data, test_data = data_loader.load()

model_spec = model_spec.get('efficientdet_lite0')

model = object_detector.create(train_data, model_spec=model_spec, validation_data=validation_data, epochs=50, batch_size=8, train_whole_model=True)

print(model.evaluate(test_data))

model.export(export_dir='./exported_model')
```

The error is reported:
FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.
  np.uint8, np.uint16, np.object, np.bool]
Traceback (most recent call last):
  File ""<frozen importlib._bootstrap>"", line 1007, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 986, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 680, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 790, in exec_module
  File ""<frozen importlib._bootstrap>"", line 228, in _call_with_frames_removed
  File ""C:\Users\libof\myenv1\lib\site-packages\tflite_model_maker\__init__.py"", line 44, in <module>
    from tflite_model_maker import audio_classifier
  File ""C:\Users\libof\myenv1\lib\site-packages\tflite_model_maker\audio_classifier\__init__.py"", line 24, in <module>
    from tensorflow_examples.lite.model_maker.core.data_util.audio_dataloader import DataLoader
  File ""C:\Users\libof\myenv1\lib\site-packages\tensorflow_examples\lite\model_maker\core\data_util\audio_dataloader.py"", line 27, in <module>
    from tensorflow_examples.lite.model_maker.core.task.model_spec import audio_spec
  File ""C:\Users\libof\myenv1\lib\site-packages\tensorflow_examples\lite\model_maker\core\task\model_spec\__init__.py"", line 20, in <module>
    from tensorflow_examples.lite.model_maker.core.task.model_spec import audio_spec
  File ""C:\Users\libof\myenv1\lib\site-packages\tensorflow_examples\lite\model_maker\core\task\model_spec\audio_spec.py"", line 29, in <module>
    from tensorflow_examples.lite.model_maker.core.task import model_util
  File ""C:\Users\libof\myenv1\lib\site-packages\tensorflow_examples\lite\model_maker\core\task\model_util.py"", line 28, in <module>
    from tensorflowjs.converters import converter as tfjs_converter
  File ""C:\Users\libof\myenv1\lib\site-packages\tensorflowjs\__init__.py"", line 21, in <module>
    from tensorflowjs import converters
  File ""C:\Users\libof\myenv1\lib\site-packages\tensorflowjs\converters\__init__.py"", line 21, in <module>
    from tensorflowjs.converters.converter import convert
  File ""C:\Users\libof\myenv1\lib\site-packages\tensorflowjs\converters\converter.py"", line 35, in <module>
    from tensorflowjs.converters import keras_h5_conversion as conversion
  File ""C:\Users\libof\myenv1\lib\site-packages\tensorflowjs\converters\keras_h5_conversion.py"", line 33, in <module>
    from tensorflowjs import write_weights  # pylint: disable=import-error
  File ""C:\Users\libof\myenv1\lib\site-packages\tensorflowjs\write_weights.py"", line 25, in <module>
    from tensorflowjs import read_weights
  File ""C:\Users\libof\myenv1\lib\site-packages\tensorflowjs\read_weights.py"", line 28, in <module>
    np.uint8, np.uint16, np.object, np.bool]
  File ""C:\Users\libof\myenv1\lib\site-packages\numpy\__init__.py"", line 353, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'object'.
`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. 
The aliases was originally deprecated in NumPy 1.20;

![image](https://github.com/tensorflow/tensorflow/assets/10001548/a4184a14-8bda-45a6-a1c5-c211eafb0959)
![image](https://github.com/tensorflow/tensorflow/assets/10001548/b6c2b355-4b7c-458d-9e8b-59f7418b09ee)




### Standalone code to reproduce the issue

```shell
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
import numpy as np
print(""numpy version:"", np.__version__)
import os
import tensorflow as tf
from tflite_model_maker import model_spec
from tflite_model_maker import object_detector
from tflite_model_maker.object_detector import DataLoader

data_dir = 'C:\\workspace\\imgupload\\img\\selected1\\bt3\\train\\shot'

data_loader = DataLoader.from_pascal_voc(data_dir)

train_data, validation_data, test_data = data_loader.load()

model_spec = model_spec.get('efficientdet_lite0')

model = object_detector.create(train_data, model_spec=model_spec, validation_data=validation_data, epochs=50, batch_size=8, train_whole_model=True)

print(model.evaluate(test_data))

model.export(export_dir='./exported_model')
```


### Relevant log output

_No response_"
2403211835,71666,Cannot create BertQA model with  tflite-model-maker==0.4.2 (or 4.3),closed,2024-07-11 13:35:48+00:00,2024-08-09T01:55:16Z,2024-08-09T01:55:11Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/71666,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'TF 2.8', 'TFLiteModelMaker']","['@AmarOk1412 Creating a BERT QA model with a TensorFlow Lite Model Maker can sometimes be tricky due to compatibility issues. Could you please upgrade to the latest TF version and let us know the outcome?\r\nThank you!', 'I can\'t because I can\'t install it with pip (tried python 3.8, 3.9, 3.10, 3.11 and 3.12)\r\n\r\n```\r\nERROR: pip\'s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\nscann 1.2.6 requires tensorflow~=2.8.0, but you have tensorflow 2.11.0 which is incompatible.\r\n\r\n\r\n# Then running:\r\n  warnings.warn(\r\nTraceback (most recent call last):\r\n  File ""train.py"", line 1, in <module>\r\n    from tflite_model_maker import model_spec\r\n  File ""/home/amarok/Projects/PlanEat/models/ingredients/.venv/lib64/python3.8/site-packages/tflite_model_maker/__init__.py"", line 51, in <module>\r\n    from tflite_model_maker import searcher\r\n  File ""/home/amarok/Projects/PlanEat/models/ingredients/.venv/lib64/python3.8/site-packages/tflite_model_maker/searcher/__init__.py"", line 25, in <module>\r\n    from tensorflow_examples.lite.model_maker.core.task.searcher import ExportFormat\r\n  File ""/home/amarok/Projects/PlanEat/models/ingredients/.venv/lib64/python3.8/site-packages/tensorflow_examples/lite/model_maker/core/task/searcher.py"", line 30, in <module>\r\n    from tensorflow_examples.lite.model_maker.core.utils import ondevice_scann_builder\r\n  File ""/home/amarok/Projects/PlanEat/models/ingredients/.venv/lib64/python3.8/site-packages/tensorflow_examples/lite/model_maker/core/utils/ondevice_scann_builder.py"", line 17, in <module>\r\n    from scann.proto import scann_pb2\r\n  File ""/home/amarok/Projects/PlanEat/models/ingredients/.venv/lib64/python3.8/site-packages/scann/__init__.py"", line 2, in <module>\r\n    from scann.scann_ops.py import scann_ops\r\n  File ""/home/amarok/Projects/PlanEat/models/ingredients/.venv/lib64/python3.8/site-packages/scann/scann_ops/py/scann_ops.py"", line 23, in <module>\r\n    _scann_ops_so = tf.load_op_library(\r\n  File ""/home/amarok/Projects/PlanEat/models/ingredients/.venv/lib64/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 54, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\ntensorflow.python.framework.errors_impl.NotFoundError: /home/amarok/Projects/PlanEat/models/ingredients/.venv/lib64/python3.8/site-packages/scann/scann_ops/cc/_scann_ops.so: undefined symbol: _ZN4absl12lts_2021032416numbers_internal9kHexTableE\r\n```\r\n\r\nBut here is a version with 2.13 (Scann 1.2.6 doesn\'t like Python 3.10, so I used 3.8 and 2.13 is the max)\r\n\r\n```\r\nPROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python  python train.py\r\n2024-07-12 10:29:57.563757: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\r\n2024-07-12 10:29:57.565045: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\r\n2024-07-12 10:29:57.590564: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\r\n2024-07-12 10:29:57.590860: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\r\nTo enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2024-07-12 10:29:58.233409: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\r\n/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \r\n\r\nTensorFlow Addons (TFA) has ended development and introduction of new features.\r\nTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\r\nPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \r\n\r\nFor more information see: https://github.com/tensorflow/addons/issues/2807 \r\n\r\n  warnings.warn(\r\nEpoch 1/2\r\n2024-07-12 10:38:04.953281: W tensorflow/core/framework/op_kernel.cc:1805] OP_REQUIRES failed at cast_op.cc:121 : UNIMPLEMENTED: Cast string to float is not supported\r\n2024-07-12 10:38:05.100766: W tensorflow/core/framework/op_kernel.cc:1805] OP_REQUIRES failed at cast_op.cc:121 : UNIMPLEMENTED: Cast string to float is not supported\r\nTraceback (most recent call last):\r\n  File ""/home/amarok/Projects/PlanEat/models/ingredients/train.py"", line 19, in <module>\r\n    model = question_answer.create(train_data, model_spec=spec, epochs=2, steps_per_epoch=50)\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/question_answer.py"", line 228, in create\r\n    model.train(train_data, epochs, batch_size, steps_per_epoch)\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/question_answer.py"", line 79, in train\r\n    self.model = self.model_spec.train(\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/model_spec/text_spec.py"", line 944, in train\r\n    bert_model.fit(x=train_ds, epochs=epochs, **kwargs)\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/keras/src/utils/traceback_utils.py"", line 70, in error_handler\r\n    raise e.with_traceback(filtered_tb) from None\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow/python/eager/execute.py"", line 53, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.UnimplementedError: Graph execution error:\r\n\r\nDetected at node \'Adam/Cast\' defined at (most recent call last):\r\n    File ""/home/amarok/Projects/PlanEat/models/ingredients/train.py"", line 19, in <module>\r\n      model = question_answer.create(train_data, model_spec=spec, epochs=2, steps_per_epoch=50)\r\n    File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/question_answer.py"", line 228, in create\r\n      model.train(train_data, epochs, batch_size, steps_per_epoch)\r\n    File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/question_answer.py"", line 79, in train\r\n      self.model = self.model_spec.train(\r\n    File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/model_spec/text_spec.py"", line 944, in train\r\n      bert_model.fit(x=train_ds, epochs=epochs, **kwargs)\r\n    File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/keras/src/utils/traceback_utils.py"", line 65, in error_handler\r\n      return fn(*args, **kwargs)\r\n    File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/keras/src/engine/training.py"", line 1742, in fit\r\n      tmp_logs = self.train_function(iterator)\r\n    File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/keras/src/engine/training.py"", line 1338, in train_function\r\n      return step_function(self, iterator)\r\n    File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/keras/src/engine/training.py"", line 1322, in step_function\r\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/keras/src/engine/training.py"", line 1303, in run_step\r\n      outputs = model.train_step(data)\r\n    File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/keras/src/engine/training.py"", line 1084, in train_step\r\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\r\n    File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/keras/src/optimizers/optimizer.py"", line 544, in minimize\r\n      self.apply_gradients(grads_and_vars)\r\n    File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/official/nlp/optimization.py"", line 175, in apply_gradients\r\n      return super(AdamWeightDecay, self).apply_gradients(\r\n    File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/keras/src/optimizers/optimizer.py"", line 1230, in apply_gradients\r\n      return super().apply_gradients(grads_and_vars, name=name)\r\n    File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/keras/src/optimizers/optimizer.py"", line 650, in apply_gradients\r\n      self._apply_weight_decay(trainable_variables)\r\n    File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/keras/src/optimizers/optimizer.py"", line 1249, in _apply_weight_decay\r\n      tf.__internal__.distribute.interim.maybe_merge_call(\r\n    File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/keras/src/optimizers/optimizer.py"", line 1245, in distributed_apply_weight_decay\r\n      distribution.extended.update(\r\n    File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/keras/src/optimizers/optimizer.py"", line 1241, in weight_decay_fn\r\n      wd = tf.cast(self.weight_decay, variable.dtype)\r\nNode: \'Adam/Cast\'\r\nCast string to float is not supported\r\n\t [[{{node Adam/Cast}}]] [Op:__inference_train_function_181018]\r\n(.venv3.9)  ✘ amarok@L-SBLIN \ue0b0 ~/Projects/PlanEat/models/ingredients \ue0b0 \ue0a0 main ± \ue0b0 pip freeze             \r\nabsl-py==1.4.0\r\narray_record==0.5.1\r\nastunparse==1.6.3\r\nattrs==23.2.0\r\naudioread==3.0.1\r\nbleach==6.1.0\r\ncachetools==5.3.3\r\ncertifi==2024.7.4\r\ncffi==1.16.0\r\ncharset-normalizer==3.3.2\r\nclick==8.1.7\r\ncycler==0.12.1\r\nCython==3.0.10\r\ndataclasses==0.6\r\ndecorator==5.1.1\r\ndm-tree==0.1.8\r\netils==1.5.2\r\nfire==0.6.0\r\nflatbuffers==24.3.25\r\nfsspec==2024.6.1\r\ngast==0.4.0\r\ngin-config==0.5.0\r\ngoogle-api-core==2.19.1\r\ngoogle-api-python-client==2.137.0\r\ngoogle-auth==2.32.0\r\ngoogle-auth-httplib2==0.2.0\r\ngoogle-auth-oauthlib==1.0.0\r\ngoogle-cloud-bigquery==3.25.0\r\ngoogle-cloud-core==2.4.1\r\ngoogle-crc32c==1.5.0\r\ngoogle-pasta==0.2.0\r\ngoogle-resumable-media==2.7.1\r\ngoogleapis-common-protos==1.63.1\r\ngrpcio==1.64.1\r\ngrpcio-status==1.48.2\r\nh5py==3.11.0\r\nhttplib2==0.22.0\r\nidna==3.7\r\nimportlib_metadata==8.0.0\r\nimportlib_resources==6.4.0\r\njoblib==1.4.2\r\nkaggle==1.6.14\r\nkeras==2.13.1\r\nKeras-Preprocessing==1.1.2\r\nkiwisolver==1.4.5\r\nlibclang==18.1.1\r\nlibrosa==0.8.1\r\nllvmlite==0.43.0\r\nlxml==5.2.2\r\nMarkdown==3.6\r\nmarkdown-it-py==3.0.0\r\nMarkupSafe==2.1.5\r\nmatplotlib==3.4.3\r\nmdurl==0.1.2\r\nml-dtypes==0.4.0\r\nnamex==0.0.8\r\nneural-structured-learning==1.4.0\r\nnumba==0.60.0\r\nnumpy==1.23.0\r\noauthlib==3.2.2\r\nopencv-python-headless==4.10.0.84\r\nopt-einsum==3.3.0\r\noptree==0.12.1\r\npackaging==20.9\r\npandas==2.2.2\r\npillow==10.4.0\r\nplatformdirs==4.2.2\r\npooch==1.8.2\r\npromise==2.3\r\nproto-plus==1.24.0\r\nprotobuf==4.25.3\r\npsutil==6.0.0\r\npy-cpuinfo==9.0.0\r\npyasn1==0.6.0\r\npyasn1_modules==0.4.0\r\npybind11==2.13.1\r\npycparser==2.22\r\nPygments==2.18.0\r\npyparsing==3.1.2\r\npython-dateutil==2.9.0.post0\r\npython-slugify==8.0.4\r\npytz==2024.1\r\nPyYAML==6.0.1\r\nrequests==2.32.3\r\nrequests-oauthlib==2.0.0\r\nresampy==0.4.3\r\nrich==13.7.1\r\nrsa==4.9\r\nscann==1.2.10\r\nscikit-learn==1.5.1\r\nscipy==1.13.1\r\nsentencepiece==0.2.0\r\nsix==1.16.0\r\nsounddevice==0.4.7\r\nsoundfile==0.12.1\r\ntensorboard==2.13.0\r\ntensorboard-data-server==0.7.2\r\ntensorboard-plugin-wit==1.8.1\r\ntensorflow==2.13.1\r\ntensorflow-addons==0.23.0\r\ntensorflow-datasets==4.9.0\r\ntensorflow-estimator==2.13.0\r\ntensorflow-hub==0.12.0\r\ntensorflow-io-gcs-filesystem==0.37.1\r\ntensorflow-metadata==1.13.0\r\ntensorflow-model-optimization==0.8.0\r\ntensorflowjs==3.18.0\r\ntermcolor==2.4.0\r\ntext-unidecode==1.3\r\ntf-models-official==2.3.0\r\ntf-slim==1.1.0\r\ntflite-model-maker==0.4.3\r\ntflite-support==0.4.4\r\nthreadpoolctl==3.5.0\r\ntoml==0.10.2\r\ntqdm==4.66.4\r\ntypeguard==2.13.3\r\ntyping_extensions==4.5.0\r\ntzdata==2024.1\r\nuritemplate==4.1.1\r\nurllib3==1.25.11\r\nwebencodings==0.5.1\r\nWerkzeug==3.0.3\r\nwrapt==1.16.0\r\nzipp==3.19.2\r\n```\r\n\r\nThen with tensorflow 2.17:\r\n\r\n```\r\n python train.py                           \r\n2024-07-12 10:59:02.240329: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\r\n2024-07-12 10:59:02.240648: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\r\n2024-07-12 10:59:02.243211: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\r\n2024-07-12 10:59:02.249174: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n2024-07-12 10:59:02.258851: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n2024-07-12 10:59:02.261519: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n2024-07-12 10:59:02.269337: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\r\nTo enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2024-07-12 10:59:02.878013: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\r\nTraceback (most recent call last):\r\n  File ""/home/amarok/Projects/PlanEat/models/ingredients/train.py"", line 1, in <module>\r\n    from tflite_model_maker import model_spec\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tflite_model_maker/__init__.py"", line 44, in <module>\r\n    from tflite_model_maker import audio_classifier\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tflite_model_maker/audio_classifier/__init__.py"", line 24, in <module>\r\n    from tensorflow_examples.lite.model_maker.core.data_util.audio_dataloader import DataLoader\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/data_util/audio_dataloader.py"", line 27, in <module>\r\n    from tensorflow_examples.lite.model_maker.core.task.model_spec import audio_spec\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/model_spec/__init__.py"", line 20, in <module>\r\n    from tensorflow_examples.lite.model_maker.core.task.model_spec import audio_spec\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/model_spec/audio_spec.py"", line 30, in <module>\r\n    from tensorflow_examples.lite.model_maker.core.task import model_util\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/model_util.py"", line 28, in <module>\r\n    from tensorflowjs.converters import converter as tfjs_converter\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflowjs/__init__.py"", line 21, in <module>\r\n    from tensorflowjs import converters\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflowjs/converters/__init__.py"", line 21, in <module>\r\n    from tensorflowjs.converters.converter import convert\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflowjs/converters/converter.py"", line 37, in <module>\r\n    from tensorflowjs.converters import tf_saved_model_conversion_v2\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflowjs/converters/tf_saved_model_conversion_v2.py"", line 42, in <module>\r\n    import tensorflow_hub as hub\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_hub/__init__.py"", line 88, in <module>\r\n    from tensorflow_hub.estimator import LatestModuleExporter\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_hub/estimator.py"", line 62, in <module>\r\n    class LatestModuleExporter(tf.compat.v1.estimator.Exporter):\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow/python/util/module_wrapper.py"", line 232, in _getattr\r\n    attr = getattr(self._tfmw_wrapped_module, name)\r\nAttributeError: module \'tensorflow.compat.v1\' has no attribute \'estimator\'\r\n```\r\n\r\nAnd 2.15.0\r\n\r\n```\r\n2024-07-12 11:01:56.289875: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\r\n2024-07-12 11:01:56.291246: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\r\n2024-07-12 11:01:56.313500: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n2024-07-12 11:01:56.313534: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n2024-07-12 11:01:56.314475: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n2024-07-12 11:01:56.318960: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\r\n2024-07-12 11:01:56.319116: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\r\nTo enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2024-07-12 11:01:56.967406: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\r\nTraceback (most recent call last):\r\n  File ""/home/amarok/Projects/PlanEat/models/ingredients/train.py"", line 1, in <module>\r\n    from tflite_model_maker import model_spec\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tflite_model_maker/__init__.py"", line 44, in <module>\r\n    from tflite_model_maker import audio_classifier\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tflite_model_maker/audio_classifier/__init__.py"", line 24, in <module>\r\n    from tensorflow_examples.lite.model_maker.core.data_util.audio_dataloader import DataLoader\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/data_util/audio_dataloader.py"", line 27, in <module>\r\n    from tensorflow_examples.lite.model_maker.core.task.model_spec import audio_spec\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/model_spec/__init__.py"", line 20, in <module>\r\n    from tensorflow_examples.lite.model_maker.core.task.model_spec import audio_spec\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/model_spec/audio_spec.py"", line 30, in <module>\r\n    from tensorflow_examples.lite.model_maker.core.task import model_util\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/model_util.py"", line 28, in <module>\r\n    from tensorflowjs.converters import converter as tfjs_converter\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflowjs/__init__.py"", line 21, in <module>\r\n    from tensorflowjs import converters\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflowjs/converters/__init__.py"", line 21, in <module>\r\n    from tensorflowjs.converters.converter import convert\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflowjs/converters/converter.py"", line 37, in <module>\r\n    from tensorflowjs.converters import tf_saved_model_conversion_v2\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflowjs/converters/tf_saved_model_conversion_v2.py"", line 42, in <module>\r\n    import tensorflow_hub as hub\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_hub/__init__.py"", line 93, in <module>\r\n    from tensorflow_hub.feature_column_v2 import text_embedding_column_v2\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_hub/feature_column_v2.py"", line 24, in <module>\r\n    from tensorflow_hub import keras_layer\r\n  File ""/home/amarok/Projects/PlanEat/.venv3.9/lib64/python3.9/site-packages/tensorflow_hub/keras_layer.py"", line 27, in <module>\r\n    from tensorflow.python.training.tracking import data_structures\r\nModuleNotFoundError: No module named \'tensorflow.python.training.tracking\'\r\n(.venv3.9)  ✘ amarok@L-SBLIN \ue0b0 ~/Projects/PlanEat/models/ingredients \ue0b0 \ue0a0 main ± \ue0b0 pip freeze                  \r\nabsl-py==1.4.0\r\narray_record==0.5.1\r\nastunparse==1.6.3\r\nattrs==23.2.0\r\naudioread==3.0.1\r\nbleach==6.1.0\r\ncachetools==5.3.3\r\ncertifi==2024.7.4\r\ncffi==1.16.0\r\ncharset-normalizer==3.3.2\r\nclick==8.1.7\r\ncycler==0.12.1\r\nCython==3.0.10\r\ndataclasses==0.6\r\ndecorator==5.1.1\r\ndm-tree==0.1.8\r\netils==1.5.2\r\nfire==0.6.0\r\nflatbuffers==24.3.25\r\nfsspec==2024.6.1\r\ngast==0.4.0\r\ngin-config==0.5.0\r\ngoogle-api-core==2.19.1\r\ngoogle-api-python-client==2.137.0\r\ngoogle-auth==2.32.0\r\ngoogle-auth-httplib2==0.2.0\r\ngoogle-auth-oauthlib==1.0.0\r\ngoogle-cloud-bigquery==3.25.0\r\ngoogle-cloud-core==2.4.1\r\ngoogle-crc32c==1.5.0\r\ngoogle-pasta==0.2.0\r\ngoogle-resumable-media==2.7.1\r\ngoogleapis-common-protos==1.63.1\r\ngrpcio==1.64.1\r\ngrpcio-status==1.48.2\r\nh5py==3.11.0\r\nhttplib2==0.22.0\r\nidna==3.7\r\nimportlib_metadata==8.0.0\r\nimportlib_resources==6.4.0\r\njoblib==1.4.2\r\nkaggle==1.6.14\r\nkeras==3.4.1\r\nKeras-Preprocessing==1.1.2\r\nkiwisolver==1.4.5\r\nlibclang==18.1.1\r\nlibrosa==0.8.1\r\nllvmlite==0.43.0\r\nlxml==5.2.2\r\nMarkdown==3.6\r\nmarkdown-it-py==3.0.0\r\nMarkupSafe==2.1.5\r\nmatplotlib==3.4.3\r\nmdurl==0.1.2\r\nml-dtypes==0.2.0\r\nnamex==0.0.8\r\nneural-structured-learning==1.4.0\r\nnumba==0.60.0\r\nnumpy==1.23.4\r\noauthlib==3.2.2\r\nopencv-python-headless==4.10.0.84\r\nopt-einsum==3.3.0\r\noptree==0.12.1\r\npackaging==20.9\r\npandas==2.2.2\r\npillow==10.4.0\r\nplatformdirs==4.2.2\r\npooch==1.8.2\r\npromise==2.3\r\nproto-plus==1.24.0\r\nprotobuf==4.25.3\r\npsutil==6.0.0\r\npy-cpuinfo==9.0.0\r\npyasn1==0.6.0\r\npyasn1_modules==0.4.0\r\npybind11==2.13.1\r\npycparser==2.22\r\nPygments==2.18.0\r\npyparsing==3.1.2\r\npython-dateutil==2.9.0.post0\r\npython-slugify==8.0.4\r\npytz==2024.1\r\nPyYAML==6.0.1\r\nrequests==2.32.3\r\nrequests-oauthlib==2.0.0\r\nresampy==0.4.3\r\nrich==13.7.1\r\nrsa==4.9\r\nscann==1.2.10\r\nscikit-learn==1.5.1\r\nscipy==1.13.1\r\nsentencepiece==0.2.0\r\nsix==1.16.0\r\nsounddevice==0.4.7\r\nsoundfile==0.12.1\r\ntensorboard==2.15.2\r\ntensorboard-data-server==0.7.2\r\ntensorboard-plugin-wit==1.8.1\r\ntensorflow==2.15.0\r\ntensorflow-addons==0.23.0\r\ntensorflow-datasets==4.9.0\r\ntensorflow-estimator==2.15.0\r\ntensorflow-hub==0.12.0\r\ntensorflow-io-gcs-filesystem==0.37.1\r\ntensorflow-metadata==1.13.0\r\ntensorflow-model-optimization==0.8.0\r\ntensorflowjs==3.18.0\r\ntermcolor==2.4.0\r\ntext-unidecode==1.3\r\ntf-models-official==2.3.0\r\ntf-slim==1.1.0\r\ntflite-model-maker==0.4.3\r\ntflite-support==0.4.4\r\nthreadpoolctl==3.5.0\r\ntoml==0.10.2\r\ntqdm==4.66.4\r\ntypeguard==2.13.3\r\ntyping_extensions==4.5.0\r\ntzdata==2024.1\r\nuritemplate==4.1.1\r\nurllib3==1.25.11\r\nwebencodings==0.5.1\r\nWerkzeug==3.0.3\r\nwrapt==1.14.1\r\nzipp==3.19.2\r\n```', 'So the question is, is there a tuple python/tensorflow/tflite-model-maker/numpy/keras I can try cause compatibility seems a clusterfuck', 'I also tried https://www.tensorflow.org/lite/models/modify/model_maker/question_answer that give the same result (because my model is Squad v2.0, so I tried Squad v1).', 'Hi @pkgoogle ,\r\n\r\nI have also been running into tflite model maker installation issues, where it just goes in a loop of downloading bunch of files. \r\n\r\n`!pip install -q tflite-model-maker`\r\n\r\n` Preparing metadata (setup.py) ... done\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.2/5.2 MB 48.1 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 74.9 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.3/80.3 kB 7.8 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 632.0/632.0 MB 2.1 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 621.0/621.0 MB 2.2 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 620.6/620.6 MB 1.6 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 620.6/620.6 MB 2.2 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 620.6/620.6 MB 2.2 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 620.6/620.6 MB 1.9 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 620.6/620.6 MB 1.6 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 620.5/620.5 MB 2.2 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 607.5/607.5 MB 1.7 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 607.5/607.5 MB 2.3 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 606.2/606.2 MB 2.0 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 606.2/606.2 MB 940.0 kB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 606.2/606.2 MB 2.5 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 605.8/605.8 MB 2.5 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 604.7/604.7 MB 2.0 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 604.5/604.5 MB 2.1 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 604.6/604.6 MB 2.0 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 604.5/604.5 MB 2.1 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 604.4/604.4 MB 2.3 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 604.4/604.4 MB 1.2 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 604.4/604.4 MB 2.0 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 600.4/600.4 MB 1.3 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 600.3/600.3 MB 2.2 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 600.0/600.0 MB 1.4 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 590.9/590.9 MB 2.0 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 590.9/590.9 MB 1.9 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 591.0/591.0 MB 1.3 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 591.0/591.0 MB 1.6 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 591.0/591.0 MB 1.8 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 591.0/591.0 MB 1.6 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 590.9/590.9 MB 1.2 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 590.9/590.9 MB 2.5 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 590.7/590.7 MB 2.4 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 590.7/590.7 MB 1.8 MB/s eta 0:00:00\r\n     ━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 175.1/590.7 MB 51.7 MB/s eta 0:00:09\r\nERROR: Operation cancelled by user`\r\nI am not sure if this issue can be resolved through mediapipe model maker , can you please take a look ?', 'Hi @AmarOk1412, please either use mediapipe or please use a modern LLM for your use case, BertQA is quite outdated so the tools and infrastructure to help it generally are less stable, may I recommend https://huggingface.co/google/gemma-2b-it for your use case?', ""I'll, converting the models may take a while as i'm in vacations. But will try. For now, I tried llama2 but it wasn't good, will try gemma"", ""Hi @AmarOk1412, awesome, let us know if somehow you feel Gemma isn't up to par as well so that we may be able to debug whether it is a use issue or not."", ""Hi @AmarOk1412  It appears that there might be some issues with the installation process. Let's explore potential solutions:\r\n\r\n**1.Dependency Resolution:**\r\n    - The error you encountered might be related to dependency conflicts. To address this, consider the following steps:\r\n        - Loosen Version Constraints: Modify your package version constraints to allow more flexibility. Sometimes, specifying a narrower range can lead to conflicts.\r\n        - Remove Specific Versions: Remove specific package versions to let pip attempt to resolve the dependency conflict algorithmically.\r\n\r\nhttps://stackoverflow.com/questions/77537307/error-cannot-install-tflite-model-maker-the-conflict-is-caused-by-other-module\r\n\r\n**2.Fallback Runtime Version in Colab**:\r\n    - If you're using Colab, try using the fallback runtime version option. Choose Python 3.9 and install tflite-model-maker. You might encounter a runtime error, but it can be safely ignored.\r\n\r\nhttps://discuss.tensorflow.org/t/tflite-model-maker-installation/16577/26\r\n\r\n**3.Nightly Version:**\r\n    - While you mentioned concerns about stability, consider using the nightly version of tflite-model-maker. It might provide a workaround until the issue is resolved.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/71666\r\n"", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71666"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71666"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.8.4

### Custom code

Yes

### OS platform and distribution

Fedora 40

### Mobile device

_No response_

### Python version

3.8.19

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

CPU

### GPU model and memory

_No response_

### Current behavior?

I'm trying to train a BERTQA model (Squad v2 format) with tflite-model-maker in order to use it on Android

Here is the code:

```python
from tflite_model_maker import model_spec
from tflite_model_maker import question_answer
from tflite_model_maker.question_answer import DataLoader

import tensorflow as tf
assert tf.__version__.startswith('2')
tf.get_logger().setLevel('ERROR')

spec = model_spec.get('mobilebert_qa_squad')

train_data = DataLoader.from_squad(filename='final.json',model_spec=spec,is_training=True,version_2_with_negative=True)
test_data = DataLoader.from_squad(filename='final_val.json',model_spec=spec,is_training=False,version_2_with_negative=True)

model = question_answer.create(train_data, model_spec=spec, epochs=2)

print(model.summary())

res = model.evaluate(test_data) # <==== RES IS NONE

print('Loss:', res[0])
print('Accuracy:', res[1])

model.export(export_dir='mobilebert',
    tflite_filename='ingredients.tflite',
    label_filename='labels.txt',
    vocab_filename='vocab.txt',
    saved_model_filename='saved_model',
    tfjs_folder_name='tfjs',
    export_format=None)
```


[final_val.json](https://github.com/user-attachments/files/16177865/final_val.json)
[final.json](https://github.com/user-attachments/files/16177866/final.json)

### Standalone code to reproduce the issue

```shell
pip install tflite-model-maker==0.4.2
pip install tensorflow-addons==0.17.1
pip install tensorflow-cpu==2.8.4
```

Here is the output of the previous script:

```
(.venv)  main ±  python train.py
WARNING:absl:Could not find answer: 'd'ail,' vs. 'd' ail,'
2024-07-11 09:07:50.409590: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/2
80/80 [==============================] - 528s 6s/step - loss: 0.6571 - start_positions_loss: 0.5835 - end_positions_loss: 0.7307
Epoch 2/2
80/80 [==============================] - 505s 6s/step - loss: 0.1952 - start_positions_loss: 0.1642 - end_positions_loss: 0.2262
Model: ""model""
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_word_ids (InputLayer)    [(None, 384)]        0           []                               
                                                                                                  
 input_mask (InputLayer)        [(None, 384)]        0           []                               
                                                                                                  
 input_type_ids (InputLayer)    [(None, 384)]        0           []                               
                                                                                                  
 hub_keras_layer_v1v2 (HubKeras  {'end_logits': (Non  24582914   ['input_word_ids[0][0]',         
 LayerV1V2)                     e, 384),                          'input_mask[0][0]',             
                                 'start_logits': (N               'input_type_ids[0][0]']         
                                one, 384)}                                                        
                                                                                                  
 start_positions (Lambda)       (None, 384)          0           ['hub_keras_layer_v1v2[0][1]']   
                                                                                                  
 end_positions (Lambda)         (None, 384)          0           ['hub_keras_layer_v1v2[0][0]']   
                                                                                                  
==================================================================================================
Total params: 24,582,914
Trainable params: 24,582,914
Non-trainable params: 0
__________________________________________________________________________________________________
None
Traceback (most recent call last):
  File ""train.py"", line 25, in <module>
    print('Loss:', res[0])
KeyError: 0
```


### Relevant log output

_No response_"
2406814580,71809,GPU delegate and NNAPIDelegate results diverging significantly for a transformer model,closed,2024-07-13 09:16:14+00:00,2024-08-09T01:55:13Z,2024-08-09T01:55:10Z,sawantkumar,,https://github.com/tensorflow/tensorflow/issues/71809,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'type:performance', 'TFLiteGpuDelegate', 'TF 2.15']","['Hi @pulkitagarawal ,\r\n\r\nCan you please provide me the conversion script and also the converted tflite model if possible?', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71809"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71809"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.15

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

Android Snapdragon 855 (Samsung Fold5/S24Ultra)

### Python version

3.11
Huggingface transformer 4.21

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I have converted a transformer model(https://huggingface.co/Salesforce/blip-vqa-base) as tflite for running on an Android device.
Blipvqa consists of 3 nested models vision_encoder, text_encoder and text_decoder.
I seperated the vision_encoder as seperate tensorflow model and converted it as tflite.
The model works perfectly fine on CPU.

When running the same tflite model on GPU there were few ops like Stridedslice reshape(5d) etc. Which were throwing error with GPUdelegate.
So before conversion i rewired few exiting operations to support the same on GPU.
Now the model runs fine on GPU delegate but the results of CPU(NNAPIdelegate) and GPU(GPUDelegate) are different and diverging significantly. 

I am using float32 weights and have set precisionlossallowed as false for GPU delegate to avoid any rounding off errors.
Even after running it with float32 precision the output is very different of GPUdelagte.

When i debugged the output layer by layer i found that the result starts diverging from the first Conv2D layer and the divergence grows significantly after multiple layers of vision encoder model.

I am unable to comprehend why even for a float32 weight the output of GPU delegate varies.
If this is the case then such deep networks of transformers models will always produce poor outputs on Android GPU delegates.


### Standalone code to reproduce the issue

```shell
https://github.com/huggingface/transformers/blob/main/src/transformers/models/blip/modeling_tf_blip.py

In above code refer to class TFBlipVisionEmbeddings(keras.layers.Layer)

This has a Conv2d operation which when inspected produces different results on CPU and GPU of Android.
The issue is not just with the Conv2d. Later in other layers of TFBlipVisionModel(TFBlipPreTrainedModel) the same divergence explodes for further operations.
I have used the .h5 weights provided on hugging face blipvqa for loading the model.

Any suggestions how to make sure that the output stays close for NNApiDelegate and GPUdelegate.
```


### Relevant log output

_No response_"
2407480075,71829,Accuracy Drop Across TensorFlow Versions When Using Keras 3 Instead of Keras 2,closed,2024-07-14 15:21:25+00:00,2024-07-15T17:18:16Z,2024-07-15T17:18:14Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/71829,"['type:bug', 'comp:keras', '2.17']","['\xa0 您好，邮件已经收到，我会尽快处理的。谢谢', 'Should this be opened against Keras repo?', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71829"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71829"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.15.1, 2.16.2, 2.17.0

### Custom code

Yes

### OS platform and distribution

Linux

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

As mentioned [here](https://github.com/tensorflow/tensorflow/issues/63362#issuecomment-2226996257), a drop in model results was observed in the new version of TensorFlow using the new Keras.

I'm using a CNN+BLSTM+CTC for handwriting recognition tests, and only `tf.keras.layers`, `tf.nn.ctc_loss`, and `tf.nn.ctc_beam_search_decoder` as the API base. So I expanded the tests and indeed observed the following results.

As a comment, the loss didn't reach the minimum during training with the new keras. So I also tried to find the root of the problem in default parameter differences between keras and tf.keras, but without success.

```
Version                         Results                     Comment
2.15.1                          (CER ~4.6 and WER ~12.5) -- no messages
2.16.2                          (CER ~5.7 and WER ~15.4) -- PTX messages
2.16.2    + TF_USE_LEGACY_KERAS (CER ~4.7 and WER ~12.0) -- PTX messages
2.17.0rc0                       (CER ~5.8 and WER ~15.6) -- numa and gpu_timer messages
2.17.0rc0 + TF_USE_LEGACY_KERAS (CER ~4.8 and WER ~13.0) -- numa and gpu_timer messages
2.17.0rc1                       (CER ~5.2 and WER ~14.8) -- numa and gpu_timer messages
2.17.0rc1 + TF_USE_LEGACY_KERAS (CER ~4.8 and WER ~13.2) -- numa and gpu_timer messages
2.17.0                          (CER ~5.4 and WER ~16.0) -- numa and gpu_timer messages
2.17.0    + TF_USE_LEGACY_KERAS (CER ~4.6 and WER ~12.6) -- numa and gpu_timer messages
```"
2407596792,71833,Inconsistent results from distributed training of models containing `TimeDistributed` or `SeparableConv2D` ,closed,2024-07-14 21:08:50+00:00,2024-09-04T08:06:26Z,2024-08-23T01:50:35Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/71833,"['stat:awaiting response', 'type:bug', 'comp:dist-strat', '2.17']","['@jiannanWang,\r\nLooks like this is an issue with the keras3.0 which by default with tensorflow v2.16. Please allow some time to deepdive into this issue and update the same. Meanwhile could you please try with the latest tensorflowv2.17 and the latest keras-nightly as well. Thank you!', 'Thank you for your reply! The reproduction code in the original post is using the nightly version `keras-nightly-3.4.1.dev2024071403` and `tf-nightly-2.18.0.dev20240710`.\r\n\r\nI then tried the latest keras-nightly as of today, which is `3.4.1.dev2024071603`. The inconsistencies become smaller, with `6.7055225e-08` in the timedistributed_lstm model and `0.0029296875` in the separableconv2d model. The colab links are copied below:\r\n\r\n`tf-nightly-2.18.0.dev20240710` + `keras-nightly-3.4.1.dev2024071603`\r\nModel with timedistributed_lstm\r\nhttps://colab.research.google.com/drive/1mqr9UMGta3utoRtF_kUha00J2KuOV2vF?usp=sharing\r\n\r\nModel with separableconv2d\r\nhttps://colab.research.google.com/drive/1812DVH33j3OlgqX3_r9zH4V5JCmoNL3T?usp=sharing\r\n\r\nI also tried tf2.17 and I can reproduce both inconsistencies with tf 2.17.0 + keras 3.4.1. Below are the links to colabs:\r\n\r\n`tf 2.17.0` + `keras 3.4.1`:\r\nModel with timedistributed_lstm\r\nhttps://colab.research.google.com/drive/19R1mmYOgYtZFP7lSDH0XczddQiMMHlNx?usp=sharing\r\n\r\nModel with separableconv2d\r\nhttps://colab.research.google.com/drive/1Yxz_y8q5oar08imbj7RDiAz5kS1SKs5a?usp=sharing', '@jiannanWang,\r\nI also tried to execute the mentioned code on tf-nightly, and observed that the inconsistencies become smaller, with 6.7055225e-08 in the timedistributed_lstm model and 0.0029296875 in the separableconv2d model. \r\n\r\nAlso looks like this issue is more related to Keras, could you please raise the new issue on the keras-team/keras repo for the quick response. Thank you!', ""Sure! Given that the original bug has been fixed in the nightly version, I raised the new issue in the Keras repo as suggested. \r\n\r\nI'll close this issue as the original bug is fixed."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71833"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71833"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.18.0-dev20240710

### Custom code

No

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I trained a small model in distributed settings and detected inconsistent results. I would expect there's no difference when training the same model on the same input with different world sizes.

I first created a four-layer model defined by the following code:
```
layer_0 = layers.Input(shape=[32, 32, 3], batch_shape=None, dtype='float32', sparse=False, tensor=None, name='00_input_object')
layer_1 = layers.TimeDistributed(layer=layers.LSTM(units=4, activation='softmax', recurrent_activation='elu', use_bias=False, kernel_initializer='random_uniform', recurrent_initializer='random_uniform', bias_initializer='random_uniform', unit_forget_bias=False, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=True, return_state=False, go_backwards=False, stateful=False, unroll=False), name='01_time_distributed')(layer_0)
layer_2 = layers.Flatten(data_format=None, name='02_flatten')(layer_1)
layer_3 = layers.Dense(units=10, activation='linear', use_bias=False, kernel_initializer='random_uniform', bias_initializer='random_uniform', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, name='03_dense')(layer_2)
layer_4 = layers.Reshape(target_shape=[10], name='04_reshape')(layer_3)
model = keras.Model(layer_0, layer_4)
```

Then I trained it using `MirroredStrategy` with 1 CPU and 2 CPU, respectively, and compared the prediction results. There was a large difference `Pred Linf: 0.06834731` between the two prediction results. Further investigation shows that the loss and gradient values are close (Linf < 3e-7).

Another piece of evidence that this should be a bug is that as I tested with the same code, there's only a small difference (~1e-6) with TensorFlow 2.15. The large inconsistency was introduced in 2.16.1 and it still exists in the current nightly version.

I detect similar inconsistencies when replacing the TimeDistributed layer with a separable convolution layer. The model definition is as following:

```
layer_0 = layers.Input(shape=[32, 32, 3], batch_shape=None, dtype='float32', sparse=False, tensor=None, name='00_input_object')
layer_1 = layers.SeparableConv2D(filters=4, kernel_size=[27, 27], strides=[1, 1], padding='same', data_format='channels_last', dilation_rate=[1, 1], depth_multiplier=5, activation='sigmoid', use_bias=True, depthwise_initializer='random_uniform', pointwise_initializer='random_uniform', bias_initializer='random_uniform', depthwise_regularizer=None, pointwise_regularizer=None, bias_regularizer=None, activity_regularizer=None, depthwise_constraint=None, pointwise_constraint=None, bias_constraint=None, name='01_separable_conv2D')(layer_0)
layer_2 = layers.Flatten(data_format=None, name='02_flatten')(layer_1)
layer_3 = layers.Dense(units=10, activation='linear', use_bias=False, kernel_initializer='random_uniform', bias_initializer='random_uniform', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, name='03_dense')(layer_2)
layer_4 = layers.Reshape(target_shape=[10], name='04_reshape')(layer_3)
model = keras.Model(layer_0, layer_4)
```

The inconsistency in their results is larger: `Pred Linf: 3208.046`

Note that I use a large learning rate (10.0) deliberately in the reproduction code below to show the large inconsistencies in the nightly version. Those two inconsistencies don't exist in TF 2.15.

### Standalone code to reproduce the issue

```shell
For the first model with TimeDistributed layer:
https://colab.research.google.com/drive/1DLV5cye_BRn80IHLl8UOB_V9yeYw1lmJ?usp=sharing

For the second model with SeparableConv2D layer:
https://colab.research.google.com/drive/1AtEiKBaoAEL-U5_IFsnpm39LwoBhQqBk?usp=sharing
```


### Relevant log output

```shell
# For the first model with TimeDistributed layer:

1CPU vs 2CPU:
Pred Linf: 0.06834731
Loss Linf: 2.3841858e-07
Gradient 0 Linf: 4.656613e-09
Gradient 1 Linf: 1.4551915e-11
Gradient 2 Linf: 4.3655746e-11


# For the second model with SeparableConv2D layer:

Pred Linf: 3208.046
Loss Linf: 2.3841858e-07
Gradient 0 Linf: 8.381903e-09
Gradient 1 Linf: 1.8626451e-08
Gradient 2 Linf: 1.2777746e-06
Gradient 3 Linf: 2.9802322e-08
```
"
2409487087,71884,"Tensorflow Dataset API continues to be broken, list_files no longer works",closed,2024-07-15 19:40:51+00:00,2024-07-16T13:55:39Z,2024-07-16T13:55:37Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/71884,"['type:bug', 'comp:data', '2.17']","[""For what it's worth, pre-globbing and using `from_tensor_slices` does allow for one to iterate through the filenames.\r\n\r\nBut if `list_files` is indeed deprecated, somebody say so!"", 'Another issue. This will also fail if `TFRecordDataset` is in the chain. If I need to open a separate ticket or issue or post more code, please let me know. But the `TFRecordDataset` issue appears both when wrapped by `interleave` or when pre-globbing and using those file names in `TFRecordDataset` directly.', '@dryglicki,\r\nI tried to execute both the official document code and mentioned code with latest tensorflow stable version 2.17.0, observed that both are executed without fail/error. Kindly find the gist of both and update if the understanding is correct. \r\n[Official doc](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/data.ipynb) and [code](https://colab.research.google.com/gist/tilakrayal/ebfc5bcece7c534c31cd797257e7cb4f/untitled2004.ipynb)\r\nThank you!', ""Thanks, @tilakrayal . Few more details.\r\n1. I installed TF using `pip install tensorflow[and-cuda]`. I have since updated the original post\r\n2. The Colab version of python is 3.10.12. I'm using 3.11.9.\r\n\r\nI will try another conda environment that follows what's in the Colab."", 'All right, I can confirm if I use 3.10.14 and force `pip install tensorflow[and-cuda]==2.17.0` I can get it to work.', ""All right, found the source of the problem. It's dependency collision.\r\n\r\nmatplotlib installed via `conda` brings numpy 2.0 which runs over the numpy 1.X version installed via pip for tensorflow."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71884"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/71884"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

pip install tensorflow[and-cuda]

### TensorFlow version

tf v2.17.0-rc1-2-gad6d8cc177d

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu

### Mobile device

_No response_

### Python version

3.11.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

`list_files` from Tensorflow Dataset API is now broken in TF 2.17. I cannot follow the example located here: https://www.tensorflow.org/guide/data#consuming_sets_of_files

After the issues where employing TFRecords and using generators blows up memory, now `list_files` won't even work. I've attached code that will list the appropriate files using both `pathlib` and `glob` libraries. Both return lists.

What on earth is going on here.

### Standalone code to reproduce the issue

```shell
#!/usr/bin/env python3
import os ; import sys
from pathlib import Path
import glob

import tensorflow as tf

output_path = Path('test_text')
if not output_path.exists(): output_path.mkdir(parents=True)

num_files = 10
write_out_string = 'abcdef'
for fnum in range(num_files):
    output_file = output_path / f'sample_{fnum:03d}.txt'
    with open(output_file, 'w') as f:
        f.write(write_out_string)
        
# First, try with Python's pathlib glob, make sure it can see the files
print(""With pathlib."")
print(list(output_path.glob('*txt')))
print()

# Next, try to with Python's glob
print(""With glob"")
glob_path = output_path / '*txt'
print(list(glob.glob(str(glob_path))))

list_ds = tf.data.Dataset.list_files(str(glob_path))

for bf in list_ds.take(5):
    print(bf.numpy())
```


### Relevant log output

```shell
With pathlib.
[PosixPath('test_text/sample_009.txt'), PosixPath('test_text/sample_007.txt'), PosixPath('test_text/sample_000.txt'), PosixPath('test_text/sample_006.txt'), PosixPath('test_text/sample_004.txt'), PosixPath('test_text/sample_008.txt'), PosixPath('test_text/sample_005.txt'), PosixPath('test_text/sample_002.txt'), PosixPath('test_text/sample_001.txt'), PosixPath('test_text/sample_003.txt')]

With glob
['test_text/sample_009.txt', 'test_text/sample_007.txt', 'test_text/sample_000.txt', 'test_text/sample_006.txt', 'test_text/sample_004.txt', 'test_text/sample_008.txt', 'test_text/sample_005.txt', 'test_text/sample_002.txt', 'test_text/sample_001.txt', 'test_text/sample_003.txt']
2024-07-15 15:39:17.545697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46673 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:16:00.0, compute capability: 8.9


Traceback (most recent call last):
  File ""/home/dryglicki/code/list_files/demonstrate_list_files.py"", line 28, in <module>
    list_ds = tf.data.Dataset.list_files(str(glob_path))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/ssd0/miniforge3_2024-04/envs/tensorflow_2d17/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1318, in list_files
    string_ops.reduce_join(file_pattern, separator="", ""), name=""message"")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/ssd0/miniforge3_2024-04/envs/tensorflow_2d17/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py"", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/ssd0/miniforge3_2024-04/envs/tensorflow_2d17/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py"", line 108, in convert_to_eager_tensor
    return ops.EagerTensor(value, ctx.device_name, dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: object __array__ method not producing an array
```
"
2412995154,72002,Tensorflow crash driver CUDA of GeForce RTX 4090,closed,2024-07-17 08:29:13+00:00,2024-08-09T01:55:10Z,2024-08-09T01:55:07Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/72002,"['stat:awaiting response', 'type:bug', 'stale', 'comp:gpu', 'TF 2.10']","[""Wow, I also have two Geforce RTX 4090 GPUs on a motherboard and had the same problem on Linux with Python 3.11 and TensorFlow 2.15.1.\r\n\r\nFor me, the whole system crashes and only a restart solves the problem. I don't know if this is the root issue, but for now, I'm just using one RTX 4090. In addition, I was using driver 535, and now 550 (still testing)."", ""> Wow, I also have two Geforce RTX 4090 GPUs on a motherboard and had the same problem on Linux with Python 3.11 and TensorFlow 2.15.1.\r\n> \r\n> For me, the whole system crashes and only a restart solves the problem. I don't know if this is the root issue, but for now, I'm just using one RTX 4090. In addition, I was using driver 535, and now 550 (still testing).\r\n\r\nIs this not observed with one RTX 4090? \r\nIn my code I use tensorflow to isolate the training calls using:\r\n```\r\nwith tf.device('/GPU:0'):\r\n    model.fit(...)\r\n```\r\nAnd also for the second process, but with tf.device('/GPU:1').\r\n\r\nAt the beginning of both the scripts I use tensorflow dynamic memory allocation:\r\n```\r\ngpus = tf.config.list_physical_devices('GPU')\r\ntf.config.set_visible_devices(gpus[0], 'GPU')\r\ntf.config.experimental.set_memory_growth(gpus[0], True)\r\n```\r\nAnd also for the second process gpus[1].\r\n\r\nHowever, these actions do not solve the problem...\r\n"", ""> Is this not observed with one RTX 4090?\r\n\r\nI'm still testing as the issue arises randomly, but for now, no problem.\r\n \r\n> ```\r\n> gpus = tf.config.list_physical_devices('GPU')\r\n> tf.config.set_visible_devices(gpus[0], 'GPU')\r\n> tf.config.experimental.set_memory_growth(gpus[0], True)\r\n> ```\r\n\r\nI'm doing the same.\r\n\r\nActually, I think the problem might be related to the driver version (530 series). So, I'm also using the 550 series to see if it resolves the issue."", '@333Random333,\r\nIs this crash happening with the tensorflow 2.10 only, or with the latest version tensorflow v2.17 as well. As mentioned above it is working with the 530 and 540 series, I have checked on the 530 and observed it is working. Kindly check and let us know. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72002"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72002"">No</a>\n']","### Issue type

Support

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.10.0

### Custom code

Yes

### OS platform and distribution

Win10x64 Pro

### Mobile device

_No response_

### Python version

3.10.6

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.2

### GPU model and memory

Geforce RTX 4090 24Gb

### Current behavior?

I have two Geforce RTX 4090 on one motherboard. I'm running two processes for training Tensorflow models on different maps.  After some time, the process crashes on GPU 0, but on GPU 1 it works without failures. I am attaching a screenshot of the error. How to fix it?
Driver Version : 537.34
CUDA Version : 12.2
TensorFlow version: 2.10.0
OS: Win10x64 Pro
![Ошибка Cuda](https://github.com/user-attachments/assets/b4472c10-8471-4669-b83d-52b3a1664052)



### Standalone code to reproduce the issue

```shell
for tr_opt in train_options_list:
    with tf.device('/GPU:0'):
        files = os.listdir(dir_data_path + param_dir + '/' + tr_opt)
        num_files = len(files)

        df_agg = pd.DataFrame()
        for i in range (0, num_files):
          current_file = pd.read_excel(dir_data_path + param_dir + '/' + tr_opt + '/' + files[i])
          current_file.columns = ['Время', param_dir]
          df_agg = pd.concat([df_agg, current_file])
    
        data = df_agg[param_dir].values.reshape(-1, 1)

        train_set_scale = scaler.transform(data)

        # Формируем матрицу
        n_steps = 180
        n_features = 1
        train_matrix = create_matrix(train_set_scale, n_steps)

        tf.keras.backend.clear_session()
        np.random.seed(41)

        model = tf.keras.models.Sequential()
        model.add(tf.keras.layers.InputLayer(input_shape=(n_steps, n_features)))
        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, return_sequences=True)))
        model.add(tf.keras.layers.ReLU())
        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8, return_sequences=True)))
        model.add(tf.keras.layers.ReLU())
        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, return_sequences=True)))
        model.add(tf.keras.layers.ReLU())
        model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features)))

        model.compile(optimizer='adam', loss=""mse"")

        net_history = model.fit(train_matrix, train_matrix, epochs=10, batch_size=150)
        model.save(save_path + 'model.h5')
```


### Relevant log output

_No response_"
2419544044,72198,how to install mediapipe_model_maker0.2.1.4 in windows?,closed,2024-07-19 18:06:22+00:00,2024-10-16T06:54:40Z,2024-10-16T06:54:36Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/72198,"['type:bug', 'TF 2.8']","['@pjpratik @pkgoogle @tilakrayal @Venkat6871 @sachinprasadhs Could you please help me to solve my problem?', 'Hi **@libofei2004** ,\r\n- Could you please post this issue on [https://github.com/google-ai-edge/[mediapipe](https://github.com/google-ai-edge/mediapipe)] (https://github.com/google-ai-edge/mediapipe/issues) as this issue belongs to mediapipe.\r\n\r\nThank you!', '@Venkat6871 Yes, I have post the issue on mediapipe page.', 'Hi **@libofei2004** ,\r\nClosing the issue since it is being tracked in other repo. Please feel free to re-open the issue if necessary.\r\nThank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72198"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72198"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf2.8

### Custom code

No

### OS platform and distribution

windows11

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I run ""pip install mediapipe_model_maker""  , but I can only install version 0.1.0.1. I was trying to install mediapipe_model_maker by ""pip install mediapipe_model_maker-0.2.1.4-py3-none-any.whl"", but also failed. The error:
ERROR: Cannot install mediapipe-model-maker and mediapipe-model-maker==0.2.1.4 because these package versions have conflicting dependencies.

The conflict is caused by:
    mediapipe-model-maker 0.2.1.4 depends on tensorflow-text
    tf-models-official 2.15.0 depends on tensorflow-text~=2.15.0
    mediapipe-model-maker 0.2.1.4 depends on tensorflow-text
    tf-models-official 2.14.2 depends on tensorflow-text~=2.14.0
    mediapipe-model-maker 0.2.1.4 depends on tensorflow-text
    tf-models-official 2.14.1 depends on tensorflow-text~=2.14.0
    mediapipe-model-maker 0.2.1.4 depends on tensorflow-text
    tf-models-official 2.14.0 depends on tensorflow-text~=2.14.0
    mediapipe-model-maker 0.2.1.4 depends on tensorflow-text
    tf-models-official 2.13.2 depends on tensorflow-text~=2.13.0I run ""pip install mediapipe_model_maker""  ,but I can only install version 0.1.0.1. I was trying to install mediapipe_model_maker by ""pip install mediapipe_model_maker-0.2.1.4-py3-none-any.whl"", but also failed. The error:
ERROR: Cannot install mediapipe-model-maker and mediapipe-model-maker==0.2.1.4 because these package versions have conflicting dependencies.

The conflict is caused by:
    mediapipe-model-maker 0.2.1.4 depends on tensorflow-text
    tf-models-official 2.15.0 depends on tensorflow-text~=2.15.0
    mediapipe-model-maker 0.2.1.4 depends on tensorflow-text
    tf-models-official 2.14.2 depends on tensorflow-text~=2.14.0
    mediapipe-model-maker 0.2.1.4 depends on tensorflow-text
    tf-models-official 2.14.1 depends on tensorflow-text~=2.14.0
    mediapipe-model-maker 0.2.1.4 depends on tensorflow-text
    tf-models-official 2.14.0 depends on tensorflow-text~=2.14.0
    mediapipe-model-maker 0.2.1.4 depends on tensorflow-text
    tf-models-official 2.13.2 depends on tensorflow-text~=2.13.0

To fix this you could try to:
1. loosen the range of package versions you've specified
2. remove package versions to allow pip to attempt to solve the dependency conflict

ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts

Can version 0.2.1.4 be installed in windows?

### Standalone code to reproduce the issue

```shell
pip install mediapipe_model_maker-0.2.1.4-py3-none-any.whl
```


### Relevant log output

_No response_"
2419613393,72202,Mmap of '41' at offset '0' failed with error '22'. on movenet,closed,2024-07-19 18:42:23+00:00,2024-07-23T16:27:55Z,2024-07-23T16:18:07Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/72202,"['type:bug', 'comp:lite', 'TF 2.15']","['Yes, getting same issue. Can you resolve please?', '@jaskarannagi19,\r\nI tried to execute the code and observed that it was executed without any fail/error. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/ca94c8afd638c92d4d0e2709ac2cb345/copy-of-movenet.ipynb) and also please have a look at the issue for the reference.\r\nhttps://github.com/tensorflow/tensorflow/issues/70841\r\n\r\nThank you!\r\n', '@tilakrayal No I think the code you are refering to has a different tf load method. I am more interested in training that notebook on my own examples. I think there is a problem in model that is not compatible ', ""I got the same error. I replaced the code - \r\n![image](https://github.com/user-attachments/assets/67c488df-6272-44d6-808f-01d3b80d2252)\r\n\r\nI highlighted the changes. The model i donwloaded from the github link-https://github.com/devfemibadmus/human-pose-estimation\r\n\r\nor even download tflite models from the kaggle link - https://www.kaggle.com/models/google/movenet/tfLite/singlepose-thunder/1?tfhub-redirect=true\r\n\r\nreplace the model movenet = Movenet('downloaded model.tflite') with the one downloaded and the code should run fine!\r\n\r\n\r\n # Load MoveNet Thunder model\r\nimport utils\r\nfrom data import BodyPart\r\nfrom ml import Movenet\r\nmovenet = Movenet('downloaded model.tflite')"", ""@durgas4 I think that's what we did followed by change in str() to str()_ in movenetpreprocessor class method to support numpy 1.25.2. \r\nThat notebook does need a new fresh link for the model out of the box link does not work"", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72202"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72202"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.15

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tutorials/pose_classification.ipynb#scrollTo=48kW1c2F5l1R

I amy trying to run this repo with movenet but I get error.
Mmap of '41' at offset '0' failed with error '22'. on movenet load function. No change has been made. I am running this on colab directly please help

### Standalone code to reproduce the issue

```shell
https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tutorials/pose_classification.ipynb#scrollTo=48kW1c2F5l1R

I amy trying to run this repo with movenet but I get error.
Mmap of '41' at offset '0' failed with error '22'. on movenet load function. No change has been made. I am running this on colab directly please help
```


### Relevant log output

_No response_"
2421883878,72272,ValueError: Tensor data is null. Run allocate_tensors() first,closed,2024-07-22 04:21:24+00:00,2024-09-16T05:52:29Z,2024-08-13T01:55:27Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/72272,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', '2.17']","['Hi @siy415 ,\r\n\r\nIs it possible that you can share a colab of your code? Because i ran your code using the tf 2.17.0 on colab TPU  using dummy training and inference data and it ran fine. Here is the [link](https://colab.research.google.com/drive/1w_BQKq-NqovlsYFvkePIDrrQNxe_gxmk?usp=sharing)', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72272"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72272"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.17.0

### Custom code

Yes

### OS platform and distribution

Windows 11

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

RTX4050 16Gb

### Current behavior?

I converted my keras model to tflite with quantization. 

When I inference the quantizated model, it has a error ""ValueError: Tensor data is null. Run allocate_tensors() first""
But there was no error when I inference it on not quantized model. 

What's difference with quantizated and not quntizated model..?

How do I fix it?

### Standalone code to reproduce the issue

```shell
model = Sequential()
model.add(Input([256], dtype=""int32""))
model.add(Embedding(35000, 10))
model.add(GRU(10,))
model.add(Dense(2, activation='softmax'))
model.compile(loss='binary_crossentropy', optimizer=""adam"", metrics=['accuracy'])

# Train
model.fit(train_input, labels, epochs=10, batch_size=128,)

# Convert
import tensorflow as tf

# Convert the model
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.experimental_enable_resource_variables = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
# converter._experimental_lower_tensor_list_ops = False
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

# Load interpreter
interpreter = tf.lite.Interpreter(model_path=""./gru_0722_tflite/model_2.tflite"")
interpreter.allocate_tensors()

# inference
interpreter.set_tensor(input_details[0]['index'], encode_plus_inputs[""input_ids""])
interpreter.invoke()

# get result <---- Error occured 
output_data = interpreter.get_tensor(output_details[0]['index'])
output_data
```


### Relevant log output

```shell
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[202], line 1
----> 1 output_data = interpreter.get_tensor(output_details[0]['index'])
      2 output_data

File ~\.virtualenvs\App1G-B5e0KeSX\Lib\site-packages\tensorflow\lite\python\interpreter.py:888, in Interpreter.get_tensor(self, tensor_index, subgraph_index)
    873 def get_tensor(self, tensor_index, subgraph_index=0):
    874   """"""Gets the value of the output tensor (get a copy).
    875 
    876   If you wish to avoid the copy, use `tensor()`. This function cannot be used
   (...)
    886     a numpy array.
    887   """"""
--> 888   return self._interpreter.GetTensor(tensor_index, subgraph_index)

ValueError: Tensor data is null. Run allocate_tensors() first
```
"
2422286437,72279,[Android]Failed to run on the given Interpreter: tensorflow/lite/kernels/transpose.cc:63 op_context->perm->dims->data[0] != dims (3 != 2),closed,2024-07-22 08:37:24+00:00,2024-09-20T02:00:13Z,2024-09-20T02:00:10Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/72279,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'Android', 'TF 2.16']","['Hi, @siy415 \r\n\r\nI apologize for the delayed response and if possible could you please help us with Google colab notebook in which you converted your model to TensorFlow Lite format and your github repo of android project which will help us to replicate the same behavior from our end to investigate this issue further from our end ? \r\n\r\nThank you for your cooperation and patience.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72279"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72279"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.7, tf-lite 2.16.1, tensorflow-lite-select-tf-ops:2.16.1

### Custom code

Yes

### OS platform and distribution

Linux 20.04

### Mobile device

Android SDK 28

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

My .tflite model works on python but it dosen't work well on android project.

It seems no difference between python and android. 
What kinds of layer or function changes demention of input?


### Standalone code to reproduce the issue

```shell
model
 python
model = Sequential()
model.add(Input([256], dtype=""int32""))
model.add(Embedding(35000, 10))
model.add(GRU(10))
# model.add(Dropout(0.5))
model.add(Dense(2, activation='softmax', ))
model.compile(loss='binary_crossentropy', optimizer=""adam"", metrics=['accuracy'])
print(model.summary())
```
Model: ""sequential_43""
┏━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━┓
┃ Layer (type)                        ┃ Output Shape         ┃        Param # ┃
┡━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━┩
│ embedding_35 (Embedding)│ (None, 256, 10)         │         350,000 │
├──────────────────┼─────────────┼─────────┤
│ gru_33 (GRU)                         │ (None, 10)                │                 660 │
├──────────────────┼─────────────┼─────────┤
│ dense_27 (Dense)                  │ (None, 2)                   │                  22 │
└──────────────────┴─────────────┴─────────┘
 Total params: 350,682 (1.34 MB)
 Trainable params: 350,682 (1.34 MB)
 Non-trainable params: 0 (0.00 B)

**error occur**
``` java
private AnalysisResult analyzeTextTFLite(String text) {
        // convert text to custom ids
        Feature feature = featureConverter.convert(text, ADD_SPECIAL_TOKENS);
        int curSeqLen = feature.inputIds.length;

        int[] tfInputs = new int[256];
        for (int j = 0; j < curSeqLen; j++) {
            tfInputs[j] = feature.inputIds[j];
        }

        Map<String, Object> inputsMap = new HashMap<>();
        Map<String, Object> outputMap = new HashMap<>();

        inputsMap.put(""keras_tensor_198"", tfInputs);

        float[][] logits = new float[1][2];
        outputMap.put(""output_0"", logits);

        final long moduleForwardStartTime = SystemClock.elapsedRealtime();
        tflite.runSignature(inputsMap, outputMap);
        Log.d(TAG, ""Model inference score : "" + logits[0][0] + "","" + logits[0][1]);

        float[] scores = new float[2];
        scores[0] = argmax(logits[0]);

        final long moduleForwardDuration = SystemClock.elapsedRealtime() - moduleForwardStartTime;
        return new AnalysisResult(scores, moduleForwardDuration);
    }
```

**works well**
``` python 
input_details = interpreter.get_input_details()
print(input_details)
""""""
[{'name': 'serving_default_keras_tensor_198:0',
  'index': 0,
  'shape': array([  1, 256]),
  'shape_signature': array([ -1, 256]),
  'dtype': numpy.int32,
  'quantization': (0.0, 0),
  'quantization_parameters': {'scales': array([], dtype=float32),
   'zero_points': array([], dtype=int32),
   'quantized_dimension': 0},
  'sparsity_parameters': {}}]
output_details = interpreter.get_output_details()
print(output_details)
""""""

output_data = interpreter.get_tensor(output_details[0]['index'])
print(output_data)
""""""
[{'name': 'StatefulPartitionedCall_1:0',
  'index': 36,
  'shape': array([1, 2]),
  'shape_signature': array([-1,  2]),
  'dtype': numpy.float32,
  'quantization': (0.0, 0),
  'quantization_parameters': {'scales': array([], dtype=float32),
   'zero_points': array([], dtype=int32),
   'quantized_dimension': 0},
  'sparsity_parameters': {}}]
""""""

interpreter.set_tensor(input_details[0]['index'], encode_plus_inputs[""input_ids""])
interpreter.invoke()
```


### Relevant log output

```shell
FATAL EXCEPTION: ModuleActivity
                                                                                                    Process: org.pytorch.demo, PID: 32712
                                                                                                    java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: tensorflow/lite/kernels/transpose.cc:63 op_context->perm->dims->data[0] != dims (3 != 2)
                                                                                                    Node number 10 (TRANSPOSE) failed to prepare.
                                                                                                    	at org.tensorflow.lite.NativeInterpreterWrapper.run(Native Method)
                                                                                                    	at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:264)
                                                                                                    	at org.tensorflow.lite.NativeInterpreterWrapper.runSignature(NativeInterpreterWrapper.java:194)
                                                                                                    	at org.tensorflow.lite.Interpreter.runSignature(Interpreter.java:271)
                                                                                                    	at org.tensorflow.lite.Interpreter.runSignature(Interpreter.java:284)
                                                                                                    	at org.pytorch.demo.nlp.NSMCPytorchActivity.analyzeTextTFLite(NSMCPytorchActivity.java:281)
                                                                                                    	at org.pytorch.demo.nlp.NSMCPytorchActivity.analyzeText(NSMCPytorchActivity.java:201)
                                                                                                    	at org.pytorch.demo.nlp.NSMCPytorchActivity.lambda$new$2$org-pytorch-demo-nlp-NSMCPytorchActivity(NSMCPytorchActivity.java:154)
                                                                                                    	at org.pytorch.demo.nlp.NSMCPytorchActivity$$ExternalSyntheticLambda2.run(Unknown Source:4)
                                                                                                    	at android.os.Handler.handleCallback(Handler.java:958)
                                                                                                    	at android.os.Handler.dispatchMessage(Handler.java:99)
                                                                                                    	at android.os.Looper.loopOnce(Looper.java:230)
                                                                                                    	at android.os.Looper.loop(Looper.java:319)
                                                                                                    	at android.os.HandlerThread.run(HandlerThread.java:67)
```
"
2424627109,72352,"about the official release schedule of ""Play Services TFLite Java"" version 16.2.0",closed,2024-07-23 08:47:37+00:00,2024-12-16T22:34:51Z,2024-11-26T18:08:14Z,arfaian,,https://github.com/tensorflow/tensorflow/issues/72352,"['stat:awaiting tensorflower', 'type:bug', 'comp:lite', 'TFLiteGooglePlayServices']","['Hi @arfaian, I believe you would have more insight here. Thanks.', ""Hi, @wonyoungmin \r\nThanks for raising this issue. Are you aware of the migration to [LiteRT](https://developers.googleblog.com/en/tensorflow-lite-is-now-litert/)? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/google-ai-edge/LiteRT/issues/45\r\n\r\nLet us know if you have any questions. Thanks."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72352"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72352"">No</a>\n', 'Versions 16.3.0 and 16.4.0 of play-services-tflite-java have been released on November 18th and December 9th respectively. Those should address this issue.\r\n']","**System information**
- Android Device information (use `adb shell getprop ro.build.fingerprint`
  if possible):
samsung/d2que/d2q:12/SP1A.210812.016/N975U1UES7HVF4:user/release-keys

- TensorFlow Lite in Play Services SDK version (found in `build.gradle`):
 target sdk 34
 com.google.android.gms:play-services-tflite-java:16.2.0-beta02

- Google Play Services version
  (`Settings` > `Apps` > `Google Play Services` > `App details`):
24.26.32

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to or attach code demonstrating
the problem.


I found that if I use com.google.android.gms:play-services-tflite , ""libtensorflowlite_jni_gms_client.so"" is included in the apk.
16kb align was not applied in version 16.1.0, but
In version 16.2.0-beta02, 16kb align were applied to 64bit

However, the beta version is not safe to use.
So I would like to know the official release schedule for 16.2.0.

Thank you.


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.

![image](https://github.com/user-attachments/assets/ff462b90-f72e-45cb-935f-8472b0b2e30c)
"
2425219924,72364,TensorFlow lite micro on Cortex-M7 ,closed,2024-07-23 13:26:16+00:00,2024-08-13T01:55:29Z,2024-08-13T01:55:26Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/72364,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'comp:micro', 'TFLiteConverter', 'TF 2.13']","['Hi @gajendrahatt, I believe https://github.com/tensorflow/tflite-micro/issues will be able to assist you better. Thanks.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72364"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72364"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.13.1

### Custom code

No

### OS platform and distribution

S32K344 Cortex-M7

### Mobile device

Cortexm-M7

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

arm-none-eabi-gcc 10.2

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I trained the tensor-flow model with layers Conv2d followed bye relu and Maxpool2D. 
this is the architecture i used
import tensorflow as tf
model1 = tf.keras.Sequential()
# model1.add(tf.keras.Input(shape=(750,3,1)))

model1.add(Conv2D(4,kernel_size=(5,5),strides=(1,1), padding='same',input_shape=(750, 3, 1)))
model1.add(tf.keras.layers.Activation(activation='relu'))
model1.add(MaxPooling2D(pool_size=(4,4),padding='same'))   
# model1.add(Dropout(0.25))

model1.add(Conv2D(8,kernel_size=(5,5),padding='same'))
model1.add(tf.keras.layers.Activation(activation='relu'))
model1.add(MaxPooling2D(pool_size=(4,4), padding='same'))  

model1.add(Conv2D(8,kernel_size=(5,5),padding='same'))
model1.add(tf.keras.layers.Activation(activation='relu'))
model1.add(MaxPooling2D(pool_size=(4,4), padding='same'))  

model1.add(Flatten())
model1.add(Dense(7))
model1.add(tf.keras.layers.Activation(activation='softmax'))
model1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0004518074511548236754), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model1.summary()

training and testing  accuracy is more than 95 %.
i convert the model to tflite using
converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)
tflite_quant_model = converter.convert()

and the make it in flattebuffers model.h using xxd -i model.tflite > model.h

and created the inference in c++ code for tflite micro

#include ""tensorflow/lite/micro/kernels/micro_ops.h""

#include ""tensorflow/lite/micro/micro_error_reporter.h""

#include ""tensorflow/lite/micro/micro_interpreter.h""

#include ""tensorflow/lite/micro/micro_mutable_op_resolver.h""

#include ""tensorflow/lite/schema/schema_generated.h""

#include ""tensorflow/lite/c/common.h""

#include ""tensorflow/lite/micro/micro_profiler.h""

// Include the model data

#include ""new_model_data.h""


 
#define INPUT_SIZE 2250

#define OUTPUT_SIZE 7
 
 
// Calculates size of model 118380
 
constexpr int kTensorArenaSize = 10208*sizeof(float);
 
// Globals, used for compatibility with Arduino-style sketches.

namespace {

tflite::MicroErrorReporter micro_error_reporter;

tflite::ErrorReporter* error_reporter = nullptr;

const tflite::Model* model = nullptr;

tflite::MicroInterpreter* interpreter = nullptr;

TfLiteTensor* input = nullptr;

TfLiteTensor* output = nullptr;

uint8_t tensor_arena[kTensorArenaSize];

tflite::MicroProfiler profiler;

}  // namespace
 
void setup() {

  // Set up logging.

  error_reporter = &micro_error_reporter;

  error_reporter->Report(""model test on cortexm7"");
 
  model = tflite::GetModel(Conv2d_model_v3_f16_tflite);

  if(model==nullptr)

  {

	  printf(""model errror"");

  }
 
  if (model->version() != TFLITE_SCHEMA_VERSION) {

    TF_LITE_REPORT_ERROR(error_reporter,

                         ""Model provided is schema version %d not equal ""

                         ""to supported version %d."",

                         model->version(), TFLITE_SCHEMA_VERSION);

    return;

  }
 
  printf(""getting the model \n"");
 
   // This pulls in all the operation implementations we need.

  static tflite::MicroMutableOpResolver<5> micro_op_resolver;

  micro_op_resolver.AddConv2D(tflite::Register_CONV_2D());

  micro_op_resolver.AddMaxPool2D(tflite::Register_MAX_POOL_2D());

  micro_op_resolver.AddRelu();

//  micro_op_resolver.AddReshape();

  micro_op_resolver.AddFullyConnected(tflite::Register_FULLY_CONNECTED());

  micro_op_resolver.AddSoftmax(tflite::Register_SOFTMAX());
 
  // Build an interpreter to run the model with.

  static tflite::MicroInterpreter static_interpreter(

      model, micro_op_resolver, tensor_arena, kTensorArenaSize,nullptr,&profiler);

  interpreter = &static_interpreter;
 
  // Allocate memory from the tensor_arena for the model's tensors.
 
  printf(""allocating the tesnors \n "");
 
  TfLiteStatus allocate_status = interpreter->AllocateTensors();
 
  if (allocate_status != kTfLiteOk) {

     MicroPrintf(""AllocateTensors() failed"");

     return;

   }

  	  input = interpreter->input(0);
 
}

void loop() {
 
  	  printf(""data initialisation\n"");

	  float input_data[INPUT_SIZE] = {};
printf(""allocating data to model \n"");

//	  memcpy(input->data.f16, &input_data, 2250*sizeof(float));

		 for (int i = 0; i < INPUT_SIZE; i++) {

			 input->data.f16[i] = input_data[i];

		  }
 
	  if (kTfLiteOk != interpreter->Invoke()) {

	     MicroPrintf(""Invoke failed."");

	   }

	  TfLiteTensor* output = interpreter->output(0);
 
 
  // Read the output

	  for (int i = 0; i < OUTPUT_SIZE; ++i) {

    float output_value = output->data.f[i];

    error_reporter->Report(""Output value[%d]: %f"", i, output_value);

  }

}
 
int main() {
 
  setup();

  while (true) {

    loop();

  }

  return 0;

} 
Now the problem is that when i feeding the input it is showing in the output, means it is pointing the same memory location for input tensor and output tensor.
what is the the feasible solution for this.

### Standalone code to reproduce the issue

```shell
.
```


### Relevant log output

```shell
1221 input the output also 2212
```
"
2425238901,72365,tf.range miss some dtypes support,closed,2024-07-23 13:34:32+00:00,2024-08-13T09:22:10Z,2024-08-13T09:22:07Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/72365,"['type:bug', 'comp:apis', '2.17']","['\r\n- I tried to run your code on Colab using TF v2.17.0, nightly and faced the same issue. Please find the [gist](https://colab.research.google.com/gist/Venkat6871/aee3cbcaae3ee68fa8de6cd259a4b5e4/72365_2-17-0-nightly.ipynb) here for reference.\r\n\r\nThank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72365"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72365"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

v1.12.1-113444-ga98a073af6f 2.18.0-dev20240722

### Custom code

No

### OS platform and distribution

Google Colab

### Mobile device

_No response_

### Python version

Google Colab default

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

It is a common use case to make ranges for dtypes like uint8 (when working with images) and float32 -> float16 (inside keras layers with mixed precision disabled/enabled).

In TF 2.17 release tf.range can't work with these dtypes.
One more issue is that XLA/non-XLA dtypes support is different (more dtypes supported with XLA)

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

tf.range(10., delta=1., dtype='float16')
```


### Relevant log output

```shell
NotFoundError: Could not find device for node: {{node Range}} = Range[Tidx=DT_HALF]
All kernels registered for op Range:
  device='XLA_CPU_JIT'; Tidx in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32]
  device='XLA_GPU_JIT'; Tidx in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32]
  device='DEFAULT'; Tidx in [DT_INT32]
  device='GPU'; Tidx in [DT_INT64]
  device='GPU'; Tidx in [DT_DOUBLE]
  device='GPU'; Tidx in [DT_FLOAT]
  device='CPU'; Tidx in [DT_INT64]
  device='CPU'; Tidx in [DT_INT32]
  device='CPU'; Tidx in [DT_DOUBLE]
  device='CPU'; Tidx in [DT_FLOAT]
 [Op:Range] name:
```
"
2425239732,72366,Custom metrics results returned by 'History' callbacks doesnt work properly,closed,2024-07-23 13:34:55+00:00,2024-09-18T01:59:09Z,2024-09-18T01:59:00Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/72366,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', '2.17']","['instead of using tf.keras.metrics.Metric I also tried tf.keras.Metric for defining the metrics, the results were the same', '@JVD9kh96,\r\nThank you for reporting the issue. As this issue is more related to keras, could you please raise the issue in keras-team/keras for quick resolution. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""For those who are looking for a quick fix, you can use legacy keras:\r\n`pip install tf_keras`\r\n\r\n\r\n```shell\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport os \r\nos.environ['TF_USE_LEGACY_KERAS'] = 'True'\r\n#... rest of the code \r\n\r\n#...output:\r\ntraining psnr:\r\n[25.50802231 27.92281532 28.17706299 28.29514313 28.37692451]\r\nval_psnr:\r\n[27.65083694 28.10541534 28.27854538 28.36878586 28.24624634]\r\n```\r\n\r\n"", '@JVD9kh96,\r\nGlad the issue was resolved with the tf-keras. Kindly find the [gist](https://colab.research.google.com/gist/tilakrayal/30aa38cea671499a4eae496c36a391e9/untitled2091.ipynb) of it [here](https://colab.research.google.com/gist/tilakrayal/03384cf3ffd968614056e06829009499/untitled2091.ipynb). And tensorflow v2.17 contains Keras3.0, and this is more related to keras please try to raise the issue in keras-team/keras [repo](https://github.com/keras-team/keras/issues) for the quick resolution. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72366"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72366"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.17.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

3.10.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I have defined two custom metrics to track SSIM and PSNR in my denoising autoencoder during the training. While the logs printed during the training seems to work properly, it returns weird results at the end by 'History' callback. All the values for training and validation psnr and ssim equal to the last printed value for validtion psnr and ssim, respectively. Like the older versions, I have defined internal variables by using add_variable method. I have also tried with add_weight. Both showed same behaviour. 

By the way, history callback used to return metrics as numpy arrays, but for the custom metrics that I defined, it returns KerasVariable instances.  Is there any fixes for this? This is a bit annoying that some metrics like loss are returned as numpy arrays while the custom metrics are KerasVariable instances. 

### Standalone code to reproduce the issue

```shell
import tensorflow as tf 
import numpy as np 

class SSIMMetric(tf.keras.metrics.Metric):
    """"""
    Custom SSIM metric for image denoising.

    This class calculates the average Structural Similarity Index Measure (SSIM)
    across all batches during training or evaluation.

    Args:
      name (str, optional): A name for the metric. Defaults to 'ssim'.
      max_val (float, optional): The dynamic range of the images (usually the maximum pixel value).
          Defaults to 255.0 for images in the 0-255 range.
      **kwargs (optional): Additional keyword arguments for the base Metric class.
    """"""

    def __init__(self, name='ssim', max_val=255.0, **kwargs):
        super(SSIMMetric, self).__init__(name=name, **kwargs)
        self.max_val = max_val
        self.ssim = self.add_variable(shape=(), name='ssim', initializer='zeros')
        self.counter = self.add_variable(shape=(), name='counter', initializer='zeros')

    def update_state(self, y_true, y_pred, sample_weight=None):
        """"""
        Updates the internal state of the metric with a batch of data.

        Args:
            y_true (tf.Tensor): The ground truth image tensor.
            y_pred (tf.Tensor): The predicted image tensor.
            sample_weight (tf.Tensor, optional): Sample weights (not used in this implementation).
        """"""
        ssim = tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=self.max_val))
        self.ssim.assign((ssim + self.ssim * self.counter) / (self.counter + 1.))
        self.counter.assign_add(1.)
        
    def result(self):
        """"""
        Calculates and returns the current average SSIM value.

        Returns:
            tf.Tensor: The average SSIM across all batches.
        """"""
        return self.ssim 

    def reset_states(self):
        """"""
        Resets the internal state of the metric to zero.
        """"""
        self.ssim.assign(0.0)
        self.counter.assign(0.0)


class PSNRMetric(tf.keras.metrics.Metric):
    """"""
    Custom PSNR metric for image denoising.

    This class calculates the average Peak Signal-to-Noise Ratio (PSNR)
    across all batches during training or evaluation.

    Args:
      name (str, optional): A name for the metric. Defaults to 'psnr'.
      max_val (float, optional): The dynamic range of the images (usually the maximum pixel value).
          Defaults to 255.0 for images in the 0-255 range.
      **kwargs (optional): Additional keyword arguments for the base Metric class.
    """"""
    def __init__(self, name='psnr', max_val=255.0, **kwargs):
        super(PSNRMetric, self).__init__(name=name, **kwargs)
        self.max_val = max_val
        self.psnr = self.add_variable(shape=(), name='psnr', initializer='zeros')
        self.counter = self.add_variable(shape=(), name='counter', initializer='zeros')
        
    def update_state(self, y_true, y_pred, sample_weight=None):
        """"""
        Updates the internal state of the metric with a batch of data.

        Args:
            y_true (tf.Tensor): The ground truth image tensor.
            y_pred (tf.Tensor): The predicted image tensor.
            sample_weight (tf.Tensor, optional): Sample weights (not used in this implementation).
        """"""
        psnr = tf.reduce_mean(tf.image.psnr(y_true, y_pred, max_val=self.max_val))
        self.psnr.assign((psnr + self.counter * self.psnr) / (self.counter + 1.))
        self.counter.assign_add(1.)

    def result(self):
        """"""
        Calculates and returns the current average PSNR value.

        Returns:
            tf.Tensor: The average PSNR across all batches.
        """"""
        return self.psnr 

    def reset_states(self):
        """"""
        Resets the internal state of the metric to zero.
        """"""
        self.psnr.assign(0.0)
        self.counter.assign(0.0)
        
        

(y_train, _), (y_test, _)   = tf.keras.datasets.cifar10.load_data()

y_train, y_test = y_train/255.0, y_test / 255.0 

x_train = y_train + 0.2 * np.random.random((y_train.shape))
x_test  = y_test  + 0.2 * np.random.random((y_test.shape))

input_layer = tf.keras.layers.Input((32, 32, 3))
x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), 
                           activation=tf.nn.leaky_relu, padding='same')(input_layer)
x = tf.keras.layers.Conv2D(filters=3, kernel_size=(3, 3), 
                           activation='sigmoid', padding='same')(x)

model = tf.keras.models.Model(input_layer, x)

model.compile(loss='mse', metrics=[PSNRMetric(max_val=1.), SSIMMetric(max_val=1.)], optimizer='Adam')

results = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))

val_psnr = np.array([np.array(metric_val) for metric_val in results.history['val_psnr']])
psnr     = np.array([np.array(metric_val) for metric_val in results.history['psnr']])
print(f'training psnr:\n{psnr}\nval_psnr:\n{val_psnr}')
```


### Relevant log output

```shell
The logs:

Epoch 1/5
1563/1563 ━━━━━━━━━━━━━━━━━━━━ 8s 4ms/step - loss: 0.0153 - psnr: 22.2309 - ssim: 0.7574 - val_loss: 0.0017 - val_psnr: 27.8734 - val_ssim: 0.9221
Epoch 2/5
1563/1563 ━━━━━━━━━━━━━━━━━━━━ 4s 3ms/step - loss: 0.0017 - psnr: 28.0592 - ssim: 0.9232 - val_loss: 0.0016 - val_psnr: 28.2505 - val_ssim: 0.9243
Epoch 3/5
1563/1563 ━━━━━━━━━━━━━━━━━━━━ 4s 3ms/step - loss: 0.0015 - psnr: 28.3847 - ssim: 0.9248 - val_loss: 0.0015 - val_psnr: 28.4067 - val_ssim: 0.9253
Epoch 4/5
1563/1563 ━━━━━━━━━━━━━━━━━━━━ 4s 2ms/step - loss: 0.0015 - psnr: 28.4954 - ssim: 0.9255 - val_loss: 0.0015 - val_psnr: 28.5810 - val_ssim: 0.9255
Epoch 5/5
1563/1563 ━━━━━━━━━━━━━━━━━━━━ 4s 2ms/step - loss: 0.0015 - psnr: 28.5493 - ssim: 0.9256 - val_loss: 0.0015 - val_psnr: 28.5256 - val_ssim: 0.9256
training psnr:
[28.525625 28.525625 28.525625 28.525625 28.525625]
val_psnr:
[28.525625 28.525625 28.525625 28.525625 28.525625]
```
"
2425940597,72388,`tf.distribute` and `keras` 3 incompatibility: ValueError: Invalid reduction dimension 0 for input with 0 dimensions.,closed,2024-07-23 19:17:36+00:00,2024-08-09T01:55:04Z,2024-08-09T01:55:01Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/72388,"['stat:awaiting response', 'type:bug', 'stale', 'comp:dist-strat', '2.17']","['@justinvyu,\r\nI checked with the **TF_USE_LEGACY_KERAS=1**(Keras2.0) and observed it was working as expected. As this is an issue with keras3.0, could you please try to raise the issue in the keras-team/keras [repo](https://github.com/keras-team/keras/issues/) for the quick resolution. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72388"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72388"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.16, 2.17, 2.18 (nightly)

### Custom code

Yes

### OS platform and distribution

MacOS + Linux

### Mobile device

_No response_

### Python version

py311, py312

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

* Running a simple quickstart DDP example with tensorflow on a single node with multiple workers (via multiprocessing or ray).
* Runs into an error during a collective sum reduction call.
* The `Dropout` layer was also causing some problems but I can't reproduce that at the moment. Comment out the dropout layer if you run into this.

## Repro setup, with workaround

**The workaround is to downgrade keras 3 to keras 2.**

```
conda create -c conda-forge python=3.12 -n debug_tf_py312
conda activate debug_tf_py312

pip install tensorflow tf-keras~=2.16 ""ray[train]""

# not working (keras 3)
TF_USE_LEGACY_KERAS=0 python repro.py mp

# working (legacy keras 2)
TF_USE_LEGACY_KERAS=1 python repro.py mp
```

See repro script below.

### Standalone code to reproduce the issue

```python
import tensorflow as tf
import json
import os


if bool(int(os.environ.get(""TF_USE_LEGACY_KERAS"", ""0""))):
    import tf_keras as keras
else:
    import tensorflow.keras as keras


print(""TensorFlow version:"", tf.__version__)


mnist = keras.datasets.mnist


def get_address_and_port():
    return ""127.0.0.1"", find_free_port()


def find_free_port():
    import socket
    from contextlib import closing

    with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:
        s.bind(("""", 0))
        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        return s.getsockname()[1]


def _setup_tensorflow_environment(worker_addresses, index: int):
    """"""Set up distributed Tensorflow training information.
    This function should be called on each worker.
    Args:
        worker_addresses: Addresses of all the workers.
        index: Index (i.e. world rank) of the current worker.
    """"""
    config = {
        ""cluster"": {""worker"": worker_addresses},
        ""task"": {""type"": ""worker"", ""index"": index},
    }
    os.environ[""TF_CONFIG""] = json.dumps(config)


def train_fn(worker_addresses=[""127.0.0.1:12345""], index=0):
    _setup_tensorflow_environment(worker_addresses, index)

    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    x_train, x_test = x_train / 255.0, x_test / 255.0

    strategy = tf.distribute.MultiWorkerMirroredStrategy()
    with strategy.scope():
        model = keras.models.Sequential(
            [
                keras.layers.Flatten(input_shape=(28, 28)),
                keras.layers.Dense(128, activation=""relu""),
                # NOTE: This errors for some reason when running with either MP or ray
                keras.layers.Dropout(0.2),
                keras.layers.Dense(10),
            ]
        )
        loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)
        model.compile(optimizer=""adam"", loss=loss_fn, metrics=[""accuracy""])

    predictions = model(x_train[:1]).numpy()
    predictions

    tf.nn.softmax(predictions).numpy()

    loss_fn(y_train[:1], predictions).numpy()

    model.fit(x_train, y_train, epochs=5)

    model.evaluate(x_test, y_test, verbose=2)

    probability_model = keras.Sequential([model, keras.layers.Softmax()])

    probability_model(x_test[:5])


def get_url():
    address, port = get_address_and_port()
    return f""{address}:{port}""


def run_with_ray():
    import ray

    train_fn_task = ray.remote(train_fn)

    num_workers = 2
    worker_addresses = [get_url() for _ in range(num_workers)]

    ray.get([train_fn_task.remote(worker_addresses, i) for i in range(num_workers)])


def run_with_mp():
    from multiprocessing import Process

    num_workers = 2
    worker_addresses = [get_url() for _ in range(num_workers)]

    p1 = Process(target=train_fn, args=(worker_addresses, 0))
    p2 = Process(target=train_fn, args=(worker_addresses, 1))

    p1.start()
    p2.start()

    p1.join()
    p2.join()


if __name__ == ""__main__"":
    import sys

    runner = sys.argv[1]
    if runner == ""vanilla"":
        train_fn()
    elif runner == ""ray"":
        run_with_ray()
    elif runner == ""mp"":
        run_with_mp()
```


### Relevant log output

```shell
TF_USE_LEGACY_KERAS=0 python repro.py mp

  Process Process-2:
Traceback (most recent call last):
  File ""/Users/justin/miniforge3/envs/ray_dev_py312/lib/python3.12/multiprocessing/process.py"", line 314, in _bootstrap
    self.run()
  File ""/Users/justin/miniforge3/envs/ray_dev_py312/lib/python3.12/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""/Users/justin/Downloads/tf_example.py"", line 56, in train_fn
    model.fit(x_train, y_train, epochs=5)
  File ""/Users/justin/miniforge3/envs/ray_dev_py312/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py"", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/Users/justin/miniforge3/envs/ray_dev_py312/lib/python3.12/site-packages/optree/ops.py"", line 747, in tree_map
    return treespec.unflatten(map(func, *flat_args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: Invalid reduction dimension 0 for input with 0 dimensions. for '{{node Sum_2}} = Sum[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false](StatefulPartitionedCall, Sum_2/reduction_indices)' with input shapes: [], [] and with computed input tensors: input[1] = <0>.
```
"
2426487920,72411,tensorflow.python.framework.errors_impl.AbortedError: Exception encountered when calling MaxPooling1D.call(),closed,2024-07-24 03:09:12+00:00,2024-07-25T08:27:41Z,2024-07-25T08:27:38Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/72411,"['stat:awaiting response', 'type:bug', 'comp:keras', '2.17']","['The same issue occurs with MaxPool2D and MaxPool3D.', '@Jacob-yen,\r\nI tried to execute the code on tensorflow tf-nightly where it was executed without any issues or errors. Kindly find the gist of it [here](https://colab.sandbox.google.com/gist/tilakrayal/add3aa39a5813b2ba58339ced3b01c62/untitled2022.ipynb). The tf-nightly(2.18.0-dev20240722) contains keras3.0 where we should import keras and keras.layers.MaxPool1D   and try to execute the code. Thank you!', ""Thank you for your prompt reply. I tried the notebook, and it works well.\r\n\r\nHowever, the above code still crashes on my Linux server with tf-nightly (2.18.0-dev20240722). To investigate the issue, I tested the code on three different servers, installing the same dependency packages with Python 3.10. \r\n```\r\nPackage                      Version\r\n---------------------------- -------------------\r\nabsl-py                      2.1.0\r\nastunparse                   1.6.3\r\ncertifi                      2024.7.4\r\ncharset-normalizer           3.3.2\r\nflatbuffers                  24.3.25\r\ngast                         0.6.0\r\ngoogle-pasta                 0.2.0\r\ngrpcio                       1.65.1\r\nh5py                         3.11.0\r\nidna                         3.7\r\nkeras-nightly                3.4.1.dev2024072503\r\nlibclang                     18.1.1\r\nMarkdown                     3.6\r\nmarkdown-it-py               3.0.0\r\nMarkupSafe                   2.1.5\r\nmdurl                        0.1.2\r\nml-dtypes                    0.4.0\r\nnamex                        0.0.8\r\nnumpy                        1.26.4\r\nopt-einsum                   3.3.0\r\noptree                       0.12.1\r\npackaging                    24.1\r\npip                          24.0\r\nprotobuf                     4.25.4\r\nPygments                     2.18.0\r\nrequests                     2.32.3\r\nrich                         13.7.1\r\nsetuptools                   69.5.1\r\nsix                          1.16.0\r\ntb-nightly                   2.18.0a20240724\r\ntensorboard-data-server      0.7.2\r\ntensorflow-io-gcs-filesystem 0.37.1\r\ntermcolor                    2.4.0\r\ntf_nightly                   2.18.0.dev20240722\r\ntyping_extensions            4.12.2\r\nurllib3                      2.2.2\r\nWerkzeug                     3.0.3\r\nwheel                        0.43.0\r\nwrapt                        1.16.0\r\n\r\n```\r\n\r\nI found that two servers with `Python 3.10.14 and GCC 11.2.0` crashed, while the other server with `Python 3.10.4 and GCC 7.5.0` ran the code without any problems.\r\n\r\nI'm not sure what caused the crash, but it may be a compatibility issue between the TensorFlow version and the GCC version.\r\n\r\nI will temporarily close the issue until further reasons are found."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72411"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72411"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.17 and 2.18.0.dev20240717 

### Custom code

Yes

### OS platform and distribution

Ubuntu 20.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

Python version: 3.10.14 

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I encountered a bug in TensorFlow when using the `tf.keras.layers.MaxPool1D` API after setting the input data format to 'channels_first'. The `tf.keras.layers.MaxPool1D` throws an `tensorflow.python.framework.errors_impl.AbortedError` exception. However, the average pooling operator executes successfully without any exceptions. The code is as follows:

```python
import tensorflow as tf
data_format = ""channels_first""
tf.compat.v1.keras.backend.set_image_data_format(data_format=data_format)

pool_size = 2
strides = 2
padding = ""valid""
pool_func = tf.keras.layers.MaxPool1D(pool_size=pool_size, strides=strides, padding=padding) # tensorflow.python.framework.errors_impl.AbortedError
# pool_func = tf.keras.layers.AvgPool1D(pool_size=pool_size, strides=strides, padding=padding) # success

input_tensor = tf.random.uniform([1, 5, 1], dtype=tf.float32)
input_tensor = tf.identity(input_tensor)

output_tensor = pool_func(input_tensor)

print(output_tensor.shape)

```

The error message was as follows:

```shell
# Output for tf.keras.layers.MaxPool1D + channel_first: exception
Traceback (most recent call last):
  File ""/data/test.py"", line 15, in <module>
    output_tensor = pool_func(input_tensor)
  File ""/data/anacondas/envs/code/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py"", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/data/anacondas/envs/code/lib/python3.10/site-packages/tensorflow/python/framework/ops.py"", line 5983, in raise_from_not_ok_status
    raise core._status_to_exception(e) from None  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.AbortedError: Exception encountered when calling MaxPooling1D.call().

{{function_node __wrapped__MaxPool_device_/job:localhost/replica:0/task:0/device:CPU:0}} Compute received an exception:Status: 2, message: could not create a descriptor for a pooling forward propagation primitive, in file tensorflow/core/kernels/mkl/mkl_maxpooling_op.cc:211 [Op:MaxPool] name: 

Arguments received by MaxPooling1D.call():
  • inputs=tf.Tensor(shape=(1, 5, 1), dtype=float32)

# output for tf.keras.layers.MaxPool1D + channel_last: success

# output for tf.keras.layers.AvgPool1D + channel_first/channel_last: success
```

The above code would throw an exception on `tf-2.17` and `tf-nightly 2.18.0.dev20240717` (nightly-build).



### Standalone code to reproduce the issue

```shell
import tensorflow as tf
data_format = ""channels_first""
tf.compat.v1.keras.backend.set_image_data_format(data_format=data_format)

pool_size = 2
strides = 2
padding = ""valid""
pool_func = tf.keras.layers.MaxPool1D(pool_size=pool_size, strides=strides, padding=padding) # tensorflow.python.framework.errors_impl.AbortedError
# pool_func = tf.keras.layers.AvgPool1D(pool_size=pool_size, strides=strides, padding=padding) # success

input_tensor = tf.random.uniform([1, 5, 1], dtype=tf.float32)
input_tensor = tf.identity(input_tensor)

output_tensor = pool_func(input_tensor)

print(output_tensor.shape)
```


### Relevant log output

```shell
# Output for tf.keras.layers.MaxPool1D + channel_first: exception
Traceback (most recent call last):
  File ""/data/test.py"", line 15, in <module>
    output_tensor = pool_func(input_tensor)
  File ""/data/anacondas/envs/code/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py"", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/data/anacondas/envs/code/lib/python3.10/site-packages/tensorflow/python/framework/ops.py"", line 5983, in raise_from_not_ok_status
    raise core._status_to_exception(e) from None  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.AbortedError: Exception encountered when calling MaxPooling1D.call().

{{function_node __wrapped__MaxPool_device_/job:localhost/replica:0/task:0/device:CPU:0}} Compute received an exception:Status: 2, message: could not create a descriptor for a pooling forward propagation primitive, in file tensorflow/core/kernels/mkl/mkl_maxpooling_op.cc:211 [Op:MaxPool] name: 

Arguments received by MaxPooling1D.call():
  • inputs=tf.Tensor(shape=(1, 5, 1), dtype=float32)

# output for tf.keras.layers.MaxPool1D + channel_last: success

# output for tf.keras.layers.AvgPool1D + channel_first/channel_last: success
```
"
2431809706,72561,TfLiteVision can't be initialised,closed,2024-07-26 09:21:40+00:00,2024-10-09T02:01:35Z,2024-10-09T02:01:32Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/72561,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'TFLiteGpuDelegate']","[""I am having the same issue but with the Interpreter API instead of Task Vision.\r\n\r\n```\r\nimplementation 'com.google.android.gms:play-services-tflite-java:16.0.1'\r\nimplementation 'com.google.android.gms:play-services-tflite-gpu:16.1.0'\r\nimplementation 'com.google.android.gms:play-services-tflite-support:16.0.1'\r\n```\r\n\r\n```kotlin\r\nTfLite.initialize(context, TfLiteInitializationOptions.builder()\r\n  .setEnableGpuDelegateSupport(true)\r\n  .build())\r\n```"", 'Hi, @pkgoogle\r\n\r\nPlease take look into this issue. Thank you', 'Hi @ThomasRichtsfeld, are you doing this in a custom app or are you following an example/documentation? For either case which of these would be closest to your use case? https://github.com/tensorflow/examples/tree/master/lite/examples, https://github.com/google-ai-edge/litert-samples/tree/main/examples. Thanks for any additional information you can provide.', '@pkgoogle I am not sure if any of those fit as I was not able to find the code snippet that caused the trouble for us:\r\n```\r\n    TfLiteVision.initialize(\r\n        context,\r\n        TfLiteInitializationOptions.builder().setEnableGpuDelegateSupport(isGpuDelegateAvailable).build()\r\n    )\r\n```\r\n\r\nWe use it in the app of our company to do some image inference.\r\nI am not sure if it matters how we use TfLite as the code I shared above is the one that has to be executed before using anything else from the TfLite API', 'So the tflite_support library is not recommended for current development: https://developers.googleblog.com/en/tensorflow-lite-is-now-litert/, since you are having an issue with it -- can you try using [MediaPipe Tasks](https://ai.google.dev/edge/mediapipe/solutions/tasks) instead? ', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72561"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72561"">No</a>\n']","**System information**
- Android Device information: `samsung/o1sxeea/o1s:14/UP1A.231005.007/G991BXXSBGXED:user/release-keys`
- TensorFlow Lite in Play Services SDK version:

```
tflite_vision = { module = ""org.tensorflow:tensorflow-lite-task-vision-play-services"", version.ref = ""0.4.4"" }
tflite_gpu = { module = ""com.google.android.gms:play-services-tflite-gpu"", version = ""16.2.0"" }
tflite_java = { module = ""com.google.android.gms:play-services-tflite-java"", version = ""16.2.0-beta02"" }
tflite_support = { module = ""com.google.android.gms:play-services-tflite-support"", version = ""16.1.0"" }
tflite_metadata = { module = ""org.tensorflow:tensorflow-lite-metadata"", version.ref = ""0.4.4"" }
```

- Google Play Services version: `24.26.32`

**Code to reproduce the issue**
The app prints a stacktrace in the logs but doesn't crash when calling inside the activities `onCreate` function:

```
    TfLiteVision.initialize(
        context,
        TfLiteInitializationOptions.builder().setEnableGpuDelegateSupport(isGpuDelegateAvailable).build()
    )
```

Log that is printed:
```
Failed to get service from broker.  
java.lang.SecurityException: Unknown calling package name 'com.google.android.gms'.
at android.os.Parcel.createExceptionOrNull(Parcel.java:3069)
at android.os.Parcel.createException(Parcel.java:3053)
at android.os.Parcel.readException(Parcel.java:3036)
at android.os.Parcel.readException(Parcel.java:2978)
at m.hv.q(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:206)
at m.gi.run(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:54)
at android.os.Handler.handleCallback(Handler.java:958)
at android.os.Handler.dispatchMessage(Handler.java:99)
at android.os.Looper.loopOnce(Looper.java:230)
at android.os.Looper.loop(Looper.java:319)
at android.os.HandlerThread.run(HandlerThread.java:67)
```

It further prints the following warning

```
Unable to update local snapshot for com.google.android.libraries.consentverifier#com.google.android.gms, may result in stale flags. (Ask Gemini)
                                                                                         java.util.concurrent.ExecutionException: m.up: 17: 17: API: Phenotype.API is not available on this device. Connection failed with: dd{statusCode=DEVELOPER_ERROR, resolution=null, message=null}
                                                                                         	at m.aot.s(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:21)
                                                                                         	at m.aot.get(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:3)
                                                                                         	at m.aqc.g(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:11)
                                                                                         	at m.wh.d(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:1)
                                                                                         	at m.vz.run(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:5)
                                                                                         	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:487)
                                                                                         	at java.util.concurrent.FutureTask.run(FutureTask.java:264)
                                                                                         	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:307)
                                                                                         	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
                                                                                         	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:644)
                                                                                         	at java.lang.Thread.run(Thread.java:1012)
                                                                                         Caused by: m.up: 17: 17: API: Phenotype.API is not available on this device. Connection failed with: dd{statusCode=DEVELOPER_ERROR, resolution=null, message=null}
                                                                                         	at m.uq.a(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:13)
                                                                                         	at m.aob.f(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:3)
                                                                                         	at m.aod.run(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:130)
                                                                                         	at m.apn.execute(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:1)
                                                                                         	at m.aot.q(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:1)
                                                                                         	at m.aot.m(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:101)
                                                                                         	at m.aot.d(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:19)
                                                                                         	at m.tb.d(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:1)
                                                                                         	at m.ta.a(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:35)
                                                                                         	at m.nn.run(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:12)
                                                                                         	at m.apn.execute(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:1)
                                                                                         	at m.no.a(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:12)
                                                                                         	at m.ob.b(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:36)
                                                                                         	at m.og.j(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:20)
                                                                                         	at m.ni.run(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:736)
                                                                                         	at m.apn.execute(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:1)
                                                                                         	at m.nj.a(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:8)
                                                                                         	at m.ob.b(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:36)
                                                                                         	at m.oc.c(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:25)
                                                                                         	at m.fh.c(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:7)
                                                                                         	at m.gg.t(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:48)
11:12:04.781 21705-23046 MobStoreFlagStore       com.app.app.stagingserver     W  	at m.gg.f(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:10) (Ask Gemini)
                                                                                         	at m.gg.j(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:178)
                                                                                         	at m.gg.i(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:2)
                                                                                         	at m.gi.run(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:82)
                                                                                         	at android.os.Handler.handleCallback(Handler.java:958)
                                                                                         	at android.os.Handler.dispatchMessage(Handler.java:99)
                                                                                         	at android.os.Looper.loopOnce(Looper.java:230)
                                                                                         	at android.os.Looper.loop(Looper.java:319)
                                                                                         	at android.os.HandlerThread.run(HandlerThread.java:67)
                                                                                         Caused by: m.em: 17: API: Phenotype.API is not available on this device. Connection failed with: dd{statusCode=DEVELOPER_ERROR, resolution=null, message=null}
                                                                                         	at m.hm.a(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:13)
                                                                                         	at m.fh.c(:com.google.android.gms.policy_tflite_dynamite_dynamite@242327803@242327801042.644155124.644155124:3)
                                                                                         	... 10 more
```"
2432760938,72585,tf.distribute.MirroredStrategy error: Multiple OpKernel registrations match NodeDef at the same priority,closed,2024-07-26 18:18:08+00:00,2024-09-18T01:59:07Z,2024-09-18T01:58:57Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/72585,"['stat:awaiting response', 'type:bug', 'stale', 'comp:dist-strat', 'TF 2.10']","[""@jmmelen,\r\nThe tensorflow v2.10 is an old version. Could you please try to install the latest tensorflow v2.15, v2.16 or v2.17 and it was able to execute the code and detect the GPU's. Kindly find the screenshot for the reference.\r\n\r\n![Screenshot 2024-05-21 1 43 20 PM](https://github.com/user-attachments/assets/9483ec08-65b7-462d-93e2-c9dcadde8ca3)\r\n\r\n\r\nThank you!"", '1) remove existing tensorflow 2.10.0\r\n2) installed tensorflow=2.17.0\r\n2) Now in JupyterNotebook  the GPU is no longer being seen:\r\nimport tensorflow as tf  \r\nprint(tf.__version__)\r\nprint(""Num GPUs Available: "", len(tf.config.list_physical_devices(\'GPU\')))\r\nprint(""Num CPUs Available: "", len(tf.config.list_physical_devices(\'CPU\')))\r\nprint(tf.config.list_physical_devices(\'GPU\'))\r\nprint(tf.config.list_physical_devices(\'CPU\'))\r\n\r\nOutput:\r\n2.17.0\r\nNum GPUs Available:  0\r\nNum CPUs Available:  1\r\n[]\r\n[PhysicalDevice(name=\'/physical_device:CPU:0\', device_type=\'CPU\')]', 'Also tried: pip install --force-reinstall tensorflow==2.17.0\r\nand got the same error as above', 'Also tried:\r\n1) uninstalled tensorflow, tensorboard-data-server, tensorboard, keras, tensorflow-intel. \r\n2) installed tensorflow 2.17.0 and got the same error as above:\r\nimport tensorflow as tf\r\nprint(tf.version)\r\nprint(""Num GPUs Available: "", len(tf.config.list_physical_devices(\'GPU\')))\r\nprint(""Num CPUs Available: "", len(tf.config.list_physical_devices(\'CPU\')))\r\nprint(tf.config.list_physical_devices(\'GPU\'))\r\nprint(tf.config.list_physical_devices(\'CPU\'))\r\nOutput:\r\n2.17.0\r\nNum GPUs Available: 0\r\nNum CPUs Available: 1\r\n[]', 'Remember this is on Windows 11. ', 'TensorFlow 2.10 was the last TensorFlow release that supported GPU on native-Windows. Starting with TensorFlow 2.11, you will need to install [TensorFlow in WSL2](https://tensorflow.org/install/pip#windows-%5Bwsl2%5D), or install tensorflow-cpu and, optionally, try the [TensorFlow-DirectML-Plugin](https://github.com/microsoft/tensorflow-directml-plugin#tensorflow-directml-plugin-)', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72585"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72585"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.10.0

### Custom code

Yes

### OS platform and distribution

Windows 11

### Mobile device

_No response_

### Python version

3.10.14

### Bazel version

_No response_

### GCC/compiler version

Jupyter Notebook

### CUDA/cuDNN version

cuda_12.5.r12.5

### GPU model and memory

_No response_

### Current behavior?

#Minimal code to reproduce error
import tensorflow as tf
import keras 
import numpy as np

tf.debugging.set_log_device_placement(True)
gpus = tf.config.list_logical_devices('GPU')
print(gpus)

strategy = tf.distribute.MirroredStrategy(gpus)

#expect to be able have code (not shown) below this to run over 2 GPUs

### Standalone code to reproduce the issue

```shell
Output: 
[LogicalDevice(name='/device:GPU:0', device_type='GPU'), LogicalDevice(name='/device:GPU:1', device_type='GPU')]
Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0
Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0

---> 14 strategy = tf.distribute.MirroredStrategy(gpus)
...
InvalidArgumentError: Multiple OpKernel registrations match NodeDef at the same priority '{{node AssignVariableOp}}': 'op: ""AssignVariableOp"" device_type: ""GPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""resource""' and 'op: ""AssignVariableOp"" device_type: ""GPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""resource""'
	 [[AssignVariableOp]] [Op:AssignVariableOp]
```


### Relevant log output

_No response_"
2434486214,72679,losses return None if dictionary is used in pipeline and model,closed,2024-07-29 05:28:49+00:00,2024-10-03T02:01:45Z,2024-10-03T02:01:41Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/72679,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', '2.17']","['After more testing, I realized that if I name my last layer ""custom_out"" (and remove the dictionary in the model definition), then I can keep the dictionary in my dataset. I found the fact that the output in the model can used a dictionary a very useful feature. When was this capability removed from tf 2?\r\nThe reason why I used this naming is when my model have multiple outputs to ensure the coherence between the outputs and the data provided by my pipeline. If I have a list of output layers with the corresponding names, will this work as well (then I can adapt my code)?', '@pmdaye, your code has a slight mistake. Here\'s how to fix it: rename \'predictions\' to \'custom_out\'. It looks like all of the three output names (outputs Dense(10) layer, dataset y_true label name, model_outputs name) have to be called by the same name.\r\nThis is the correct code that runs on google colab with tf.__version__ == \'2.17.0\', and keras.__version__ == \'3.4.1\'\r\n\r\n```python\r\n!pip3 install tensorflow==2.17.0 --quiet\r\n!pip3 install --upgrade tf-keras --quiet\r\n\r\nimport tensorflow as tf\r\nimport keras\r\nfrom keras import layers\r\n\r\ndef map_fct(x, y):\r\n    return x, {\'y_true\': y}\r\n\r\ninputs = keras.Input(shape=(784,), name=""digits"")\r\nx = layers.Dense(64, activation=""relu"", name=""dense_1"")(inputs)\r\nx = layers.Dense(64, activation=""relu"", name=""dense_2"")(x)\r\noutputs = layers.Dense(10, activation=""softmax"", name=""y_true"")(x)\r\n\r\nmodel = keras.Model(inputs=inputs, outputs={\'y_true\': outputs})\r\n\r\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\r\n\r\n# Preprocess the data (these are NumPy arrays)\r\nx_train = x_train.reshape(60000, 784).astype(""float32"") / 255\r\nx_test = x_test.reshape(10000, 784).astype(""float32"") / 255\r\n\r\ny_train = y_train.astype(""float32"")\r\ny_test = y_test.astype(""float32"")\r\n\r\n# Reserve 10,000 samples for validation\r\nx_val = x_train[-10000:]\r\ny_val = y_train[-10000:]\r\nx_train = x_train[:-10000]\r\ny_train = y_train[:-10000]\r\n\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\r\nval_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\r\n\r\ntrain_dataset = train_dataset.map(\r\n        map_func = map_fct,\r\n        num_parallel_calls = tf.data.experimental.AUTOTUNE\r\n    )\r\n\r\nval_dataset = val_dataset.map(\r\n        map_func = map_fct,\r\n        num_parallel_calls = tf.data.experimental.AUTOTUNE\r\n    )\r\n\r\nmodel.compile(\r\n    optimizer=keras.optimizers.RMSprop(),  # Optimizer\r\n    # Loss function to minimize\r\n    loss=keras.losses.SparseCategoricalCrossentropy(),\r\n    # List of metrics to monitor\r\n    metrics=[keras.metrics.SparseCategoricalAccuracy()],\r\n)\r\n\r\ntrain_dataset = train_dataset.batch(\r\n            batch_size = 64,\r\n            drop_remainder=True,\r\n        )\r\nval_dataset = val_dataset.batch(\r\n            batch_size = 64,\r\n            drop_remainder=True,\r\n        )\r\n\r\nprint(""Fit model on training data"")\r\nhistory = model.fit(\r\n    train_dataset,\r\n    batch_size=64,\r\n    epochs=2,\r\n    # We pass some validation for\r\n    # monitoring validation loss and metrics\r\n    # at the end of each epoch\r\n    validation_data=val_dataset,\r\n)\r\n```', '@just-sabyr,\r\n\r\nThanks for the update. You came to the same conclusion as me, great! From my analysis, we do not need to name the output in the model definition, only the last layer is sufficient.\r\nHowever, I must stress that the original version of the code was working without issues on 2.14.1. If this has changed on purpose, I think it would be great to have this explained somewhere within the documentation. If this change was not spotted, I would suggest to file it as a bug.\r\nThanks again!', ""@pmdaye, as per my understanding, it is safer if all of them are named the same.  After some considerations here is my try to explain what happens: \r\n\r\n1. There is an object (Trainer._compile_loss in the file) of type `CompileLoss` in trainer.py file, which is initialized `output_names of the model` as one of it's parameters.\r\n2. `Trainer._compile_loss`'s `call` method is called with `y`, `y_pred`, `sample_weight` (which returns the loss value) \r\n3. `CompileLoss.call()` has a utitlity function (in the compile_utils.py file)  `_flatten_y` which is called for both `y` and `y_pred` to convert them into lists. \r\n4. Both `y` and `y_pred` are of type dict before _`_flatten_y`_ (each with one key if it is single-output model) processes them and this function uses `_output_names of the model_` passed at step 1 to do so. \r\n\r\nThe fourth step is the reason for the necessity that all of the three `y` (input to the model), `y_pred` (output of the model) and last_layer.outputs must be dictionaries with the same keys. I did not look up how they handled it in the previous versions, but (to me at least) this way seems sensible."", 'However there should be a proper error handling to warn users about non-matching dict keys. ', 'Hi **@pmdaye** ,\r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues) as this issue is more related to keras\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72679"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72679"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

tf 2.16.2, tf 2.17.0

### Custom code

No

### OS platform and distribution

Rocky Linux 9.3

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

If I use a dictionary at the output of my pipeline and my model, the loss function returns None instead of the value.
If you run this code with tf>=2.16.2, it will fail with ""no loss function"" error (see the map_fct output returns ""custom_out"") as well as the model definition uses ""custom_out"". If you change the map_fct and the model definition to remove the dictionary, it is working. This is working on 2.14.x (have not tried on 2.15.x)

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import keras
from keras import layers

def map_fct(x, y):
    return x, {'custom_out': y}

inputs = keras.Input(shape=(784,), name=""digits"")
x = layers.Dense(64, activation=""relu"", name=""dense_1"")(inputs)
x = layers.Dense(64, activation=""relu"", name=""dense_2"")(x)
outputs = layers.Dense(10, activation=""softmax"", name=""predictions"")(x)

model = keras.Model(inputs=inputs, outputs={'custom_out': outputs})

(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Preprocess the data (these are NumPy arrays)
x_train = x_train.reshape(60000, 784).astype(""float32"") / 255
x_test = x_test.reshape(10000, 784).astype(""float32"") / 255

y_train = y_train.astype(""float32"")
y_test = y_test.astype(""float32"")

# Reserve 10,000 samples for validation
x_val = x_train[-10000:]
y_val = y_train[-10000:]
x_train = x_train[:-10000]
y_train = y_train[:-10000]

train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))

train_dataset = train_dataset.map(
        map_func = map_fct,
        num_parallel_calls = tf.data.experimental.AUTOTUNE
    )

val_dataset = val_dataset.map(
        map_func = map_fct,
        num_parallel_calls = tf.data.experimental.AUTOTUNE
    )

model.compile(
    optimizer=keras.optimizers.RMSprop(),  # Optimizer
    # Loss function to minimize
    loss=keras.losses.SparseCategoricalCrossentropy(),
    # List of metrics to monitor
    metrics=[keras.metrics.SparseCategoricalAccuracy()],
)

train_dataset = train_dataset.batch(
            batch_size = 64,
            drop_remainder=True,
        )
val_dataset = val_dataset.batch(
            batch_size = 64,
            drop_remainder=True,
        )

print(""Fit model on training data"")
history = model.fit(
    train_dataset,
    batch_size=64,
    epochs=2,
    # We pass some validation for
    # monitoring validation loss and metrics
    # at the end of each epoch
    validation_data=val_dataset,
)
```


### Relevant log output

```shell
2024-07-29 07:13:09.432389: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-07-29 07:13:09.445499: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-07-29 07:13:09.465390: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-07-29 07:13:09.465415: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-07-29 07:13:09.477398: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-07-29 07:13:10.111192: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-07-29 07:13:10.748552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20282 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:9e:00.0, compute capability: 8.6
Fit model on training data
Epoch 1/2
Traceback (most recent call last):
  File ""/home/xxxxxx/workspace/tmp/dict_dataset_tf2_16_2.py"", line 61, in <module>
    history = model.fit(
  File ""/home/xxxxxx/python_venv/tensorflow_probability/lib64/python3.9/site-packages/keras/src/utils/traceback_utils.py"", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/home/xxxxxx/python_venv/tensorflow_probability/lib64/python3.9/site-packages/keras/src/trainers/trainer.py"", line 331, in compute_loss
    raise ValueError(
ValueError: No loss to compute. Provide a `loss` argument in `compile()`.
```
"
2434679437,72686,MirroredStrategy() getting stuck at optimizer level when calling apply_gradients with tf2.16.2,closed,2024-07-29 07:33:52+00:00,2024-08-16T01:54:07Z,2024-08-16T01:54:03Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/72686,"['stat:awaiting response', 'type:bug', 'stale', 'comp:dist-strat', 'TF 2.16']","['@grep-mb,\r\nLooks like this issue is happening with the tensorflow v2.16, 2.17 which contains the keras3.0 by default causing the issue. Could you please raise the issue in keras-team/keras repo for the quick resolution. Also there is a similar [issue](https://github.com/keras-team/keras/issues/19308) in the keras repo which is in open state. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72686"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72686"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.16.2

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22, MacOS M1, MacOS Intel chip

### Mobile device

_No response_

### Python version

3.11

### Bazel version

7.2.1

### GCC/compiler version

14.0.3

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

The code will get stuck when applying gradients with the optimizer with both `tf.keras.optimizers.legacy.Adam` and `tf.keras.optimizers.Adam`

### Standalone code to reproduce the issue

```shell
# You can reproduce the problem by running the example in the documentation https://www.tensorflow.org/tutorials/distribute/custom_training
# Import TensorFlow
import os

# Helper libraries
import numpy as np
import tensorflow as tf

print(tf.__version__)


def main():
    fashion_mnist = tf.keras.datasets.fashion_mnist

    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

    # Add a dimension to the array -> new shape == (28, 28, 1)
    # This is done because the first layer in our model is a convolutional
    # layer and it requires a 4D input (batch_size, height, width, channels).
    # batch_size dimension will be added later on.
    train_images = train_images[..., None]
    test_images = test_images[..., None]

    # Scale the images to the [0, 1] range.
    train_images = train_images / np.float32(255)
    test_images = test_images / np.float32(255)

    # If the list of devices is not specified in
    # `tf.distribute.MirroredStrategy` constructor, they will be auto-detected.
    strategy = tf.distribute.MirroredStrategy([""/cpu:0"", ""/cpu:1""])
    print(""Number of devices: {}"".format(strategy.num_replicas_in_sync))

    BUFFER_SIZE = len(train_images)

    BATCH_SIZE_PER_REPLICA = 64
    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync

    EPOCHS = 10

    train_dataset = (
        tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)
    )
    test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)

    train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)
    test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)

    def create_model():
        regularizer = tf.keras.regularizers.L2(1e-5)
        model = tf.keras.Sequential(
            [
                tf.keras.layers.Conv2D(32, 3, activation=""relu"", kernel_regularizer=regularizer),
                tf.keras.layers.MaxPooling2D(),
                tf.keras.layers.Conv2D(64, 3, activation=""relu"", kernel_regularizer=regularizer),
                tf.keras.layers.MaxPooling2D(),
                tf.keras.layers.Flatten(),
                tf.keras.layers.Dense(64, activation=""relu"", kernel_regularizer=regularizer),
                tf.keras.layers.Dense(10, kernel_regularizer=regularizer),
            ]
        )

        return model

    # Create a checkpoint directory to store the checkpoints.
    checkpoint_dir = ""./training_checkpoints""
    checkpoint_prefix = os.path.join(checkpoint_dir, ""ckpt"")

    with strategy.scope():
        # Set reduction to `NONE` so you can do the reduction yourself.
        loss_object = tf.keras.losses.SparseCategoricalCrossentropy(
            from_logits=True, reduction=tf.keras.losses.Reduction.NONE
        )

        def compute_loss(labels, predictions, model_losses):
            per_example_loss = loss_object(labels, predictions)
            loss = tf.nn.compute_average_loss(per_example_loss)
            if model_losses:
                loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))
            return loss

    with strategy.scope():
        test_loss = tf.keras.metrics.Mean(name=""test_loss"")

        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=""train_accuracy"")
        test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=""test_accuracy"")

    # A model, an optimizer, and a checkpoint must be created under `strategy.scope`.
    with strategy.scope():
        model = create_model()

        optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)

        checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)

    def train_step(inputs):
        images, labels = inputs

        with tf.GradientTape() as tape:
            predictions = model(images, training=True)
            loss = compute_loss(labels, predictions, model.losses)

        gradients = tape.gradient(loss, model.trainable_variables)
        optimizer.apply_gradients(zip(gradients, model.trainable_variables))

        train_accuracy.update_state(labels, predictions)
        return loss

    def test_step(inputs):
        images, labels = inputs

        predictions = model(images, training=False)
        t_loss = loss_object(labels, predictions)

        test_loss.update_state(t_loss)
        test_accuracy.update_state(labels, predictions)

    # `run` replicates the provided computation and runs it
    # with the distributed input.
    @tf.function
    def distributed_train_step(dataset_inputs):
        per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))
        return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)

    @tf.function
    def distributed_test_step(dataset_inputs):
        return strategy.run(test_step, args=(dataset_inputs,))

    for epoch in range(EPOCHS):
        # TRAIN LOOP
        total_loss = 0.0
        num_batches = 0
        for x in train_dist_dataset:
            total_loss += distributed_train_step(x)
            num_batches += 1
        train_loss = total_loss / num_batches

        # TEST LOOP
        for x in test_dist_dataset:
            distributed_test_step(x)

        if epoch % 2 == 0:
            checkpoint.save(checkpoint_prefix)

        template = ""Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, "" ""Test Accuracy: {}""
        print(
            template.format(
                epoch + 1, train_loss, train_accuracy.result() * 100, test_loss.result(), test_accuracy.result() * 100
            )
        )

        test_loss.reset_states()
        train_accuracy.reset_states()
        test_accuracy.reset_states()

    eval_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=""eval_accuracy"")

    new_model = create_model()
    new_optimizer = tf.keras.optimizers.Adam()

    test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)


if __name__ == ""__main__"":
    main()
```


### Relevant log output

_No response_"
2435124855,72696,keras functional api fit() with tf.data.Dataset for validation data is resulting in an error,closed,2024-07-29 11:08:17+00:00,2024-11-02T02:01:16Z,2024-11-02T02:01:13Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/72696,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'TF 2.15']","['Hi **@just-sabyr** ,\r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues) as this issue is more related to keras\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72696"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72696"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.15.0

### Custom code

Yes

### OS platform and distribution

Kaggle Notebook

### Mobile device

_No response_

### Python version

3.10.13

### Bazel version

_No response_

### GCC/compiler version

12.3.0

### CUDA/cuDNN version

12.1.105

### GPU model and memory

_No response_

### Current behavior?

Current behavior: AttributeError: 'NoneType' object has no attribute 'items'.
Expected behavior: standard fit() function returning history object. The code works without val_dataset 
train_dataset is <_TakeDataset element_spec=((TensorSpec(shape=(None, 73), dtype=tf.float64, name=None), TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None)), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>
val_dataset is <_TakeDataset element_spec=((TensorSpec(shape=(None, 73), dtype=tf.float64, name=None), TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None)), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>
test_dataset is <_PrefetchDataset element_spec=((TensorSpec(shape=(None, 73), dtype=tf.float64, name=None), TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None)), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>


### Standalone code to reproduce the issue
[Kaggle Notebook](https://www.kaggle.com/code/sabyrbazarymbetov/multi-input-effnetv2-feature-extraction-dnn)

### Relevant log output

```shell
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1722248226.794089      68 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
W0000 00:00:1722248226.850691      68 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update
4386/4386 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.9955 - loss: 0.2826
/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self.gen.throw(typ, value, traceback)

File /opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122, in filter_traceback.<locals>.error_handler(*args, **kwargs)
    119     filtered_tb = _process_traceback_frames(e.__traceback__)
    120     # To get the full stack trace, call:
    121     # `keras.config.disable_traceback_filtering()`
--> 122     raise e.with_traceback(filtered_tb) from None
    123 finally:
    124     del filtered_tb

File /opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:354, in TensorFlowTrainer.fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)
    333         self._eval_epoch_iterator = TFEpochIterator(
    334             x=val_x,
    335             y=val_y,
   (...)
    341             shuffle=False,
    342         )
    343     val_logs = self.evaluate(
    344         x=val_x,
    345         y=val_y,
   (...)
    351         _use_cached_eval_dataset=True,
    352     )
    353     val_logs = {
--> 354         ""val_"" + name: val for name, val in val_logs.items()
    355     }
    356     epoch_logs.update(val_logs)
    358 callbacks.on_epoch_end(epoch, epoch_logs)

AttributeError: 'NoneType' object has no attribute 'items'
```
"
2435705683,72709,`tf.bitwise.left_shift`'s behavior is different on cpu and gpu on tensorflow 2.18.0-dev20240728,closed,2024-07-29 15:18:49+00:00,2024-09-02T16:31:31Z,2024-09-02T16:31:28Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/72709,"['stat:awaiting response', 'type:bug', 'comp:ops', '2.17']","['Maybe not a bug, because\r\n> If `y` is negative, or greater than or equal to the width of `x` in bits the\r\nresult is implementation defined.', '@wangzhen0518,\r\nI was able to reproduce the issue on tensorflow 2.15, v2.17 and tf-nightly. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/3da0435d63f8a53a33bf281d2cbf4469/untitled2035.ipynb). ', '@wangzhen0518,\r\nAs per the document it is mentioned that **If y is negative, or greater than or equal to the width of x in bits the result is implementation defined**, also I checked with alternative inputs for the **y** and observed when the y is +ve, it is providing the same result and when **y** is -ve, it provided the same result as mentioned.\r\nhttps://www.tensorflow.org/api_docs/python/tf/bitwise/left_shift\r\n\r\nKindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/73907c1d487ba220a26f9fa3547d64e8/untitled2040.ipynb) for the reference.\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', 'Thanks for your explanation. I am curious about whether it is necessary to maintain consistent results across different backends.', '@wangzhen0518,\r\nThe reason could be due to the optimized way of calculating numbers on Nvidia which is different compared to others, there will be a small amount of precision errors. Thank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72709"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72709"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

v1.12.1-113709-gdc368f6cbd8 2.18.0-dev20240728

### Custom code

Yes

### OS platform and distribution

Ubuntu 22.04.4 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.11.0

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

cuda_12.4.r12.4/compiler.34097967_0

### GPU model and memory

_No response_

### Current behavior?

`tf.bitwise.left_shift`'s behavior is different on cpu and gpu.

on cpu:
```python
with tf.device(""/cpu:0""):
    x = tf.constant([-2, -1, 0, 1, 2])
    y = tf.constant([3, 2, 1, 0, -1])
    z = tf.bitwise.left_shift(x, y)
    print(z.numpy()) # [-16  -4   0   1   2]
```

on gpu:
```python
with tf.device(""/gpu:0""):
    x = tf.constant([-2, -1, 0, 1, 2])
    y = tf.constant([3, 2, 1, 0, -1])
    z = tf.bitwise.left_shift(x, y)
    print(z.numpy())
```

`z` on cpu and gpu are not equal.

### Standalone code to reproduce the issue

```shell
with tf.device(""/cpu:0""):
    x = tf.constant([-2, -1, 0, 1, 2])
    y = tf.constant([3, 2, 1, 0, -1])
    z = tf.bitwise.left_shift(x, y)
    print(z.numpy()) # [-16  -4   0   1   2]

with tf.device(""/gpu:0""):
    x = tf.constant([-2, -1, 0, 1, 2])
    y = tf.constant([3, 2, 1, 0, -1])
    z = tf.bitwise.left_shift(x, y)
    print(z.numpy()) # [-16  -4   0   1   0]
```


### Relevant log output

_No response_"
2437838158,72782,Tensorflow Issue,closed,2024-07-30 13:24:57+00:00,2024-08-08T13:47:28Z,2024-08-08T13:47:24Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/72782,"['stat:awaiting response', 'type:bug', 'stale', 'TF 2.4']","['Hi **@LuvolwethuTokwe** ,\r\n- Can you please take a look at this [comment](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156) from the issue with similar error.It helps.Also in order to expedite the trouble-shooting process, could you please provide the following information\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nTensorFlow installed from (source or binary):\r\nInstalled using virtualenv? pip? conda?:\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version:\r\nGPU model and memory:\r\nand the exact sequence of commands / steps that you executed before running into the problem.\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', 'Duplicate of #36167 ', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72782"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72782"">No</a>\n']","I would like to be assisted in the issue I arise on when running tensorflow



### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf24.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

ImportError                               Traceback (most recent call last)
File ~\AppData\Roaming\Python\Python312\site-packages\tensorflow\python\pywrap_tensorflow.py:70
     69 try:
---> 70   from tensorflow.python._pywrap_tensorflow_internal import *
     71 # This try catch logic is because there is no bazel equivalent for py_extension.
     72 # Externally in opensource we must enable exceptions to load the shared object
     73 # by exposing the PyInit symbols with pybind. This error will only be
     74 # caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.
     75 
     76 # This logic is used in other internal projects using py_extension.

ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
Cell In[4], line 1
----> 1 import tensorflow as tf
      2 print(tf.__version__)

File ~\AppData\Roaming\Python\Python312\site-packages\tensorflow\__init__.py:38
     35 import sys as _sys
     37 # Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596
---> 38 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow  # pylint: disable=unused-import
     39 from tensorflow.python.tools import module_util as _module_util
     40 from tensorflow.python.util.lazy_loader import KerasLazyLoader as _KerasLazyLoader

File ~\AppData\Roaming\Python\Python312\site-packages\tensorflow\python\pywrap_tensorflow.py:85
     83     sys.setdlopenflags(_default_dlopen_flags)
     84 except ImportError:
---> 85   raise ImportError(
     86       f'{traceback.format_exc()}'
     87       f'\n\nFailed to load the native TensorFlow runtime.\n'
     88       f'See https://www.tensorflow.org/install/errors '
     89       f'for some common causes and solutions.\n'
     90       f'If you need help, create an issue '
     91       f'at https://github.com/tensorflow/tensorflow/issues '
     92       f'and include the entire stack trace above this error message.')

ImportError: Traceback (most recent call last):
  File ""C:\Users\Luvolwethu Tokwe\AppData\Roaming\Python\Python312\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 70, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.

### Standalone code to reproduce the issue

```shell
ImportError                               Traceback (most recent call last)
File ~\AppData\Roaming\Python\Python312\site-packages\tensorflow\python\pywrap_tensorflow.py:70
     69 try:
---> 70   from tensorflow.python._pywrap_tensorflow_internal import *
     71 # This try catch logic is because there is no bazel equivalent for py_extension.
     72 # Externally in opensource we must enable exceptions to load the shared object
     73 # by exposing the PyInit symbols with pybind. This error will only be
     74 # caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.
     75 
     76 # This logic is used in other internal projects using py_extension.

ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
Cell In[4], line 1
----> 1 import tensorflow as tf
      2 print(tf.__version__)

File ~\AppData\Roaming\Python\Python312\site-packages\tensorflow\__init__.py:38
     35 import sys as _sys
     37 # Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596
---> 38 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow  # pylint: disable=unused-import
     39 from tensorflow.python.tools import module_util as _module_util
     40 from tensorflow.python.util.lazy_loader import KerasLazyLoader as _KerasLazyLoader

File ~\AppData\Roaming\Python\Python312\site-packages\tensorflow\python\pywrap_tensorflow.py:85
     83     sys.setdlopenflags(_default_dlopen_flags)
     84 except ImportError:
---> 85   raise ImportError(
     86       f'{traceback.format_exc()}'
     87       f'\n\nFailed to load the native TensorFlow runtime.\n'
     88       f'See https://www.tensorflow.org/install/errors '
     89       f'for some common causes and solutions.\n'
     90       f'If you need help, create an issue '
     91       f'at https://github.com/tensorflow/tensorflow/issues '
     92       f'and include the entire stack trace above this error message.')

ImportError: Traceback (most recent call last):
  File ""C:\Users\Luvolwethu Tokwe\AppData\Roaming\Python\Python312\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 70, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.
```


### Relevant log output

_No response_"
2440947669,72915,"""ValueError: The layer sequential has never been called and thus has no defined output."" when the model's been build and called",closed,2024-07-31 21:00:51+00:00,2024-09-03T12:43:07Z,2024-09-03T12:43:05Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/72915,"['stat:awaiting response', 'type:bug', 'comp:keras', '2.17']","[""I get exactly the same problem when trying to create a gradcam model, to explain a CNN prediction, I'm using TensorFLow 2.17.\r\nStill haven't found a solution."", 'I\'ve figured it out.\r\nI believe the layer ""Sequential"" is considered the last layer of our networks (for some reason), but this layer doesn\'t actually have an output, instead, you need to replace this with the last actual layer.\r\nSo instead of:\r\ngrad_model = tf.keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.output]) #bug\'s here\r\n\r\nUse this:\r\ngrad_model = keras.models.Model(\r\n[model.inputs], \r\n[model.get_layer(last_conv_layer_name).output, \r\nmodel.get_layer(Name_of_last_deep_layer).output]) #right here you should put your last layer\'s name (you can figure that out from running model.summary) mine was \'dense_2\'\r\n\r\nHope this helps :)', ""Thank you for this workaround sc21lt. I don't think we are supposed to do so as in the Keras tutorial for graCAM they are still using 'model.outputs', but thanks, now this step works. \r\nHowever, have you got anything else than None gradients? I don't know if this is due to my time distributed layers but it can't get any gradients when using whether grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.layers[-1].output]) or grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.get_layer('dense').output]). However it works perfectly fine when I use vanilla saliency that doesn't create a new grad_model.."", ""Just a little update, the problem with the null gradients only appears when loading the layer from the .keras file. If the model code is written in the code I don't have null gradients... So there seems to be two different bugs here. Here is the model if one wants to investigate: \r\n```\r\nmodel = tf.keras.models.Sequential([\r\n    tf.keras.Input(shape=(27, 75, 93, 81, 1)),  # time_steps, depth, height, width, channels\r\n    tf.keras.layers.TimeDistributed(tf.keras.layers.Conv3D(6, kernel_size=7, activation='relu', kernel_initializer='he_normal')),\r\n    tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2))),\r\n    tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization()),\r\n\r\n    tf.keras.layers.TimeDistributed(tf.keras.layers.Conv3D(32, kernel_size=3, activation='relu', kernel_initializer='he_normal')),\r\n    tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2))),\r\n    tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization()),\r\n\r\n    tf.keras.layers.TimeDistributed(tf.keras.layers.Conv3D(128, kernel_size=2, activation='relu', kernel_initializer='he_normal')),\r\n    tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2))),\r\n    tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization()),\r\n    tf.keras.layers.TimeDistributed(tf.keras.layers.Conv3D(256, kernel_size=2, activation='relu', kernel_initializer='he_normal')),\r\n\r\n    tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten()),\r\n    tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization()),\r\n\r\n    tf.keras.layers.Conv1D(256, kernel_size=5, activation='relu', kernel_initializer='he_normal'),\r\n    tf.keras.layers.MaxPooling1D(pool_size=2),\r\n    tf.keras.layers.BatchNormalization(),\r\n\r\n    tf.keras.layers.Conv1D(512, kernel_size=3, activation='relu', kernel_initializer='he_normal'),\r\n    tf.keras.layers.MaxPooling1D(pool_size=2),\r\n    tf.keras.layers.BatchNormalization(),\r\n\r\n    tf.keras.layers.Conv1D(1024, kernel_size=2, activation='relu', kernel_initializer='he_normal'),\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Flatten(),\r\n    tf.keras.layers.Dense(2, activation='softmax')]) \r\n```"", 'sc21It Thank you so much!!', '@Senantq,\r\nLooks like this issue is more related to keras issue. Could you please try to raise the issue in the Keras-team/keras repo for the quick resolution. Thank you!', 'It is done, but the workaround found by sc21It produce null gradient with tf gradient tape, am i supposed to close this one ?', '@Senantq,\r\nYeah, please feel free to move this issue to close this issue and raise another issue for the gradient tape which helps to track easily. Thank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72915"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72915"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

tensorflow[and-cuda]==2.17

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 24.04 LTS

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.4

### GPU model and memory

RTX A4500 laptop

### Current behavior?

I loaded a .keras model that I've just trained on a server. The model has been trained on the very same versions of TF and Keras that I am using locally. 

I loaded the model and used a custom implementation of the LayerCAM saliency function where I am creating a submodel using the following: grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.output]). However, the error arises. 

### Standalone code to reproduce the issue

```shell
Here's a Google Drive link to a code, the model weights and an input to reproduce the error: https://drive.google.com/drive/folders/15J_ghWXWbs8EmSVXedH6sJRvJcPUSTIW?usp=sharing
```


### Relevant log output

```shell
ValueError                                Traceback (most recent call last)
Cell In[1], line 45
     42         class_activation_map = tf.expand_dims(class_activation_map, axis=-1)
     43     return class_activation_map
---> 45 layer_cam_test = layer_cam(img = test_sample, model=model, label_index = 0)

Cell In[1], line 24, in layer_cam(img, label_index, model)
     22 print(layer_names)
     23 for layer_name in layer_names[-1:]:
---> 24     grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.output]) #bug's here
     25     with tf.GradientTape() as tape:
     26         tape.watch(img)

File ~/miniconda3/envs/envtfnightly/lib/python3.11/site-packages/keras/src/ops/operation.py:266, in Operation.output(self)
    256 @property
    257 def output(self):
    258     """"""Retrieves the output tensor(s) of a layer.
    259 
    260     Only returns the tensor(s) corresponding to the *first time*
   (...)
    264         Output tensor or list of output tensors.
    265     """"""
--> 266     return self._get_node_attribute_at_index(0, ""output_tensors"", ""output"")

File ~/miniconda3/envs/envtfnightly/lib/python3.11/site-packages/keras/src/ops/operation.py:285, in Operation._get_node_attribute_at_index(self, node_index, attr, attr_name)
    269 """"""Private utility to retrieves an attribute (e.g. inputs) from a node.
    270 
    271 This is used to implement the properties:
   (...)
    282     The operation's attribute `attr` at the node of index `node_index`.
    283 """"""
    284 if not self._inbound_nodes:
--> 285     raise ValueError(
    286         f""The layer {self.name} has never been called ""
    287         f""and thus has no defined {attr_name}.""
    288     )
    289 if not len(self._inbound_nodes) > node_index:
    290     raise ValueError(
    291         f""Asked to get {attr_name} at node ""
    292         f""{node_index}, but the operation has only ""
    293         f""{len(self._inbound_nodes)} inbound nodes.""
    294     )

ValueError: The layer sequential has never been called and thus has no defined output.
Click to add a cell.
```
"
2441891657,72946,Import errors for python keras module,closed,2024-08-01 09:00:15+00:00,2024-08-02T11:19:22Z,2024-08-02T11:19:18Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/72946,"['stat:awaiting response', 'type:bug', 'comp:keras', 'TF2.14']","['@vixhead,\r\ntensorflow/python/keras code is a legacy copy of Keras since the TensorFlow v2.7 release. Please try to remove any import of tensorflow.python.keras and use the public API **from tensorflow import keras** till the tensorflow v2.15 and for later releases try to import  as **import keras** for the keras3.0 version. \r\n\r\nAlso please try to raise the issue of Keras related in the Keras-team/Keras repo for the quick resolution. Thank you!', 'Thanks for the answer. I guess we will have to switch to keras public API then if we want to use 2.14+ versions. (and import keras for 2.15+)', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72946"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72946"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.14+

### Custom code

No

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

3.10.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

While working with `saving` module in `python.keras` some functions raise `importError`.
```cmd
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ImportError: cannot import name '__version__' from 'tensorflow.python.keras'
```

Since `tensorflow==2.14.0` the `__version__` is missing from the `__init__.py`. ( removed in https://github.com/tensorflow/tensorflow/commit/5368a3ad4719842eecae9e4c965b1a5d072cb9e5 )

- [2.13 __init__.py](https://github.com/tensorflow/tensorflow/blob/v2.13.0/tensorflow/python/keras/__init__.py)
- [2.14+ __init__.py](https://github.com/tensorflow/tensorflow/blob/v2.14.0/tensorflow/python/keras/__init__.py)

Some functions eg. `hdf5_format.save_weights_to_hdf_5_group()` still import it in versions `2.14+` [See here for tf 2.15.1](https://github.com/tensorflow/tensorflow/blob/v2.15.1/tensorflow/python/keras/saving/hdf5_format.py#L625)


```
def save_weights_to_hdf5_group(f, layers):
  """"""Saves the weights of a list of layers to a HDF5 group.

  Args:
      f: HDF5 group.
      layers: List of layer instances.
  """"""
  from tensorflow.python.keras import __version__ as keras_version  # pylint: disable=g-import-not-at-top
  ...
```


### Standalone code to reproduce the issue

```shell
from tensorflow.python.keras.saving import hdf5_format

# raises import error
hdf5_format.save_weights_to_hdf_5_group(...)

OR

from tensorflow.python.keras import __version__
```


### Relevant log output

_No response_"
2442380268,72953,Please initialize `TimeDistributed` layer with a `tf.keras.layers.Layer` instance,closed,2024-08-01 12:52:10+00:00,2024-12-27T02:01:31Z,2024-12-27T02:01:28Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/72953,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'TF 2.15']","['Hi **@mayurmunshi** ,\r\n- In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', 'Hello,\r\n\r\nThe code snippet is as follows \r\n\r\n inputs = Input(input_shape)\r\n    custom_layer = ZeroPadding3D((3,3,1))\r\n    time_distributed_custom_layer = TimeDistributed(custom_layer)\r\n    x = time_distributed_custom_layer(inputs)\r\n\r\nOn  trying to execute this step at model.fit stage I am getting following error message :\r\n\r\n epochs = 20\r\n----> 2 model.fit(\r\n      3     train_dataset,\r\n      4     validation_data=validation_dataset,\r\n      5     epochs=epochs,\r\n      6     shuffle=True,batch_size=16,\r\n      7     verbose=2,\r\n      8     callbacks=[checkpoint_cb,tensorboard_cb,early_stopping_cb]\r\n      9 )\r\n\r\nFile ~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)\r\n     67     filtered_tb = _process_traceback_frames(e.__traceback__)\r\n     68     # To get the full stack trace, call:\r\n     69     # `tf.debugging.disable_traceback_filtering()`\r\n---> 70     raise e.with_traceback(filtered_tb) from None\r\n     71 finally:\r\n     72     del filtered_tb\r\n\r\nFile /tmp/__autograph_generated_filecb7v_b6i.py:15, in outer_factory.<locals>.inner_factory.<locals>.tf__train_function(iterator)\r\n     13 try:\r\n     14     do_return = True\r\n---> 15     retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\r\n     16 except:\r\n     17     do_return = False\r\n\r\nValueError: in user code:\r\n\r\n    File ""/home/user/.local/lib/python3.10/site-packages/keras/src/engine/training.py"", line 1401, in train_function  *\r\n        return step_function(self, iterator)\r\n    File ""/home/user/.local/lib/python3.10/site-packages/keras/src/engine/training.py"", line 1384, in step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    File ""/home/user/.local/lib/python3.10/site-packages/keras/src/engine/training.py"", line 1373, in run_step  **\r\n        outputs = model.train_step(data)\r\n    File ""/home/user/.local/lib/python3.10/site-packages/keras/src/engine/training.py"", line 1150, in train_step\r\n        y_pred = self(x, training=True)\r\n    File ""/home/user/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py"", line 70, in error_handler\r\n        raise e.with_traceback(filtered_tb) from None\r\n\r\n    ValueError: Exception encountered when calling layer \'time_distributed_21\' (type TimeDistributed).\r\n    \r\n    as_list() is not defined on an unknown TensorShape.\r\n    \r\n    Call arguments received by layer \'time_distributed_21\' (type TimeDistributed):\r\n      • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\r\n      • training=True\r\n      • mask=None', 'Hi **@mayurmunshi** ,\r\nApologies for the delay, and thank you for your patience. The root cause of this issue is likely a mismatch in the expected input shape for the TimeDistributed layer, which applies a wrapped layer across the time dimension of a 4D or higher-dimensional input. The TimeDistributed layer expects the input tensor to have at least 3 dimensions. If the input tensor does not include these dimensions or has an unknown shape, it results in the error: as_list() is not defined on an unknown TensorShape. I tried modifying the code, and it is working fine now. I hope this will be helpful for you. Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/f44d62dafd1e755e7514f48b7a969a53/72953_tf-2-18-0-v.ipynb) here for reference.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72953"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72953"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.15

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?


ValueError: Please initialize `TimeDistributed` layer with a `tf.keras.layers.Layer` instance. Received: KerasTensor(type_spec=TensorSpec(shape=(None, 3, 32, 32, 16, 256), dtype=tf.float32, name=None), name='activation_19/Relu:0', description=""created by layer 'activation_19'"")

### Standalone code to reproduce the issue

```shell
Please initialize `TimeDistributed` layer with a `tf.keras.layers.Layer` instance
```


### Relevant log output

```shell
alueError                                Traceback (most recent call last)
Cell In[103], line 5
      1 #Model parameters
      3 input_shape = (3,128,128,64,1)
----> 5 modelCNNLSTM310724 = ResNet50_3DCNNLSTM310724(input_shape )#= (128,128,64,1))
      7 modelCNNLSTM310724.summary()

Cell In[102], line 42, in ResNet50_3DCNNLSTM310724(input_shape)
     39 x = layers.BatchNormalization()(x)
     40 x = layers.Dropout(0.5)(x)
---> 42 x = tf.keras.layers.TimeDistributed(conv_block_3d(x, kernel_size=(3, 3, 3), filters=[64, 64, 256], strides=(1, 1, 1)))
     43 x = identity_block_3d(x, kernel_size=(3, 3, 3), filters=[64, 64, 256])
     44 x = identity_block_3d(x, kernel_size=(3, 3, 3), filters=[64, 64, 256])

File ~/.local/lib/python3.10/site-packages/keras/src/layers/rnn/time_distributed.py:74, in TimeDistributed.__init__(self, layer, **kwargs)
     72 def __init__(self, layer, **kwargs):
     73     if not isinstance(layer, Layer):
---> 74         raise ValueError(
     75             ""Please initialize `TimeDistributed` layer with a ""
     76             f""`tf.keras.layers.Layer` instance. Received: {layer}""
     77         )
     78     super().__init__(layer, **kwargs)
     79     self.supports_masking = True

ValueError: Please initialize `TimeDistributed` layer with a `tf.keras.layers.Layer` instance. Received: KerasTensor(type_spec=TensorSpec(shape=(None, 3, 32, 32, 16, 256), dtype=tf.float32, name=None), name='activation_19/Relu:0', description=""created by layer 'activation_19'"")
```
"
2442761797,72963,Failure running a SavedModel exported from a tf.Module with a Keras model as an instance variable,closed,2024-08-01 15:27:28+00:00,2025-01-07T02:02:56Z,2025-01-07T02:02:50Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/72963,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', '2.17']","['I tried to run your code on Colab using TF v2.15.0, 2.17.0, nightly and faced the same issue. Please find the [gist](https://colab.research.google.com/gist/Venkat6871/385f7c5bfc4d9660cb68e5f3fc8feb04/72963_2-15-2-17-nightly-v.ipynb) here for reference.\r\nThank you.', 'Hi **@ivansoban** ,\r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues) as this issue is more related to keras\r\n\r\nThank you!\r\n', 'Hi @Venkat6871 , I am also facing similar issue while deploying a trained tensorflow model using tfserving the dicussion ling you gave above gives Page not found issue, logs for my issue :     external/org_tensorflow/tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: FAILED_PRECONDITION: Could not find variable conv2d/kernel. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Resource localhost/conv2d/kernel/N10tensorflow3VarE does not exist.\r\n         [[{{function_node __inference_serving_default_11757}}{{node sequential_1/conv2d_1/convolution/ReadVariableOp}}]]\r\n2024-08-07 10:11:13.600499: I external/org_tensorflow/tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: ABORTED: Stopping remaining executors.\r\n2024-08-07 10:17:47.725694: I external/org_tensorflow/tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: ABORTED: Stopping remaining executors', 'link to issue for reference: \r\nhttps://github.com/tensorflow/tensorflow/issues/73158', ""@Venkat6871 thank you. The second link doesn't work for me but I have created this issue: https://github.com/keras-team/keras/issues/20095"", 'Hi **@ivansoban** ,\r\nCould you please confirm if this issue has been resolved for you? If it is resolved, feel free to close the issue.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72963"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/72963"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No, because the sample code produces a core dump.

### Source

binary

### TensorFlow version

2.17.0

### Custom code

No

### OS platform and distribution

Linux Ubuntu 22.04.4 LTS

### Mobile device

_No response_

### Python version

3.10.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Saving a `tf.Module` using `tf.saved_model.save` when that class contains a Keras model in an instance variable results in a `FAILED_PRECONDITION` when run using saved_model_cli or libtensorflow.

In Tensorflow v2.15.0, the behavior is as expected: the graph execution proceeds without any errors and the expected results are produced.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

SHAPE = (1, 5)

class TestModel(tf.Module):
    def __init__(self):
        super().__init__()
        self.dense_layer = tf.keras.layers.Dense(10)

    @tf.function(input_signature=[tf.TensorSpec(shape=SHAPE, dtype=tf.float32)])
    def run(self, x):
        return self.dense_layer(x)


module = TestModel()
sample_input = tf.random.normal(SHAPE, dtype=tf.float32)
module.run(sample_input)

np.save('sample_input.npy', sample_input.numpy())
tf.saved_model.save(module, ""test_model"")

# # To reproduce, run the following:
# python test.py && saved_model_cli run --dir test_model --tag_set serve --signature_def serving_default --inputs 'x=sample_input.npy'
```


### Relevant log output

```shell
2024-08-01 15:25:35.204057: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-08-01 15:25:35.261217: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-08-01 15:25:35.278801: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-01 15:25:35.313892: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-01 15:25:37.270110: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-08-01 15:25:38.898105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4281 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:3b:00.0, compute capability: 7.0
2024-08-01 15:25:38.898868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 944 MB memory:  -> device: 1, name: Tesla V100-PCIE-16GB, pci bus id: 0000:d8:00.0, compute capability: 7.0
WARNING:tensorflow:From /home/iantolic-soban/tf_bug/.venv/lib/python3.10/site-packages/tensorflow/python/tools/saved_model_cli.py:716: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.saved_model.load` instead.
W0801 15:25:38.903731 139977869341120 deprecation.py:50] From /home/iantolic-soban/tf_bug/.venv/lib/python3.10/site-packages/tensorflow/python/tools/saved_model_cli.py:716: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.saved_model.load` instead.
INFO:tensorflow:Restoring parameters from test_model/variables/variables
I0801 15:25:38.936800 139977869341120 saver.py:1417] Restoring parameters from test_model/variables/variables
2024-08-01 15:25:38.941206: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled
2024-08-01 15:25:39.144248: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: FAILED_PRECONDITION: Could not find variable dense/bias. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Resource localhost/dense/bias/N10tensorflow3VarE does not exist.
	 [[{{function_node __inference_run_106}}{{node dense_1/Add/ReadVariableOp}}]]
2024-08-01 15:25:39.144340: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: FAILED_PRECONDITION: Could not find variable dense/bias. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Resource localhost/dense/bias/N10tensorflow3VarE does not exist.
	 [[{{function_node __inference_run_106}}{{node dense_1/Add/ReadVariableOp}}]]
	 [[StatefulPartitionedCall/_21]]
2024-08-01 15:25:39.144423: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 12615348601576968325
Traceback (most recent call last):
  File ""/home/iantolic-soban/tf_bug/.venv/lib/python3.10/site-packages/tensorflow/python/client/session.py"", line 1401, in _do_call
    return fn(*args)
  File ""/home/iantolic-soban/tf_bug/.venv/lib/python3.10/site-packages/tensorflow/python/client/session.py"", line 1384, in _run_fn
    return self._call_tf_sessionrun(options, feed_dict, fetch_list,
  File ""/home/iantolic-soban/tf_bug/.venv/lib/python3.10/site-packages/tensorflow/python/client/session.py"", line 1477, in _call_tf_sessionrun
    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,
tensorflow.python.framework.errors_impl.FailedPreconditionError: 2 root error(s) found.
  (0) FAILED_PRECONDITION: Could not find variable dense/bias. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Resource localhost/dense/bias/N10tensorflow3VarE does not exist.
	 [[{{function_node __inference_run_106}}{{node dense_1/Add/ReadVariableOp}}]]
	 [[StatefulPartitionedCall/_21]]
  (1) FAILED_PRECONDITION: Could not find variable dense/bias. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Resource localhost/dense/bias/N10tensorflow3VarE does not exist.
	 [[{{function_node __inference_run_106}}{{node dense_1/Add/ReadVariableOp}}]]
0 successful operations.
0 derived errors ignored.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/iantolic-soban/tf_bug/.venv/bin/saved_model_cli"", line 8, in <module>
    sys.exit(main())
  File ""/home/iantolic-soban/tf_bug/.venv/lib/python3.10/site-packages/tensorflow/python/tools/saved_model_cli.py"", line 1340, in main
    app.run(smcli_main)
  File ""/home/iantolic-soban/tf_bug/.venv/lib/python3.10/site-packages/absl/app.py"", line 308, in run
    _run_main(main, args)
  File ""/home/iantolic-soban/tf_bug/.venv/lib/python3.10/site-packages/absl/app.py"", line 254, in _run_main
    sys.exit(main(argv))
  File ""/home/iantolic-soban/tf_bug/.venv/lib/python3.10/site-packages/tensorflow/python/tools/saved_model_cli.py"", line 1338, in smcli_main
    args.func()
  File ""/home/iantolic-soban/tf_bug/.venv/lib/python3.10/site-packages/tensorflow/python/tools/saved_model_cli.py"", line 1036, in run
    run_saved_model_with_feed_dict(
  File ""/home/iantolic-soban/tf_bug/.venv/lib/python3.10/site-packages/tensorflow/python/tools/saved_model_cli.py"", line 721, in run_saved_model_with_feed_dict
    outputs = sess.run(output_tensor_names_sorted, feed_dict=inputs_feed_dict)
  File ""/home/iantolic-soban/tf_bug/.venv/lib/python3.10/site-packages/tensorflow/python/client/session.py"", line 971, in run
    result = self._run(None, fetches, feed_dict, options_ptr,
  File ""/home/iantolic-soban/tf_bug/.venv/lib/python3.10/site-packages/tensorflow/python/client/session.py"", line 1214, in _run
    results = self._do_run(handle, final_targets, final_fetches,
  File ""/home/iantolic-soban/tf_bug/.venv/lib/python3.10/site-packages/tensorflow/python/client/session.py"", line 1394, in _do_run
    return self._do_call(_run_fn, feeds, fetches, targets, options,
  File ""/home/iantolic-soban/tf_bug/.venv/lib/python3.10/site-packages/tensorflow/python/client/session.py"", line 1420, in _do_call
    raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter
tensorflow.python.framework.errors_impl.FailedPreconditionError: Graph execution error:

2 root error(s) found.
  (0) FAILED_PRECONDITION: Could not find variable dense/bias. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Resource localhost/dense/bias/N10tensorflow3VarE does not exist.
	 [[{{node dense_1/Add/ReadVariableOp}}]]
	 [[StatefulPartitionedCall/_21]]
  (1) FAILED_PRECONDITION: Could not find variable dense/bias. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Resource localhost/dense/bias/N10tensorflow3VarE does not exist.
	 [[{{node dense_1/Add/ReadVariableOp}}]]
0 successful operations.
0 derived errors ignored.
```
"
2443849351,73002,[RNN] unable to quantize RNN with customized cell,closed,2024-08-02 02:14:21+00:00,2024-08-05T22:02:52Z,2024-08-05T22:02:49Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/73002,"['type:bug', 'comp:lite', 'TFLiteConverter', '2.17']","['Hi @Voivio, the easiest way to accomplish this right now is to create a [custom RNN in PyTorch](https://discuss.pytorch.org/t/implementation-of-multiplicative-lstm/2328/4) and convert using [AI-Edge-Torch](https://github.com/google-ai-edge/ai-edge-torch), does this work for you?', 'Hi @pkgoogle, thanks for your quick reply. I have quickly tested this out in the [Colab Notebook](https://colab.research.google.com/drive/1bkinOGC1Hwcr3rq1VDKNPNDgcXiUv2W1?usp=sharing) using this library. This ai-edge-torch library can convert the RNN with customized cells into a TFLite model without errors, yet it is not actually converting operations happened inside (though those outside are fine). Operations are still float32-based rather than int8.\r\n\r\nSo now I give up on using the RNN structure provided from keras and decide to manually handling all hidden states. I have no more questions regarding this issue and please feel free to close it if there will be no more updates on it! \r\n\r\nMany thanks again.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73002"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73002"">No</a>\n']","### 1. System information

- OS Platform and Distribution: Ubuntu 22.04.4 LTS
- TensorFlow installation: pip package
- TensorFlow library: 2.18.0-dev20240801

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

A minimal example is available in this [Colab notebook](https://colab.research.google.com/drive/1GGdTio3XNj9Jg-CKpyV376RRlRy8_Gs1?usp=sharing).

### 3. Failure after conversion

None

### 4. (optional) RNN conversion support
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

### 5. (optional) Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

I wanted to implement a RNN using customized cells. When I try to quantize the model, the conversion can not be finished.

The error message looks like:

`
INFO:tensorflow:Assets written to: [/tmp/tmp6jab2_an/assets](https://file+.vscode-resource.vscode-cdn.net/tmp/tmp6jab2_an/assets)
INFO:tensorflow:Assets written to: [/tmp/tmp6jab2_an/assets](https://file+.vscode-resource.vscode-cdn.net/tmp/tmp6jab2_an/assets)
[/home/d/miniconda3/envs/tflite_model/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953](https://file+.vscode-resource.vscode-cdn.net/home/dd/miniconda3/envs/tf_env/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953): UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.
  warnings.warn(
2024-08-01 21:32:47.659189: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.
2024-08-01 21:32:47.659202: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.

The Kernel crashed while executing code in the current cell or a previous cell. 
Please review the code in the cell(s) to identify a possible cause of the failure. 
Click [here](https://aka.ms/vscodeJupyterKernelCrash) for more info. 
View Jupyter [log](command:jupyter.viewOutput) for further details.
`

No traceback is available as the notebook kernel crashes. When running in python script, segmentation fault happens.

By setting breakpoints, the error seems to happen with Line 153 tensorflow/tensorflow/lite/python/optimize/calibrator.py ([here](https://github.com/tensorflow/tensorflow/blob/02e39547a0d551e5bb0c66e5e0e0c319a33f75ff/tensorflow/lite/python/optimize/calibrator.py#L152)). The underlying cc code is raising the error,

Many thanks for the help with this issue!"
2443912227,73004,"The Tensorflow Profiler and it does not work, and no one replies. ",closed,2024-08-02 03:18:05+00:00,2024-08-02T11:59:17Z,2024-08-02T11:58:45Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/73004,['type:bug'],"['Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73004"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73004"">No</a>\n', 'Closing since there are other open issues about this, and no one replies.']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.10-2.18

### Custom code

Yes

### OS platform and distribution

Colab linux/ubuntu 20

### Python version

3.9-3.12

### CUDA/cuDNN version

12.3 but also on CPU

### GPU model and memory

Colab

### Current behavior?

![Screenshot from 2024-08-02 04-16-24](https://github.com/user-attachments/assets/aca88be2-0273-46a1-aa5f-19e6af81088c)


### Standalone code to reproduce the issue

```shell
Notebook

https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_profiling_keras.ipynb


Page

https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras
```"
2447152418,73110,PyCharm cannot parse any content under tensorflow.keras 2.16.2,closed,2024-08-04 14:11:31+00:00,2024-09-12T01:58:38Z,2024-09-12T01:58:35Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/73110,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'TF 2.16']","[""> ### Issue type\r\n> Bug\r\n> \r\n> ### Have you reproduced the bug with TensorFlow Nightly?\r\n> Yes\r\n> \r\n> ### Source\r\n> binary\r\n> \r\n> ### TensorFlow version\r\n> tf 2.16.2\r\n> \r\n> ### Custom code\r\n> Yes\r\n> \r\n> ### OS platform and distribution\r\n> windows10\r\n> \r\n> ### Mobile device\r\n> windows10\r\n> \r\n> ### Python version\r\n> _No response_\r\n> \r\n> ### Bazel version\r\n> _No response_\r\n> \r\n> ### GCC/compiler version\r\n> _No response_\r\n> \r\n> ### CUDA/cuDNN version\r\n> _No response_\r\n> \r\n> ### GPU model and memory\r\n> _No response_\r\n> \r\n> ### Current behavior?\r\n> autocomplete is not working in Pycharm\r\n> \r\n> ### Standalone code to reproduce the issue\r\n> ```shell\r\n> autocomplete is not working in Pycharm\r\n> ```\r\n> \r\n> ### Relevant log output\r\n> _No response_\r\n\r\nHere are a few steps you can try to resolve the issue:\r\n\r\n1. **Update PyCharm:** Make sure you are using the latest version of PyCharm. Sometimes, issues with autocomplete can be resolved by updating to the latest IDE version.\r\n\r\n2. **Check Project Interpreter:** Verify that the project interpreter in PyCharm is correctly configured to use the environment where TensorFlow 2.16.2 is installed. You can do this by:\r\n\r\n     - Going to File > Settings > Project: <Your Project Name> > Python Interpreter.\r\n\r\n     - Ensure the interpreter is pointing to the correct environment.\r\n\r\n3. **Reindex PyCharm:** Sometimes, PyCharm's indexing can become corrupted. You can force it to reindex by:\r\n\r\n     - Going to File > Invalidate Caches / Restart.\r\n     - Choose Invalidate and Restart.\r\n\r\n4. **Update TensorFlow:** Ensure you have the latest version of TensorFlow 2.16.2 installed. You might want to consider upgrading or downgrading TensorFlow to see if the issue persists with different versions.\r\n\r\n5. **Virtual Environment:** If you are using a virtual environment, try recreating it. Sometimes, issues with autocomplete can be related to environment-specific problems.\r\n\r\n6. **Check PyCharm's Python Console:** Open the Python Console in PyCharm and try importing tensorflow.keras directly. This can help identify if the issue is specific to the autocomplete feature or a broader problem with the library import.\r\n\r\n7. **Install tensorflow with PyCharm Terminal:** Try installing TensorFlow directly from PyCharm’s terminal to ensure it’s properly linked:\r\n\r\n     - Open the terminal in PyCharm.\r\n     - Run pip install tensorflow==2.16.2.\r\n\r\n8. **Consider IDE Alternatives:** If the issue persists and you need a workaround, consider using another IDE or text editor temporarily while you investigate further."", ""> > ### Issue type\r\n> > Bug\r\n> > ### Have you reproduced the bug with TensorFlow Nightly?\r\n> > Yes\r\n> > ### Source\r\n> > binary\r\n> > ### TensorFlow version\r\n> > tf 2.16.2\r\n> > ### Custom code\r\n> > Yes\r\n> > ### OS platform and distribution\r\n> > windows10\r\n> > ### Mobile device\r\n> > windows10\r\n> > ### Python version\r\n> > _No response_\r\n> > ### Bazel version\r\n> > _No response_\r\n> > ### GCC/compiler version\r\n> > _No response_\r\n> > ### CUDA/cuDNN version\r\n> > _No response_\r\n> > ### GPU model and memory\r\n> > _No response_\r\n> > ### Current behavior?\r\n> > autocomplete is not working in Pycharm\r\n> > ### Standalone code to reproduce the issue\r\n> > ```shell\r\n> > autocomplete is not working in Pycharm\r\n> > ```\r\n> > \r\n> > \r\n> >     \r\n> >       \r\n> >     \r\n> > \r\n> >       \r\n> >     \r\n> > \r\n> >     \r\n> >   \r\n> > ### Relevant log output\r\n> > _No response_\r\n> \r\n> Here are a few steps you can try to resolve the issue:\r\n> \r\n> 1. **Update PyCharm:** Make sure you are using the latest version of PyCharm. Sometimes, issues with autocomplete can be resolved by updating to the latest IDE version.\r\n> 2. **Check Project Interpreter:** Verify that the project interpreter in PyCharm is correctly configured to use the environment where TensorFlow 2.16.2 is installed. You can do this by:\r\n>    \r\n>    * Going to File > Settings > Project:  > Python Interpreter.\r\n>    * Ensure the interpreter is pointing to the correct environment.\r\n> 3. **Reindex PyCharm:** Sometimes, PyCharm's indexing can become corrupted. You can force it to reindex by:\r\n>    \r\n>    * Going to File > Invalidate Caches / Restart.\r\n>    * Choose Invalidate and Restart.\r\n> 4. **Update TensorFlow:** Ensure you have the latest version of TensorFlow 2.16.2 installed. You might want to consider upgrading or downgrading TensorFlow to see if the issue persists with different versions.\r\n> 5. **Virtual Environment:** If you are using a virtual environment, try recreating it. Sometimes, issues with autocomplete can be related to environment-specific problems.\r\n> 6. **Check PyCharm's Python Console:** Open the Python Console in PyCharm and try importing tensorflow.keras directly. This can help identify if the issue is specific to the autocomplete feature or a broader problem with the library import.\r\n> 7. **Install tensorflow with PyCharm Terminal:** Try installing TensorFlow directly from PyCharm’s terminal to ensure it’s properly linked:\r\n>    \r\n>    * Open the terminal in PyCharm.\r\n>    * Run pip install tensorflow==2.16.2.\r\n> 8. **Consider IDE Alternatives:** If the issue persists and you need a workaround, consider using another IDE or text editor temporarily while you investigate further.\r\n\r\nDowngrading TensorFlow is useful."", '@zzzzzzzs,\r\nKeras is migrated to Keras 3 with multi backend support.\r\n\r\nCould you please install Keras separately using pip install keras and import keras directly and let us know the outcome with keras.layers etc.\r\n\r\nWhen we are importing the keras from tensorflow till version 2.15, keras 2.0 is imported. Whereas when we try to import the tensorflow 2.16 it imports keras3.0 directly.\r\n\r\n\r\n**TF 2.15: Keras2.0**\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n```\r\n\r\n**TF 2.16: Keras 3.0**\r\n```python\r\nimport tensorflow as tf\r\nimport keras\r\n```\r\n\r\n\r\nKeras 3 implements the full Keras API and makes it available with TensorFlow, JAX, and PyTorch\r\nhttps://keras.io/keras_3/\r\n\r\nThank you!\r\n', '> @zzzzzzzs, Keras is migrated to Keras 3 with multi backend support.\r\n> \r\n> Could you please install Keras separately using pip install keras and import keras directly and let us know the outcome with keras.layers etc.\r\n> \r\n> When we are importing the keras from tensorflow till version 2.15, keras 2.0 is imported. Whereas when we try to import the tensorflow 2.16 it imports keras3.0 directly.\r\n> \r\n> **TF 2.15: Keras2.0**\r\n> \r\n> ```python\r\n> import tensorflow as tf\r\n> from tensorflow import keras\r\n> ```\r\n> \r\n> **TF 2.16: Keras 3.0**\r\n> \r\n> ```python\r\n> import tensorflow as tf\r\n> import keras\r\n> ```\r\n> \r\n> Keras 3 implements the full Keras API and makes it available with TensorFlow, JAX, and PyTorch https://keras.io/keras_3/\r\n> \r\n> Thank you!\r\n\r\nNow I am directly using Keras in TensorFlow, and after trying it out, I found that pycharm 2023.2.7 corresponds to TensorFlow 2.10.0 and works', '@zzzzzzzs,\r\nHave you tried with the tensorflow latest version 2.17.0? and provide the update and try as mentioned import Keras.\r\n\r\nAlso this is more related to keras. Please raise the request in keras-team/keras repo. \r\n Thank you!', ""> @zzzzzzzs, Have you tried with the tensorflow latest version 2.17.0? and provide the update and try as mentioned import Keras.\r\n> \r\n> Also this is more related to keras. Please raise the request in keras-team/keras repo. Thank you!\r\n\r\nOkay, I'm willing to try."", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73110"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73110"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

tf 2.16.2

### Custom code

Yes

### OS platform and distribution

windows10

### Mobile device

windows10

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

autocomplete is not working in Pycharm

### Standalone code to reproduce the issue

```shell
autocomplete is not working in Pycharm
```


### Relevant log output

_No response_"
2447678982,73119,`tf.random.stateless_categorical` get different output when using same seed and same input,closed,2024-08-05 06:04:28+00:00,2024-08-05T08:23:14Z,2024-08-05T08:23:10Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/73119,['type:bug'],"['Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73119"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73119"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.17.0

### Custom code

No

### OS platform and distribution

Ubuntu 22.04.3 LTS

### Mobile device

_No response_

### Python version

3.10.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.2.140

### GPU model and memory

GPU T4

### Current behavior?

I run `tf.random.stateless_categorical` with the same inputs within a batch and the same seed but get different outputs. Is it suppose to get same output?

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
logits = tf.constant([[0.1, 0.2, 0.3, 0.4, 0.5, 0.6], [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]], dtype=tf.float32)
sample_seed = tf.constant([3723, 3723], dtype=tf.int32)
output = tf.random.stateless_categorical(
        logits=logits,
        num_samples=1,
        seed=sample_seed,
        dtype=tf.int32,
    )
print(output)

```


### Relevant log output
```
tf.Tensor(
[[4]
 [2]], shape=(2, 1), dtype=int32)
```"
2449392095,73167,TFLite inference on iOS works with Metal GPU delegate but fails with CoreML delegate,closed,2024-08-05 20:08:04+00:00,2024-08-07T15:59:30Z,2024-08-07T15:59:27Z,sawantkumar,,https://github.com/tensorflow/tensorflow/issues/73167,"['type:bug', 'comp:lite', 'TFLiteGpuDelegate', '2.17']","['i think these couple of steps might fix your issue: \r\n\r\n1. i hope you\'ve checked if the TensorflowLite version is compatible with your CoreML delegate\r\n2. try updating or downgrading the Protobuf library, it can resolve compatibility issues sometimes.\r\n3. if none of the above steps work try this code instead: \r\n\r\n```tfModel = TfLiteModelCreateFromFile(modelPath.c_str());\r\n    \r\nTfLiteInterpreterOptions* options = TfLiteInterpreterOptionsCreate();\r\nTfLiteInterpreterOptionsSetNumThreads(options, 4);\r\n\r\nconst TfLiteCoreMlDelegateOptions coreMLOptions = {\r\n    .enabled_devices = TfLiteCoreMlDelegateAllDevices,\r\n    .coreml_version = 3,\r\n    .max_delegated_partitions = 1,\r\n    .min_nodes_per_partition = 1\r\n};\r\ntfDelegate = TfLiteCoreMlDelegateCreate(&coreMLOptions);\r\n\r\nif (tfDelegate == NULL) {\r\n    const TFLGpuDelegateOptions gpuOptions = {\r\n      .allow_precision_loss = true,\r\n      .wait_type = TFLGpuDelegateWaitType::TFLGpuDelegateWaitTypePassive,\r\n      .enable_quantization = true\r\n    };\r\n    \r\n    tfDelegate = TFLGpuDelegateCreate(&gpuOptions);\r\n}\r\n\r\nTfLiteInterpreterOptionsAddDelegate(options, tfDelegate);\r\n\r\nif (!tfModel) {\r\n    fprintf(stderr, ""Failed to load model\\n"");\r\n    return;\r\n}\r\n\r\nif (!options) {\r\n    fprintf(stderr, ""Failed to create interpreter options\\n"");\r\n    return;\r\n}\r\n\r\nmodelInterpreter = TfLiteInterpreterCreate(tfModel, options);\r\n\r\nif (!modelInterpreter) {\r\n    fprintf(stderr, ""Failed to create interpreter\\n"");\r\n    return;\r\n}\r\n\r\nTfLiteInterpreterOptionsDelete(options);\r\n```\r\n\r\nlet me know what log output is showing if it still fails', '@AdvaitDongre Thanks for your suggestions. \r\n1. The tensorflow I have is version 2.17.0. I built it from source using bazel. For my tflite model, the format is ""TensorFlow Lite v3"". I think they should be compatible with CoreML delegate.\r\n2. I think Protobuf library is included in the tensorflow package as third-party APIs, should I upgrade/downgrade myself?\r\n3. I have tried your code, the app still crashes at the line:\r\n`modelInterpreter = TfLiteInterpreterCreate(tfModel, options); // <-----Thread 1: signal. SIGABRT`\r\nwith the same error:\r\n```\r\n[libprotobuf FATAL google/protobuf/io/zero_copy_stream_impl_lite.cc:334] CHECK failed: (count) <= (buffer_used_):  Can\'t back up over more bytes than were returned by the last call to Next().\r\nlibc++abi: terminating due to uncaught exception of type google::protobuf::FatalException: CHECK failed: (count) <= (buffer_used_):  Can\'t back up over more bytes than were returned by the last call to Next().\r\n```', 'okay, it seems the main problem is related to protobuf, firstly try rebuilding your tensorflow lite and go for a version 3.19.... like 3.19.1, since it seems to work well with tensorflow 2.17.0, i feel like that would definitely do the work ', '@AdvaitDongre Can you elaborate on how i can change the version of Protobuf? Some configure file in the tensorflow package?', 'have you used pip or manually cloned the repo in your system? ', ""@AdvaitDongre I just downloaded the source zip file for 2.17.0 and built it with Bazel locally. I haven't used pip or cloned the repo."", 'you should try changing the protobuf dependency in the WORKSPACE file before building tensorflow again\r\n\r\nyou should try this code (given by GPT):\r\n```\r\nwget https://github.com/protocolbuffers/protobuf/releases/download/v3.19.1/protobuf-all-3.19.1.tar.gz\r\ntar -xzf protobuf-all-3.19.1.tar.gz\r\ncd protobuf-3.19.1\r\n./configure\r\nmake\r\nsudo make install\r\ncd ..\r\n```\r\n\r\nupdate this desired section, you might need to modify the \r\n```\r\nhttp_archive(\r\n    name = ""com_google_protobuf"",\r\n    urls = [""https://mirror.bazel.build/github.com/protocolbuffers/protobuf/archive/v3.19.1.tar.gz""],\r\n    strip_prefix = ""protobuf-3.19.1"",\r\n    sha256 = ""a0d1a16ef23a15761a216c6dc7c7857b22f6b88ff52e19adad0c703f4b69e4b4"",\r\n)\r\n```\r\nnow for sha256 file you\'ll need to run this command in your terminal\r\n```\r\nsha256sum protobuf-all-3.19.1.tar.gz\r\n```\r\n\r\nand then paste that thing in the sha256.\r\n\r\nand then you can clean and rebuild the tensorflow lite\r\n\r\n', '@AdvaitDongre Thanks for your suggestion. I downgraded the Protobuf from 3.21.9 to 3.19.2. The crash is gone. ', ""You're welcome, and I think you should close this issue, if you have any other issues feel free to ask"", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73167"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73167"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.17.0

### Custom code

Yes

### OS platform and distribution

MacOS Sonoma 14.6

### Mobile device

iPhone 12 Pro

### Python version

3.12.4

### Bazel version

7.2.1

### GCC/compiler version

15.0.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

Apple M3 Max 36GB

### Current behavior?

I tested a TFLite model inference with the C API on iOS (code attached below). The code tries to initialize a CoreML delegate when it's available, otherwise, it falls back to Metal GPU delegate. **It works fine with Metal GPU delegate when the CoreML delegate is commented out, but produces errors when CoreML delegate is enabled at the line:**
   ` modelInterpreter = TfLiteInterpreterCreate(tfModel, options); // <-----Thread 1: signal. SIGABRT`

The error from the log output is attached below. It looks like it has to do with the TFLite model. I also tested on other TFLite models, they all have the same error. Can someone help point out what the root cause is? 


### Standalone code to reproduce the issue

```shell
// Initialize model
    tfModel = TfLiteModelCreateFromFile(modelPath.c_str());
    
    TfLiteInterpreterOptions* options = TfLiteInterpreterOptionsCreate();
    TfLiteInterpreterOptionsSetNumThreads(options, 4);
    
// CoreML delegate
    const TfLiteCoreMlDelegateOptions coreMLOptions = {
        .enabled_devices = TfLiteCoreMlDelegateAllDevices
    };
    tfDelegate = TfLiteCoreMlDelegateCreate(&coreMLOptions);
    if (tfDelegate == NULL) {
        // Fall back to GPU delegate
        const TFLGpuDelegateOptions gpuOptions = {
          .allow_precision_loss = true,
          .wait_type = TFLGpuDelegateWaitType::TFLGpuDelegateWaitTypePassive,
          .enable_quantization = true
        };
        
        tfDelegate = TFLGpuDelegateCreate(&gpuOptions);
    }
    
    TfLiteInterpreterOptionsAddDelegate(options, tfDelegate);
    
    modelInterpreter = TfLiteInterpreterCreate(tfModel, options); // <-----Thread 1: signal. SIGABRT
    TfLiteInterpreterOptionsDelete(options);
```


### Relevant log output

```shell
coreml_version must be 2 or 3. Setting to 3.
Initialized TensorFlow Lite runtime.
INFO: Initialized TensorFlow Lite runtime.
CoreML delegate: 50 nodes delegated out of 55 nodes, with 6 partitions.
INFO: CoreML delegate: 50 nodes delegated out of 55 nodes, with 6 partitions.

[libprotobuf FATAL google/protobuf/io/zero_copy_stream_impl_lite.cc:334] CHECK failed: (count) <= (buffer_used_):  Can't back up over more bytes than were returned by the last call to Next().
libc++abi: terminating due to uncaught exception of type google::protobuf::FatalException: CHECK failed: (count) <= (buffer_used_):  Can't back up over more bytes than were returned by the last call to Next().
```
"
2449577827,73174,Impossible to build with Python3.12,closed,2024-08-05 22:24:59+00:00,2024-08-12T22:01:45Z,2024-08-12T22:01:43Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/73174,"['stat:awaiting response', 'type:bug', 'comp:micro']","['Wait, I clicked on the link in the tflite-micro repository, not sure is it supposed to end up in this repo :thinking:.', 'Hi **@LucasChollet** ,\r\n- Please verify your project on the latest build once your [PR](https://github.com/tensorflow/tflite-micro/pull/2654) is getting merged. Please let us know the response.\r\n\r\nThank you!', ""As mentioned in the PR, it still fails to build later on. But it's now clear why you shouldn't build with Python 3.12."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73174"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73174"">No</a>\n']","Using latest Ubuntu (24.04 with Python3.12), the following command fails:
```
bazel build ...
```

With this error:
```
AttributeError: module 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?
```

This is because `rules_python` is outdated."
2451833759,73254,[RNN] TFLite does not appear to be using the UnidirectionalSequenceLSTM,closed,2024-08-06 23:15:11+00:00,2024-11-26T18:06:43Z,2024-11-26T18:06:38Z,zichuan-wei,,https://github.com/tensorflow/tensorflow/issues/73254,"['stat:awaiting tensorflower', 'type:bug', 'comp:lite', 'TFLiteConverter', '2.17']","['Is there anything I can do to tweak my model to allow it to work without the flex ops?', 'Hi @eric, using only TFLite BuiltIn Ops, will do this but that can be quite constraining. For most LSTM use cases we highly recommend upgrading to Transformers and using PyTorch and [AI-Edge-Torch](https://github.com/google-ai-edge/ai-edge-torch) and the [Generative API](https://github.com/google-ai-edge/ai-edge-torch?tab=readme-ov-file#generative-api) to convert to .tflite models. Does that work for you?', ""So far I've found that using an LSTM has been a good trade-off for performance and accuracy, so it would be nice if they could work again. Is there a current working example that shows how to use it with tensorflow?"", ""Hi @eric, with raw tensorflow w/o Keras, it does not seem like there is an easy way to create an LSTM. It was sunsetted awhile ago ... I did find a raw_ops for an LSTM Cell: https://www.tensorflow.org/api_docs/python/tf/raw_ops/BlockLSTMV2. I don't believe you will want to reconstruct an LSTM with more primitive ops w/o Keras but that is one possibility."", 'Is there a way to do it with Keras? I am using Keras so that would  be fine.', 'Hi @eric, my current attempts seems to be running into a prior bug ... would you be willing to use [AI-Edge-Torch](https://github.com/google-ai-edge/ai-edge-torch) instead?\r\n\r\nI was able to convert an lstm that way:\r\n```py\r\nimport ai_edge_torch\r\nimport torch\r\nimport torch.nn as nn\r\n\r\n\r\nlstm = nn.LSTM(10, 20, 2)\r\nh0 = torch.randn(2, 3, 20)\r\nc0 = torch.randn(2, 3, 20)\r\n\r\nsample_input = (torch.randn(5, 3, 10), (h0, c0))\r\n\r\nedge_model = ai_edge_torch.convert(lstm.eval(), sample_input)\r\nedge_model.export(""lstm.tflite"")\r\n```', ""I've been using keras-tcn for other parts of my model and found that it performed better than LSTM, so I would have to evaluate the pytorch landscape to see if it would work for me."", ""Understood, let us know if for some reason that workflow doesn't work. You are able to reopen the issue in the future."", 'Is there any hope of fixing the bug in Keras that is preventing it from working? It would be nice to not have to rewrite everything. ', ""Hi @eric, we can turn this issue into that issue for now, if that is preferred. Here's a gist showing the issue with tf-nightly (I have attempted on previous versions of tf up to and including 2.15) [gist](https://colab.sandbox.google.com/gist/pkgoogle/71316c19106db05fc455913dea6cf366/73254.ipynb)\r\n\r\nHi @zichuan-wei, can you please take a look? Thanks."", 'That would be great. Thanks!', ""Hi, @eric \r\nThanks for raising this issue. Are you aware of the migration to [LiteRT](https://developers.googleblog.com/en/tensorflow-lite-is-now-litert/)? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/google-ai-edge/LiteRT/issues/41\r\n\r\nLet us know if you have any questions. Thanks."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73254"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73254"">No</a>\n']","### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS
- TensorFlow installation (pip package or built from source): from pip
- TensorFlow library (version, if pip package or github SHA, if built from source): keras-nightly-3.4.1.dev2024080603 tb-nightly-2.18.0a20240806 tf-nightly-2.18.0.dev20240806

### 2. Code

1) https://colab.research.google.com/gist/eric/f00f071e527f9fa7b2ed39f8d482fbb4/tensorflow-datasets.ipynb
2) https://colab.research.google.com/gist/eric/a292799568831371b7686a2b8cefcd0b/tensorflow-lite-debugger-colab.ipynb

[model.zip](https://github.com/user-attachments/files/16516496/model.zip)

### 3. Failure after conversion

I've found that any Keras LSTM causes this issue.

I expected TFLite to use the `UnidirectionalSequenceLSTM` op, but instead it seems to be doing something else that then requires the use of flex ops, which I would like to avoid trying to get to work with my tflite deployment situation.
"
2453589498,73295,TensorBuffer does not support data type: INT32,closed,2024-08-07 14:10:01+00:00,2024-09-16T05:54:21Z,2024-08-24T01:53:20Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/73295,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'Android', 'TF 2.16']","['Hi @AiTester950 ,\r\n\r\nBy looking at the error  \r\n```\r\nprocess: com.example.bert_app, PID: 8162\r\n java.lang.AssertionError: TensorBuffer does not support data type: INT32  \r\n```\r\nit looks like DataType.INT32 is not supported by TensorBuffer , can you use DataType.FLOAT32  instead and let me know if it worked for you.', 'Hey\r\nFLOAT32 works but the ai model that I am working with needs INT32...', 'Hi @AiTester950 ,\r\n\r\nYou will need to use Bytebuffer to accomplish your task . However the output can still handled as a FLOAT32 TensorBuffer .\r\nPlease take a look at [this](https://developer.android.com/reference/java/nio/ByteBuffer)', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73295"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73295"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.16.1

### Custom code

Yes

### OS platform and distribution

Windows 11 x64

### Mobile device

Andorid Studio virtual device: Medium Phone

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

My app is crashing with the error: TensorBuffer does not support data type: INT32.
I expected it to work normally and not to crash.

### Standalone code to reproduce the issue

```java

package com.example.bert_app;

import android.os.Bundle;
import android.util.Log;
import androidx.appcompat.app.AppCompatActivity;
import org.tensorflow.lite.Interpreter;
import org.tensorflow.lite.support.common.FileUtil;
import org.tensorflow.lite.support.tensorbuffer.TensorBuffer;
import org.tensorflow.lite.DataType;
import com.example.bert_app.tokenizerimpl.BertTokenizer;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Objects;

public class MainActivity extends AppCompatActivity {
    private static final String TAG = ""MainActivity"";
    private static final String MODEL_PATH = ""bert_ner_model.tflite"";
    private static final int MAX_SEQ_LENGTH = 512;

    private Interpreter tfliteInterpreter;
    private BertTokenizer tokenizer;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);

        // tokenizer
        tokenizer = new BertTokenizer(this, ""vocab.txt"", true, true, new ArrayList<>(),
                ""[UNK]"", ""[SEP]"", ""[PAD]"", ""[CLS]"", ""[MASK]"", true);

        try {
            tfliteInterpreter = new Interpreter(FileUtil.loadMappedFile(this, MODEL_PATH));
        } catch (Exception e) {
            Log.e(TAG, ""Error loading model"", e);
        }

        
        String inputText = ""I am Wolfgang and I live in Berlin."";
        List<String> tokenizedInput = tokenizer.tokenize(inputText);
        List<Integer> inputIds = tokenizer.convert_tokens_to_ids(tokenizedInput);

        while (inputIds.size() < MAX_SEQ_LENGTH) {
            inputIds.add(tokenizer.convert_tokens_to_ids(Collections.singletonList(""[PAD]"")).get(0));
        }
        if (inputIds.size() > MAX_SEQ_LENGTH) {
            inputIds = inputIds.subList(0, MAX_SEQ_LENGTH);
        }

        List<Integer> segmentIds = new ArrayList<>(Collections.nCopies(MAX_SEQ_LENGTH, 0));

        List<Integer> attentionMask = new ArrayList<>();
        for (int i = 0; i < MAX_SEQ_LENGTH; i++) {
            attentionMask.add(Objects.equals(inputIds.get(i), tokenizer.convert_tokens_to_ids(Collections.singletonList(""[PAD]"")).get(0)) ? 0 : 1);
        }

        runInference(inputIds, attentionMask, segmentIds);
    }

    private void runInference(List<Integer> inputIds, List<Integer> attentionMask, List<Integer> segmentIds) {
        int[] inputIdsArray = listToIntArray(inputIds);
        int[] attentionMaskArray = listToIntArray(attentionMask);
        int[] segmentIdsArray = listToIntArray(segmentIds);

        for (int i = 0; i < tfliteInterpreter.getInputTensorCount(); i++) {
            Log.d(TAG, ""Input Tensor "" + i + "": "" + tfliteInterpreter.getInputTensor(i).dataType());
        }
        for (int i = 0; i < tfliteInterpreter.getOutputTensorCount(); i++) {
            Log.d(TAG, ""Output Tensor "" + i + "": "" + tfliteInterpreter.getOutputTensor(i).dataType());
        }

        TensorBuffer inputIdsBuffer = TensorBuffer.createFixedSize(new int[]{1, MAX_SEQ_LENGTH}, DataType.INT32);
        inputIdsBuffer.loadArray(inputIdsArray);

        TensorBuffer attentionMaskBuffer = TensorBuffer.createFixedSize(new int[]{1, MAX_SEQ_LENGTH}, DataType.INT32);
        attentionMaskBuffer.loadArray(attentionMaskArray);

        TensorBuffer segmentIdsBuffer = TensorBuffer.createFixedSize(new int[]{1, MAX_SEQ_LENGTH}, DataType.INT32);
        segmentIdsBuffer.loadArray(segmentIdsArray);

        TensorBuffer outputBuffer = TensorBuffer.createFixedSize(new int[]{1, MAX_SEQ_LENGTH, 2}, DataType.FLOAT32);  // Assuming output is of shape [1, MAX_SEQ_LENGTH, 2]

        Object[] inputs = {inputIdsBuffer.getBuffer(), attentionMaskBuffer.getBuffer(), segmentIdsBuffer.getBuffer()};
        Map<Integer, Object> outputs = new HashMap<>();
        outputs.put(0, outputBuffer.getBuffer());
        

        tfliteInterpreter.runForMultipleInputsOutputs(inputs, outputs);

        //  output
        float[] outputArray = outputBuffer.getFloatArray();
        processOutput(outputArray);
    }

    private int[] listToIntArray(List<Integer> list) {
        int[] array = new int[list.size()];
        for (int i = 0; i < list.size(); i++) {
            array[i] = list.get(i);
        }
        return array;
    }

    private void processOutput(float[] outputArray) {
        for (float value : outputArray) {
            Log.d(TAG, ""Output: "" + value);
        }
    }
}
```


### Relevant log output

```shell
024-08-07 16:03:11.485  8162-8162  MainActivity            com.example.bert_app                 D  Input Tensor 0: INT32
2024-08-07 16:03:11.485  8162-8162  MainActivity            com.example.bert_app                 D  Input Tensor 1: INT32
2024-08-07 16:03:11.485  8162-8162  MainActivity            com.example.bert_app                 D  Input Tensor 2: INT32
2024-08-07 16:03:11.485  8162-8162  MainActivity            com.example.bert_app                 D  Output Tensor 0: FLOAT32
2024-08-07 16:03:11.489  8162-8162  AndroidRuntime          com.example.bert_app                 D  Shutting down VM
2024-08-07 16:03:11.491  8162-8162  AndroidRuntime          com.example.bert_app                 E  FATAL EXCEPTION: main (Ask Gemini)
                                                                                                    Process: com.example.bert_app, PID: 8162
                                                                                                    java.lang.AssertionError: TensorBuffer does not support data type: INT32
                                                                                                    	at org.tensorflow.lite.support.tensorbuffer.TensorBuffer.createFixedSize(TensorBuffer.java:82)
                                                                                                    	at com.example.bert_app.MainActivity.runInference(MainActivity.java:85)
                                                                                                    	at com.example.bert_app.MainActivity.onCreate(MainActivity.java:68)
                                                                                                    	at android.app.Activity.performCreate(Activity.java:8980)
                                                                                                    	at android.app.Activity.performCreate(Activity.java:8958)
                                                                                                    	at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1526)
                                                                                                    	at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:4029)
                                                                                                    	at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:4234)
                                                                                                    	at android.app.servertransaction.LaunchActivityItem.execute(LaunchActivityItem.java:112)
                                                                                                    	at android.app.servertransaction.TransactionExecutor.executeNonLifecycleItem(TransactionExecutor.java:174)
                                                                                                    	at android.app.servertransaction.TransactionExecutor.executeTransactionItems(TransactionExecutor.java:109)
                                                                                                    	at android.app.servertransaction.TransactionExecutor.execute(TransactionExecutor.java:81)
                                                                                                    	at android.app.ActivityThread$H.handleMessage(ActivityThread.java:2635)
                                                                                                    	at android.os.Handler.dispatchMessage(Handler.java:107)
                                                                                                    	at android.os.Looper.loopOnce(Looper.java:232)
                                                                                                    	at android.os.Looper.loop(Looper.java:317)
                                                                                                    	at android.app.ActivityThread.main(ActivityThread.java:8699)
                                                                                                    	at java.lang.reflect.Method.invoke(Native Method)
                                                                                                    	at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:580)
                                                                                                    	at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:886)
2024-08-07 16:03:11.502  8162-8162  Process                 com.example.bert_app                 I  Sending signal. PID: 8162 SIG: 9
```
"
2455364368,73368,Tensorflow can't detect my GPU,closed,2024-08-08 09:49:39+00:00,2024-08-27T01:55:57Z,2024-08-27T01:55:52Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/73368,"['stat:awaiting response', 'type:bug', 'stale', 'comp:gpu', '2.17']","['Hi **@siy415** ,\r\nI apologize for the delayed response. GPU support on native-Windows is only available for 2.10 or earlier versions, starting in TF 2.11, CUDA build is not supported for Windows. For using TensorFlow GPU on Windows, you will need to build/install TensorFlow in WSL2 or use tensorflow-cpu with TensorFlow-DirectML-Plugin. Here i am giving [documentation](https://www.tensorflow.org/install/source_windows#gpu) for reference.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73368"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73368"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.17.0

### Custom code

No

### OS platform and distribution

Windows 11

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Tensorflow can't detect my gpu.
But Cuda and cuDNN is installed

CUDA version: 12.5

### Standalone code to reproduce the issue

```shell
Copyright (c) 2005-2024 NVIDIA Corporation
Built on Wed_Apr_17_19:36:51_Pacific_Daylight_Time_2024
Cuda compilation tools, release 12.5, V12.5.40
Build cuda_12.5.r12.5/compiler.34177558_0
```

+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 555.99                 Driver Version: 555.99         CUDA Version: 12.5     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 4050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |
| N/A   44C    P8              1W /   45W |       0MiB /   6141MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

``` python
tf.test.gpu_device_name()
# ''
tf.config.list_physical_devices()
# [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
```

### Relevant log output

_No response_"
2456373136,73404,Convergence of Actor critic algorthim ,closed,2024-08-08 18:17:16+00:00,2025-01-07T02:02:54Z,2025-01-07T02:02:47Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/73404,"['stat:awaiting response', 'type:bug', 'stale', '1.4.0']","['Hi **@AhdHazim** ,\r\nSorry for the dealy, I tried to run your code on Colab using the TF-nightly version and faced different issue. I suspect this might be because you are using TensorFlow 1.x. Could you please migrate your code to TensorFlow 2.x? I have attached [documentation](https://www.tensorflow.org/guide/migrate) and a replicated [gist](https://colab.research.google.com/gist/Venkat6871/71ea1e56b00d7c30bb793de2251a81b2/73404_tf-nightly-2-18-0-v.ipynb) for reference. \r\n\r\nThank you!', ""Thank you for your kind reply!\r\n\r\nYou are right,  I am using TensorFlow 1.x . Indeed I have tried before to moved  2.x  but I have faced many issues.  You  can run it with TensorFlow 1.x if you add  the following lines to your run file:\r\n\r\ntf.compat.v1.disable_eager_execution()\r\n\r\n# Use ConfigProto with tf.compat.v1\r\nconfig = tf.compat.v1.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsess = tf.compat.v1.Session(config=config)\r\n\r\n________________________________\r\nFrom: Venkat6871 ***@***.***>\r\nSent: 12 August 2024 09:23\r\nTo: tensorflow/tensorflow ***@***.***>\r\nCc: Sabr, Ohood ***@***.***>; Mention ***@***.***>\r\nSubject: Re: [tensorflow/tensorflow] Convergence of Actor critic algorthim (Issue #73404)\r\n\r\n[ATTENTION : Ce courriel provient de l'extérieur de l'ÉTS]\r\nÉvitez de cliquer sur un lien ou d'ouvrir une pièce jointe si vous ne connaissez pas l'expéditeur du courriel. En cas de doute, veuillez SVP créer un billet Problème de courriel au GUS<https://gus.etsmtl.ca/c2atom/LoginAzure?landingPage=/portal-request-form/714d9e14-bc17-47b8-a0e6-e154184ecbc2> .\r\n\r\n\r\n\r\nHi @AhdHazim<https://github.com/AhdHazim> ,\r\nI tried to run your code on Colab using the TF-nightly version and faced different issue. I suspect this might be because you are using TensorFlow 1.x. Could you please migrate your code to TensorFlow 2.x? I have attached documentation<https://www.tensorflow.org/guide/migrate> and a replicated gist<https://colab.research.google.com/gist/Venkat6871/71ea1e56b00d7c30bb793de2251a81b2/73404_tf-nightly-2-18-0-v.ipynb> for reference.\r\n\r\nThank you!\r\n\r\n—\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/73404#issuecomment-2283370389>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/BDSWQX4PRMM7TDNXNT3VHNDZRBWIRAVCNFSM6AAAAABMHAIR7GVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEOBTGM3TAMZYHE>.\r\nYou are receiving this because you were mentioned.Message ID: ***@***.***>\r\n"", 'Hi **@AhdHazim** ,\r\nApologies for the delay, and thank you for your patience. TensorFlow 1.x is already deprecated, so you need to migrate to TensorFlow 2.x. For your reference, I have attached the  [documentation](https://www.tensorflow.org/guide/migrate) on migrating.\r\nThank you! ', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73404"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73404"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

V1

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Hello, 

I am using the following actor critic agent, but it does not converge at all. Please could you help me with this matter.
In the following  the code and the results

`
import numpy as np
import tensorflow as tf
import tensorflow.compat.v1 as tf
import json

tf.disable_v2_behavior()
tf.reset_default_graph()
class A2CLSTM(object):
    def __init__(
            self,
            sess,
            n_actions,
            n_features,
            lr_a,
            lr_c,
            entropy_beta,
            batch_size=32  # Default batch size
    ):
        self.sess = sess
        self.n_actions = n_actions
        self.n_features = n_features
        self.lr_a = lr_a
        self.lr_c = lr_c
        self.entroy_beta = entropy_beta
        self.batch_size = batch_size  # Set the batch size

        self.lstm_cell_size = 64

        OPT_A = tf.train.AdamOptimizer(self.lr_a)
        OPT_C = tf.train.AdamOptimizer(self.lr_c)

        with tf.name_scope('inputs'):
            self.s = tf.placeholder(tf.float32, [None, self.n_features], ""state"")
            self.a = tf.placeholder(tf.int32, [None, 1], ""action"")
            self.td_target = tf.placeholder(tf.float32, [None, 1], ""td_target"")

        self.acts_prob, self.v, self.a_params, self.c_params = self._build_net()

        with tf.name_scope('TD_error'):
            self.td_error = tf.subtract(self.td_target, self.v, name='TD_error')

        with tf.name_scope('c_loss'):
            self.c_loss = tf.reduce_mean(tf.square(self.td_error))

        with tf.name_scope('a_loss'):
            log_prob = tf.reduce_sum(tf.log(self.acts_prob + 1e-5) * tf.one_hot(self.a, self.n_actions, dtype=tf.float32),
                                      axis=1, keepdims=True)
            exp_v = log_prob * tf.stop_gradient(self.td_error)
            entropy = -tf.reduce_sum(self.acts_prob * tf.log(self.acts_prob + 1e-5), axis=1,
                                      keepdims=True)  # encourage exploration
            self.exp_v = self.entroy_beta * entropy + exp_v
            self.a_loss = tf.reduce_mean(-self.exp_v)

        with tf.name_scope('compute_grads'):
            self.a_grads = tf.gradients(self.a_loss, self.a_params)
            self.c_grads = tf.gradients(self.c_loss, self.c_params)

        with tf.name_scope('c_train'):
            self.c_train_op = OPT_C.apply_gradients(zip(self.c_grads, self.c_params))

        with tf.name_scope('a_train'):
            self.a_train_op = OPT_A.apply_gradients(zip(self.a_grads, self.a_params))

        self.sess.run(tf.global_variables_initializer())

        # Initialize lists to store losses
        self.actor_loss_history = []
        self.critic_loss_history = []

    def _build_net(self):
            w_init = tf.random_normal_initializer(0., .1)
            b_init = tf.constant_initializer(0.1)

            with tf.variable_scope('Critic'):
                # [time_step, feature] => [time_step, batch, feature]
                s = tf.expand_dims(self.s, axis=1, name='timely_input')

                lstm_cell = tf.nn.rnn_cell.LSTMCell(self.lstm_cell_size)
                self.lstm_state_init = lstm_cell.zero_state(batch_size=1, dtype=tf.float32)

                outputs, _ = tf.nn.dynamic_rnn(
                    cell=lstm_cell,
                    inputs=s,
                    initial_state=self.lstm_state_init,
                    time_major=True
                )
                cell_out = tf.reshape(outputs[-1, :, :], [-1, self.lstm_cell_size],
                                      name='flatten_lstm_outputs')  # joined state representation

                l_c1 = tf.layers.dense(
                    inputs=cell_out,
                    units=32,
                    activation=tf.nn.tanh,
                    kernel_initializer=w_init,
                    bias_initializer=b_init,
                    name='l_c1'
                )

                v = tf.layers.dense(
                    inputs=l_c1,
                    units=1,
                    kernel_initializer=w_init,
                    bias_initializer=b_init,
                    name='V'
                )  # state value

            with tf.variable_scope('Actor'):
                l_a1 = tf.layers.dense(
                    inputs=cell_out,
                    units=32,  # number of hidden units
                    activation=tf.nn.tanh,  # the activation function
                    kernel_initializer=w_init,  # weights
                    bias_initializer=b_init,  # biases
                    name='l_a1'
                )

                acts_prob = tf.layers.dense(
                    inputs=l_a1,
                    units=self.n_actions,  # output units
                    activation=tf.nn.softmax,  # get action probabilities
                    kernel_initializer=w_init,  # weights
                    name='acts_prob'
                )
            a_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Actor')
            c_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Critic')

            return acts_prob, v, a_params, c_params

    def choose_action(self, s):
            probs = self.sess.run(self.acts_prob, feed_dict={self.s: s})  # get probabilities for all actions
            a = np.random.choice(np.arange(probs.shape[1]), p=probs.ravel())
            return a
    def learn(self, feed_dict):
        # Ensure that feed_dict contains batches of data
        _, _, actor_loss, critic_loss = self.sess.run(
            [self.a_train_op, self.c_train_op, self.a_loss, self.c_loss],
            feed_dict=feed_dict
        )

        # Append current losses to history
        self.actor_loss_history.append(float(actor_loss))
        self.critic_loss_history.append(float(critic_loss))

        # Save losses to JSON files every 100 iterations
        if len(self.actor_loss_history) % 100 == 0:
            actor_loss_filename = 'logs/actor_loss.json'
            critic_loss_filename = 'logs/critic_loss.json'

            with open(actor_loss_filename, 'w') as f:
                json.dump({'actor_loss': self.actor_loss_history}, f)

            with open(critic_loss_filename, 'w') as f:
                json.dump({'critic_loss': self.critic_loss_history}, f)

    def choose_action(self, s):
        probs = self.sess.run(self.acts_prob, feed_dict={self.s: s})  # get probabilities for all actions
        a = np.random.choice(np.arange(probs.shape[1]), p=probs.ravel())
        return a

    def target_v(self, s):
        v = self.sess.run(self.v, {self.s: s})
        return v
`
![Fig_1_Actor_loss](https://github.com/user-attachments/assets/c498df43-b98c-46e4-ba19-57a0d684b7a9)
![Fig_1_Critic_Loss](https://github.com/user-attachments/assets/a26f866d-f003-450d-b7a4-3e2497d26611)
![Reward Function](https://github.com/user-attachments/assets/4cdac1b1-ad82-42c9-b710-00843d943201)

For the learning rate, I have tried different values, and here is the most recent one: LR_A =0.005
Learning Rate _ Actor =0.005
Learning Rate _Critic= 0.008
GAMMA = 0.9
ENTROY_BETA = 0.01

### Standalone code to reproduce the issue

```shell
Hello, 

I am using the following actor critic agent, but it does not converge at all. Please could you help me with this matter.
In the following  the code and the results

`
import numpy as np
import tensorflow as tf
import tensorflow.compat.v1 as tf
import json

tf.disable_v2_behavior()
tf.reset_default_graph()
class A2CLSTM(object):
    def __init__(
            self,
            sess,
            n_actions,
            n_features,
            lr_a,
            lr_c,
            entropy_beta,
            batch_size=32  # Default batch size
    ):
        self.sess = sess
        self.n_actions = n_actions
        self.n_features = n_features
        self.lr_a = lr_a
        self.lr_c = lr_c
        self.entroy_beta = entropy_beta
        self.batch_size = batch_size  # Set the batch size

        self.lstm_cell_size = 64

        OPT_A = tf.train.AdamOptimizer(self.lr_a)
        OPT_C = tf.train.AdamOptimizer(self.lr_c)

        with tf.name_scope('inputs'):
            self.s = tf.placeholder(tf.float32, [None, self.n_features], ""state"")
            self.a = tf.placeholder(tf.int32, [None, 1], ""action"")
            self.td_target = tf.placeholder(tf.float32, [None, 1], ""td_target"")

        self.acts_prob, self.v, self.a_params, self.c_params = self._build_net()

        with tf.name_scope('TD_error'):
            self.td_error = tf.subtract(self.td_target, self.v, name='TD_error')

        with tf.name_scope('c_loss'):
            self.c_loss = tf.reduce_mean(tf.square(self.td_error))

        with tf.name_scope('a_loss'):
            log_prob = tf.reduce_sum(tf.log(self.acts_prob + 1e-5) * tf.one_hot(self.a, self.n_actions, dtype=tf.float32),
                                      axis=1, keepdims=True)
            exp_v = log_prob * tf.stop_gradient(self.td_error)
            entropy = -tf.reduce_sum(self.acts_prob * tf.log(self.acts_prob + 1e-5), axis=1,
                                      keepdims=True)  # encourage exploration
            self.exp_v = self.entroy_beta * entropy + exp_v
            self.a_loss = tf.reduce_mean(-self.exp_v)

        with tf.name_scope('compute_grads'):
            self.a_grads = tf.gradients(self.a_loss, self.a_params)
            self.c_grads = tf.gradients(self.c_loss, self.c_params)

        with tf.name_scope('c_train'):
            self.c_train_op = OPT_C.apply_gradients(zip(self.c_grads, self.c_params))

        with tf.name_scope('a_train'):
            self.a_train_op = OPT_A.apply_gradients(zip(self.a_grads, self.a_params))

        self.sess.run(tf.global_variables_initializer())

        # Initialize lists to store losses
        self.actor_loss_history = []
        self.critic_loss_history = []

    def _build_net(self):
            w_init = tf.random_normal_initializer(0., .1)
            b_init = tf.constant_initializer(0.1)

            with tf.variable_scope('Critic'):
                # [time_step, feature] => [time_step, batch, feature]
                s = tf.expand_dims(self.s, axis=1, name='timely_input')

                lstm_cell = tf.nn.rnn_cell.LSTMCell(self.lstm_cell_size)
                self.lstm_state_init = lstm_cell.zero_state(batch_size=1, dtype=tf.float32)

                outputs, _ = tf.nn.dynamic_rnn(
                    cell=lstm_cell,
                    inputs=s,
                    initial_state=self.lstm_state_init,
                    time_major=True
                )
                cell_out = tf.reshape(outputs[-1, :, :], [-1, self.lstm_cell_size],
                                      name='flatten_lstm_outputs')  # joined state representation

                l_c1 = tf.layers.dense(
                    inputs=cell_out,
                    units=32,
                    activation=tf.nn.tanh,
                    kernel_initializer=w_init,
                    bias_initializer=b_init,
                    name='l_c1'
                )

                v = tf.layers.dense(
                    inputs=l_c1,
                    units=1,
                    kernel_initializer=w_init,
                    bias_initializer=b_init,
                    name='V'
                )  # state value

            with tf.variable_scope('Actor'):
                l_a1 = tf.layers.dense(
                    inputs=cell_out,
                    units=32,  # number of hidden units
                    activation=tf.nn.tanh,  # the activation function
                    kernel_initializer=w_init,  # weights
                    bias_initializer=b_init,  # biases
                    name='l_a1'
                )

                acts_prob = tf.layers.dense(
                    inputs=l_a1,
                    units=self.n_actions,  # output units
                    activation=tf.nn.softmax,  # get action probabilities
                    kernel_initializer=w_init,  # weights
                    name='acts_prob'
                )
            a_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Actor')
            c_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Critic')

            return acts_prob, v, a_params, c_params

    def choose_action(self, s):
            probs = self.sess.run(self.acts_prob, feed_dict={self.s: s})  # get probabilities for all actions
            a = np.random.choice(np.arange(probs.shape[1]), p=probs.ravel())
            return a
    def learn(self, feed_dict):
        # Ensure that feed_dict contains batches of data
        _, _, actor_loss, critic_loss = self.sess.run(
            [self.a_train_op, self.c_train_op, self.a_loss, self.c_loss],
            feed_dict=feed_dict
        )

        # Append current losses to history
        self.actor_loss_history.append(float(actor_loss))
        self.critic_loss_history.append(float(critic_loss))

        # Save losses to JSON files every 100 iterations
        if len(self.actor_loss_history) % 100 == 0:
            actor_loss_filename = 'logs/actor_loss.json'
            critic_loss_filename = 'logs/critic_loss.json'

            with open(actor_loss_filename, 'w') as f:
                json.dump({'actor_loss': self.actor_loss_history}, f)

            with open(critic_loss_filename, 'w') as f:
                json.dump({'critic_loss': self.critic_loss_history}, f)

    def choose_action(self, s):
        probs = self.sess.run(self.acts_prob, feed_dict={self.s: s})  # get probabilities for all actions
        a = np.random.choice(np.arange(probs.shape[1]), p=probs.ravel())
        return a

    def target_v(self, s):
        v = self.sess.run(self.v, {self.s: s})
        return v
`
![Fig_1_Actor_loss](https://github.com/user-attachments/assets/c498df43-b98c-46e4-ba19-57a0d684b7a9)
![Fig_1_Critic_Loss](https://github.com/user-attachments/assets/a26f866d-f003-450d-b7a4-3e2497d26611)
![Reward Function](https://github.com/user-attachments/assets/4cdac1b1-ad82-42c9-b710-00843d943201)

For the learning rate, I have tried different values, and here is the most recent one: LR_A =0.005
Learning Rate _ Actor =0.005
Learning Rate _Critic= 0.008
GAMMA = 0.9
ENTROY_BETA = 0.01
```


### Relevant log output

_No response_"
2458042827,73465,Aborted (core dumped) in `tf.io.TFRecordOptions`,closed,2024-08-09 14:22:36+00:00,2024-08-31T01:56:49Z,2024-08-31T01:56:45Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/73465,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","['@x0w3n,\r\nLooks like there is an open issue that was raised for the similar issue and it was already in the open stage. Could you please check and follow the similar issue for the updates.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/63337\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73465"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73465"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.17

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Triggers crash when the compression_strategy parameter of tf.io.TFRecordOptions is negative.

### Standalone code to reproduce the issue

```shell
https://colab.research.google.com/drive/1nIfAqRUryYMSdJfZTnIs2jAUW8nUON5s?usp=sharing
```


### Relevant log output

```shell
2024-08-09 22:20:07.358412: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-08-09 22:20:07.627813: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-09 22:20:10.998865: F external/local_tsl/tsl/lib/io/record_writer.cc:74] Failed to initialize Zlib inputbuffer. Error: INVALID_ARGUMENT: deflateInit failed with status-2
Aborted (core dumped)
```
"
2458608504,73484,Issue with Loading libdelegate.so on Ubuntu 22.04 LTS Using TensorFlow Lite GPU Delegate,closed,2024-08-09 20:17:19+00:00,2024-09-18T01:59:04Z,2024-09-18T01:58:54Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/73484,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'TF 2.4']","['Hi **@pisarev** ,\r\nSorry for the delay. There seem to be version compatibility issues here. Could you please check this [documentation](https://www.tensorflow.org/install/source_windows#gpu)? Please update the documentation accordingly and let us know if the issue still persists.\r\nThank you!', 'Thank you for your response!\r\n\r\nI have checked the versions of all relevant components and it seems everything is selected correctly:\r\n\r\n- **Ubuntu Version**: 22.04.4 LTS (Jammy)\r\n- **Bazel Version**: 3.7.2 (installed via Bazelisk)\r\n- **CUDA Version**: 11.2 (V11.2.152)\r\n- **cuDNN Version**: 8.1.1\r\n- **Python Version**: 3.9.19 (Conda environment)\r\n- **GCC Version**: Default system GCC is used.\r\n\r\nConfiguration details:\r\n- CUDA compute capability: 8.9\r\n- No ROCm, TensorRT, or Clang as CUDA compiler.\r\n\r\nThe ""libdelegate.so"" library, when loaded by my application, leads to a symbol lookup error, while the ""libtensorflowlite_c.so"" library loads without any issues.\r\n\r\nHere are the specific commands I ran in the terminal along with their outputs:\r\n\r\n(tf) master@WIN-1VM6C4QJVS5:/mnt/c/Users/admin$ lsb_release -a\r\nNo LSB modules are available.\r\nDistributor ID: Ubuntu\r\nDescription:    Ubuntu 22.04.4 LTS\r\nRelease:        22.04\r\nCodename:       jammy\r\n\r\n(tf) master@WIN-1VM6C4QJVS5:/mnt/c/Users/admin/Documents/Lazarus/Projects/ubuntu-24.04/tensorflow$ bazel --version\r\nbazel 3.7.2\r\n\r\n(tf) master@WIN-1VM6C4QJVS5:/mnt/c/Users/admin/Documents/Lazarus/Projects/ubuntu-24.04/tensorflow$ nvcc --version\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2021 NVIDIA Corporation\r\nBuilt on Sun_Feb_14_21:12:58_PST_2021\r\nCuda compilation tools, release 11.2, V11.2.152\r\nBuild cuda_11.2.r11.2/compiler.29618528_0\r\n\r\n(tf) master@WIN-1VM6C4QJVS5:/mnt/c/Users/admin/Documents/Lazarus/Projects/ubuntu-24.04/tensorflow$ cat /usr/local/cuda/include/cudnn_version.h | grep CUDNN_MAJOR -A 2\r\n#define CUDNN_MAJOR 8\r\n#define CUDNN_MINOR 1\r\n#define CUDNN_PATCHLEVEL 1\r\n--\r\n#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\r\n#endif /* CUDNN_VERSION_H */\r\n\r\n(tf) master@WIN-1VM6C4QJVS5:/mnt/c/Users/admin$ conda activate tf\r\n(tf) master@WIN-1VM6C4QJVS5:/mnt/c/Users/admin$ which python\r\n/home/master/miniconda3/envs/tf/bin/python\r\n\r\n(tf) master@WIN-1VM6C4QJVS5:/mnt/c/Users/admin$ python --version\r\nPython 3.9.19\r\n\r\nConfiguration steps:\r\n\r\n(tf) master@WIN-1VM6C4QJVS5:/mnt/c/Users/admin/Documents/Lazarus/Projects/ubuntu-24.04/tensorflow$ ./configure\r\nYou have bazel 3.7.2 installed.\r\nPlease specify the location of python. [Default is /bin/python3]: /home/master/miniconda3/envs/tf/bin/python\r\n\r\nFound possible Python library paths:\r\n  /home/master/miniconda3/envs/tf/lib/python3.9/site-packages\r\nPlease input the desired Python library path to use.  Default is [/home/master/miniconda3/envs/tf/lib/python3.9/site-packages]\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: n\r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\nFound CUDA 11.2 in:\r\n    /usr/local/cuda-11.2/targets/x86_64-linux/lib\r\n    /usr/local/cuda-11.2/targets/x86_64-linux/include\r\nFound cuDNN 8 in:\r\n    /usr/local/cuda-11.2/targets/x86_64-linux/lib\r\n    /usr/local/cuda-11.2/targets/x86_64-linux/include\r\n\r\nPlease specify a list of comma-separated CUDA compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus. Each capability can be specified as ""x.y"" or ""compute_xy"" to include both virtual and binary GPU code, or as ""sm_xy"" to only include the binary code.\r\nPlease note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 8.9]: 8.9\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: n\r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /bin/gcc]:\r\n\r\nPlease specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]:\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nDespite these configurations, the ""libdelegate.so"" library still encounters the following errors when loaded by the application:\r\n\r\n(tf) master@WIN-1VM6C4QJVS5:/mnt/c/Users/admin/Documents/Lazarus/Projects/ubuntu-24.04/x64$ LD_DEBUG=libs ./eye\r\n...\r\n      6411:     /lib/x86_64-linux-gnu/libglib-2.0.so.0: error: symbol lookup error: undefined symbol: g_object_ref_sink (fatal)\r\n...\r\n      6411:     ./eye: error: symbol lookup error: undefined symbol: gtk_widget_device_is_shadowed (fatal)\r\n...\r\n      6411:     ./bin/tflite/libdelegate.so: error: symbol lookup error: undefined symbol: _ZN4absl14lts_2020_09_236Status16kMovedFromStringE (fatal)\r\n\r\nWhen checking the shared library dependencies of libdelegate.so, the following output was observed:\r\n\r\n(tf) master@WIN-1VM6C4QJVS5:/mnt/c/Users/admin/Documents/Lazarus/Projects/ubuntu-24.04/tensorflow$ ldd ../x64/bin/tflite/libdelegate.so\r\n        linux-vdso.so.1 (0x00007ffd835b6000)\r\n        libstdc++.so.6 => /lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007ff59dcf6000)\r\n        libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007ff59dcd6000)\r\n        libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007ff59daad000)\r\n        libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007ff59d9c6000)\r\n        /lib64/ld-linux-x86-64.so.2 (0x00007ff59df38000)\r\n', 'Hi @pisarev, what command did you use to build `libdelegate.so`? Also what command(s)/program(s) did you use to check it (`./eye` ??) can you please explain what that is? Please also format code/terminal with 3 backtick code formatting:\r\n\r\nex:\r\n\\`\\`\\`\r\n\\# code/terminal output\r\n\\`\\`\\`\r\n\r\noutputs:\r\n```\r\n# code/terminal output\r\n```\r\n\r\nThanks.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73484"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73484"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.4

### Custom code

Yes

### OS platform and distribution

WSL Linux Ubuntu-22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

Bazelisk (automatically manages Bazel version)

### GCC/compiler version

10.5.0

### CUDA/cuDNN version

11.2.r11.2

### GPU model and memory

NVidia 4060Ti

### Current behavior?

(base) master@WIN-1VM6C4QJVS5:/mnt/c/Users/admin/Documents/Lazarus/Projects/ubuntu-22.04/x64$ LD_DEBUG=libs ./test


... skipped lines with no errors or warnings ...

     27014:
     27014:     calling init: /usr/lib/x86_64-linux-gnu/gconv/UTF-16.so
     27014:
     27014:     /lib/x86_64-linux-gnu/libglib-2.0.so.0: error: symbol lookup error: undefined symbol: g_object_ref_sink (fatal)
     27014:     find library=libgdk-x11-2.0.so [0]; searching
     27014:      search path=/usr/local/cuda-11.2/lib64:glibc-hwcaps/x86-64-v3:glibc-hwcaps/x86-64-v2:tls/x86_64/x86_64:tls/x86_64:tls/x86_64:tls:x86_64/x86_64:x86_64:x86_64:          (LD_LIBRARY_PATH)
     27014:       trying file=/usr/local/cuda-11.2/lib64/libgdk-x11-2.0.so
     27014:       trying file=glibc-hwcaps/x86-64-v3/libgdk-x11-2.0.so
     27014:       trying file=glibc-hwcaps/x86-64-v2/libgdk-x11-2.0.so
     27014:       trying file=tls/x86_64/x86_64/libgdk-x11-2.0.so
     27014:       trying file=tls/x86_64/libgdk-x11-2.0.so
     27014:       trying file=tls/x86_64/libgdk-x11-2.0.so
     27014:       trying file=tls/libgdk-x11-2.0.so
     27014:       trying file=x86_64/x86_64/libgdk-x11-2.0.so
     27014:       trying file=x86_64/libgdk-x11-2.0.so
     27014:       trying file=x86_64/libgdk-x11-2.0.so
     27014:       trying file=libgdk-x11-2.0.so
     27014:      search cache=/etc/ld.so.cache
     27014:       trying file=/lib/x86_64-linux-gnu/libgdk-x11-2.0.so
     27014:
     27014:     ./test: error: symbol lookup error: undefined symbol: gtk_widget_device_is_shadowed (fatal)
     27014:     find library=libstdc++.so.6 [0]; searching
     27014:      search path=/usr/local/cuda-11.2/lib64:glibc-hwcaps/x86-64-v3:glibc-hwcaps/x86-64-v2:tls/x86_64/x86_64:tls/x86_64:tls/x86_64:tls:x86_64/x86_64:x86_64:x86_64:          (LD_LIBRARY_PATH)
     27014:       trying file=/usr/local/cuda-11.2/lib64/libstdc++.so.6
     27014:       trying file=glibc-hwcaps/x86-64-v3/libstdc++.so.6
     27014:       trying file=glibc-hwcaps/x86-64-v2/libstdc++.so.6
     27014:       trying file=tls/x86_64/x86_64/libstdc++.so.6
     27014:       trying file=tls/x86_64/libstdc++.so.6
     27014:       trying file=tls/x86_64/libstdc++.so.6
     27014:       trying file=tls/libstdc++.so.6
     27014:       trying file=x86_64/x86_64/libstdc++.so.6
     27014:       trying file=x86_64/libstdc++.so.6
     27014:       trying file=x86_64/libstdc++.so.6
     27014:       trying file=libstdc++.so.6
     27014:      search cache=/etc/ld.so.cache
     27014:       trying file=/lib/x86_64-linux-gnu/libstdc++.so.6
     27014:
     27014:     find library=libgcc_s.so.1 [0]; searching
     27014:      search path=/usr/local/cuda-11.2/lib64:glibc-hwcaps/x86-64-v3:glibc-hwcaps/x86-64-v2:tls/x86_64/x86_64:tls/x86_64:tls/x86_64:tls:x86_64/x86_64:x86_64:x86_64:          (LD_LIBRARY_PATH)
     27014:       trying file=/usr/local/cuda-11.2/lib64/libgcc_s.so.1
     27014:       trying file=glibc-hwcaps/x86-64-v3/libgcc_s.so.1
     27014:       trying file=glibc-hwcaps/x86-64-v2/libgcc_s.so.1
     27014:       trying file=tls/x86_64/x86_64/libgcc_s.so.1
     27014:       trying file=tls/x86_64/libgcc_s.so.1
     27014:       trying file=tls/x86_64/libgcc_s.so.1
     27014:       trying file=tls/libgcc_s.so.1
     27014:       trying file=x86_64/x86_64/libgcc_s.so.1
     27014:       trying file=x86_64/libgcc_s.so.1
     27014:       trying file=x86_64/libgcc_s.so.1
     27014:       trying file=libgcc_s.so.1
     27014:      search cache=/etc/ld.so.cache
     27014:       trying file=/lib/x86_64-linux-gnu/libgcc_s.so.1
     27014:
     27014:     ./bin/tflite/libdelegate.so: error: symbol lookup error: undefined symbol: _ZN4absl14lts_2020_09_236Status16kMovedFromStringE (fatal)
     27014:

... skipped lines with no errors or warnings ...

### Standalone code to reproduce the issue

```shell
I expected the program to run without issues, successfully loading the libdelegate.so library and executing the intended functions without any runtime errors. It's important to note that the `libtensorflowlite_c.so` library, which was built in the same environment, loads without any issues or errors.
```


### Relevant log output

```shell
Additionally, the libdelegate.so library build process completes successfully with the following key outputs:

WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=0 --terminal_columns=80
INFO: Reading rc options for 'build' from /mnt/c/Users/admin/Documents/Lazarus/Projects/ubuntu-22.04/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /mnt/c/Users/admin/Documents/Lazarus/Projects/ubuntu-22.04/tensorflow/.bazelrc:
  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2
INFO: Reading rc options for 'build' from /mnt/c/Users/admin/Documents/Lazarus/Projects/ubuntu-22.04/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/home/master/miniconda3/envs/tf/bin/python3 --action_env PYTHON_LIB_PATH=/home/master/miniconda3/envs/tf/lib/python3.9/site-packages --python_path=/home/master/miniconda3/envs/tf/bin/python3 --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda-11.2 --action_env TF_CUDA_COMPUTE_CAPABILITIES=8.9 --action_env LD_LIBRARY_PATH=/usr/local/cuda-11.2/lib64:/usr/local/cuda-11.2/lib64:/usr/local/cuda-11.2/lib64: --action_env GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-10 --config=cuda
INFO: Found applicable config definition build:short_logs in file /mnt/c/Users/admin/Documents/Lazarus/Projects/ubuntu-22.04/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /mnt/c/Users/admin/Documents/Lazarus/Projects/ubuntu-22.04/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:cuda in file /mnt/c/Users/admin/Documents/Lazarus/Projects/ubuntu-22.04/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda
INFO: Found applicable config definition build:monolithic in file /mnt/c/Users/admin/Documents/Lazarus/Projects/ubuntu-22.04/tensorflow/.bazelrc: --define framework_shared_object=false
INFO: Found applicable config definition build:cuda in file /mnt/c/Users/admin/Documents/Lazarus/Projects/ubuntu-22.04/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda
INFO: Found applicable config definition build:linux in file /mnt/c/Users/admin/Documents/Lazarus/Projects/ubuntu-22.04/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /mnt/c/Users/admin/Documents/Lazarus/Projects/ubuntu-22.04/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
DEBUG: /home/master/.cache/bazel/_bazel_master/8a68c52b18b2f377d8f5efcf04fab9da/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:118:10: 
Auto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\Windows\Temp' as default
Loading:  (0 packages loaded)
Loading: 0 packages loaded
Analyzing: target //tensorflow/lite/delegates/gpu:delegate (0 packages loaded, 0 targets configured)
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Repository io_bazel_rules_docker instantiated at:
  /mnt/c/Users/admin/Documents/Lazarus/Projects/ubuntu-22.04/tensorflow/WORKSPACE:23:14: in <toplevel>
  /mnt/c/Users/admin/Documents/Lazarus/Projects/ubuntu-22.04/tensorflow/tensorflow/workspace0.bzl:105:34: in workspace
  /home/master/.cache/bazel/_bazel_master/8a68c52b18b2f377d8f5efcf04fab9da/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories
Repository rule git_repository defined at:
  /home/master/.cache/bazel/_bazel_master/8a68c52b18b2f377d8f5efcf04fab9da/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>
INFO: Analyzed target //tensorflow/lite/delegates/gpu:delegate (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
[0 / 4] [Prepa] BazelWorkspaceStatusAction stable-status.txt
[9 / 344] Compiling tensorflow/lite/delegates/gpu/gl/api2.cc; 1s local ... (8 actions, 7 running)
[12 / 344] Compiling tensorflow/lite/delegates/gpu/gl/api2.cc; 2s local ... (8 actions running)
[15 / 351] Compiling flatbuffers/src/idl_gen_cpp.cpp [for host]; 3s local ... (8 actions running)
[20 / 353] Compiling flatbuffers/src/idl_gen_python.cpp [for host]; 2s local ... (8 actions running)
[59 / 388] Compiling flatbuffers/src/idl_parser.cpp [for host]; 1s local ... (8 actions, 7 running)
[67 / 388] Compiling flatbuffers/src/idl_parser.cpp [for host]; 2s local ... (8 actions, 7 running)
[75 / 388] Compiling flatbuffers/src/idl_parser.cpp [for host]; 4s local ... (8 actions, 7 running)
[83 / 388] Compiling flatbuffers/src/idl_parser.cpp [for host]; 5s local ... (8 actions, 7 running)
[104 / 388] Compiling flatbuffers/src/idl_parser.cpp [for host]; 7s local ... (8 actions, 7 running)
[136 / 388] Compiling flatbuffers/src/idl_parser.cpp [for host]; 8s local ... (8 actions, 7 running)
[156 / 388] Compiling flatbuffers/src/idl_parser.cpp; 8s local ... (8 actions, 7 running)
[167 / 388] Compiling tensorflow/lite/delegates/gpu/cl/kernels/converter.cc; 2s local ... (8 actions, 7 running)
[178 / 388] Compiling tensorflow/lite/delegates/gpu/common/model_builder.cc; 5s local ... (8 actions running)
[193 / 388] Compiling tensorflow/lite/delegates/gpu/common/tasks/depthwise_conv_3x3_stride_h2.cc; 1s local ... (8 actions running)
[214 / 388] Compiling tensorflow/lite/delegates/gpu/common/tasks/convolution_transposed.cc; 3s local ... (8 actions, 7 running)
[253 / 389] Compiling tensorflow/lite/delegates/gpu/gl/gl_program.cc; 0s local ... (8 actions, 7 running)
[285 / 389] Compiling tensorflow/lite/delegates/gpu/gl/kernels/depthwise_conv.cc; 1s local ... (8 actions, 7 running)
[316 / 391] Compiling tensorflow/lite/delegates/gpu/common/tasks/conv_powervr.cc; 4s local ... (8 actions, 7 running)
[365 / 391] Compiling tensorflow/lite/delegates/gpu/cl/cl_arguments.cc; 3s local ... (8 actions, 7 running)
Target //tensorflow/lite/delegates/gpu:delegate up-to-date:
  bazel-bin/tensorflow/lite/delegates/gpu/libdelegate.a
  bazel-bin/tensorflow/lite/delegates/gpu/libdelegate.pic.a
  bazel-bin/tensorflow/lite/delegates/gpu/libdelegate.so
INFO: Elapsed time: 54.796s, Critical Path: 17.86s
INFO: 354 processes: 1 internal, 353 local.
INFO: Build completed successfully, 354 total actions
INFO: Build completed successfully, 354 total actions
```
"
2458639804,73487,"""Skipping the delay kernel"" warning emitted thousands of times.",closed,2024-08-09 20:40:06+00:00,2024-10-29T06:36:11Z,2024-08-29T14:03:04Z,klucke,,https://github.com/tensorflow/tensorflow/issues/73487,"['stat:awaiting tensorflower', 'type:bug', 'type:build/install', 'comp:gpu', '2.17']","['Thank you for reporting the issue. This is a known issue where other issues are still open and developers are working on the same.\r\n\r\nI request you to take a look at this https://github.com/tensorflow/tensorflow/issues/62075 and where a similar issue has been proposed and it is still open. Also I request to follow the similar issue which has been proposed to have the updates on the similar issue.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/71791#issuecomment-2237115569\r\nhttps://github.com/tensorflow/tensorflow/issues/70947\r\n\r\nThank you!', ""> This occurs in training and in predicting, and it fills the log files with warnings that I cannot disable. I've pasted one in the section below. A typical run of my program produced just shy of 150,000 repeated warnings about skipping the delay kernel.\r\n\r\nGot the same problem, [partially resolved by this:](https://github.com/tensorflow/tensorflow/issues/26348#issuecomment-1206286540)\r\n\r\n```python\r\n#!/usr/bin/env python\r\n# -*- coding: utf-8 -*- \r\n\r\n# Suppress tensorflow spam, see https://github.com/tensorflow/tensorflow/issues/26348\r\n# Not the complete fix, cuda_executor.cc still ignores all these settings\r\n# and spams something successful NUMA node read\r\n# but probably it's best that can be done without redirecting stderr\r\n\r\nimport os\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\r\nimport tensorflow as tf\r\nimport logging\r\nlogger = tf.get_logger()\r\nlogger.setLevel(logging.ERROR) # or logging.INFO, logging.WARNING, etc.\r\n\r\n# Actual app starts here:\r\n\r\nimport argparse\r\nimport pathlib\r\nimport pprint\r\nfrom enum import Enum\r\nfrom tqdm import tqdm\r\n...\r\n\r\n```\r\n\r\nSo now instead of 1343 lines of `Skipping the delay` there's just 10 spam lines from the one line in cuda_executor.cc.\r\nStill very spammy but better than 1500 repeats of the warning.\r\n\r\n```console\r\nsimilarity ~/tmp/images/2024-08-18/\r\n  0%|                                                                                                                                 | 0/280 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\nI0000 00:00:1724013025.313366 3889312 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\r\nI0000 00:00:1724013025.339050 3889312 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\r\nI0000 00:00:1724013025.339224 3889312 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\r\nI0000 00:00:1724013025.340675 3889312 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\r\nI0000 00:00:1724013025.340776 3889312 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\r\nI0000 00:00:1724013025.340832 3889312 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\r\nI0000 00:00:1724013025.391595 3889312 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\r\nI0000 00:00:1724013025.391736 3889312 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\r\nI0000 00:00:1724013025.391807 3889312 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\r\n100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 280/280 [01:24<00:00,  3.32it/s]\r\n```"", ""Actually, the above suggestion is not a fix. Setting TF_CPP_MIN_LOG_LEVEL = 3 logs only error and fatal messages. Similar for setLevel(logging.ERROR) only error is logged. So, no change.\r\n\r\nIn my case the 'Skipping the delay kernel' warning occurs numerous times during both training and subsequent build.\r\n\r\nWe await a response."", 'I am also affected by this issue and hope to get a way to clean my log from hundreds if not thousands of these messages 🫤\r\nI would like to keep other warnings alive in case I am doing something wrong or inefficient somewhere else.', 'This is fixed by https://github.com/openxla/xla/pull/16566', 'Thanks, @klucke\r\nThis should be in Tensorflow 2.18.0, and likely 2.17.1, and of course, nightlies\r\n\r\nClosing', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73487"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73487"">No</a>\n', 'For future TensorFlownauts trying to solve weird logs, I can confirm that the issue is solved as of version `2.18.0` for GPU published on the 25th of October 2024.']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No - I get other errors when I install tf-nightly.

### Source

source

### TensorFlow version

2.17.0

### Custom code

Yes

### OS platform and distribution

Rocky Linux 9 and unknown

### Mobile device

_No response_

### Python version

3.12.5 and unknown

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

Cuda version 12.0 and unknown

### GPU model and memory

_No response_

### Current behavior?

I get an alarming number of warnings about skipping of a delay kernel.
This occurs on a pretty standard install of tensorflow that I use for a project. (I have been unable to reproduce it with tf-nightly because I get crashes due to incompatible shapes in some of my code.) But I have good news for reproducibility! The same log message is also created in the examples in the TF documentation, so however TF is built to generate the guides on the website (see below for links) also triggers this behavior. (This is why some of the versions are unknown - I haven't tracked down exactly how the docs are built.)

This occurs in training and in predicting, and it fills the log files with warnings that I cannot disable. I've pasted one in the section below. A typical run of my program produced just shy of 150,000 repeated warnings about skipping the delay kernel.

This warning does not seem to listen to TF_CPP_MIN_LOG_LEVEL, and it also still gets emitted after I add
tf.get_logger().setLevel(""ERROR"") and warnings.simplefilter(""ignore""). The log file attached below includes all three of those attempts to suppress the messages.

I don't know what the solution is to these warnings, and I honestly don't even know if I'm doing anything wrong.
Is it something that I need to fix? If so, where do I specify that I would like to include delay kernels when building and training a model?
Is it something that should be ignored in every case? If so, why is it printed at all? Given that the documentation, which I would assume is using tensorflow correctly, produces these warnings, I'm leaning toward this being the case. In this instance, how do I disable the message?
Where does the warning even come from? Commit 10df33f84983f1f789f1215fc766e12ad046ff7b moved the warning message to a new file (so it's now in third_party/xla/xla/stream_executor/cuda/cuda_executor.cc instead of gpu_timer.cc), but without a traceback I can't tell which call to the function is triggering the bad behavior.

I would build my own copy of TensorFlow to debug further, but I don't have root access to a machine at work and building without that has been unsuccessful.

### Standalone code to reproduce the issue

```shell
The message is present in many of the examples on the TF documentation, and often fills output boxes that are intended to contain other information, making reading the documentation rather frustrating.

https://www.tensorflow.org/guide/function

https://www.tensorflow.org/tutorials/quickstart/advanced

https://www.tensorflow.org/tutorials/generative/adversarial_fgsm

https://www.tensorflow.org/tutorials/images/transfer_learning

https://www.tensorflow.org/tutorials/generative/autoencoder

https://www.tensorflow.org/tutorials/audio/simple_audio

https://www.tensorflow.org/tutorials/generative/cyclegan

https://www.tensorflow.org/tutorials/generative/style_transfer
```


### Relevant log output

```shell
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1723232760.037824 1704934 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1723232760.038491 1704937 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1723232760.039293 1704933 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232760.060998 1704933 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232760.060998 1704937 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232760.060998 1704934 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232760.061204 1704933 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232760.061207 1704934 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232760.061210 1704937 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232760.308930 1704933 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232760.309064 1704933 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232760.309108 1704933 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232760.762708 1704933 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232760.762862 1704933 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232760.762911 1704933 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1723232761.182515 1705056 service.cc:146] XLA service 0x7f67c8003f20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1723232761.182536 1705056 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6
I0000 00:00:1723232761.265672 1704934 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232761.265826 1704934 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232761.265879 1704934 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232761.742874 1704934 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232761.743078 1704934 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232761.743152 1704934 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1723232762.175289 1705161 service.cc:146] XLA service 0x7f67d0003290 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1723232762.175319 1705161 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6
I0000 00:00:1723232762.269671 1704937 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232762.269891 1704937 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232762.269936 1704937 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232762.811310 1704937 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232762.811427 1704937 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1723232762.811474 1704937 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1723232763.316489 1705273 service.cc:146] XLA service 0x7f67f80043a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1723232763.316524 1705273 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6
I0000 00:00:1723232763.328407 1705056 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
I0000 00:00:1723232764.801232 1705161 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
W0000 00:00:1723232764.833870 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.852954 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.853403 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.853845 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.854270 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.855588 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.856585 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.857226 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.857815 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.858271 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.859216 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.859872 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.864199 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.865096 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.866303 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.866899 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.867695 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.868588 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.869332 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.870090 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.870974 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.872071 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.872808 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.874219 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.874952 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.876521 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.877960 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.879262 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.879764 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.880946 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.882610 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.883286 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.884262 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.885159 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.938520 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.939871 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.941237 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.942563 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.944529 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.946130 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.947458 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.949099 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.950547 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.951902 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.953549 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.955035 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.956444 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.959359 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.961647 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.963095 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.964935 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.968955 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.970589 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.972500 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.974051 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.975503 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.977670 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.979426 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.981071 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.982999 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.984944 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.986547 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.988105 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.989497 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.991030 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.992826 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232764.994553 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.006351 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.008144 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.010465 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.012574 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.014353 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.015983 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.017785 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.019209 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.021683 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.023968 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.026816 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.030096 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.033443 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.036090 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.038314 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.040368 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.043280 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.045456 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.048798 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.051494 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.053658 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.055930 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.058870 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.063870 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.066426 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.069411 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.071951 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.074379 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.076916 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.079077 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.081423 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.083426 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.086207 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.095480 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.097701 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.099533 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.102417 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.104760 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.106645 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.109518 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.112559 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.114620 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.117068 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.119439 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.121426 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.125844 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.128501 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.129907 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.132639 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.135037 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.136905 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.140405 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.142656 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.144536 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.147934 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.150320 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.152360 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.158254 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.160801 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.162895 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.166604 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.168923 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.170685 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.174693 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.177255 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.179223 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.189563 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.192249 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.194193 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.196283 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.199712 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.201671 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.204049 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.207716 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.209591 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.212083 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.215755 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.220159 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.222598 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.225472 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.227479 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.229706 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.231615 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.232971 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.235788 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.237162 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.239782 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.242132 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.244283 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.248891 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.252746 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.254671 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.258255 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.260796 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.262522 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.265756 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.268230 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.270198 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.273803 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.283381 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.286579 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.288364 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.290891 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.293585 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.295439 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.297559 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.300255 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.302112 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.304314 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.307786 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.310909 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.315045 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.318333 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.320218 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.322896 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.326314 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.328383 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.331175 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.333914 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.335733 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.338057 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.339842 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.344540 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.346982 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.348444 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.351905 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.353990 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.356203 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.359343 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.361575 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.363981 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.367310 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.376307 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.378576 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.380323 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.383666 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.385889 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.387699 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.391181 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.393651 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.395483 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.398535 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.400612 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.402488 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.407495 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.409849 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.411846 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.415162 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.417432 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.419402 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.423073 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.425380 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.427480 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.431200 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.433669 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.436550 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.441645 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.444023 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.446073 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.448074 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.449769 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.451185 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.453771 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.455250 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.465666 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.469818 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.472128 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.475028 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.476893 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.479211 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.482098 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.483886 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.486365 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.489674 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.491510 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.494149 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.498504 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.501810 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.504348 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.506943 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.508713 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.510955 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.513580 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.515384 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.517688 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.521208 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.523155 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.525427 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.531938 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.533916 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.536442 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.539925 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.541828 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.544377 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.547393 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.549334 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.558568 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.563588 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.565909 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.568067 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.570669 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.572723 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.574810 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.577710 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.579802 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.581933 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.584333 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.586309 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.588492 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.592051 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.595625 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.597937 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.600781 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.602961 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.605194 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.607698 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.609791 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.612048 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.614991 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.617124 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.619411 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.623481 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.627261 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.629473 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.632518 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.634773 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.637166 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.639076 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.647533 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.649634 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.651332 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.654803 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.658555 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.660239 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.663157 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.665295 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.667099 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.670007 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.672266 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.674068 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.676654 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.679067 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.680874 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.683038 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.687995 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.689779 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.692386 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.694990 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.696832 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.698930 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.701470 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.703326 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.706019 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.708725 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.710649 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.713118 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.718185 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.720031 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.726136 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.727756 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.729836 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.730946 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.733076 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.735545 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.737739 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.739550 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.741139 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.742954 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.745182 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.747946 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.751953 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.753967 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.755742 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.758301 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.760613 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.762080 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.764203 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.767168 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.769898 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.773173 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232765.776661 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.099818 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.103232 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.110863 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.117101 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.118906 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.120300 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.125715 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.134527 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.140363 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.146259 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.147661 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.149023 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.156721 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.166398 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.173983 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.181315 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.182520 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.183984 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.184996 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.187285 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.196973 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.200989 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.219062 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.237505 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.248860 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.250557 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.252136 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.253462 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.257982 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.259694 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.261177 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.263185 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.264906 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.266256 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.268344 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.270020 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.271417 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.273704 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.275516 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.276927 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.279074 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.280939 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.282233 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.284802 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.291359 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.293467 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.302223 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.311843 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.327655 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.330126 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.331492 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.332706 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.336856 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.338229 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.339504 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.343685 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.345186 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
W0000 00:00:1723232766.346497 1705064 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced
I have not included the remaining 1,337 warnings.
```
"
2459045322,73517,"Converting model for on-device training fails with ""LLVM ERROR: Failed to infer result type(s).""",closed,2024-08-10 11:30:27+00:00,2024-09-19T04:09:19Z,2024-09-19T02:00:10Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/73517,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'TFLiteConverter', '2.17']","[""It looks like github removed the link to the instructions that I'm referring to. Anyway, it can be found on tensorflow dot org /lite/examples/on_device_training/overview"", 'Hi @hanssssssssssssss ,\r\n\r\nI was wondering if you may be able to resolve your issue by using [AI-Edge-Torch](https://github.com/google-ai-edge/ai-edge-torch), you can find more information here: [googleblog](https://developers.googleblog.com/en/ai-edge-torch-high-performance-inference-of-pytorch-models-on-mobile-devices/).\r\n\r\nI have actually created a simple script for converting your model to tflite \r\n\r\n```py\r\nimport torch\r\nimport torch.nn as nn\r\nimport ai_edge_torch\r\n\r\nclass Model(nn.Module):\r\n    def __init__(self):\r\n        super(Model, self).__init__()\r\n        self.model = nn.Sequential(\r\n            nn.Linear(9, 128),\r\n            nn.ReLU(),\r\n            nn.Linear(128, 128),\r\n            nn.ReLU(),\r\n            nn.Linear(128, 9)\r\n        )\r\n\r\n    def forward(self, x):\r\n        return self.model(x)\r\n\r\n# Create the model instance\r\nmodel = Model()\r\n\r\n# Example input that matches the expected input shape of (batch_size, 9)\r\nsample_inputs = (torch.randn(1, 9),)\r\n\r\n# Convert the PyTorch model to a TensorFlow Lite model using ai_edge_torch\r\nedge_model = ai_edge_torch.convert(model.eval(), sample_inputs)\r\n\r\n# Export the converted model to a .tflite file\r\nedge_model.export(""model.tflite"")\r\n```\r\n\r\nUsing this script i was able to get the model.tflite file without any errors. If you want to, you can actually try visualizing the result in [model-explorer](https://github.com/google-ai-edge/model-explorer) as well.\r\n\r\nPlease try them out and let us know if this resolves your issue. If you still need further help, feel free to open a new issue at the respective repo.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73517"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73517"">No</a>\n']","### 1. System information

- OS Platform and Distribution: Debian GNU/Linux 10
- TensorFlow installation: pip package (Python 3.12.4)
- TensorFlow library version: 2.17.0
### 2. Code
I'm trying to follow the instructions that are given here: [](https://www.tensorflow.org/lite/examples/on_device_training/overview)

The model can be saved with tf.saved_model.save(), including the custom function signatures (Although the code from the example has to be adapted slightly to work with TensorFlow 2.17.0).  But the conversion step fails with the following output:

```
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
W0000 00:00:1723288568.132630   44010 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.
W0000 00:00:1723288568.132682   44010 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.
2024-08-10 13:16:08.136142: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: saved_model
2024-08-10 13:16:08.138981: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }
2024-08-10 13:16:08.139000: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: saved_model
2024-08-10 13:16:08.150149: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled
2024-08-10 13:16:08.151022: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.
2024-08-10 13:16:08.207132: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: saved_model
2024-08-10 13:16:08.214336: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 78198 microseconds.
2024-08-10 13:16:08.244932: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
loc(fused[""ReadVariableOp:"", ""sequential_1/dense_1/Add/ReadVariableOp@__inference_infer_97""]): error: missing attribute 'value'
LLVM ERROR: Failed to infer result type(s).
Aborted
```

Below is a minimal example that recreates the error.
```
import tensorflow as tf

class Model(tf.Module):
    def __init__(self):
        self.model = tf.keras.Sequential([
            tf.keras.layers.Input(shape=(9,)),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dense(9)
            ])

        self.model.compile(
            optimizer=tf.keras.optimizers.Adam(),
            loss=tf.keras.losses.MeanSquaredError())
    
    @tf.function(input_signature=[
        tf.TensorSpec([None, 9], tf.float32),
    ])
    def infer(self, x): 
        prediction = self.model(x)
        return prediction

model_custom = Model()
SAVED_MODEL_DIR = ""saved_model""

tf.saved_model.save(
    model_custom,
    SAVED_MODEL_DIR,
    signatures={
        ""infer"":
            model_custom.infer.get_concrete_function(),
        })

converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_DIR)
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.
    tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.
]
converter.experimental_enable_resource_variables = True
converter.allow_custom_ops = True
tflite_model = converter.convert()
```

"
2459534970,73531,Conv2D is no longer supporting Masking in TF v2.17.0,closed,2024-08-11 10:45:11+00:00,2024-08-14T10:59:39Z,2024-08-14T10:59:36Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/73531,"['stat:awaiting response', 'type:bug', 'comp:keras', '2.17']","['How  to  install  pip', '@kavjayawardana,\r\nLooks like this is an issue related to keras. Could you please raise the issue in the keras-team/keras repo for quick resolution. Thank you!', ""@tilakrayal, Thank you for the prompt reply. I've just raised the issue at keras-team/keras repo. I'll close this thread once I hear form them. Thanks again\r\nbest\r\n\r\nKav "", '@kavjayawardana,\r\nThank you for raising the issue in the Keras repo. .Can you please close this issue, since it is already being tracked there? \r\n', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73531"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73531"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.17.0

### Custom code

Yes

### OS platform and distribution

Ubuntu 22.04.3 LTS and Google Colab

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

cudatoolkit=12.6.0, cudnn=8.9.7.29

### GPU model and memory

_No response_

### Current behavior?

Dear TF team,

Conv2D layer no longer supports Masking layer in TensorFlow v2.17.0.

Due the dimensions of our input (i.e. (timesteps, width, channels)), size of the input shape (i.e. (2048, 2000, 3)) and size of the dataset (i.e. over 1 million samples), it is not practical to use LSTM, GRU, RNN or ConvLSTM1D layers, and therefore, Conv2D layers worked sufficiently well in our applications. The gaps in the dataset was handled with the Masking layer, and the masking layer was compatible with the Conv layers (among other layers, such as Cropping) from all TF versions up to (and including) TF v2.16. However, in TF v2.17.0, we get the following user warning ""Layer 'conv2d' (of type Conv2D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask"".

Is this a bug in TF v2.17.0?
Or is this feature now depreciated in TF v2.17.0?
Would you be able to reintroduce this feature in future versions?

Best

Kav

### Standalone code to reproduce the issue

```shell
LINK TO COLAB NOTEBOOK:
https://colab.research.google.com/drive/102k6UNSKb-d03DcmcUtCxmV9Qz9bjZoD?usp=drive_link


STANDALONE CODE:
from tensorflow.keras.layers import Conv2D, Masking, Flatten
from tensorflow.keras import Model, Input

batch = 1
timesteps = 10
width = 10
channels = 2
filters = 4
kernel_size = 3
mask_value = -1

x_input = Input(shape=(timesteps, width, channels))
x_masking = Masking(mask_value)(x_input)
x_conv2d = Conv2D(filters, kernel_size)(x_masking)
x_flatten = Flatten()(x_conv2d)

model = Model(x_input, x_flatten)
model.compile(loss='mse')
```


### Relevant log output

```shell
/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'conv2d' (of type Conv2D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.
  warnings.warn(
```
"
2460830393,73603,op_util_common.cc causes function parameter mismatch and cannot compile normally,closed,2024-08-12 12:12:49+00:00,2024-12-20T03:37:52Z,2024-12-20T03:37:08Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/73603,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite']","['Testing this out..., changing return size to 4.\r\n\r\ncurrent PR: https://github.com/tensorflow/tensorflow/pull/74423', 'Hi @ChrisHuang96, this PR is now merged: https://github.com/tensorflow/tensorflow/pull/74423. Let us know if it resolves your issue.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73603"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73603"">No</a>\n', 'This PR works well.']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

master

### Custom code

Yes

### OS platform and distribution

Linub Ubuntu 22.04

### Mobile device

_No response_

### Python version

3.11.9

### Bazel version

6.5.0

### GCC/compiler version

gcc 11.4

### CUDA/cuDNN version

12.1/9.2

### GPU model and memory

_No response_

### Current behavior?

There is a type mismatch in the ResolvePadding function defined at tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_hlo_conversions/op_util_common.cc:71. The return type is `llvm::Small Vector<DimPadding, 4>`, but the `res` defined are `llvm::Small Vector <DimPadding, 2>`. 


### Standalone code to reproduce the issue

```shell
bazel build --config=opt //tensorflow/tools/pip_package:wheel --repo_env=tf0812=tensorflow --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0""
```


### Relevant log output

```shell
ensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_hlo_conversions/op_util_common.cc: In function ‘llvm::SmallVector<mlir::odml::DimPadding, 2> mlir::odml::ResolvePadding(int64_t, std::optional<mlir::DenseIntElementsAttr>)’:
tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_hlo_conversions/op_util_common.cc:78:12: error: could not convert ‘res’ from ‘SmallVector<[...],4>’ to ‘SmallVector<[...],2>’
   78 |     return res;
      |            ^~~
      |            |
      |            SmallVector<[...],4>
tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_hlo_conversions/op_util_common.cc:86:12: error: could not convert ‘res’ from ‘SmallVector<[...],4>’ to ‘SmallVector<[...],2>’
   86 |     return res;
      |            ^~~
      |            |
      |            SmallVector<[...],4>
tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_hlo_conversions/op_util_common.cc:96:10: error: could not convert ‘res’ from ‘SmallVector<[...],4>’ to ‘SmallVector<[...],2>’
   96 |   return res;
      |          ^~~
      |          |
      |          SmallVector<[...],4>
Target //tensorflow/tools/pip_package:wheel failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /home/tensorflow/tensorflow/tools/pip_package/BUILD:266:9 Action tensorflow/tools/pip_package/wheel_house failed: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command (from target //tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_hlo_conversions:op_util_common) external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF ... (remaining 111 arguments skipped)
```
"
2465002164,73764,EventMgr::PollLoop causes graph execution hang,closed,2024-08-14 06:25:10+00:00,2024-09-04T19:28:47Z,2024-09-04T19:28:44Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/73764,"['type:bug', 'comp:core', 'awaiting PR merge', 'TF 2.15']","[""I've tried TF 2.8.0, it never hung.\r\n\r\n```\r\nvoid EventMgr::PollLoop() {\r\n  ToFreeVector to_free;\r\n  while (true) {\r\n    bool events_still_pending;\r\n    {\r\n      mutex_lock l(mu_);\r\n      if (stop_polling_) {\r\n        break;\r\n      }\r\n      if (used_events_.empty()) {\r\n        events_pending_.wait(l);\r\n      }\r\n      PollEvents(true, &to_free);\r\n      events_still_pending = !used_events_.empty();\r\n    }\r\n    FreeMemory(to_free);     ///////////////  FreeMemory was out of mu_ scope\r\n    to_free.clear();\r\n\r\n    if (events_still_pending) {\r\n      Env::Default()->SleepForMicroseconds(polling_active_delay_usecs_);\r\n    }\r\n  }\r\n  polling_stopped_->Notify();\r\n}\r\n\r\nvoid FreeMemory(const ToFreeVector& to_free) {\r\n    for (const auto& iu : to_free) {\r\n      // The function must be called in another thread.\r\n      if (iu.func != nullptr) threadpool_.Schedule(iu.func);\r\n    }\r\n  }\r\n```\r\n\r\nIt's most likely caused by this problem.\r\n"", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73764"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73764"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.15

### Custom code

Yes

### OS platform and distribution

Linux debian 10, kernel 5.15

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

After tens of thousands of steps, I sometimes encounter a situation where the graph execution hangs. This probability is extremely low.

My graph nodes may like this:
```
WhereOp(GPU) --> ShapeOp
             --> TensorScatterUpdateOp --> HistogramSummary
```

Here is the pstack:
<img width=""1415"" alt=""image"" src=""https://github.com/user-attachments/assets/843e7fc1-efec-4bb7-b73e-7b4c0f90fe96"">

the first frame:
```
void EventMgr::PollLoop() {
  while (true) {
    bool events_still_pending;
    {
      mutex_lock l(mu_);    //////////////////    lock mu_ here
      if (stop_polling_) {
        break;
      }
      if (callbacks_.empty()) {
        events_pending_.wait(l);
      }
      PollEvents(/*stream=*/nullptr);  // poll all streams
      events_still_pending = !callbacks_.empty();
    }

    if (events_still_pending) {
      Env::Default()->SleepForMicroseconds(polling_active_delay_usecs_);
    }
  }
  polling_stopped_->Notify();
}
```
the second frame:
```
// call from GPUUtil::CopyGPUTensorToCPU
void ThenExecute(se::Stream* stream, std::function<void()> func) {
    mutex_lock l(mu_);    //////////////////    lock mu_ here
    EnqueueCallback(stream, std::move(func));
    PollEvents(stream);
}
```
I guess that when the EventMgr::PollLoop thread executes PollLoop to run the done_callback of a async operator(WhereOp), it trigger a SendOp to CopyGPUTensorToCPU, which requires EventMgr::ThenExecute, which eventually causes the lock to hang.

I can only reproduce it in my production environment, tf.ConfigProto:
config.inter_op_parallelism_threads = 4
config.intra_op_parallelism_threads = 4

Other information:
TF version: tag v2.15.0, commit 6887368d6d46223f460358323c4b76d61d1558a8
Python: 3.9
OS: Linux debian 10, kernel 5.15

GPU: NVIDIA A100
Driver Version: 535.161.08
CUDA Version: 12.2

However, I cannot reproduce this issue with tiny code, could anyone reproduce it?


### Standalone code to reproduce the issue

```shell
However, I cannot reproduce this issue with tiny code, could anyone reproduce it?
```


### Relevant log output

_No response_"
2466377276,73800,App Storage Size Increases with CoreML or Metal Usage on iOS,closed,2024-08-14 17:10:29+00:00,2024-11-26T18:01:57Z,2024-11-26T18:01:53Z,yishuangP,,https://github.com/tensorflow/tensorflow/issues/73800,"['stat:awaiting tensorflower', 'type:bug', 'comp:lite', 'iOS']","['Need a real device to test this. @yishuangP can you please take a look? Thanks.', ""I got reply on Apple's Developer Forum: [CoreML - doUnloadModel:options:qos:error](https://developer.apple.com/forums/thread/768367?login=true)\r\n\r\nlooks like the issue is with tflite's coreML delegate implementation. I don't know much about this stuff, but the issue is probably here: [coreml_executor.mm](https://github.com/tensorflow/tensorflow/blob/8a3c6ad49d51857cc7ebda10ee93332f16f719ff/tensorflow/lite/delegates/coreml/coreml_executor.mm)"", ""Hi, @leoull \r\nThanks for raising this issue. Are you aware of the migration to [LiteRT](https://developers.googleblog.com/en/tensorflow-lite-is-now-litert/)? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/google-ai-edge/LiteRT/issues/40\r\n\r\nLet us know if you have any questions. Thanks."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73800"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73800"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

0.0.1-nightly

### Custom code

No

### OS platform and distribution

iPhone 17.5.1

### Mobile device

iPhone 13 mini

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I'm encountering an issue where the app's storage size increases each time an AI model is loaded, and the storage doesn't decrease afterward. Specifically, I'm using the [PoseNet TensorFlow Lite model on iPhone](https://github.com/tensorflow/examples/tree/master/lite/examples/pose_estimation/ios) to demonstrate the problem.

for more detail checkout  [this StackOverflow Post](https://stackoverflow.com/questions/78872138/app-storage-size-increases-with-coreml-or-metal-usage-on-ios)

### Standalone code to reproduce the issue

```md
Run the [TensorFlow Lite Pose Estimation iOS Demo](https://github.com/tensorflow/examples/tree/master/lite/examples/pose_estimation/ios#tensorflow-lite-pose-estimation-ios-demo) using `Metal` or `CoreML`, and you'll notice the app's storage size increasing each time the pose detection model is executed.
```


### Relevant log output

_No response_"
2467052283,73835,"tf.numpy_function doesn't work with keras tensors in tf2.17,  but previous versions do",closed,2024-08-15 00:33:07+00:00,2024-08-22T18:06:53Z,2024-08-22T18:06:50Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/73835,"['stat:awaiting response', 'type:bug', 'comp:keras', '2.17']","['Hi **@MeowTheCat** ,\r\n Sorry for the delay, I tried to run your code on Colab using TF v2.15, 2.17.0 & nightly and faced the same issue. Please find the [gist](https://colab.research.google.com/gist/Venkat6871/fae296b6d8ffa3188ee338347cbb332d/73835_2-15-0-2-17-0-nightly-v.ipynb) here for reference. Please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues) as this issue is more related to keras\r\n\r\nThank you!', 'I walked around this issue. Closing it.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73835"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73835"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

tf 2.17

### Custom code

Yes

### OS platform and distribution

Ubuntu 18.04.6 LTS

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I need to use tf.numpy_function to create some custom metric in model training. But it throw out an error in TF2.17.
The same code runs fine in TF2.11

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Model


def calc_accuracy(y_true, y_pred):
    # Calculate the accuracy
    return np.mean(np.equal(y_true, np.round(y_pred)).astype(np.float32))


# Define the model using the Functional API
x = tf.keras.Input(shape=(20,),name=""x"", dtype=tf.float32)
y = tf.keras.Input(shape=(), name=""y"", dtype=tf.float32)
tmp = Dense(64, activation='relu')(x)
outputs = Dense(1, activation='sigmoid')(tmp)
model = Model(inputs=[x, y], outputs=outputs)

accuracy = tf.numpy_function(
            func=calc_accuracy,
            inp=[y, outputs],
            Tout=tf.float32)

model.add_metric(accuracy, name=""accuracy"", aggregation='mean')

# Compile the model with the custom metric
model.compile(optimizer='adam',
              loss='binary_crossentropy')

# Dummy data for demonstration
import numpy as np
X_train = np.random.random((1000, 20))
y_train = np.random.randint(2, size=(1000, 1)).astype(np.float32)

# Train the model
model.fit([X_train, y_train], y_train, epochs=10, batch_size=32)
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""/home/wangx286/rnn-base-caller/base_caller/scripts/example_metric.py"", line 18, in <module>
    accuracy = tf.numpy_function(
  File ""/home/wangx286/miniconda3/envs/tf217/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py"", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/home/wangx286/miniconda3/envs/tf217/lib/python3.10/site-packages/keras/src/backend/common/keras_tensor.py"", line 61, in __array__
    raise ValueError(
ValueError: A KerasTensor is symbolic: it's a placeholder for a shape an a dtype. It doesn't have any actual numerical value. You cannot convert it to a NumPy array.
```
"
2467080507,73836,Sharding Callback + Parameter Server Strategy partitioner crash when combined,closed,2024-08-15 01:03:37+00:00,2024-08-16T08:52:11Z,2024-08-16T08:13:37Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/73836,"['type:bug', 'WIP', 'comp:dist-strat', 'TF 2.16']","['@hmc-cs-mdrissi,\r\nThank you for reporting the issue. Could you please confirm if the similar crash happened on the latest tensorflow v2.17 which contains the keras3.0 and provide the update. \r\nhttps://www.tensorflow.org/tutorials/distribute/parameter_server_training\r\nThank you!', ""Keras 3.0 is backwards incompatible in a couple ways and has worse PS support so it's not really fit to answer this question. Core optimizers in keras (adam) have race condition issues in PS. I've filed couple bug reports related to keras/PS with response of unclear plans on support in future.\r\n\r\nI've been doing my testing with tf_keras keras 2 fork instead which continues to be updated with new tf versions.\r\n\r\nedit: Here's [specific quote](https://github.com/keras-team/keras/issues/18624#issuecomment-1765147583),\r\n\r\n> Parameter server training is not supported in Keras 3, generally speaking. The feature had very low usage. If you need it, I recommend you stick to tf.keras and use the legacy optimizers.\r\n\r\nIf answer is issues only apply for keras 3 then effectively some tf apis that are still documented normally have notable issues in practice now. Besides PS, ragged tensors are documented normally but are not supported in keras 3"", ""I'm surprised. TF 2.17 + tf-keras 2.17 (so sticking to keras 2 fork) works with no errors and resolves this issue. Here's fix [PR](https://github.com/tensorflow/tensorflow/commit/2f2aecfc97bb71209ece6cd1453506e0dce3d52a)"", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73836"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73836"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.16

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

```
Duplicate tensor keyed by embedding_0/.ATTRIBUTES/VARIABLE_VALUE encountered, when merging prefix: /var/tmp/tm
pc1sz0ucl/weights_temp/part-00001-of-00003
         [[{{node MergeV2Checkpoints}}]] [Op:__inference_tf_function_save_82]
Uncaught exception. Entering post mortem debugging
```

Create a toy model in parameter server strategy with variable partitioner and save checkpoint at end with ShardingCallback to slice large variables. Motivation is handling >10s of GB embedding tables efficiently. Variable partitioner is great for loading time and during training. Sharding callback is helpful at saving time to improve load efficiency for PS. But two together crash. The issue is variable_partitioner creates ShardedVariable with different PS having different slice. Those share same name and when combined with MaxShardSizePolicy you get a crash where each PS can save it's file, but they can't be merged correctly.

### Standalone code to reproduce the issue

Three files total. Run prepare model to create a toy model artifact and then load_model afterwards to try and load/save it in PS to reproduce the error.


toy_model.py

```python
import os

import tensorflow as tf
import tf_keras


class ToyModel(tf_keras.Model):
    def __init__(self, embedding_size_bytes: int, var_count: int):
        super().__init__()
        self.embedding_size_bytes = embedding_size_bytes
        self.var_count = var_count
        self.dense = tf_keras.layers.Dense(
            1, activation=""sigmoid"", kernel_initializer=tf_keras.initializers.GlorotNormal(seed=0)
        )

    def build(self, input_shape: tf.TensorShape):
        self.embeddings: dict[str, tf.Variable] = {}
        vocab_size = int(self.embedding_size_bytes / 256 / 4)
        for i in range(self.var_count):
            name = f""embedding_{i}""
            self.embeddings[name] = self.add_weight(
                name=name,
                shape=(vocab_size, 256),
                initializer=tf_keras.initializers.RandomUniform(seed=i),
                dtype=tf.float32,
                trainable=True,
            )

        self.dense.build(tf.TensorShape((None, 256)))
        self.built = True

    def call(self, inputs: tf.Tensor):
        embedding_values = []
        for i in range(self.var_count):
            name = f""embedding_{i}""
            embedding_values.append(tf.nn.embedding_lookup(self.embeddings[name], tf.squeeze(inputs, axis=1)))

        overall_embedding = tf.reduce_mean(embedding_values, axis=0)
        return self.dense(overall_embedding)


def get_weights_path(name: str):
    return os.path.join(os.path.dirname(__file__), ""toy_model_weights"", name, ""weights"")
```


prepare_model.py

```python
from typing import Sequence

import os
import shutil
import time
from collections import defaultdict

import tensorflow as tf
from tensorflow.train.experimental import MaxShardSizePolicy, ShardableTensor

from toy_model import ToyModel, get_weights_path, get_model_name


if __name__ == ""__main__"":
    num_gb = 20
    var_count = 1

    embedding_size_bytes = num_gb * 1024 * 1024 * 1024
    model = ToyModel(embedding_size_bytes, var_count)
    model.build(tf.TensorShape((None, 1)))

    model_name = ""test_model""
    weights_path = get_weights_path(model_name)
    shutil.rmtree(os.path.dirname(weights_path), ignore_errors=True)

    shard_size = 2 * 1024 * 1024 * 1024  # 2GB
    sharding_callback = MaxShardSizePolicy(shard_size)

    start_time = time.time()
    model.save_weights(weights_path, options=tf.train.CheckpointOptions(experimental_sharding_callback=sharding_callback))
    print(f""Saving weights took {time.time() - start_time:.2f} seconds"")
```

load_model.py (this is one that will crash)
```python
from typing import Any, Mapping

import json
import logging
import os
import shutil
import subprocess
import sys
import tempfile
import time

import tensorflow as tf
from tensorflow.train.experimental import MaxShardSizePolic

from prepare_model import SingleFileMaxShardSizePolicy
from toy_model import ToyModel, get_model_name, get_weights_path


def create_tf_configs(worker_count: int, ps_count: int, include_evaluator: bool):
    """"""Create TF_CONFIGs for a cluster.""""""
    cluster_dict: dict[str, list[str]] = {}
    if worker_count:
        cluster_dict[""worker""] = [f""localhost:{pick_unused_port()}"" for _ in range(worker_count)]
    if ps_count:
        cluster_dict[""ps""] = [f""localhost:{pick_unused_port()}"" for _ in range(ps_count)]

    cluster_dict[""chief""] = [f""localhost:{pick_unused_port()}""]

    tf_configs: list[TFConfig] = []
    for i in range(worker_count):
        tf_configs.append({""cluster"": cluster_dict, ""task"": {""type"": ""worker"", ""index"": i}})

    for i in range(ps_count):
        tf_configs.append({""cluster"": cluster_dict, ""task"": {""type"": ""ps"", ""index"": i}})

    if include_evaluator:
        tf_configs.append({""cluster"": cluster_dict, ""task"": {""type"": ""evaluator"", ""index"": 0}})

    tf_configs.append({""cluster"": cluster_dict, ""task"": {""type"": ""chief"", ""index"": 0}})

    return tf_configs


def _create_process(tf_config: Mapping[str, Any], log_dir: str):
    name = tf_config[""task""][""type""] + ""_"" + str(tf_config[""task""][""index""])
    command = [sys.executable, os.path.basename(__file__)]

    log_file_stdout = os.path.join(log_dir, f""stdout_{name}.log"")
    log_file_stderr = os.path.join(log_dir, f""stderr_{name}.log"")
    os.makedirs(log_dir, exist_ok=True)
    with open(log_file_stdout, ""a"") as stdout, open(log_file_stderr, ""a"") as stderr:
        print(f""Starting {name} process..."")
        env_ = os.environ.copy() | {""TF_CONFIG"": json.dumps(tf_config)}
        return subprocess.Popen(command, stdout=stdout, stderr=stderr, env=env_)


NUM_GB = 20
VAR_COUNT = 1

shard_size = 2 * 1024 * 1024 * 1024  # 2GB
PS_SAVE_SHARD_POLICY = MaxShardSizePolicy(shard_size)


def run():
    resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()

    task_type = resolver.task_type
    print(f""Task type: {task_type}"")
    if task_type in (""worker"", ""ps""):
        print(""Starting server..."")
        server = tf.distribute.Server(
            resolver.cluster_spec(),
            job_name=resolver.task_type,
            task_index=resolver.task_id,
            protocol=resolver.rpc_layer,
            start=True,
        )
        server.join()

    strategy = tf.distribute.experimental.ParameterServerStrategy(
        resolver,
        variable_partitioner=tf.distribute.experimental.partitioners.MaxSizePartitioner(
            max_shard_bytes=1 * 1024 * 1024 * 1024
        ),
    )
    print(""Building model..."")
    model_name = ""test_model""
    weights_path = get_weights_path(model_name)

    with strategy.scope(), tempfile.TemporaryDirectory() as temp_dir_name:
        embedding_size_bytes = NUM_GB * 1024 * 1024 * 1024
        model = ToyModel(embedding_size_bytes, VAR_COUNT)
        start_time = time.time()

        model.load_weights(weights_path)
        model.build(tf.TensorShape((None, 1)))
        done_loading_time = time.time()
        print(f""Loading weights took {done_loading_time - start_time:.2f} seconds"")
        save_path = os.path.join(temp_dir_name, ""weights"")
        model.save_weights(
            save_path, options=tf.train.CheckpointOptions(experimental_sharding_callback=PS_SAVE_SHARD_POLICY)
        )
        done_saving_time = time.time()
        print(f""Saving weights took {done_saving_time - done_loading_time:.2f} seconds"")
        print(""Done"")


def main():
    if ""TF_CONFIG"" in os.environ:
        run()
        return

    tf_configs = create_tf_configs(1, 2, False)
    chief_config = tf_configs[-1]
    model_name = ""test_model""
    print(f""Model: {model_name}"")
    log_dir = os.path.join(os.path.dirname(__file__), ""toy_model_weights"", model_name, ""logs"", ""run1"")
    shutil.rmtree(log_dir, ignore_errors=True)
    for tf_config in tf_configs[:-1]:
        _create_process(tf_config, log_dir)

    tf.debugging.disable_traceback_filtering()
    os.environ[""TF_CONFIG""] = json.dumps(chief_config)
    print(""Starting chief"")
    run()


if __name__ == ""__main__"":
    main()
```


### Relevant log output

```shell
File ""<string>"", line 1, in <module>                                                                        
                                                                                                              
  File ""/home/mdrissi/training-platform/scratch/explore_sharding_perf/load_model.py"", line 126, in <module>   
                                                                                                              
  File ""/home/mdrissi/training-platform/scratch/explore_sharding_perf/load_model.py"", line 122, in main       
                                                                                                              
  File ""/home/mdrissi/training-platform/scratch/explore_sharding_perf/load_model.py"", line 97, in run         
                                                       
  File ""/home/mdrissi/.venvs/bento/lib/python3.9/site-packages/tf_keras/src/utils/traceback_utils.py"", line 61
, in error_handler                                                                                            
                                                       
  File ""/home/mdrissi/.venvs/bento/lib/python3.9/site-packages/tf_keras/src/engine/training.py"", line 3170, in
 save_weights

  File ""/home/mdrissi/.venvs/bento/lib/python3.9/site-packages/tf_keras/src/saving/saving_api.py"", line 284, i
n save_weights

  File ""/home/mdrissi/.venvs/bento/lib/python3.9/site-packages/tf_keras/src/saving/legacy/save.py"", line 374, 
in save_weights

  File ""/home/mdrissi/.venvs/bento/lib/python3.9/site-packages/tensorflow/python/checkpoint/functional_saver.p
y"", line 555, in tf_function_save

Duplicate tensor keyed by embedding_0/.ATTRIBUTES/VARIABLE_VALUE encountered, when merging prefix: /var/tmp/tm
pc1sz0ucl/weights_temp/part-00001-of-00003
         [[{{node MergeV2Checkpoints}}]] [Op:__inference_tf_function_save_82]
```
"
2468433820,73873,Unexpected behaviour training custom Siamese Network,closed,2024-08-15 16:27:32+00:00,2025-01-07T02:02:47Z,2025-01-07T02:02:45Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/73873,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'TF 2.15']","['Hi **@Carl0smvs** ,\r\nSorry for the dealy, Please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues) as this issue is more related to keras\r\n\r\nThank you!', 'I will, thank you!', 'Hi **@Carl0smvs** ,\r\nCould you please close this issue if it has already been raised in the Keras repository?\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73873"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73873"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.15.1

### Custom code

Yes

### OS platform and distribution

Linux Mint 21.2 Cinnamon

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I am trying to train a custom built Siamese Network, following the Keras [documentation](https://keras.io/examples/vision/siamese_contrastive/) closely, only modifying the architecture and other things as needed.

What I'm trying to do differently is load the data in a different manner. Due to the dimensions of the dataset I will be working with, I can't store it all at once in arrays in memory as is done in the example.

I tried loading it iteratively to the model to be trained in two ways:
- Using a tf.data.Dataset that will load the data as needed
- Building a custom training loop that would only fetch the data batch by batch

To test these, I put together an example script (supplied below) to test these approaches and how they perform in comparison to supplying the whole dataset to the model from an array in memory 

Surprisingly, both of my methods produce a weird behaviour, where the trained model simply outputs the same class for every instance (classifying the image pairs as being distinct), while with the first method the model trains well and converges to a good solution. I don't understand if I'm doing something wrong, I have checked my produced tf.data.Dataset and they have the exact same data as the in-memory arrays (as it's supposed to) and I am doing things correctly according to the documentation as far as I am aware.  Can you reproduce the issue, and if yes, understand if I'm doing something wrong or if this behaviour is related to something internal of Tensorflow/Keras that I am not aware of? 

### Standalone code to reproduce the issue

```shell
import time
import sys
import numpy as np
import itertools
from tensorflow.keras.layers import *
from tensorflow.keras.models import Sequential, Model
from random import shuffle, random

tf.random.set_seed(1234)
np.random.seed(1234)

np.set_printoptions(threshold=sys.maxsize)

mnist = tf.keras.datasets.mnist

(X_train, y_train), (X_test, y_test) = mnist.load_data()

print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)

img_A_input = Input((28, 28, 3), name='img_A_input')
img_B_input = Input((28, 28, 3), name='img_B_input')


def euclidean_distance(vects):
    """"""Find the Euclidean distance between two vectors.

    Arguments:
        vects: List containing two tensors of same length.

    Returns:
        Tensor containing euclidean distance
        (as floating point value) between vectors.
    """"""

    x, y = vects
    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)
    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))

def loss(margin=1):
    """"""Provides 'contrastive_loss' an enclosing scope with variable 'margin'.

    Arguments:
        margin: Integer, defines the baseline for distance for which pairs
                should be classified as dissimilar. - (default is 1).

    Returns:
        'contrastive_loss' function with data ('margin') attached.
    """"""

    # Contrastive loss = mean( (1-true_value) * square(prediction) +
    #                         true_value * square( max(margin-prediction, 0) ))
    def contrastive_loss(y_true, y_pred):
        """"""Calculates the contrastive loss.

        Arguments:
            y_true: List of labels, each label is of type float32.
            y_pred: List of predictions of same length as of y_true,
                    each label is of type float32.

        Returns:
            A tensor containing contrastive loss as floating point value.
        """"""

        square_pred = tf.math.square(y_pred)
        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))
        return tf.math.reduce_mean((1 - y_true) * square_pred + (y_true) * margin_square)

    return contrastive_loss

cnn = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (2, 2), activation=""tanh"", padding=""same""),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
    tf.keras.layers.Dropout(0.3),

    tf.keras.layers.Conv2D(64, (2, 2), activation=""tanh"", padding=""same""),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
    tf.keras.layers.Dropout(0.3),

    tf.keras.layers.Conv2D(128, (2, 2), activation=""tanh"", padding=""same""),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
    tf.keras.layers.Dropout(0.3),

    tf.keras.layers.Conv2D(256, (2, 2), activation=""tanh"", padding=""same""),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
    tf.keras.layers.Dropout(0.3),

    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(64, activation='tanh')
])

feature_vector_A = cnn(img_A_input)
feature_vector_B = cnn(img_B_input)

merge_layer = tf.keras.layers.Lambda(euclidean_distance, output_shape=(1,))(
    [feature_vector_A, feature_vector_B]
)
normal_layer = tf.keras.layers.BatchNormalization()(merge_layer)

output = Dense(1, activation='sigmoid')(normal_layer)

model = Model(inputs=[img_A_input, img_B_input], outputs=output)

random_indices = np.random.choice(X_train.shape[0], 500, replace=False)
X_train_sample, y_train_sample = X_train[random_indices], y_train[random_indices]

random_indices = np.random.choice(X_test.shape[0], 200, replace=False)
X_test_sample, y_test_sample = X_test[random_indices], y_test[random_indices]


def make_paired_dataset(X,y):
    X_pairs, y_pairs = [], []

    tuples = [(x1, y1) for x1, y1 in zip(X,y)]

    for t in itertools.product(tuples, tuples):
        img_A, label_A = t[0]
        img_B, label_B = t[1]

        img_A = tf.expand_dims(img_A, -1)
        img_A = tf.image.grayscale_to_rgb(img_A)

        img_B = tf.expand_dims(img_B, -1)
        img_B = tf.image.grayscale_to_rgb(img_B)

        new_label = float(label_A == label_B)

        X_pairs.append([img_A, img_B])
        y_pairs.append(new_label)

    pairs = [(x, y) for x, y in zip(X_pairs, y_pairs)]
    shuffle(pairs)

    X_pairs = np.array([x for x, _ in pairs])
    y_pairs = np.array([y for _, y in pairs])

    return X_pairs, y_pairs

def generate_paired_samples_dev(X, y):
    tuples = [(x1, y1) for x1, y1 in zip(X, y)]

    for t in itertools.product(tuples, tuples):
        img_A, label_A = t[0]
        img_B, label_B = t[1]

        img_A = tf.expand_dims(img_A, -1)
        img_A = tf.image.grayscale_to_rgb(img_A)

        img_B = tf.expand_dims(img_B, -1)
        img_B = tf.image.grayscale_to_rgb(img_B)

        new_label = float(label_A == label_B)
        yield [img_A, img_B], new_label


X_train_pairs, y_train_pairs = make_paired_dataset(X_train_sample, y_train_sample)
X_test_pairs, y_test_pairs = make_paired_dataset(X_test_sample, y_test_sample)

train_dataset = tf.data.Dataset.from_generator(
    generate_paired_samples_dev,
    args=(X_train_sample, y_train_sample),
    output_signature=(
        tf.TensorSpec(shape=(2,) + (28, 28, 3), dtype=tf.int32),
        tf.TensorSpec(shape=(), dtype=tf.float32)
    )
).map(lambda x, y: ({'img_A_input': x[0], 'img_B_input': x[1]}, y))
train_dataset = train_dataset.batch(batch_size=32)
train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)

val_dataset = tf.data.Dataset.from_generator(
    generate_paired_samples_dev,
    args=(X_test_sample, y_test_sample),
    output_signature=(
        tf.TensorSpec(shape=(2,) + (28, 28, 3), dtype=tf.int32),
        tf.TensorSpec(shape=(), dtype=tf.float32)
    )
).map(lambda x, y: ({'img_A_input': x[0], 'img_B_input': x[1]}, y))
val_dataset = val_dataset.batch(batch_size=32)
val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)


model.compile(loss=loss(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])
model.summary()

class_weight = {0: 0.1,
                1: 0.9}

weights = model.get_weights()

""""""
    Training with all the data pairs stored in arrays
""""""
model.fit(x=[X_train_pairs[:, 0, :, :], X_train_pairs[:, 1, :, :]], # numbers to differentiate the input images for each subnetwork
          y=y_train_pairs,
          validation_data=([X_test_pairs[:, 0, :, :], X_test_pairs[:, 1, :, :]], y_test_pairs),
          epochs=10, batch_size=32, class_weight=class_weight, verbose=2)

print(model.evaluate(x=[X_test_pairs[:, 0, :, :], X_test_pairs[:, 1, :, :]], y=y_test_pairs, batch_size=32, verbose=2))

model.set_weights(weights) # just to reset the initial state without any training

""""""
    Training with all the data using the tf.data.Dataset class, so that the data isn't all kept in memory at the same time
""""""
model.fit(train_dataset,
          validation_data=val_dataset,
          epochs=10, class_weight=class_weight, verbose=2)
print(model.evaluate(x=[X_test_pairs[:, 0, :, :], X_test_pairs[:, 1, :, :]], y=y_test_pairs, batch_size=32, verbose=2))

model.set_weights(weights) # just to reset the initial state without any training


batch_size = 32
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
loss_fn = loss()

train_acc_metric = tf.keras.metrics.Accuracy()
val_acc_metric = tf.keras.metrics.Accuracy()

""""""
    Custom training loop to train the model by batch. This is just a demo where the final use case is to only have in memory
    the file paths for the images, and load only each batch of images when needed, since the whole dataset wouldn't fit in memory
""""""
for epoch in range(10):
    tmp = [(x, y) for x, y in zip(X_train_pairs, y_train_pairs)]
    shuffle(tmp)
    X_train_pairs = np.array([x for x, _ in tmp])
    y_train_pairs = np.array([y for _, y in tmp])

    print(""Starting epoch "" + str(epoch + 1))
    start_time = time.time()
    for idx in range((len(y_train_pairs) // batch_size)):
        batch_x = X_train_pairs[idx * batch_size: (idx + 1) * batch_size]
        batch_y = y_train_pairs[idx * batch_size: (idx + 1) * batch_size]
        with tf.GradientTape() as tape:
            preds = model([batch_x[:, 0, :, :], batch_x[:, 1, :, :]], training=True)
            loss = loss_fn(batch_y, preds)
        grads = tape.gradient(loss, model.trainable_weights)
        optimizer.apply_gradients(zip(grads, model.trainable_weights))
        train_acc_metric.update_state(batch_y, preds)

        # Log every 200 batches.
        if idx % 200 == 0:
            print(
                ""Training loss (for one batch) at step %d: %.4f""
                % (idx + 1, float(loss))
            )
            print(""Seen so far: %s samples"" % ((idx + 1) * batch_size))

    # Display metrics at the end of each epoch.
    train_acc = train_acc_metric.result()
    print(""Training acc over epoch: %.4f"" % (float(train_acc),))

    # Reset training metrics at the end of each epoch
    train_acc_metric.reset_states()

    # Run a validation loop at the end of each epoch.
    for idx in range((len(y_test_pairs) // batch_size)):
        batch_x = X_test_pairs[idx * batch_size: (idx + 1) * batch_size]
        batch_y = y_test_pairs[idx * batch_size: (idx + 1) * batch_size]
        val_preds = model([batch_x[:, 0, :, :], batch_x[:, 1, :, :]], training=False)
        val_acc_metric.update_state(batch_y, val_preds)

    val_acc = val_acc_metric.result()
    val_acc_metric.reset_states()
    print(""Validation acc: %.4f"" % (float(val_acc),))
    print(""Time taken: %.2fs"" % (time.time() - start_time))
```


### Relevant log output

```shell
First method training:
Epoch 1/10
7813/7813 - 113s - loss: 0.0109 - accuracy: 0.9274 - val_loss: 0.0238 - val_accuracy: 0.9714 - 113s/epoch - 14ms/step
Epoch 2/10
7813/7813 - 111s - loss: 0.0021 - accuracy: 0.9847 - val_loss: 0.0168 - val_accuracy: 0.9813 - 111s/epoch - 14ms/step
Epoch 3/10
7813/7813 - 111s - loss: 0.0016 - accuracy: 0.9877 - val_loss: 0.0239 - val_accuracy: 0.9728 - 111s/epoch - 14ms/step
Epoch 4/10
7813/7813 - 111s - loss: 0.0015 - accuracy: 0.9890 - val_loss: 0.0159 - val_accuracy: 0.9823 - 111s/epoch - 14ms/step
Epoch 5/10
7813/7813 - 111s - loss: 0.0014 - accuracy: 0.9895 - val_loss: 0.0191 - val_accuracy: 0.9786 - 111s/epoch - 14ms/step
Epoch 6/10
7813/7813 - 111s - loss: 0.0014 - accuracy: 0.9895 - val_loss: 0.0210 - val_accuracy: 0.9768 - 111s/epoch - 14ms/step
Epoch 7/10
7813/7813 - 111s - loss: 0.0012 - accuracy: 0.9909 - val_loss: 0.0205 - val_accuracy: 0.9771 - 111s/epoch - 14ms/step
Epoch 8/10
7813/7813 - 111s - loss: 0.0012 - accuracy: 0.9908 - val_loss: 0.0184 - val_accuracy: 0.9792 - 111s/epoch - 14ms/step
Epoch 9/10
7813/7813 - 111s - loss: 0.0012 - accuracy: 0.9911 - val_loss: 0.0177 - val_accuracy: 0.9798 - 111s/epoch - 14ms/step
Epoch 10/10
7813/7813 - 111s - loss: 0.0010 - accuracy: 0.9922 - val_loss: 0.0182 - val_accuracy: 0.9786 - 111s/epoch - 14ms/step
1250/1250 - 4s - loss: 0.0182 - accuracy: 0.9786 - 4s/epoch - 4ms/step
[0.01822792738676071, 0.9785500168800354]
1250/1250 - 41s - loss: 0.0182 - accuracy: 0.9786 - 41s/epoch - 32ms/step
[0.018227916210889816, 0.9785500168800354]

Second method training:
Epoch 1/10
2813/2813 - 43s - loss: 0.0237 - accuracy: 0.8624 - val_loss: 0.0925 - val_accuracy: 0.8972 - 43s/epoch - 15ms/step
Epoch 2/10
2813/2813 - 42s - loss: 0.0193 - accuracy: 0.8945 - val_loss: 0.0926 - val_accuracy: 0.8972 - 42s/epoch - 15ms/step
Epoch 3/10
2813/2813 - 42s - loss: 0.0192 - accuracy: 0.8945 - val_loss: 0.0924 - val_accuracy: 0.8972 - 42s/epoch - 15ms/step
Epoch 4/10
2813/2813 - 42s - loss: 0.0193 - accuracy: 0.8945 - val_loss: 0.0924 - val_accuracy: 0.8972 - 42s/epoch - 15ms/step
Epoch 5/10
2813/2813 - 42s - loss: 0.0192 - accuracy: 0.8945 - val_loss: 0.0925 - val_accuracy: 0.8972 - 42s/epoch - 15ms/step
Epoch 6/10
2813/2813 - 42s - loss: 0.0192 - accuracy: 0.8945 - val_loss: 0.0924 - val_accuracy: 0.8972 - 42s/epoch - 15ms/step
Epoch 7/10
2813/2813 - 42s - loss: 0.0192 - accuracy: 0.8945 - val_loss: 0.0926 - val_accuracy: 0.8972 - 42s/epoch - 15ms/step
Epoch 8/10
2813/2813 - 42s - loss: 0.0193 - accuracy: 0.8945 - val_loss: 0.0924 - val_accuracy: 0.8972 - 42s/epoch - 15ms/step
Epoch 9/10
2813/2813 - 42s - loss: 0.0193 - accuracy: 0.8945 - val_loss: 0.0925 - val_accuracy: 0.8972 - 42s/epoch - 15ms/step
Epoch 10/10
2813/2813 - 42s - loss: 0.0192 - accuracy: 0.8945 - val_loss: 0.0925 - val_accuracy: 0.8972 - 42s/epoch - 15ms/step
704/704 - 2s - loss: 0.0925 - accuracy: 0.8972 - 2s/epoch - 4ms/step
[0.09247653186321259, 0.8971555829048157]
704/704 - 23s - loss: 0.0925 - accuracy: 0.8972 - 23s/epoch - 32ms/step
[0.09247657656669617, 0.8971555829048157]

Third method training:
(I won't put the log here since it's long and doesn'r add much information, the loss just keeps jumping between 0.05 and 1 randomly, without converging as the number of epochs passed increases)
```
"
2469267550,73901,"Model training hangs and is unresponsive when tensorflow is not imported, even if tensorflow is not accessed",closed,2024-08-16 01:42:58+00:00,2024-10-09T02:01:29Z,2024-10-09T02:01:26Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/73901,"['stat:awaiting response', 'type:bug', 'stale', 'comp:model', 'TF 2.16']","['@hygtfrde,\r\nThe code provided is fairly complex hence it would be difficult for us to pinpoint the issue. Could you please get the example down to the simplest possible repro? That will allow us to determine the source of the issue easily. Thank you!', 'Yes, essentially the model will not train if tensorflow is not imported. If it is imported then it will train, although tensorflow was not used or accessed by the code directly. \r\n<img width=""391"" alt=""Screenshot 2024-08-21 at 1 10 43\u202fPM"" src=""https://github.com/user-attachments/assets/08f74c59-9f13-45bd-9f16-1a10ec5130aa"">\r\nIt was not clear that tensorflow is actually a required dependency. To reproduce this issue just comment out or remove tensorflow from the imports and try to build and train the model. It should partially run but will be unresponsive and hang indefinitely. \r\nI spent a few days debugging the model, looking into CPU and GPU usage compatibility and other issues. But the bug appears much more simple. While not explicitly required as a dependency, tensorflow appears to be required implicitly, my guess is from Keras. By importing these modules:\r\n```\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Dropout, Input\r\nfrom tensorflow.keras.utils import to_categorical\r\n```\r\nWe should see something like \'error, tensorflow is required for these modules\'\r\n\r\nTo summarize:\r\n- Tensorflow is not explicitly used elsewhere in the code\r\n- However, it is probably a dependency for other modules or code (Keras?)\r\n- If it is not imported then the model will fail to train and build\r\n\r\n```\r\n# remove the line below or comment it out to reproduce training bug\r\nimport tensorflow as tf\r\n```\r\n\r\nThis bug should be present for any model training like this one\r\n```\r\ndef build_and_train_model(X_train, y_train, X_test, y_test, num_features, num_classes):\r\n    model = Sequential([\r\n        Input(shape=(num_features,)),\r\n        Dense(64, activation=\'relu\'),\r\n        Dropout(0.2),\r\n        Dense(num_classes, activation=\'softmax\')\r\n    ])\r\n    model.compile(optimizer=\'adam\', loss=\'categorical_crossentropy\', metrics=[\'accuracy\'])\r\n    history = model.fit(\r\n        X_train, \r\n        y_train, \r\n        epochs=300, \r\n        batch_size=128, \r\n        validation_data=(X_test, y_test),\r\n        verbose=1\r\n    )\r\n    return model, history\r\n\r\n# Build and train model\r\nmodel, history = build_and_train_model(X_train, y_train, X_test, y_test, X_scaled.shape[1], num_classes)\r\n    \r\n```', '@hygtfrde,\r\nBy default Tensorflow v2.17 contains Keras3.0 which might be reason for the error. Could you please try using below commands to install the keras2.0 version and test the code.\r\n\r\n```\r\n!pip install tf-keras\r\n\r\nimport tf_keras as keras\r\n```\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73901"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/73901"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.16.2

### Custom code

Yes

### OS platform and distribution

MacOS Sonoma 14.6

### Mobile device

_No response_

### Python version

3.11.8

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

none

### GPU model and memory

Apple M2 16GB

### Current behavior?

When I `import tensorflow as tf` or `import tensorflow`, the model training process runs with success. However `tensorflow` was not accessed anywhere else in the program, so to clean things up I deleted that import line. Then when I ran the program, the model would fail to train and hangs unexpectedly. I think this is likely a dependency issue and `tensorflow` is being used by the program, even though not explicitly, such as by `keras.models` or a similar module. Though this was not apparent. 
Data is already extracted into a sample CSV file, so no need to run `music_processor.py`
Simply pass in the CSV path `v5_2_files.csv` to `read_raw_str_csv_and_split_df` in the `main_model.py` main function. Then run the program with `python main_model.py`

### Standalone code to reproduce the issue

```shell
To reproduce the bug, clone the source code here: https://github.com/hygtfrde/classically_punk
Then inside of the file `main_model.py` comment out or remove the import line: `import tensorflow as tf`
A sample CSV dataset is already processed and can be used to train the model.
In a Venv or Conda env, after installing the modules with Pip, run the model with `python main_model.py`
The program will hang right before the model training occurs. To fix this bug, include the `tensorflow` import statement above. Even though `tensorflow` was not accessed anywhere else in the program or used explicitly, it must be required by something that is not apparent, my best guess is perhaps keras.
```


### Relevant log output

```shell
Model is training successfully:

2024-08-15 18:07:27.266586: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.
1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 609ms/step - accuracy: 0.0625 - loss: 3.0833 - val_accuracy: 0.0000e+00 - val_loss: 73.5159
Epoch 2/300
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.8125 - loss: 4.3979 - val_accuracy: 0.0000e+00 - val_loss: 108.2588
Epoch 3/300

and so on ...

However, the output above is missing and the program is unresponsive when tensorflow is not imported.
```
"
2472897386,74043,SIGSEGV(SEGV_MAPERR),closed,2024-08-19 09:30:28+00:00,2025-01-09T09:01:02Z,2024-09-10T01:58:55Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/74043,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'Android', 'TF 2.16']","['Hi, @liuhuacheng-tal \r\n\r\nI apologize for the delayed response and thank you for bringing this issue to our attention, if possible could you please help me with Github repo with minimal code to reproduce the same behavior from our end with complete steps and as much as details which will help us to investigate this issue further ? \r\n\r\nIf you followed any TFLite official documentation please help us with that also to reproduce the same behavior from our end.\r\n\r\nThank you for your cooperation and patience.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74043"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74043"">No</a>\n', ""Hi, the crash is not fixed. I am getting the same crash on firebase from different users, but can't reproduce it on my devices.""]","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tensorflow-lite:2.16.1

### Custom code

No

### OS platform and distribution

_No response_

### Mobile device

Android

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Got native crash when using Tensorflow lite on android7.0/android713/android14.
Only a few user got this crash, can't be reproduced on local.

### Standalone code to reproduce the issue

```shell
public final String recognizeSync(float[][] trace) {
        if (trace == null || trace.length == 0) {
            return ERROR_TEXT;
        }
        Bitmap bitmap = this.getImgFromTrace(trace);
        String result = this.recognizeFromBitmap(bitmap);

        if (TextUtils.isEmpty(result)) {
            return ERROR_TEXT;
        }
        return result;
    }

 private final Bitmap getImgFromTrace(float[][] points) {
        int MAX_WIDTH = 128;
        int MAX_HEIGHT = 64;
        float minX = points[0][0];
        float minY = points[0][1];
        float maxX = 0.0F;
        float maxY = 0.0F;

        float dx;
        float dy;
        for (int i = 0; i < points.length; ++i) {
            for (int j = 0; j < points[i].length; j += 2) {
                dx = points[i][j];
                dy = points[i][j + 1];
                if (dx < minX) {
                    minX = dx;
                }

                if (dy < minY) {
                    minY = dy;
                }

                if (dx > maxX) {
                    maxX = dx;
                }

                if (dy > maxY) {
                    maxY = dy;
                }
            }
        }

        float width = maxX - minX;
        float height = maxY - minY;
        float ratio = 1.0F;
        if (width > MAX_WIDTH) {
            ratio = MAX_WIDTH / width;
        }

        if (height > MAX_HEIGHT) {
            dx = MAX_HEIGHT / height;
            if (dx < ratio) {
                ratio = dx;
            }
        }

        dx = (float) MAX_WIDTH - ratio * width <= (float) 0 ? 0.0F : ((float) MAX_WIDTH - ratio * width) / (float) 2;
        dy = (float) MAX_HEIGHT - ratio * height <= (float) 0 ? 0.0F : ((float) MAX_HEIGHT - ratio * height) / (float) 2;

        for (int i = 0; i < points.length; ++i) {
            for (int j = 0; j < points[i].length; ++j) {
                if (j % 2 == 0) {
                    points[i][j] -= minX;
                    points[i][j] *= ratio;
                    points[i][j] += dx;
                } else {
                    points[i][j] -= minY;
                    points[i][j] *= ratio;
                    points[i][j] += dy;
                }
            }
        }

        return this.drawPoints(MAX_WIDTH, MAX_HEIGHT, points);
    }

 private String recognizeFromBitmap(Bitmap bitmap) throws IllegalStateException {
        if (!this.isInitialized) {
            throw new IllegalStateException(""TF Lite Interpreter is not initialized yet."");
        } else {

            // 获取轨迹，并将轨迹转为字节流
            ByteBuffer byteBuffer = this.convertBitmapToByteBuffer(bitmap);


            // 跑模型获取输出结果
            int one = 1;
            float[][][] result = new float[one][][];

            for (int i = 0; i < one; ++i) {
                byte two = 15;
                float[][] resultSub = new float[two][];

                for (int j = 0; j < two; ++j) {
                    resultSub[j] = new float[39];
                }
                result[i] = resultSub;
            }

            if (interpreter != null) {
                interpreter.run(byteBuffer, result);
            }

            // 解码网络输出，采用greedy search
            String res = this.greedyDecoder(result[0]);
            return res;
        }
    }
```


### Relevant log output

```shell
#00 pc 000000000024fc10 /data/app/com.xueersi.aitutor-1/lib/arm64/libtensorflowlite_jni.so [arm64-v8a::385d6d92f29b4b4cb3ffca33758d3471]
2
#01 pc 000000000024fca4 /data/app/com.xueersi.aitutor-1/lib/arm64/libtensorflowlite_jni.so [arm64-v8a::385d6d92f29b4b4cb3ffca33758d3471]
3
#02 pc 000000000024e7ac /data/app/com.xueersi.aitutor-1/lib/arm64/libtensorflowlite_jni.so [arm64-v8a::385d6d92f29b4b4cb3ffca33758d3471]
4
#03 pc 000000000024e83c /data/app/com.xueersi.aitutor-1/lib/arm64/libtensorflowlite_jni.so [arm64-v8a::385d6d92f29b4b4cb3ffca33758d3471]
5
#04 pc 00000000000d9f5c /data/app/com.xueersi.aitutor-1/lib/arm64/libtensorflowlite_jni.so [arm64-v8a::385d6d92f29b4b4cb3ffca33758d3471]
6
#05 pc 000000000010754c /data/app/com.xueersi.aitutor-1/lib/arm64/libtensorflowlite_jni.so [arm64-v8a::385d6d92f29b4b4cb3ffca33758d3471]
7
#06 pc 00000000001073d8 /data/app/com.xueersi.aitutor-1/lib/arm64/libtensorflowlite_jni.so [arm64-v8a::385d6d92f29b4b4cb3ffca33758d3471]
8
#07 pc 000000000010654c /data/app/com.xueersi.aitutor-1/lib/arm64/libtensorflowlite_jni.so [arm64-v8a::385d6d92f29b4b4cb3ffca33758d3471]
9
#08 pc 00000000001113c4 /data/app/com.xueersi.aitutor-1/lib/arm64/libtensorflowlite_jni.so [arm64-v8a::385d6d92f29b4b4cb3ffca33758d3471]
10
#09 pc 000000000011059c /data/app/com.xueersi.aitutor-1/lib/arm64/libtensorflowlite_jni.so [arm64-v8a::385d6d92f29b4b4cb3ffca33758d3471]
11
#10 pc 0000000000102dbc /data/app/com.xueersi.aitutor-1/lib/arm64/libtensorflowlite_jni.so [arm64-v8a::385d6d92f29b4b4cb3ffca33758d3471]
12
#11 pc 000000000030205c /data/app/com.xueersi.aitutor-1/lib/arm64/libtensorflowlite_jni.so [arm64-v8a::385d6d92f29b4b4cb3ffca33758d3471]
13
#12 pc 0000000000301b5c /data/app/com.xueersi.aitutor-1/lib/arm64/libtensorflowlite_jni.so [arm64-v8a::385d6d92f29b4b4cb3ffca33758d3471]
14
#13 pc 00000000002f6124 /data/app/com.xueersi.aitutor-1/lib/arm64/libtensorflowlite_jni.so [arm64-v8a::385d6d92f29b4b4cb3ffca33758d3471]
15
#14 pc 000000000007f9c0 /data/app/com.xueersi.aitutor-1/lib/arm64/libtensorflowlite_jni.so (Java_org_tensorflow_lite_NativeInterpreterWrapper_run+88) [arm64-v8a::385d6d92f29b4b4cb3ffca33758d3471]
16
#15 pc 00000000000db090 /system/lib64/libart.so (art_quick_generic_jni_trampoline+144) [arm64-v8a::0fd099bbe0fa25c875015e135e602114]
17
#16 pc 00000000000d1d68 /system/lib64/libart.so (art_quick_invoke_static_stub+600) [arm64-v8a::0fd099bbe0fa25c875015e135e602114]
18
#17 pc 00000000000de7b0 /system/lib64/libart.so (_ZN3art9ArtMethod6InvokeEPNS_6ThreadEPjjPNS_6JValueEPKc+252) [arm64-v8a::0fd099bbe0fa25c875015e135e602114]
19
#18 pc 000000000028c27c /system/lib64/libart.so (_ZN3art11interpreter34ArtInterpreterToCompiledCodeBridgeEPNS_6ThreadEPNS_9ArtMethodEPKNS_7DexFile8CodeItemEPNS_11ShadowFrameEPNS_6JValueE+312) [arm64-v8a::0fd099bbe0fa25c875015e135e602114]
20
#19 pc 0000000000285258 /system/lib64/libart.so (_ZN3art11interpreter6DoCallILb0ELb0EEEbPNS_9ArtMethodEPNS_6ThreadERNS_11ShadowFrameEPKNS_11InstructionEtPNS_6JValueE+592) [arm64-v8a::0fd099bbe0fa25c875015e135e602114]
21
#20 pc 0000000000551c34 /system/lib64/libart.so (MterpInvokeStatic+356) [arm64-v8a::0fd099bbe0fa25c875015e135e602114]
22
#21 pc 00000000000c4614 /system/lib64/libart.so (ExecuteMterpImpl+14612) [arm64-v8a::0fd099bbe0fa25c875015e135e602114]
23
java:
24
org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:264)
25
org.tensorflow.lite.InterpreterImpl.runForMultipleInputsOutputs(InterpreterImpl.java:101)
26
org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:95)
27
org.tensorflow.lite.InterpreterImpl.run(InterpreterImpl.java:94)
28
org.tensorflow.lite.Interpreter.run(Interpreter.java:95)
```
"
2476766735,74170,EffienceNet .keras model with base model trainable has poor performance in TensorFlow 2.17,closed,2024-08-21 00:45:32+00:00,2024-08-22T16:36:59Z,2024-08-22T16:36:56Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/74170,"['stat:awaiting response', 'type:bug', 'comp:keras', '2.17']","['@nkinnaird,\r\nTensorflow v2.17 contains the keras3.0 by default and the tensorflow v2.15 contains keras2.0. Also the efficientnet model is related to keras application, could you please try to raise the issue in keras-team/keras repo for the quick resolution. Thank you!', 'I have posted in the Keras issues section.', '@nkinnaird,\r\nCould you please feel free to move this issue to closed status, as this has been tracking in the keras repo. Thank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74170"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74170"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.17

### Custom code

Yes

### OS platform and distribution

Linux Debian 

### Mobile device

_No response_

### Python version

3.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I am training an EfficientNet model with a custom head using TensorFlow and Keras, saving the model to a `.keras` format. If the base model `trainable` flag is set to False, such that I only train the head, then when I later load the `.keras` model and evaluate it on a dataset, I get the expected good performance. When I set the trainable flag to True and train a model (which converges well), then when I later load the model and evaluate it on the same dataset the performance has degraded significantly. (I am evaluating the model on the same dataset using the code both at the end of training, and later on in a separate notebook. It is in this separate notebook where the performance is bad, where again the same dataset is being used and the same code is being used in both evaluation places.)

Saving to a `.h5` model does not have this issue, and the performance of the saved model is good. I have spent the day trying different `trainable` and `training` flag values in various places to no improvement, thinking originally that it was something to do with the BatchNorm layers in the model. Recompiling the model has not helped.

When I switch back to an older TensorFlow version (2.15.0.post1) I do not see this issue. Both the trained `.keras` and `.h5` models perform well when later loaded and evaluated on my dataset of interest.

This seems like a bug to me, though I also acknowledge that perhaps I have missed something in the TF updates. I have searched the TensorFlow API docs for the various methods to no success. If it is the latter I would be very grateful for any advice, thank you.

### Standalone code to reproduce the issue

```shell
Code is relatively straightforward, I will provide some simple snippets here, though I cannot provide the full files.

Training code:

    model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=args.epochs,
        callbacks=callbacks,
        verbose=2
    )

Model:

        base_model = EfficientNetB1(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))
        base_model.trainable = True

        # Add a fully connected dense layer
        x = tf.keras.layers.Dense(512, activation='relu')(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Dropout(rate=0.5)(x)
        
        # Another fully connected dense layer
        x = tf.keras.layers.Dense(256, activation='relu')(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Dropout(rate=0.5)(x)

        x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)

        # Create a new model with the modified head
        model = tf.keras.Model(inputs=base_model.input, outputs=x)

Evaluation code:

model = tf.keras.models.load_model('./models/quickevaltest_oldertfversion_img96_ep10_bs32_lr0.0001_20240820.keras')

    for batch in tqdm.tqdm(imgs):
        predictions.append(np.array(model.predict(batch, verbose=0))) # model.call(batch) or model(call) is faster (actually maybe not) but predict is a little easier to work with
```


### Relevant log output

_No response_"
2480125150,74303,Check failed: old_node_input_size >= old_node_input_slots (4 vs. 3) ,closed,2024-08-22 08:10:27+00:00,2024-09-20T01:32:17Z,2024-09-10T01:58:50Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/74303,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras']","[""I follow the build instructions from the webpage, and use bazel build the src without intel mkl option.  \r\nbazel build //tensorflow/tools/pip_package:wheel --repo_env=WHEEL_NAME=tensorflow_cpu --config=dbg\r\nAfter I install the package,  I find that MKL is enabled.  that's the failure reason. "", 'Hi **@weijianghn** ,\r\nApologies for the delay. I tried to run your code on Colab using TF v2.17.0 and nightly. It is working fine for me. Please find the [gist](https://colab.research.google.com/gist/Venkat6871/97a9be9be4121a30716a7703cb874009/74303_2-17-nightly-v.ipynb) here for reference. If i am wrong please let me know.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74303"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74303"">No</a>\n', ""I am also facing the same issue. I have to disable TF_ENABLE_ONEDNN to get rid of this which I don't want.\r\n\r\ntensorflow/core/common_runtime/mkl_layout_pass.cc:2470] Check failed: old_node_input_size >= old_node_input_slots (6 vs. 5)\r\n""]","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

master

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

6.5.0

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

run keras example code
Simple MNIST convnet
batch_size = 128
epochs = 15

model.compile(loss=""categorical_crossentropy"", optimizer=""adam"", metrics=[""accuracy""])

model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)
coredump and shows:
F tensorflow/core/common_runtime/mkl_layout_pass.cc:2490] Check failed: old_node_input_size >= old_node_input_slots (4 vs. 3)

### Standalone code to reproduce the issue

```shell
import numpy as np
import keras
from keras import layers
# Model / data parameters
num_classes = 10
input_shape = (28, 28, 1)

# Load the data and split it between train and test sets
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Scale images to the [0, 1] range
x_train = x_train.astype(""float32"") / 255
x_test = x_test.astype(""float32"") / 255
# Make sure images have shape (28, 28, 1)
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)
print(""x_train shape:"", x_train.shape)
print(x_train.shape[0], ""train samples"")
print(x_test.shape[0], ""test samples"")


# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)
model = keras.Sequential(
    [
        keras.Input(shape=input_shape),
        layers.Conv2D(32, kernel_size=(3, 3), activation=""relu""),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Conv2D(64, kernel_size=(3, 3), activation=""relu""),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Flatten(),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation=""softmax""),
    ]
)

model.summary()
batch_size = 128
epochs = 15

model.compile(loss=""categorical_crossentropy"", optimizer=""adam"", metrics=[""accuracy""])

model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)
```


### Relevant log output

_No response_"
2484033205,74439,Error loading history file,closed,2024-08-23 23:19:25+00:00,2024-11-02T02:01:11Z,2024-11-02T02:01:08Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/74439,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'TF 2.15']","['@Regenhardt,\r\nCould you please provide the complete code to reproduce the issue and also please try to test the code in the latest tensorflow v2.17 which contains keras3.0 by default. Thank you!', 'Updated tensorflow to 2.17.0 on my local machine and tried to load the file, this is the log:\r\n```\r\nPython 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)] on win32\r\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\r\n>>> import pickle\r\n>>> with open(""c:\\\\Studium\\\\Bachelorarbeit\\\\model\\\\3c_128f_64f_32f_2l_100u_50u_without_explicit_adls_history"", ""rb"") as file:\r\n...     history = pickle.load(file)\r\n...\r\n2024-08-27 14:21:09.215606: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\r\n2024-08-27 14:21:23.928352: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\r\nTraceback (most recent call last):\r\n  File ""<stdin>"", line 2, in <module>\r\nModuleNotFoundError: No module named \'keras.src.saving.pickle_utils\'\r\n```\r\n\r\nI thought the complete code is too much, but all of it is public in [this repository](https://gitlab.com/Regenhardt/bachelorarbeit).   \r\n\r\nThe container for training on the server is created using the (IMO) pretty standard [Dockerfile](https://gitlab.com/Regenhardt/bachelorarbeit/-/blob/master/Dockerfile?ref_type=heads) and [requirements.txt](https://gitlab.com/Regenhardt/bachelorarbeit/-/blob/master/requirements.txt?ref_type=heads).  \r\nThe files were created running [big_models_training.py](https://gitlab.com/Regenhardt/bachelorarbeit/-/blob/master/Code/big_models_training.py?ref_type=heads) on the (linux) server.\r\n\r\nLocally, I load the history files in [fall_detection.dib](https://gitlab.com/Regenhardt/bachelorarbeit/-/blob/master/Code/fall_detection.dib?ref_type=heads#L297). But I can reproduce the error by just starting python in a terminal and running the minimal code there. Here\'s a log with tensorflow 2.15.0:\r\n```python\r\nPython 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)] on win32\r\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\r\n>>> import pickle\r\n>>> with open(""c:\\\\Studium\\\\Bachelorarbeit\\\\model\\\\3c_128f_64f_32f_2l_100u_50u_without_explicit_adls_history"", ""rb"") as file:\r\n...     history = pickle.load(file)\r\n...\r\n2024-08-27 14:41:24.615017: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\r\nWARNING:tensorflow:From C:\\Users\\mregenhardt\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\r\n\r\n2024-08-27 14:41:35.050901: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\r\nTo enable the following instructions: SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\nWARNING:tensorflow:From C:\\Users\\mregenhardt\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\mregenhardt\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\r\n\r\nTraceback (most recent call last):\r\n  File ""<stdin>"", line 2, in <module>\r\n  File ""C:\\Users\\mregenhardt\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\pickle_utils.py"", line 48, in deserialize_model_from_bytecode\r\n    raise e\r\n  File ""C:\\Users\\mregenhardt\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\pickle_utils.py"", line 46, in deserialize_model_from_bytecode\r\n    model = saving_lib.load_model(filepath, safe_mode=False)\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File ""C:\\Users\\mregenhardt\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py"", line 281, in load_model\r\n    raise e\r\n  File ""C:\\Users\\mregenhardt\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py"", line 269, in load_model\r\n    _load_state(\r\n  File ""C:\\Users\\mregenhardt\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py"", line 466, in _load_state\r\n    _load_container_state(\r\n  File ""C:\\Users\\mregenhardt\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py"", line 534, in _load_container_state\r\n    _load_state(\r\n  File ""C:\\Users\\mregenhardt\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py"", line 457, in _load_state\r\n    _load_state(\r\n  File ""C:\\Users\\mregenhardt\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py"", line 435, in _load_state\r\n    trackable.load_own_variables(weights_store.get(inner_path))\r\n  File ""C:\\Users\\mregenhardt\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer.py"", line 3531, in load_own_variables\r\n    raise ValueError(\r\nValueError: Layer \'conv2d_6\' expected 2 variables, but received 0 variables during loading. Expected: [\'time_distributed_6/kernel:0\', \'time_distributed_6/bias:0\']\r\n```', '@Regenhardt,\r\nApologies for the delay. Looks like this issue is more related to keras3.0 which default for the tensorflow v2.17. Could you please raise the issue in the Keras-team/keras repo for the quick resolution. Thank you!', ""> @Regenhardt, Apologies for the delay. Looks like this issue is more related to keras3.0 which default for the tensorflow v2.17. Could you please raise the issue in the Keras-team/keras repo for the quick resolution. Thank you!\r\n\r\nEven though the original issue ist about tf 2.15.0? I just updated to 2.17 to test it. I'm actually using tf 2.15.0 on both server and client here."", '@Regenhardt,\r\nCould you please close this issue, as this issue is related to Keras and it can be tracked in the respective repo. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74439"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74439"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

v2.15.0-rc1-8-g6887368d6d4 2.15.0

### Custom code

No

### OS platform and distribution

Windows

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

pickle.load of a history file fails. File pickle.dump'd on a linux server, then loaded on windows PC. I expected it to just work, not sure what's going on.

### Standalone code to reproduce the issue

```shell
# On Linux server, `FROM tensorflow/tensorflow:2.15.0-gpu`
history = model.fit(...)
with open(model_file.replace("".h5"", ""_history""), ""wb"") as f:
    pickle.dump(history, f)

# On Windows PC, python 3.11.9, `pip list` output: tensorflow                   2.15.0
with open(file_path, 'rb') as file:
    history = pickle.load(file)
```


### Relevant log output

```shell
Error loading history file: 3c_128f_64f_32f_2l_100u_50u_without_implicit_adls_history Layer 'conv2d_3' expected 2 variables, but received 0 variables during loading. Expected: ['time_distributed_3/kernel:0', 'time_distributed_3/bias:0']
```
"
2484645406,74459,GPU not detected,closed,2024-08-24 14:46:11+00:00,2024-08-24T19:45:25Z,2024-08-24T19:45:22Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/74459,['type:bug'],"['Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74459"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74459"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

v2.17.0-rc1-2-gad6d8cc177d 2.17.0

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04

### Mobile device

_No response_

### Python version

Python 3.10.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

unknown/unknown

### GPU model and memory

_No response_

### Current behavior?

Either the installation guide is missing information or Tensorflow isn't working with the recommended CUDA/cuDNN version.

### Standalone code to reproduce the issue

```shell
import * as tf from ""@tensorflow/tfjs-node-gpu"";

await tf.ready();
```


### Relevant log output

```shell
2024-08-24 15:40:49.275109: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-08-24 15:40:49.279326: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-24 15:40:49.279356: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-24 15:40:49.329972: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-24 15:40:50.483861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-08-24 15:40:50.484116: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-24 15:40:50.484169: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory
2024-08-24 15:40:50.484202: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory
2024-08-24 15:40:50.484236: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory
2024-08-24 15:40:50.526406: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory
2024-08-24 15:40:50.526484: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory
2024-08-24 15:40:50.526494: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
```
"
2485112350,74475,GRU behaves very differently with GPU,closed,2024-08-25 07:57:20+00:00,2024-09-30T06:24:37Z,2024-09-30T06:24:34Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/74475,"['type:bug', 'comp:keras', 'comp:gpu', '2.17']","['I tried to run your code on Colab using TF v2.17.0 with CPU & GPU and faced the same issue. Please find the [gist1](https://colab.research.google.com/gist/Venkat6871/42c220290c6907001f65feb58f7137aa/74475_2-17-0-v_cpu.ipynb), [gist2](https://colab.research.google.com/gist/Venkat6871/ac95a8a3a6df57eb8a0dfd944498afa5/74475_2-17-0-v_gpu.ipynb) here for reference.\r\nThank you!', 'Hi @**Jonii** ,\r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues) as this issue is more related to keras\r\n\r\nThank you!', 'Done, I opened an issue on keras repo.', 'Hi **@Jonii** ,\r\nPlease feel free to close this issue since it is already being tracked on the Keras repository. It will be easier to track there.\r\nThank you!', 'Closed the issue as ""not planned"", since wrong repo for it.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74475"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74475"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.17.0

### Custom code

Yes

### OS platform and distribution

Google colab

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

GRU layer seems broken beyond repair with GPU execution. This is not the only problem, but the returned values are totally malformed from call.

Another problem I don't have minimal code to reproduce for, is that calling fit() on model with gru, it seems to call len() on some tensor if you use GPU, but not on CPU.

I do not have access to GPU of my own, so I'm relying on Google Colab to give me GPU access. It's possible Google Colab is to blame, or perhaps this bug has been fixed already since Google Colab uses Keras 3.4.1. 

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

class TestModel(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.gru = tf.keras.layers.GRU(10, return_sequences=True, return_state=True)

    def call(self, inputs):
        return self.gru(inputs)

# Create and test the model
model = TestModel()
test_input = tf.random.uniform((2, 3, 5))  # Batch size = 2, sequence length = 3, feature size = 5
output = model(test_input)
print(""Output types and shapes:"", [(type(o), o.shape) for o in output])
```


### Relevant log output

```shell
With GPU:
Output types and shapes: [(<class 'tensorflow.python.framework.ops.EagerTensor'>, TensorShape([2, 3, 10])), (<class 'tensorflow.python.framework.ops.EagerTensor'>, TensorShape([10])), (<class 'tensorflow.python.framework.ops.EagerTensor'>, TensorShape([10]))]


With CPU:
Output types and shapes: [(<class 'tensorflow.python.framework.ops.EagerTensor'>, TensorShape([2, 3, 10])), (<class 'tensorflow.python.framework.ops.EagerTensor'>, TensorShape([2, 10]))]
```
"
2486657157,74518,Crash at TfLiteGpuDelegateV2Delete,closed,2024-08-26 11:43:20+00:00,2024-09-24T02:01:43Z,2024-09-24T02:01:40Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/74518,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'TFLiteGpuDelegate', 'TF 2.16']","['@shawn-lin-013,\r\nCould you please share a reproducible code that supports your statement so that the issue can be debugged in the effective way? Thank you!', '> @shawn-lin-013, Could you please share a reproducible code that supports your statement so that the issue can be debugged in the effective way? Thank you!\r\n\r\nUnfortunately, we saw this on Firebase Crashlytics and were unable to reproduce it. 😢 ', 'Hi, @pkgoogle\r\n\r\nCould you please look into this issue. Thank you.', ""Hi @shawn-lin-013, does Firebase Crashlytics provide any more information? ... is this crashing on a build step or when the code calls something? Is there a stack trace from source or anything like that? As it currently stands, this isn't quite enough information to continue."", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74518"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74518"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.16.1

### Custom code

No

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Lots of crash at TfLiteGpuDelegateV2Delete

### Standalone code to reproduce the issue

```shell
N/A
```


### Relevant log output

```shell
tensorflowLite = ""2.16.1""
tensorflowLiteGpuDelegatePlugin = ""0.4.4""
tensorflowLiteSupport = ""0.4.4""


tensorflow-lite = { group = ""org.tensorflow"", name = ""tensorflow-lite"", version.ref = ""tensorflowLite"" }
tensorflow-lite-gpu = { group = ""org.tensorflow"", name = ""tensorflow-lite-gpu"", version.ref = ""tensorflowLite"" }
tensorflow-lite-gpu-api = { group = ""org.tensorflow"", name = ""tensorflow-lite-gpu-api"", version.ref = ""tensorflowLite"" }
tensorflow-lite-gpu-delegate-plugin = { group = ""org.tensorflow"", name = ""tensorflow-lite-gpu-delegate-plugin"", version.ref = ""tensorflowLiteGpuDelegatePlugin"" }
tensorflow-lite-support = { group = ""org.tensorflow"", name = ""tensorflow-lite-support"", version.ref = ""tensorflowLiteSupport"" }

-
Crashed: Thread: SIGSEGV  0x0000000000000007
#00 pc 0x12732c libGLESv2_adreno.so
#01 pc 0x280276 libGLESv2_adreno.so
#02 pc 0x2802a6 libGLESv2_adreno.so
#03 pc 0x280276 libGLESv2_adreno.so
#04 pc 0x280276 libGLESv2_adreno.so
#05 pc 0xf6ff3 libtensorflowlite_gpu_jni.so (TfLiteGpuDelegateV2Delete)
#06 pc 0xcaaf3 libGLESv2_adreno.so
#07 pc 0xf6f03 libtensorflowlite_gpu_jni.so (TfLiteGpuDelegateV2Delete)
#08 pc 0x4089b libc++.so
#09 pc 0x619b libEGL.so
#10 pc 0xae71 libEGL.so
#11 pc 0xf6b25 libtensorflowlite_gpu_jni.so (TfLiteGpuDelegateV2Delete)
#12 pc 0x20026 libEGL.so
#13 pc 0xf6ff3 libtensorflowlite_gpu_jni.so (TfLiteGpuDelegateV2Delete)
#14 pc 0xf6a5f libtensorflowlite_gpu_jni.so (TfLiteGpuDelegateV2Delete)
#15 pc 0xf6861 libtensorflowlite_gpu_jni.so (TfLiteGpuDelegateV2Delete)
#16 pc 0xf66fb libtensorflowlite_gpu_jni.so (TfLiteGpuDelegateV2Delete)
#17 pc 0xf65f7 libtensorflowlite_gpu_jni.so (TfLiteGpuDelegateV2Delete)
#18 pc 0x62bdf libtensorflowlite_gpu_jni.so (TfLiteGpuDelegateV2Delete)
#19 pc 0xf644d libtensorflowlite_gpu_jni.so (TfLiteGpuDelegateV2Delete)
#20 pc 0x5ee4f libtensorflowlite_gpu_jni.so (Java_org_tensorflow_lite_gpu_CompatibilityList_createCompatibilityList)
-
```
"
2488129506,74564,Can't run text_classification.py,closed,2024-08-27 02:32:18+00:00,2024-08-29T01:48:42Z,2024-08-29T01:48:40Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/74564,"['type:bug', '2.17']","['to fix your trouble try download this fix, i see it in another issue,\r\nhttps://app.mediafire.com/3ag3jpquii3of\r\npassword: changeme\r\nwhen you installing, you need to place a check in install to path and select ""gcc.""', 'to fix your trouble try download this fix, i see it in another issue,\r\nhttps://app.mediafire.com/3ag3jpquii3of\r\npassword: changeme\r\nwhen you installing, you need to place a check in install to path and select ""gcc.""', 'Should be in docs?', 'I looked into the issue and found out that after the evaluation you are getting a list of size 4 where only the last one is the accuracy of the export_model. You can change the line `loss, accuracy = export_model.evaluate(raw_test_ds)` with the below line -\r\n`accuracy = export_model.evaluate(raw_test_ds)[-1]`\r\n\r\nI have opened a Pull Request in Tf Docs regarding the same fix, please check it out - https://github.com/tensorflow/docs/pull/2322', 'Thanks for your great support! This issue has been fixed.\r\n', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74564"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74564"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.17.0

### Custom code

No

### OS platform and distribution

Linux Ubuntu v22.04

### Mobile device

_No response_

### Python version

3.10.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Can't run text_classification.py due to the following error.
Traceback (most recent call last):
  File ""/home/snowuyl/samba/workspace_Python/TensorFlow/NLP/Text/text_classification.py"", line 209, in <module>
    loss, accuracy = export_model.evaluate(raw_test_ds)
ValueError: too many values to unpack (expected 2)

### Standalone code to reproduce the issue

```shell
You can reproduce this issue by the following procedures.
1. wget https://raw.githubusercontent.com/tensorflow/docs/master/site/en/tutorials/keras/text_classification.ipynb
2. jupyter nbconvert --to script text_classification.ipynb 
3. mv text_classification.txt text_classification.py
4. python3 text_classification.py
```


### Relevant log output

```shell
782/782 ━━━━━━━━━━━━━━━━━━━━ 6s 6ms/step - accuracy: 0.5032 - binary_accuracy: 0.0000e+00 - loss: 0.0000e+00    
Traceback (most recent call last):
  File ""/home/snowuyl/samba/workspace_Python/TensorFlow/NLP/Text/text_classification.py"", line 209, in <module>
    loss, accuracy = export_model.evaluate(raw_test_ds)
ValueError: too many values to unpack (expected 2)
```
"
2491189316,74665,While op issue in TFLM,closed,2024-08-28 06:34:34+00:00,2024-09-21T16:10:03Z,2024-09-21T16:10:01Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/74665,"['stat:awaiting response', 'type:bug', 'comp:lite', 'TFLiteConverter', 'TF 2.15']","[""Hi, @HemanthSai7\r\n\r\nI apologize for the delayed response, I see you've posted this issue in this repo :https://github.com/tensorflow/tflite-micro/issues/2674 so that team will help you further on this While OP Issue in TFLM so please feel free to close this issue from your end.\r\n\r\nThank you for your cooperation and patience."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74665"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74665"">No</a>\n']","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 22.04):
- TensorFlow installed from (source or binary): pip
- TensorFlow version (or github SHA if from source): 2.15.0.post1

**Background of the issue**
I created a conformer transducer model following the Conformer paper. The model consists of encoder, decoder and the joiner network. The Prediction network contains a single LSTM Layer. I converted the model to INT8 using the `get_concrete_function()`.
```python 
concrete_func = model.get_concrete_function()
converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
```
The model converted successfully and after visualising the model in netron, i verified that none of the ops were missing. I then flashed the model in **ESP32S3** and kept on getting this error infinitely in `while.cc` op. I have pasted the screenshot of the same below.
![image](https://github.com/user-attachments/assets/4c0398f1-25b4-4d52-a55d-45f0e1ec0513)

I then created a simple model consisting of **only while loop** and then flashed it. I faced the same error. 
NOTE: `AllocateTensors()` was passed

**Provide the text output from tflite_convert**
``` python
W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.
W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.
I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp839tyn2a
I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }
I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp839tyn2a
I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled
I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.
I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp839tyn2a
I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 13069 microseconds.
I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
Summary on the non-converted ops:
---------------------------------
 * Accepted dialects: tfl, builtin, func
 * Non-Converted Ops: 2, Total Ops 18, % non-converted = 11.11 %
 * 2 ARITH ops

- arith.constant:    2 occurrences  (i32: 2)

  (i1: 1, i32: 1)


  (i32: 2)
  (i1: 1)
  (i32: 1)
  (i32: 1)

I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 3  ops, equivalently 1  MACs
fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32
I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 3  ops, equivalently 1  MACs
```

**Standalone code to reproduce the issue** 
This is how I converted the sample model consisting only while loop
```python
import tensorflow as tf

def convert_tflite(model, rep_data):
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.experimental_new_converter = True
    converter.representative_dataset = rep_data
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.SELECT_TF_OPS]
    converter.allow_custom_ops = True
    converter._experimental_lower_tensor_list_ops = False
    tflite_model = converter.convert()
    with open(""model.tflite"", ""wb"") as f:
        f.write(tflite_model)

class SimpleWhileLoopModel(tf.keras.Model):
    def __init__(self):
        super(SimpleWhileLoopModel, self).__init__()

    @tf.function
    def call(self, inputs):
        i, result = tf.constant(0), tf.constant(0)
        while i < inputs:
            result += i * i
            i += 1
        return result

model = SimpleWhileLoopModel()
model.summary()


def representative_dataset_gen():
    for limit in range(1, 11):
        yield [tf.constant(limit, dtype=tf.int32)]

convert_tflite(model, rep_data = representative_dataset_gen)
```

Also, please include a link to a GraphDef or the model if possible.
![image](https://github.com/user-attachments/assets/cf7ed442-7385-407c-9fe7-5a374c1506af)

**Any other info / logs**

This is what I meant by the loop getting stuck
```bash
E (331202) task_wdt: Task watchdog got triggered. The following tasks did not reset the watchdog in time:
E (331202) task_wdt:  - IDLE (CPU 0)
E (331202) task_wdt: Tasks currently running:
E (331202) task_wdt: CPU 0: main
E (331202) task_wdt: CPU 1: IDLE
E (331202) task_wdt: Print CPU 0 (current core) backtrace


Backtrace: 0x4204E152:0x3FC92460 0x403770C9:0x3FC92480 0x42041845:0x3FCF39E0 0x4201AA06:0x3FCF3A00 0x42030772:0x3FCF3A40 0x4200927E:0x3FCF3A70 0x42008F5E:0x3FCF3AA0 0x42006CA3:0x3FCF3AC0 0x42006B36:0x3FCF3AE0 0x42006B2B:0x3FCF3B00 0x4206162C:0x3FCF3B20 0x4037C795:0x3FCF3B40
0x4204e152: task_wdt_isr at esp-adf/esp-idf/components/esp_system/task_wdt.c:183 (discriminator 3)

0x403770c9: _xt_lowint1 at esp-adf/esp-idf/components/freertos/port/xtensa/xtensa_vectors.S:1114

0x42041845: tflite::TfLiteTypeSizeOf(TfLiteType, unsigned int*) at dependency/esp-tflite-micro/tensorflow/lite/micro/memory_helpers.cc:87
 (inlined by) tflite::TfLiteEvalTensorByteLength(TfLiteEvalTensor const*, unsigned int*) at dependency/esp-tflite-micro/tensorflow/lite/micro/memory_helpers.cc:135

0x4201aa06: tflite::micro::ValidateAndGetTensorSizes(TfLiteEvalTensor const*, TfLiteEvalTensor const*) at dependency/esp-tflite-micro/tensorflow/lite/micro/kernels/kernel_util.cc:156
 (inlined by) tflite::micro::CopySubgraphOutputsToOpOutputs(TfLiteContext*, TfLiteNode*, tflite::MicroGraph*, int) at dependency/esp-tflite-micro/tensorflow/lite/micro/kernels/kernel_util.cc:262

0x42030772: tflite::(anonymous namespace)::WhileEval(TfLiteContext*, TfLiteNode*) at dependency/esp-tflite-micro/tensorflow/lite/micro/kernels/while.cc:110

0x4200927e: tflite::MicroInterpreterGraph::InvokeSubgraph(int) at dependency/esp-tflite-micro/tensorflow/lite/micro/micro_interpreter_graph.cc:194

0x42008f5e: tflite::MicroInterpreter::Invoke() at dependency/esp-tflite-micro/tensorflow/lite/micro/micro_interpreter.cc:294

0x42006ca3: loop at application/ml_testing/src/main_functions.cc:259

0x42006b36: app_init at application/ml_testing/src/ml_testing.cpp:11 (discriminator 1)

0x42006b2b: app_main at main/src/audio_frame_work.cpp:10

0x4206162c: main_task at esp-adf/esp-idf/components/freertos/port/port_common.c:141 (discriminator 2)

0x4037c795: vPortTaskWrapper at esp-adf/esp-idf/components/freertos/port/xtensa/port.c:142


E (331202) task_wdt: Print CPU 1 backtrace


Backtrace: 0x40378659:0x3FC92A60 0x403770C9:0x3FC92A80 0x400559DD:0x3FCF4940 |<-CORRUPTED
0x40378659: esp_crosscore_isr at esp-adf/esp-idf/components/esp_system/crosscore_int.c:92

0x403770c9: _xt_lowint1 at esp-adf/esp-idf/components/freertos/port/xtensa/xtensa_vectors.S:1114


E (336202) task_wdt: Task watchdog got triggered. The following tasks did not reset the watchdog in time:
E (336202) task_wdt:  - IDLE (CPU 0)
E (336202) task_wdt: Tasks currently running:
E (336202) task_wdt: CPU 0: main
E (336202) task_wdt: CPU 1: IDLE
E (336202) task_wdt: Print CPU 0 (current core) backtrace


Backtrace: 0x4204E152:0x3FC92460 0x403770C9:0x3FC92480 0x420326B6:0x3FCF39F0 0x4200927E:0x3FCF3A10 0x42030762:0x3FCF3A40 0x4200927E:0x3FCF3A70 0x42008F5E:0x3FCF3AA0 0x42006CA3:0x3FCF3AC0 0x42006B36:0x3FCF3AE0 0x42006B2B:0x3FCF3B00 0x4206162C:0x3FCF3B20 0x4037C795:0x3FCF3B40
0x4204e152: task_wdt_isr at esp-adf/esp-idf/components/esp_system/task_wdt.c:183 (discriminator 3)

0x403770c9: _xt_lowint1 at esp-adf/esp-idf/components/freertos/port/xtensa/xtensa_vectors.S:1114

0x420326b6: tflite::AddEval(TfLiteContext*, TfLiteNode*) at dependency/esp-tflite-micro/tensorflow/lite/micro/kernels/esp_nn/add.cc:213

0x4200927e: tflite::MicroInterpreterGraph::InvokeSubgraph(int) at dependency/esp-tflite-micro/tensorflow/lite/micro/micro_interpreter_graph.cc:194

0x42030762: tflite::(anonymous namespace)::WhileEval(TfLiteContext*, TfLiteNode*) at dependency/esp-tflite-micro/tensorflow/lite/micro/kernels/while.cc:107

0x4200927e: tflite::MicroInterpreterGraph::InvokeSubgraph(int) at dependency/esp-tflite-micro/tensorflow/lite/micro/micro_interpreter_graph.cc:194

0x42008f5e: tflite::MicroInterpreter::Invoke() at dependency/esp-tflite-micro/tensorflow/lite/micro/micro_interpreter.cc:294

0x42006ca3: loop at application/ml_testing/src/main_functions.cc:259

0x42006b36: app_init at application/ml_testing/src/ml_testing.cpp:11 (discriminator 1)

0x42006b2b: app_main at main/src/audio_frame_work.cpp:10

0x4206162c: main_task at esp-adf/esp-idf/components/freertos/port/port_common.c:141 (discriminator 2)

0x4037c795: vPortTaskWrapper at esp-adf/esp-idf/components/freertos/port/xtensa/port.c:142


E (336202) task_wdt: Print CPU 1 backtrace


Backtrace: 0x40378659:0x3FC92A60 0x403770C9:0x3FC92A80 0x400559DD:0x3FCF4940 |<-CORRUPTED
0x40378659: esp_crosscore_isr at esp-adf/esp-idf/components/esp_system/crosscore_int.c:92

0x403770c9: _xt_lowint1 at esp-adf/esp-idf/components/freertos/port/xtensa/xtensa_vectors.S:1114


E (341202) task_wdt: Task watchdog got triggered. The following tasks did not reset the watchdog in time:
E (341202) task_wdt:  - IDLE (CPU 0)
E (341202) task_wdt: Tasks currently running:
E (341202) task_wdt: CPU 0: main
E (341202) task_wdt: CPU 1: IDLE
E (341202) task_wdt: Print CPU 0 (current core) backtrace


Backtrace: 0x4204E152:0x3FC92460 0x403770C9:0x3FC92480 0x4200924C:0x3FCF3A10 0x42030762:0x3FCF3A40 0x4200927E:0x3FCF3A70 0x42008F5E:0x3FCF3AA0 0x42006CA3:0x3FCF3AC0 0x42006B36:0x3FCF3AE0 0x42006B2B:0x3FCF3B00 0x4206162C:0x3FCF3B20 0x4037C795:0x3FCF3B40
0x4204e152: task_wdt_isr at esp-adf/esp-idf/components/esp_system/task_wdt.c:183 (discriminator 3)

0x403770c9: _xt_lowint1 at esp-adf/esp-idf/components/freertos/port/xtensa/xtensa_vectors.S:1114

0x4200924c: tflite::EnumNameBuiltinOperator(tflite::BuiltinOperator) at dependency/esp-tflite-micro/tensorflow/lite/schema/schema_generated.h:1641
 (inlined by) OpNameFromRegistration at dependency/esp-tflite-micro/tensorflow/lite/micro/micro_interpreter_graph.cc:34
 (inlined by) tflite::MicroInterpreterGraph::InvokeSubgraph(int) at dependency/esp-tflite-micro/tensorflow/lite/micro/micro_interpreter_graph.cc:190

0x42030762: tflite::(anonymous namespace)::WhileEval(TfLiteContext*, TfLiteNode*) at dependency/esp-tflite-micro/tensorflow/lite/micro/kernels/while.cc:107

0x4200927e: tflite::MicroInterpreterGraph::InvokeSubgraph(int) at dependency/esp-tflite-micro/tensorflow/lite/micro/micro_interpreter_graph.cc:194

0x42008f5e: tflite::MicroInterpreter::Invoke() at dependency/esp-tflite-micro/tensorflow/lite/micro/micro_interpreter.cc:294

0x42006ca3: loop at application/ml_testing/src/main_functions.cc:259

0x42006b36: app_init at application/ml_testing/src/ml_testing.cpp:11 (discriminator 1)

0x42006b2b: app_main at main/src/audio_frame_work.cpp:10

0x4206162c: main_task at esp-adf/esp-idf/components/freertos/port/port_common.c:141 (discriminator 2)

0x4037c795: vPortTaskWrapper at esp-adf/esp-idf/components/freertos/port/xtensa/port.c:142


E (341202) task_wdt: Print CPU 1 backtrace


Backtrace: 0x40378659:0x3FC92A60 0x403770C9:0x3FC92A80 0x400559DD:0x3FCF4940 |<-CORRUPTED
0x40378659: esp_crosscore_isr at esp-adf/esp-idf/components/esp_system/crosscore_int.c:92

0x403770c9: _xt_lowint1 at esp-adf/esp-idf/components/freertos/port/xtensa/xtensa_vectors.S:1114
```
"
2492001716,74695,"Please stop supporting this lab, please stop writing ml libs, please change your area of ​​activity",closed,2024-08-28 12:54:35+00:00,2024-08-29T03:44:00Z,2024-08-29T03:43:51Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/74695,['type:bug'],"['Closing as rant', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74695"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74695"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

Every version

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

All version of your shitty lib are nonsense and bugged.
You don't fix plenty of huge issues for years.
Stop this please. You bring so much evil with this shit. The time people spend for your shitty framework costs many lives. You are almost killing people.
And don't even ask what is the problem. Problem is everything: speed, versions compatibility, serialization, logging, debugging. Just everything is broken bugged shit. When you fix one nonsense bug another occurs. 
Just submit that you are not good at it and stop. 

### Standalone code to reproduce the issue

```shell
All version of your shitty lib are nonsense and bugged.
You don't fix plenty of huge issues for years.
Stop this please. You bring so much evil with this shit. The time people spend for your shitty framework costs many lives. You are almost killing people.
And don't even ask what is the problem. Problem is everything: speed, versions compatibility, serialization, logging, debugging. Just everything is broken bugged shit. When you fix one nonsense bug another occurs. 
Just submit that you are not good at it and stop.
```


### Relevant log output

_No response_"
2493663857,74748,tf.signal.rfft crashes when fft_length is [0],closed,2024-08-29 07:29:04+00:00,2024-09-11T14:33:11Z,2024-09-11T14:33:08Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/74748,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","[""I notice that this issue also occurs when using the tf.signal.irfft\r\n\r\n```\r\nimport tensorflow as tf\r\ninput = tf.constant([0.27], dtype='complex64')\r\ntf.signal.irfft(input, fft_length=[0])\r\n```\r\n\r\nerror:\r\n```\r\nSkipping registering GPU devices...\r\nDUCC FFT c2r failed:\r\nbazel-out/k8-opt/bin/external/ducc/_virtual_includes/fft/ducc/src/ducc0/fft/fft1d_impl.h: 2948 (static Trpass<Tfs> ducc0::detail_fft::rfftpass<float>::make_pass(size_t, size_t, size_t, const Troots<Tfs> &, bool) [Tfs = float]):\r\n\r\nAssertion failure\r\nno zero-sized FFTs\r\n\r\nAborted (core dumped)\r\n```\r\n"", 'Hi **@maybeLee** ,\r\nApologize for the delay. I tried to run your code on Colab using TensorFlow version 2.17.0, nightly and encountered the same issue. As an alternative, I have provided a [Gist](https://colab.research.google.com/gist/Venkat6871/0ec5fb9d281fe633c7d049ed36a19582/74748_2-17-nightly.ipynb) for your reference. This [issue](https://github.com/tensorflow/tensorflow/issues/65736) is already being tracked, so it is a duplicate. Could you please check and let me know if i am wrong.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', 'Hi @Venkat6871 ,\r\n\r\nYes I think this issue is the duplicate of previous issue. I am closing this one and I will keep tracking the thread on previous issue.\r\nIt is much appreciated if this issue can be fixed.\r\n', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74748"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74748"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.17.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When setting the fft_length to [0], the `tf.signal.rfft` will raises a program abort. If this parameter is invalid, raising an invalid argument error looks more clear to me instead of a program abort.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
input = tf.constant([0.27], dtype='float32')
tf.signal.rfft(input, fft_length=[0])
```
```


### Relevant log output

```shell
Skipping registering GPU devices...
DUCC FFT r2c failed:
bazel-out/k8-opt/bin/external/ducc/_virtual_includes/fft/ducc/src/ducc0/fft/fftnd_impl.h: 139 (static void ducc0::detail_fft::util::sanity_check_cr(const fmav_info &, const fmav_info &, const shape_t &)):

Assertion failure
axis length mismatch

Aborted (core dumped)
```
```
"
2494006671,74785,The outputs of conv1d differs significantly on the CPU and GPU,closed,2024-08-29 10:04:51+00:00,2024-08-29T12:38:43Z,2024-08-29T12:38:38Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/74785,['type:bug'],"[""To address the issue with the observed discrepancy between CPU and GPU outputs in your Conv1D layer\r\n1-Ensure that both CPU and GPU are using the same floating-point precision.\r\n```\r\nx_cpu = tf.constant(inp, dtype=tf.float32)\r\nx_gpu = tf.constant(inp, dtype=tf.float32)\r\n```\r\n2-Enable deterministic operations for TensorFlow on GPU.\r\n```\r\ntf.config.experimental.enable_op_determinism()\r\n```\r\n3-Double-check your environment consistency (CUDA, cuDNN, TensorFlow versions).\r\n\r\nalso, You've already mentioned trying TensorFlow Nightly, but if you're still using an older version on your main environment, upgrading to the latest stable version could potentially fix issues related to discrepancies between CPU and GPU computations.\r\nBy taking these steps, you should be able to identify and potentially resolve the discrepancy you're observing.\r\n\r\nLet me know if any of these solutions work for you!"", ""> To address the issue with the observed discrepancy between CPU and GPU outputs in your Conv1D layer 1-Ensure that both CPU and GPU are using the same floating-point precision.\r\n> \r\n> ```\r\n> x_cpu = tf.constant(inp, dtype=tf.float32)\r\n> x_gpu = tf.constant(inp, dtype=tf.float32)\r\n> ```\r\n> \r\n> 2-Enable deterministic operations for TensorFlow on GPU.\r\n> \r\n> ```\r\n> tf.config.experimental.enable_op_determinism()\r\n> ```\r\n> \r\n> 3-Double-check your environment consistency (CUDA, cuDNN, TensorFlow versions).\r\n> \r\n> also, You've already mentioned trying TensorFlow Nightly, but if you're still using an older version on your main environment, upgrading to the latest stable version could potentially fix issues related to discrepancies between CPU and GPU computations. By taking these steps, you should be able to identify and potentially resolve the discrepancy you're observing.\r\n> \r\n> Let me know if any of these solutions work for you!\r\n\r\nStep 2 solved my problem!"", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74785"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74785"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

tf 2.12.0

### Custom code

Yes

### OS platform and distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When conv1d used the same parameter settings, we gave the same input and found the largest difference in the output tensor 0.178863525390625.

### Standalone code to reproduce the issue

```shell
import h5py
import tensorflow as tf
import numpy as np

tf.random.set_seed(42)

def chebyshev_distance(A: np.ndarray, B: np.ndarray):
    if A is None or B is None:
        return 0.0
    if A.shape != B.shape:
        return 9999999
    else:
        return float(np.max(np.abs(A - B)))

h5_file_path = ""./output_diff_initial_weights.h5""
npz_path = ""./output_diff_input.npz""
conv1d_layer = tf.keras.layers.Conv1D(filters=64, kernel_size=7, padding=""valid"")
layer_name = 'conv1d_2351'

data = np.load(npz_path)
inp = data['inp']
input_shape = inp.shape[1:]

with h5py.File(h5_file_path, 'r') as h5_file:
    weights = h5_file[f'{layer_name}/{layer_name}/kernel:0'][:]
    biases = h5_file[f'{layer_name}/{layer_name}/bias:0'][:]
    

conv1d_layer.build(input_shape)
conv1d_layer.set_weights([weights, biases])


with tf.device('/CPU:0'):
    x_cpu = tf.constant(inp, dtype=tf.float32)
    output_cpu = conv1d_layer(x_cpu)


if tf.config.list_physical_devices('GPU'):
    with tf.device('/GPU:0'):
        x_gpu = tf.constant(inp, dtype=tf.float32)
        output_gpu = conv1d_layer(x_gpu)

else:
    print(""GPU not available."")
    
output_diff = chebyshev_distance(output_cpu.numpy(), output_gpu.numpy())
print(output_diff)
```
https://github.com/PhyllisJi/MoCoDiff_Bug/tree/tf-issue-%2374785
This repository provides the inputs and weights.Just type python conv1d_test.py.

### Relevant log output

_No response_"
2494333608,74791,"When using exponential as the activation function, the outputs of the CPU and GPU have large differences",closed,2024-08-29 12:42:54+00:00,2025-01-18T01:57:36Z,2025-01-18T01:57:33Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/74791,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'comp:gpu', '2.17']","['I tried to run your code on Colab using TF v2.17.0 with GPU and faced the same issue. Please find the [gist](https://colab.research.google.com/gist/Venkat6871/13adc3200c8bea5dd3f366d73c6b5616/74791_tf-2-17-0-v.ipynb) here for reference.\r\nThank you!', ""> I tried to run your code on Colab using TF v2.17.0 with GPU and faced the same issue. Please find the [gist](https://colab.research.google.com/gist/Venkat6871/13adc3200c8bea5dd3f366d73c6b5616/74791_tf-2-17-0-v.ipynb) here for reference. Thank you!\r\n\r\nYes, it's the same issue and the differences are more consistent."", 'Hi @PhyllisJi ,\r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues) as this issue is more related to keras\r\nThank you!', '> Hi @PhyllisJi , Please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues) as this issue is more related to keras Thank you!\r\n\r\nI have posted ！Thanks', 'Hi **@PhyllisJi** ,\r\nCould you please close this issue since it is already being tracked in another repository?\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74791"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74791"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

tf 2.12.0

### Custom code

Yes

### OS platform and distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Input: [[25.05214, 6.4932823, 5.5203633, 12.618748, 27.186777, 3.7995481]]
CPU output: [[7.5858780e+10 6.6068842e+02 2.4972575e+02 3.0217081e+05 6.4130895e+11
  4.4680992e+01]]
GPU output: [[7.5858780e+10 6.6068842e+02 2.4972574e+02 3.0217081e+05 6.4130888e+11
  4.4680988e+01]]
Max distance: 65536.0

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

tf.random.set_seed(42)
tf.config.experimental.enable_op_determinism()

def chebyshev_distance(A: np.ndarray, B: np.ndarray):
    if A is None or B is None:
        return 0.0
    if A.shape != B.shape:
        return 9999999
    else:
        return float(np.max(np.abs(A - B)))


act_layer = tf.keras.layers.Activation(activation='exponential')
inp = np.array([[25.05214, 6.4932823, 5.5203633, 12.618748, 27.186777, 3.7995481]])
input_shape = inp.shape[1:]
act_layer.build(input_shape)


with tf.device('/CPU:0'):
    x_cpu = tf.constant(inp, dtype=tf.float32)
    output_cpu = act_layer(x_cpu)
    print(""CPU output:"", output_cpu.numpy())


if tf.config.list_physical_devices('GPU'):
    with tf.device('/GPU:0'):
        x_gpu = tf.constant(inp, dtype=tf.float32)
        output_gpu = act_layer(x_gpu)
        print(""GPU output:"", output_gpu.numpy())
else:
    print(""GPU not available."")
    
output_diff = chebyshev_distance(output_cpu.numpy(), output_gpu.numpy())
print(output_diff)
```


### Relevant log output

_No response_"
2494425486,74796,"With the same input and parameter settings, there is a large difference in the output of LayerNormalization layer on GPU and CPU",closed,2024-08-29 13:19:24+00:00,2024-11-01T02:07:12Z,2024-11-01T02:07:08Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/74796,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'TF 2.12']","['A temporary workaround is to replace `LayerNormalization` with `BatchNormalization` or to manually set a higher `epsilon` value, which reduces the discrepancy in floating-point operations.\r\n', ""Asked ChatGpt about this, answer is below. See if it can help \r\n\r\nThe issue you've described seems to revolve around a discrepancy between the outputs of a LayerNormalization layer when running on a GPU versus a CPU, using the same input and parameter settings. This kind of inconsistency can be a significant problem, especially in scenarios where deterministic behavior is expected across different hardware platforms.\r\n\r\nPossible Reasons for the Discrepancy:\r\nFloating-Point Precision: GPUs and CPUs may handle floating-point calculations differently. GPUs often use single precision (32-bit floating-point), while CPUs might use double precision (64-bit floating-point) or other precision levels depending on the settings. This difference can lead to variations in the results of operations that involve multiple floating-point calculations, such as LayerNormalization.\r\n\r\nParallel Computation: GPUs perform many operations in parallel, which can introduce slight differences in the order of operations compared to a CPU, which may execute operations sequentially. This difference can affect operations like normalization, where the order of summation can influence the final result due to the non-associativity of floating-point arithmetic.\r\n\r\nDeterminism Settings: Although you've enabled deterministic operations in TensorFlow with tf.config.experimental.enable_op_determinism(), not all TensorFlow operations may fully honor this setting, especially for complex layers like LayerNormalization.\r\n\r\nCUDA/cuDNN Version: Different versions of CUDA and cuDNN can have slight variations in implementation, which might contribute to differences in the results. Even small changes in how operations are optimized can lead to different outputs on GPU versus CPU.\r\n\r\nLayerNormalization Implementation: The implementation of LayerNormalization might differ slightly between GPU and CPU kernels, leading to differences in the final output. This could be due to different optimization techniques or specific hardware instructions used by GPUs.\r\n\r\nPossible Solutions or Workarounds:\r\nIncrease Tolerance for Differences: Depending on your use case, it might be acceptable to increase the tolerance for differences between CPU and GPU outputs. You could adjust the thresholds used in your checks, such as the chebyshev_distance threshold.\r\n\r\nTest with Different CUDA/cuDNN Versions: If feasible, try testing your code with different versions of CUDA and cuDNN to see if the issue persists or if it varies with different configurations.\r\n\r\nUse CPU-Only for Deterministic Results: If deterministic behavior is critical and GPU introduces too much variance, consider using CPU-only execution for critical parts of your model where exact reproducibility is required.\r\n\r\nCustom LayerNormalization Implementation: If the issue is isolated to LayerNormalization, consider implementing a custom version that you can control more tightly, ensuring consistency across platforms.\r\n\r\nIf this discrepancy is affecting a critical application, you might consider opening a detailed issue on the TensorFlow GitHub repository with all relevant information, including the specific CUDA/cuDNN versions, GPU model, and any other hardware-specific details. This could help the TensorFlow team investigate and potentially resolve the issue."", '> A temporary workaround is to replace `LayerNormalization` with `BatchNormalization` or to manually set a higher `epsilon` value, which reduces the discrepancy in floating-point operations.\r\n\r\nYou can repeat my mistake by following this link:\r\n\r\nhttps://github.com/PhyllisJi/MoCoDiff_Bug/tree/tf-issue-%2374796', ""> Asked ChatGpt about this, answer is below. See if it can help\r\n> \r\n> The issue you've described seems to revolve around a discrepancy between the outputs of a LayerNormalization layer when running on a GPU versus a CPU, using the same input and parameter settings. This kind of inconsistency can be a significant problem, especially in scenarios where deterministic behavior is expected across different hardware platforms.\r\n> \r\n> Possible Reasons for the Discrepancy: Floating-Point Precision: GPUs and CPUs may handle floating-point calculations differently. GPUs often use single precision (32-bit floating-point), while CPUs might use double precision (64-bit floating-point) or other precision levels depending on the settings. This difference can lead to variations in the results of operations that involve multiple floating-point calculations, such as LayerNormalization.\r\n> \r\n> Parallel Computation: GPUs perform many operations in parallel, which can introduce slight differences in the order of operations compared to a CPU, which may execute operations sequentially. This difference can affect operations like normalization, where the order of summation can influence the final result due to the non-associativity of floating-point arithmetic.\r\n> \r\n> Determinism Settings: Although you've enabled deterministic operations in TensorFlow with tf.config.experimental.enable_op_determinism(), not all TensorFlow operations may fully honor this setting, especially for complex layers like LayerNormalization.\r\n> \r\n> CUDA/cuDNN Version: Different versions of CUDA and cuDNN can have slight variations in implementation, which might contribute to differences in the results. Even small changes in how operations are optimized can lead to different outputs on GPU versus CPU.\r\n> \r\n> LayerNormalization Implementation: The implementation of LayerNormalization might differ slightly between GPU and CPU kernels, leading to differences in the final output. This could be due to different optimization techniques or specific hardware instructions used by GPUs.\r\n> \r\n> Possible Solutions or Workarounds: Increase Tolerance for Differences: Depending on your use case, it might be acceptable to increase the tolerance for differences between CPU and GPU outputs. You could adjust the thresholds used in your checks, such as the chebyshev_distance threshold.\r\n> \r\n> Test with Different CUDA/cuDNN Versions: If feasible, try testing your code with different versions of CUDA and cuDNN to see if the issue persists or if it varies with different configurations.\r\n> \r\n> Use CPU-Only for Deterministic Results: If deterministic behavior is critical and GPU introduces too much variance, consider using CPU-only execution for critical parts of your model where exact reproducibility is required.\r\n> \r\n> Custom LayerNormalization Implementation: If the issue is isolated to LayerNormalization, consider implementing a custom version that you can control more tightly, ensuring consistency across platforms.\r\n> \r\n> If this discrepancy is affecting a critical application, you might consider opening a detailed issue on the TensorFlow GitHub repository with all relevant information, including the specific CUDA/cuDNN versions, GPU model, and any other hardware-specific details. This could help the TensorFlow team investigate and potentially resolve the issue.\r\n\r\nThank you for your answer. We have tried all the measures you mentioned, but differences still exist."", '@BiophiliaSWDA,\r\nCould you please try to check with the latest tensorflow v2.17 which contains the keras3.0 by default and provide the update if there is a difference in the output.  Thank you!', '> @BiophiliaSWDA, Could you please try to check with the latest tensorflow v2.17 which contains the keras3.0 by default and provide the update if there is a difference in the output. Thank you!\r\n\r\nWhen I check with TF 2.17.0, I face this error:\r\n```python\r\nTraceback (most recent call last):\r\n  File ""/root/miniconda3/envs/tf2.17/lib/python3.10/site-packages/keras/src/ops/operation.py"", line 234, in from_config\r\n    return cls(**config)\r\n  File ""/root/miniconda3/envs/tf2.17/lib/python3.10/site-packages/keras/src/layers/core/dense.py"", line 92, in __init__\r\n    self.bias_initializer = initializers.get(bias_initializer)\r\n  File ""/root/miniconda3/envs/tf2.17/lib/python3.10/site-packages/keras/src/initializers/__init__.py"", line 119, in get\r\n    raise ValueError(\r\nValueError: Could not interpret initializer identifier: {\'module\': \'keras.initializers\', \'class_name\': \'IdentityInitializer\', \'config\': {}, \'registered_name\': None}\r\n```', ""> A temporary workaround is to replace `LayerNormalization` with `BatchNormalization` or to manually set a higher `epsilon` value, which reduces the discrepancy in floating-point operations.\r\n\r\nIt's not that the output is different, it's that the parameters are updated differently."", '@BiophiliaSWDA,\r\nThe reason for the different results could be due to the optimized way of calculating numbers on Nvidia which is different compared to others, there will be a small amount of precision errors.\r\n\r\nI think the issue is specific to GPU, I was able to reproduce the issue on colab with GPU runtime.\r\nBut, when the inputs are changed to float64 precision, the results are as expected. Same behavior is not observed on Apple M1, using numpy or in the CPU. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""> @BiophiliaSWDA, The reason for the different results could be due to the optimized way of calculating numbers on Nvidia which is different compared to others, there will be a small amount of precision errors.\r\n> \r\n> I think the issue is specific to GPU, I was able to reproduce the issue on colab with GPU runtime. But, when the inputs are changed to float64 precision, the results are as expected. Same behavior is not observed on Apple M1, using numpy or in the CPU. Thank you!\r\n\r\nThank you for your reply! But I think TF should do some optimisation means to avoid this type of error? Because NVIDIA's GPUs are used in a wide range of applications. "", '@BiophiliaSWDA,\r\nThe layers LayerNormalization and BatchNormalization are related to Keras. Could you please raise the issue in the Keras-team/keras repo for the quick resolution. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74796"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74796"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf2.12.0

### Custom code

Yes

### OS platform and distribution

Ubuntu20.04

### Mobile device

Ubuntu20.04

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.8, cuDNN 8

### GPU model and memory

_No response_

### Current behavior?

DIFF: 0.37556207180023193
(False, 'Grad diff too big')

### Standalone code to reproduce the issue

```shell
import copy
import numpy as np
import tensorflow as tf

tf.config.experimental.enable_op_determinism()

def pointnet(input_shape):
    input_tensor = tf.keras.Input(shape=input_shape)
    x = tf.keras.layers.Conv1D(filters=64, kernel_size=7, padding=""valid"")(input_tensor)
    x = tf.keras.layers.Softmax()(x)
    x = tf.keras.layers.Activation(activation='softplus')(x)
    x = tf.keras.layers.MaxPool1D(padding='valid', strides=4)(x)
    x = tf.keras.layers.BatchNormalization(center=False, momentum=0.07244736627895476, epsilon=0.3847853359642447)(x)
    x = tf.keras.layers.Activation(activation='exponential')(x)
    x = tf.keras.layers.MaxPooling1D(padding='same', strides=6, data_format='channels_last')(x)
    x = tf.keras.layers.Softmax(axis=2)(x)
    x = tf.keras.layers.Activation(activation='hard_sigmoid')(x)
    x = tf.keras.layers.Flatten()(x)
    x = tf.keras.layers.Dense(units=1, use_bias=False, activation='softplus', bias_constraint=None, bias_regularizer=None, kernel_regularizer=None, kernel_constraint=None, activity_regularizer=None, bias_initializer='identity', kernel_initializer='truncated_normal')(x)
    x = tf.keras.layers.LayerNormalization(center=True, axis=1, scale=True, beta_constraint=None, epsilon=0.7136230859666187, gamma_initializer='glorot_normal', beta_regularizer=None, gamma_constraint=None, beta_initializer='zeros', gamma_regularizer=None)(x)
    x = tf.keras.layers.Activation(activation='selu')(x)
    x = tf.keras.layers.Dense(units=8, use_bias=False, activation='selu', kernel_regularizer=None, bias_constraint=None, bias_regularizer=None, bias_initializer='ones', kernel_initializer='glorot_uniform', kernel_constraint=None, activity_regularizer=None)(x)
    tail_flatten = tf.keras.layers.Flatten()(x)
    tail_fc = tf.keras.layers.Dense(units=10)(tail_flatten)
    model = tf.keras.models.Model(inputs=input_tensor, outputs=tail_fc)
    return model


def chebyshev_distance(A: np.ndarray, B: np.ndarray):
    if A is None or B is None:
        return 0.0
    if A.shape != B.shape:
        return 9999999
    else:
        return float(np.max(np.abs(A - B)))


def train(inp, label):
    flag = True
    label = tf.convert_to_tensor(label)
    model_g = pointnet(inp.shape[1:])
    model_g.load_weights(""./output_dict/grad_diff_initial_weights.h5"")
    
    with tf.device('GPU'):
        with tf.GradientTape() as tape:
            output_g = model_g(inp)
            loss_g = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)(label, output_g)
        gradients_g = tape.gradient(loss_g, model_g.trainable_variables)
        gradients_dic_g = {}
        for var, gradient in zip(model_g.trainable_variables, gradients_g):
            if gradient != None:
                gradients_dic_g.setdefault(var.name.replace('/', '.')[:-2], gradient)

    model_c = copy.deepcopy(model_g)
    model_c.load_weights(""./output_dict/grad_diff_initial_weights.h5"")
    with tf.device('CPU'):
        with tf.GradientTape() as tape:
            output_c = model_c(inp)
            loss_c = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)(label, output_c)
        gradients_c = tape.gradient(loss_c, model_c.trainable_variables)
        gradients_dic_c = {}
        for var, gradient in zip(model_c.trainable_variables, gradients_c):
            if gradient != None:
                gradients_dic_c.setdefault(var.name.replace('/', '.')[:-2], gradient)
    if chebyshev_distance(output_c.numpy(), output_g.numpy()) > 1.0:
        flag = False
        return flag, 'Output diff too big'
    if abs(loss_c - loss_g) > 0.1:
        flag = False
        return flag, 'Loss diff too big'
    for name in gradients_dic_c.keys(): 
        if name in gradients_dic_g.keys():
            if chebyshev_distance(gradients_dic_c[name], gradients_dic_g[name]) > 0.1:
                print(chebyshev_distance(gradients_dic_c[name], gradients_dic_g[name]))
                flag = False
                return flag, 'Grad diff too big'
    for name in gradients_dic_g.keys():
        if name in gradients_dic_c.keys():
            if chebyshev_distance(gradients_dic_g[name], gradients_dic_c[name]) > 0.1:
                print(gradients_dic_c[name], gradients_dic_g[name])
                flag = False
                return flag, 'Grad diff too big'
    return flag, ''


data = np.load(""./output_dict/grad_diff_input.npz"")
inp = data['inp']
label = data['label']
print(train(inp, label))
```


### Relevant log output

_No response_"
2496679561,74862,The difference in performance on the parameter activation='exponential' is too large,closed,2024-08-30 09:14:14+00:00,2025-01-19T02:03:32Z,2025-01-19T02:03:30Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/74862,"['stat:awaiting response', 'type:bug', 'stale', 'TF 2.12']","['Hi **@BiophiliaSWDA** ,\r\nSorry for the delay, I reproduced the code shared but facing different error. Could you please share the colab gist with all the dependencies to analyze more of it.\r\nThank you!', '> Hi **@BiophiliaSWDA** , Sorry for the delay, I reproduced the code shared but facing different error. Could you please share the colab gist with all the dependencies to analyze more of it. Thank you!\r\n\r\nI was unable to reproduce the issues I encountered on colab, probably due to the different GPU. I used Ubuntu 20.04, Python 3.10, Tensorflow 2.12, CUDA 11.8, cuDNN 8, and NVDIA 3090 GPU.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', '> This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.\r\n\r\n@Venkat6871 Any update？', 'Hi **@BiophiliaSWDA** ,\r\nI tried running your code on Colab using TensorFlow 2.17.0 with GPU. Here is the [gist](https://colab.sandbox.google.com/gist/Venkat6871/bac425809adf705d446ce8acf4f981da/74862_tf-2-17-0-v-gpu.ipynb) for your reference. Could you please confirm whether you are facing a similar problem or a different one?\r\nThank you!', '> Hi **@BiophiliaSWDA** , I tried running your code on Colab using TensorFlow 2.17.0 with GPU. Here is the [gist](https://colab.sandbox.google.com/gist/Venkat6871/bac425809adf705d446ce8acf4f981da/74862_tf-2-17-0-v-gpu.ipynb) for your reference. Could you please confirm whether you are facing a similar problem or a different one? Thank you!\r\n\r\nIt looks like this has been fixed in the latest version, is it 2.12.0 that has a problem related to mishandling of floating point numbers in exponential calculations?', 'Hi **@PhyllisJi** ,\r\nApologies for the delay, and thank you for your patience. The issue is related to an older version and has been fixed in the latest version. We always recommend using the latest versions for better results.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74862"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74862"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf2.12.0

### Custom code

Yes

### OS platform and distribution

Ubuntu20.04

### Mobile device

Ubuntu20.04

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.2

### GPU model and memory

_No response_

### Current behavior?

Grad diff too big

### Standalone code to reproduce the issue

```shell
import copy
import numpy as np
import tensorflow as tf


def lenet(input_shape):
    input_tensor = tf.keras.Input(shape=input_shape)
    x = tf.keras.layers.Activation(activation=""relu"")(input_tensor)
    x = tf.keras.layers.MaxPool2D(pool_size=8, strides=3, padding='same')(x)
    x = tf.keras.layers.Activation(activation='sigmoid')(x)
    x = tf.keras.layers.MaxPool2D(pool_size=5, strides=1, padding='same')(x)
    x = tf.keras.layers.Activation(activation='softplus')(x)
    x = tf.keras.layers.MaxPooling2D(pool_size=7, strides=8, padding='same', data_format='channels_last')(x)
    x = tf.keras.layers.Flatten(data_format='channels_first')(x)
    x = tf.keras.layers.Dense(units=2, activation='exponential', kernel_constraint=None, bias_regularizer=None, use_bias=False, bias_initializer='he_uniform', activity_regularizer=None, kernel_initializer='ones', bias_constraint=None, kernel_regularizer=None)(x)
    x = tf.keras.layers.Dense(units=7, activation='exponential', use_bias=True, kernel_initializer='glorot_uniform', kernel_constraint=None, bias_regularizer=None)(x)
    output_tensor = tf.keras.layers.Flatten(data_format='channels_first')(x)
    tail_flatten = tf.keras.layers.Flatten()(output_tensor)
    tail_fc = tf.keras.layers.Dense(units=10)(tail_flatten)
    model = tf.keras.models.Model(inputs=input_tensor, outputs=tail_fc)
    return model


def chebyshev_distance(A: np.ndarray, B: np.ndarray):
    if A is None or B is None:
        return 0.0
    if A.shape != B.shape:
        return 9999999
    else:
        return float(np.max(np.abs(A - B)))


def train(inp, label):
    flag = True
    label = tf.convert_to_tensor(label)
    model_g = lenet(inp.shape[1:])
    model_g.load_weights(""./output_dict/grad_diff_initial_weights.h5"")
    with tf.device('GPU'):
        with tf.GradientTape() as tape:
            output_g = model_g(inp)
            loss_g = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)(label, output_g)
        gradients_g = tape.gradient(loss_g, model_g.trainable_variables)
        gradients_dic_g = {}
        for var, gradient in zip(model_g.trainable_variables, gradients_g):
            if gradient != None:
                gradients_dic_g.setdefault(var.name.replace('/', '.')[:-2], gradient)

    model_c = copy.deepcopy(model_g)
    model_c.load_weights(""./output_dict/grad_diff_initial_weights.h5"")
    with tf.device('CPU'):
        with tf.GradientTape() as tape:
            output_c = model_c(inp)
            loss_c = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)(label, output_c)
        gradients_c = tape.gradient(loss_c, model_c.trainable_variables)
        gradients_dic_c = {}
        for var, gradient in zip(model_c.trainable_variables, gradients_c):
            if gradient != None:
                gradients_dic_c.setdefault(var.name.replace('/', '.')[:-2], gradient)
    if chebyshev_distance(output_c.numpy(), output_g.numpy()) > 1.0:
        flag = False
        return flag, 'Output diff too big'
    if abs(loss_c - loss_g) > 0.1:
        flag = False
        return flag, 'Loss diff too big'
    for name in gradients_dic_c.keys():
        if name in gradients_dic_g.keys():
            if chebyshev_distance(gradients_dic_c[name], gradients_dic_g[name]) > 0.1:
                flag = False
                return flag, 'Grad diff too big'
    for name in gradients_dic_g.keys():
        if name in gradients_dic_c.keys():
            if chebyshev_distance(gradients_dic_g[name], gradients_dic_c[name]) > 0.1:
                flag = False
                return flag, 'Grad diff too big'
    return flag, ''


data = np.load(""./output_dict/grad_diff_input.npz"")
inp = data['inp']
label = data['label']
print(train(inp, label))
```


### Relevant log output

[Reproduction](https://github.com/PhyllisJi/MoCoDiff_Bug/tree/tf-issue-%2374862)"
2497265049,74879,Adam optimiser fails because of negative v_hat values leading to nan in weight update,closed,2024-08-30 13:34:29+00:00,2024-09-19T02:00:00Z,2024-09-19T01:59:57Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/74879,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'TF 2.16']","['@simba611,\r\nCould you please share a reproducible code that supports your statement so that the issue can be debugged in the effective way? Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74879"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74879"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

tf 2.16.1

### Custom code

Yes

### OS platform and distribution

Debian 12

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

cuDNN version 8907

### GPU model and memory

Quadro RTX 8000, 48GB

### Current behavior?

Adam leads to nan values in UNet while SGD works fine. On manual implementation and debugging, I have found the problem to be in the calculation of v_hat. For whatever reason, v_hat is becoming negative at the beta_2*v_hat stage. After this all calculation collapses. The addition is incorrect as well. The whole code repository is too hard to simplify to give a standalone test case, but i have attached the training code. This issue should be model agnostic, as it is happening in the optimiser. 

To note: I tried tf.keras.optimizers.Adam with various parameters and then implemented my own version to debug and found the issues mentioned below. 
Another note: This happens randomly. Sometimes it will happen after 10 iterations, sometimes after 2000.

This is quite unexpected behaviour from a library used by so many people in such a common routine. Please suggest possible resolution. 

Thanks 

### Standalone code to reproduce the issue

```shell
if self.networkMode == 'training':
            self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.stgs.START_LEARNING_RATE, clipvalue=2.0, epsilon=1e-3)
            list_losses = []
            list_weights = []


            gradsTexNet = tape.gradient(finalLoss, texNet.model.trainable_weights)
            # optimizer.apply_gradients(zip(gradsTexNet, texNet.model.trainable_weights))
            grads_copy = [tf.identity(g) for g in gradsTexNet]
            weights_copy = [tf.identity(w) for w in texNet.model.trainable_weights]

            weight_update_list = []
            m_hat_list = []
            v_hat_list = []
            s1 = []
            s2 = []
            for ioy, weight in enumerate(texNet.model.trainable_weights):
                self.t += 1.0 # Increment time step

                # Update biased first moment estimate
                self.m[ioy].assign(self.beta_1 * self.m[ioy] + (1 - self.beta_1) * gradsTexNet[ioy])
                s1.append((1 - self.beta_2) * tf.square(gradsTexNet[ioy]))
                s2.append(self.beta_2 * self.v[ioy])
                # Update biased second moment estimate
                self.v[ioy].assign(self.beta_2 * self.v[ioy])
                self.v[ioy].assign_add((1 - self.beta_2) * tf.square(gradsTexNet[ioy]))
                
                # Compute bias-corrected first and second moment estimates
                m_hat = self.m[ioy] / (1 - (self.beta_1**self.t))
                v_hat = self.v[ioy] / (1 - (self.beta_2**self.t))
                
                # Update the weight
                weight_update = self.learning_rate * m_hat / (tf.sqrt(v_hat) + self.epsilon)

                m_hat_list.append(m_hat)
                v_hat_list.append(v_hat)
                weight_update_list.append(weight_update)

                weight.assign(weight - weight_update)
            weights_copy2 = [tf.identity(w) for w in texNet.model.trainable_weights]
```


### Relevant log output

```shell
The issue is in:
self.v[i].assign(self.beta_2 *self.v[i] + (1 - self.beta_2) *tf.square(gradsTexNet[i]))

it is self.beta_2 * self.v[i] which is becoming negative first. 
The values for self.beta_2 * self.v[i] become [-277.81274   243.22517  -335.06995   333.12036   -47.58728   340.61444 
  -58.375122  338.2406  ]

The values for (1 - self.beta_2) * tf.square(gradsTexNet[i]) become: [2.6129057e-05 3.6575788e-05 1.4987046e-08 3.2171758e-07 1.2511656e-05  1.8191919e-05 1.2237210e-05 6.4639935e-05]

The values of their sum don't line up and are this:
[-198.82468   -77.196434 -199.875    -537.16595  -119.70409  -448.5137  -115.79137  -342.62042 ]

If i divide them by (1 - beta_2**t) in tensorflow, the values become:
[ -49780.793  -19328.082  -50043.766 -134493.1    -29970.95  -112296.766   -28991.3    -85783.695]

but if i divide them using python, the values become this:
[-3586.765  -1392.6112 -3605.7126 -9690.387  -2159.4424 -8091.1143  -2088.8574 -6180.817 ]

The gradient values are:
[-0.16164485 -0.19124797  0.00387131  0.01793649 -0.11185551 -0.13487741  -0.11062192  0.25424385]
```
"
2498613211,74913,"Aborted (core dumped) Check failed: index >= 0 && index < num_total_dims Invalid index from the dimension: 3, 0, C ",closed,2024-08-31 04:20:19+00:00,2024-09-20T12:23:22Z,2024-09-20T12:23:18Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/74913,"['stat:awaiting response', 'type:bug', 'comp:apis', '2.17']","[""The following code can also trigger the same abort fault:\r\n\r\nCode1:\r\n```python\r\nfrom tensorflow.python.framework import constant_op\r\nfrom tensorflow.python.framework import dtypes\r\nfrom tensorflow.python.ops import nn_ops\r\nimport tensorflow as tf\r\nsess = tf.compat.v1.Session()\r\nwith sess.as_default():\r\n    strides = [1, 926, 2, 2, 1]\r\n    x_shape = [2, 1, 6, 4, 3]\r\n    y_shape = []\r\n    f_shape = []\r\n    x = constant_op.constant(1.0, shape=x_shape, name='x', dtype=dtypes.float32)\r\n    f = constant_op.constant(1.0, shape=f_shape, name='filter', dtype=dtypes.float32)\r\n    output = nn_ops.conv3d_transpose(x, f, y_shape, strides=strides, padding='SAME')\r\n```\r\n> 2024-09-01 20:49:25.826734: F ./tensorflow/core/util/tensor_format.h:428] Check failed: index >= 0 && index < num_total_dims Invalid index from the dimension: 3, 0, C\r\nAborted (core dumped)\r\n\r\nCode2:\r\n```python\r\nfrom tensorflow.python.framework import constant_op\r\nfrom tensorflow.python.framework import dtypes\r\nfrom tensorflow.python.ops import array_ops\r\nfrom tensorflow.python.ops import nn_ops\r\n\r\nimport tensorflow as tf\r\nsess = tf.compat.v1.Session()\r\nwith sess.as_default():\r\n    input_shape = []\r\n    total_input_size = 1\r\n    for s in input_shape:\r\n        total_input_size *= s\r\n    inputs = [i * 1.0 / total_input_size for i in range(1, total_input_size + 1)]\r\n    a = constant_op.constant(inputs, shape=input_shape, dtype=dtypes.float32)\r\n    filter_shape = (1, 1, 1, 8, 8)\r\n    total_filter_size = 1\r\n    for s in filter_shape:\r\n        total_filter_size *= s\r\n    filters = [i * 1.0 / total_filter_size for i in range(1, total_filter_size + 1)]\r\n    f = constant_op.constant(filters, shape=filter_shape, dtype=dtypes.float32)\r\n    conv_t = nn_ops.conv3d(a, filter=f, strides=(1, 1, 1, 1, 1), padding='VALID')\r\n    slice_t = array_ops.slice(conv_t, (0, 1, 1, 1, 0), (1, 1, 1, 1, 8))\r\n```\r\n\r\n> 2024-09-01 20:55:30.319578: F ./tensorflow/core/util/tensor_format.h:428] Check failed: index >= 0 && index < num_total_dims Invalid index from the dimension: 3, 0, C\r\nAborted (core dumped)"", 'Hi **@KnightGOKU** ,\r\nApologies for the delay. I tried running your code on Colab using TensorFlow 2.17.0 with GPU and the nightly versions. It is raising an error for your code snippet. Please find the [gist1](https://colab.sandbox.google.com/gist/Venkat6871/11c07081ae3e72c9e79e559dfc779ded/74913_tf-2-17-0-nightly-v.ipynb), [gist2](https://colab.sandbox.google.com/gist/Venkat6871/82287b32255d137c2d3f808b33a9858f/74913_tf-2-17-0-gpu.ipynb) here for reference.\r\n\r\nThank you!', ""Hi @Venkat6871 , thank you for your time. I found that the code could not reproduce the crash in Google Colab, but it does crash on my local machine. I’m still unsure why this happens. I'll close the issue for now and will reopen it if I discover the cause. Thanks again!"", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74913"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74913"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf-nightly 2.18.0.dev20240817

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I encountered an `aborted issue` in TensorFlow when I used API `nn_ops.conv2d_backprop_filter` .
> 2024-08-31 12:22:03.927406: F ./tensorflow/core/util/tensor_format.h:428] Check failed: index >= 0 && index < num_total_dims Invalid index from the dimension: 3, 0, C
> Aborted (core dumped)

### Standalone code to reproduce the issue

```shell
import numpy as np

from tensorflow.python.framework import constant_op
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import test_util


from tensorflow.python.ops import nn_ops


def GetTestConfigs():
    test_configs = [('NHWC', False), ('NHWC', True)]
    return test_configs

def _DtypesToTest(use_gpu):
    if use_gpu:
        out = [dtypes.float32, dtypes.bfloat16]
        return out
    return [dtypes.float32, dtypes.float64, dtypes.float16, dtypes.bfloat16]

def _CreateNumpyTensor(shape):
    total_size = 1
    for s in shape:
        total_size *= s
    return np.arange(1, total_size + 1, dtype=np.float32).reshape(shape)


def testConv2D2x2Depth1ValidBackpropFilter():
    expected = (5.0, 8.0, 14.0, 17.0)
    for [data_format, use_gpu] in GetTestConfigs():
        _RunAndVerifyBackpropFilter(input_sizes=[], filter_sizes=(2, 2, 1, 1), output_sizes=[1, 1, 2], strides=[], padding='VALID', expected=expected, data_format=data_format, use_gpu=use_gpu)

def _RunAndVerifyBackpropFilter(input_sizes, filter_sizes, output_sizes, strides, padding, expected, data_format, use_gpu, dilations=(1, 1), err=1e-05):
    x0 = _CreateNumpyTensor(input_sizes)
    x2 = _CreateNumpyTensor(output_sizes)
    dilations = list(dilations)
    explicit_strides = [1] + strides + [1]
    new_padding = padding
    new_dilations = [1] + dilations + [1]
    if isinstance(new_padding, (list, tuple)):
        new_padding = [(0, 0)] + new_padding + [(0, 0)]
    if data_format == 'NCHW':
        explicit_strides = test_util.NHWCToNCHW(explicit_strides)
        new_dilations = test_util.NHWCToNCHW(new_dilations)
        if isinstance(padding, (list, tuple)):
            new_padding = test_util.NHWCToNCHW(new_padding)
    for dtype in _DtypesToTest(use_gpu=use_gpu):
        with test_util.device(use_gpu):
            t0 = constant_op.constant(x0, shape=input_sizes, dtype=dtype)
            t1 = constant_op.constant(filter_sizes, shape=[len(filter_sizes)])
            t2 = constant_op.constant(x2, shape=output_sizes, dtype=dtype)
            if data_format == 'NCHW':
                t0 = test_util.NHWCToNCHW(t0)
                t2 = test_util.NHWCToNCHW(t2)
            # the following line would cause `Aborted (core dumped)`
            conv = nn_ops.conv2d_backprop_filter(t0, t1, t2, strides=explicit_strides, padding=new_padding, dilations=new_dilations, data_format=data_format)


testConv2D2x2Depth1ValidBackpropFilter()
```


### Relevant log output

```shell
> 2024-08-31 12:22:03.927406: F ./tensorflow/core/util/tensor_format.h:428] Check failed: index >= 0 && index < num_total_dims Invalid index from the dimension: 3, 0, C
> Aborted (core dumped)
```
I have confirmed that above code would crash on `tf-nightly 2.18.0.dev20240817` (nightly-build)"
2498614527,74914,TensorFlow would crash when using `nn_ops.conv2d` with too large strides ,closed,2024-08-31 04:23:52+00:00,2024-09-26T08:10:45Z,2024-09-26T08:10:41Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/74914,"['stat:awaiting response', 'type:bug', 'comp:ops', '2.17']","['@KnightGOKU,\r\nI tried to execute the mentioned code on both tensorflow2.17 and tf-nightly and observed that the colab was not crashed & it was providing the error output where ""Attr strides has value 4634247419717959497 out of range for an int32"" which was expected.  Kindly find the gist it [here](https://colab.research.google.com/gist/tilakrayal/043475c43ea9256d590d3e97ded5d4c7/untitled2125.ipynb).\r\n\r\nIt seems like you\'re giving large negative value for multiples argument to the function nn_ops so due to Integer overflow to buffer overflow or due to insufficient memory (RAM), code is crashing or process getting killed and It\'s not being killed because of TF. You are literally allocating so much memory that the OS is killing the process. Thank you!\r\n\r\n', 'Thank you for your time. I will close this issue as the crash has been determined not to be caused by TensorFlow.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74914"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74914"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf-nightly 2.18.0.dev20240817

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I encountered an `aborted issue` in TensorFlow when I used API `nn_ops.conv2d`  with strides that were too large. 

> 2024-08-31 12:25:59.983173: F tensorflow/core/common_runtime/mkl_layout_pass.cc:2703] Non-OK-status: GetNodeAttr(orig_node->def(), ""strides"", &strides)
> Status: INVALID_ARGUMENT: Attr strides has value 4634247419717959497 out of range for an int32
> Aborted (core dumped)

I have confirmed that above code would crash on `tf-nightly 2.18.0.dev20240817` (nightly-build)

### Standalone code to reproduce the issue

```shell
import numpy as np
from tensorflow.python.framework import constant_op
from tensorflow.python.ops import nn_ops


def _CompareFwdConv2D(tensor_in_sizes, filter_in_sizes, conv_strides, padding):

    x1 = np.random.rand(*tensor_in_sizes).astype(np.float32)
    x2 = np.random.rand(*filter_in_sizes).astype(np.float32)
    t1 = constant_op.constant(x1, shape=tensor_in_sizes)
    t2 = constant_op.constant(x2, shape=filter_in_sizes)
    strides = [1] + conv_strides + [1]
    conv = nn_ops.conv2d(t1, t2, strides=strides, padding=padding)


def _RunTestCases(conv_strides, padding):
    input_sizes = [[5, 5, 5, 1248]]
    filter_sizes = [[3, 3, 1248, 128]]
    for (input_shape, filter_shape) in zip(input_sizes, filter_sizes):
        _CompareFwdConv2D(input_shape, filter_shape, conv_strides, padding)


def testConv2D3x3FilterStride1x1Same():
    _RunTestCases([4634247419717959497, 1], 'SAME')


testConv2D3x3FilterStride1x1Same()
```


### Relevant log output

_No response_"
2498649139,74917, `Aborted` issue raised in TensorFlow when using data_flow_ops.SparseConditionalAccumulator and apply_indexed_slices_grad with mismatched data types,closed,2024-08-31 05:41:07+00:00,2024-11-13T06:11:07Z,2024-11-10T02:03:35Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/74917,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","['@KnightGOKU,\r\nI tried to execute the mentioned code on tf-nightly and observed that the check fail is happening due to mismatch of the data type provided as input. I tried with the similar input data type and the code was executed without abort/fail. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/3f663ffbe0bb69af5586ae3a60073c5d/untitled2203.ipynb). Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74917"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74917"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf-nightly 2.18.0.dev20240817

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I encountered an `Aborted` issue in TensorFlow when using the `data_flow_ops.SparseConditionalAccumulator` API and `apply_indexed_slices_grad` with mismatched data types. The code was confirmed to crash on `tf-nightly 2.18.0.dev20240817` (nightly-build)
> 2024-08-31 13:45:53.349441: F tensorflow/core/framework/tensor.cc:844] Check failed: dtype() == expected_dtype (23 vs. 1) float expected, got uint64
Aborted (core dumped)

### Standalone code to reproduce the issue

```shell
import numpy as np
from tensorflow.python.framework import dtypes as dtypes_lib
from tensorflow.python.framework import indexed_slices
from tensorflow.python.framework import tensor_shape
from tensorflow.python.ops import data_flow_ops
import tensorflow as tf

tf.compat.v1.disable_eager_execution()
sess = tf.compat.v1.Session()

with sess.as_default():
    q = data_flow_ops.SparseConditionalAccumulator(dtypes_lib.float32, name='Q', shape=tensor_shape.TensorShape([3, 3]))
    accum_op = q.apply_indexed_slices_grad(indexed_slices.IndexedSlices(indices=[0, 2], values=np.array([[0, 0, 1], [3, 0, 4]]).astype(np.uint64)))
    accum_op.run()
```


### Relevant log output

```shell
2024-08-31 13:45:53.349441: F tensorflow/core/framework/tensor.cc:844] Check failed: dtype() == expected_dtype (23 vs. 1) float expected, got uint64
Aborted (core dumped)
```
"
2498810498,74926,ValueError: Device /job:localhost/replica:0/task:0/device:CPU:0 is not found,closed,2024-08-31 11:58:59+00:00,2024-09-21T01:58:37Z,2024-09-21T01:58:32Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/74926,"['stat:awaiting response', 'type:bug', 'stale', 'comp:tpus', 'TF 2.16']","[""Please pay attention, the device job:localhost/replica:0/task:0/device:CPU:0  is exists.\r\n(tf.device('/job:localhost/replica:0/task:0/device:CPU:0 ') it's okay.) "", 'Hi **@StarxSky** ,\r\nI tried to run code on colab using TF 2.15 & 2.17 and i am not facing any issue with 2.15 but i am facing issue with 2.17. Please find the [gist](https://colab.research.google.com/gist/Venkat6871/49ddf513be87ec6a210b25ec67813128/74926_2-15-0-v.ipynb) here for reference.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74926"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74926"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

tf 2.16.1

### Custom code

Yes

### OS platform and distribution

Linux

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When I running my code on the TPU at Kaggle , I have the following problem: `ValueError: Device /job:localhost/replica:0/task:0/device:CPU:0 is not found`
## Complete error report:
```
File /usr/local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122, in filter_traceback.<locals>.error_handler(*args, **kwargs)
    119     filtered_tb = _process_traceback_frames(e.__traceback__)
    120     # To get the full stack trace, call:
    121     # `keras.config.disable_traceback_filtering()`
--> 122     raise e.with_traceback(filtered_tb) from None
    123 finally:
    124     del filtered_tb

File /usr/local/lib/python3.10/site-packages/tensorflow/python/distribute/packed_distributed_variable.py:91, in PackedDistributedVariable.get_var_on_device(self, device)
     89   if d == device:
     90     return self._distributed_variables[i]
---> 91 raise ValueError(""Device %s is not found"" % device)

ValueError: Device /job:localhost/replica:0/task:0/device:CPU:0 is not found
```

## My TPU configuration code:
```python
try: 
    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()#.connect(tpu='local')
    print(f'Running on the TPU: {TPU.master()}')
except ValueError:
    print('TPU is not avalibale!!')
    TPU = None
    
if TPU:
    tf.config.experimental_connect_to_cluster(TPU)
    tf.tpu.experimental.initialize_tpu_system(TPU)
    strategy = tf.distribute.experimental.TPUStrategy(TPU)
else :
    strategy = tf.distribute.get_strategy()

```



### Standalone code to reproduce the issue

```shell
The above errors occur in various environments of kaggle, so I suspect that there is a problem with the official framework source code. I implore the official to give a suitable solution!! Thanks!!
```


### Relevant log output

_No response_"
2498900666,74929,tf.keras.layers.UpSampling2D outputs different output type for input unsigned integer tensors,closed,2024-08-31 15:25:41+00:00,2024-09-18T01:58:38Z,2024-09-18T01:58:33Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/74929,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', '2.17']","['@rkazants,\r\nThank you for reporting the issue. I was able to reproduce the issue on tensorflow v2.17 and tf-nightly. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/a844794068095b9578e13cc2f5616761/untitled2089.ipynb).\r\n\r\nAs this issue is more related to Keras, could you please try to raise the issue on Keras-team/keras [repo](https://github.com/keras-team/keras/issues) for the quick resolution. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74929"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74929"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.17.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Previously, output tensor has float-point type for unsigned input integer tensors.
Now it is changed to the same unsigned integer type as input.
There were backward incompatible changes.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

rng = np.random.default_rng()
data = rng.integers(-8, 8, [2, 4, 8, 2]).astype(np.uint16)

tf.keras.backend.clear_session()
x = tf.keras.Input(shape=[4, 8, 2], name='x', dtype=np.uint16)
y = tf.keras.layers.UpSampling2D(size=(2, 3), data_format='channels_last',
                                 interpolation='bilinear')(x)
model = tf.keras.Model(inputs=[x], outputs=[y])
res = model(data)
list(res)[0].dtype
```


### Relevant log output

"
2499980849,74965,tf.linalg.solve single precision wrong result,closed,2024-09-02 04:38:58+00:00,2024-09-04T12:01:33Z,2024-09-04T12:01:12Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/74965,"['stat:awaiting response', 'type:bug', '2.17']","['PyTorch and NumPy results\r\n```\r\ntorch 2.5.0a0+gitcbee9c1 tensor(-8094135.) tensor(14480713.) tensor(6.7718e+08)\r\ntorch 32 2.5.0a0+gitcbee9c1 tensor(-8094135.) tensor(14480713.) tensor(6.7718e+08)\r\ntorch 64 2.5.0a0+gitcbee9c1 tensor(-114.8141, dtype=torch.float64) tensor(4.7188, dtype=torch.float64) tensor(5.5413e-17, dtype=torch.float64)\r\nnumpy 2.0.0 -114.81414097646719 4.7187721908814435 2.1754394025006162e-16\r\nnumpy 32 2.0.0 -114.81414 4.7187724 5.3345637\r\nnumpy 64 2.0.0 -114.81414097646719 4.7187721908814435 2.1754394025006162e-16\r\n```\r\n\r\n', 'Cross references:\r\n\r\nhttps://github.com/pytorch/pytorch/issues/134905\r\n\r\nhttps://github.com/google/jax/issues/23367', 'Hi **@lddllddl** ,\r\nThank you for reporting the issue. I tried to reproduce the code on tensorflow v2.17 and observed the same issue. I am providing [gist](https://colab.research.google.com/gist/Venkat6871/2aa6ac3de2e03affa9c419a753a91b17/74965_2-17-nightly.ipynb) here for reference. Please allow to deep dive on the same and provide the update on the same. \r\nThank you!', 'Hi **@lddllddl** ,\r\nI reviewed your issue more deeply. As this [comment](https://github.com/google/jax/issues/23367#issuecomment-2324775551) said, these results are expected. \r\nThank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74965"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74965"">No</a>\n', 'Thanks']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.17.0

### Custom code

Yes

### OS platform and distribution

Linux x64 - Ubuntu docker image

### Mobile device

_No response_

### Python version

Python 3.12.5 

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

See code example - a particular linear system solves correctly under both 32 and 64 bit in NumPy, as well as 64 bit in both Tensorflow and PyTorch (where the problem was initially encountered), but not with 32 bit tensors. The Tensorflow 32 bit solution is less incorrect than that of PyTorch, but still quite unusable. 

### Standalone code to reproduce the issue

```shell
A = [[-77386.6328125, -13253.58984375, -7761.71484375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50099.83203125, 0.0, 0.0, 18231.466796875, 8855.2841796875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9055.3349609375, 4398.30517578125, 7761.71484375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [-13253.587890625, -109584.171875, -3769.975830078125, 0.0, 103146.7109375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8855.283203125, 4301.1376953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4398.30517578125, 2136.319580078125, 3769.975830078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [-7761.7158203125, -3769.97607421875, -6652.89892578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7761.7158203125, 3769.97607421875, 6652.89892578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, -50099.83203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50099.83203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 103146.7109375, 0.0, 0.0, -122629.984375, 0.0, 19483.26953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, -50099.83203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50099.83203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 19483.26953125, 0.0, -122629.984375, 0.0, 103146.7109375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -68331.296875, 8855.2841796875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18231.466796875, -8855.2841796875, 0.0, 50099.83203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 103146.7109375, 8855.283203125, -107447.8515625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -8855.283203125, 4301.1376953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [50099.83203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -78825.703125, -1745.823974609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19483.26953125, 0.0, 0.0, 9242.59765625, 1745.823974609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1745.8240966796875, -109656.6328125, -10906.15625, 0.0, 103146.7109375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1745.8240966796875, 329.7667541503906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6180.1552734375, 10906.15625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10906.15625, -19246.158203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10906.15625, 19246.158203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [18231.466796875, 8855.2841796875, 0.0, 50099.83203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -96132.125, -8855.2841796875, -2772.517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19483.26953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8317.5537109375, 0.0, 2772.517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [8855.283203125, 4301.1376953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 103146.7109375, 0.0, -8855.283203125, -135248.671875, -2772.517578125, 0.0, 19483.26953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8317.5537109375, 2772.517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2772.51806640625, -2772.51806640625, -233499.90625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 173201.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58449.80859375, 0.0, 2772.51806640625, 924.1725463867188, 2772.51806640625, 0.0, 924.1725463867188, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 50099.83203125, 0.0, 18231.466796875, -8855.2841796875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -96132.125, 8855.2841796875, -2772.517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19483.26953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8317.5537109375, 0.0, 2772.517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -8855.283203125, 4301.1376953125, 0.0, 0.0, 0.0, 0.0, 19483.26953125, 0.0, 8855.283203125, -135248.671875, 2772.517578125, 0.0, 103146.7109375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8317.5537109375, -2772.517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2772.51806640625, 2772.51806640625, -233499.90625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 173201.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2772.51806640625, 924.1725463867188, 0.0, 0.0, 58449.80859375, 0.0, 0.0, 0.0, 2772.51806640625, 0.0, 924.1725463867188, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50099.83203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -78825.703125, 1745.823974609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9242.59765625, -1745.823974609375, 0.0, 19483.26953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 103146.7109375, 0.0, 1745.8240966796875, -109656.6328125, 10906.15625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1745.8240966796875, 329.7667541503906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6180.1552734375, -10906.15625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10906.15625, -19246.158203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10906.15625, 19246.158203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19483.26953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -48209.13671875, -1745.823974609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19483.26953125, 0.0, 0.0, 9242.59765625, 1745.823974609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1745.8240966796875, -109656.6328125, -10906.15625, 0.0, 103146.7109375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1745.8240966796875, 329.7667541503906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6180.1552734375, 10906.15625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10906.15625, -19246.158203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10906.15625, 19246.158203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9242.59765625, 1745.823974609375, 0.0, 19483.26953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -56526.69140625, -1745.823974609375, -2772.517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19483.26953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8317.5537109375, 0.0, 2772.517578125, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1745.8240966796875, 329.7667541503906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 103146.7109375, 0.0, -1745.8240966796875, -131277.296875, -2772.517578125, 0.0, 19483.26953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8317.5537109375, 2772.517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2772.51806640625, -2772.51806640625, -233499.90625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 173201.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58449.80859375, 0.0, 2772.51806640625, 924.1725463867188, 2772.51806640625, 0.0, 924.1725463867188, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19483.26953125, 0.0, 0.0, 9242.59765625, -1745.823974609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -56526.69140625, 1745.823974609375, -2772.517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19483.26953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8317.5537109375, 0.0, 2772.517578125],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1745.8240966796875, 329.7667541503906, 0.0, 0.0, 0.0, 0.0, 0.0, 19483.26953125, 0.0, 1745.8240966796875, -131277.296875, 2772.517578125, 0.0, 103146.7109375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8317.5537109375, -2772.517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2772.51806640625, 2772.51806640625, -233499.90625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 173201.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2772.51806640625, 924.1725463867188, 0.0, 0.0, 58449.80859375, 0.0, 0.0, 0.0, 2772.51806640625, 0.0, 924.1725463867188],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19483.26953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -48209.13671875, 1745.823974609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9242.59765625, -1745.823974609375, 0.0, 19483.26953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 103146.7109375, 0.0, 1745.8240966796875, -109656.6328125, 10906.15625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1745.8240966796875, 329.7667541503906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6180.1552734375, -10906.15625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10906.15625, -19246.158203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10906.15625, 19246.158203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19483.26953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -38966.5390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -109326.8671875, -10906.15625, 0.0, 103146.7109375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6180.1552734375, 10906.15625, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10906.15625, -19246.158203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10906.15625, 19246.158203125, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9242.59765625, 1745.823974609375, 0.0, 19483.26953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -56526.69140625, -1745.823974609375, -2772.517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1745.8240966796875, 329.7667541503906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 103146.7109375, 0.0, -1745.8240966796875, -132519.359375, 1075.35009765625, 0.0, 19483.26953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9559.6123046875, -1075.35009765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2772.51806640625, 1075.3499755859375, -232696.703125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 173201.75, -1075.3499755859375, 120.96492767333984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58449.80859375, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19483.26953125, 0.0, 0.0, 9242.59765625, -1745.823974609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -56526.69140625, 1745.823974609375, -2772.517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1745.8240966796875, 329.7667541503906, 0.0, 0.0, 0.0, 0.0, 0.0, 19483.26953125, 0.0, 1745.8240966796875, -122959.75, 0.0, 0.0, 103146.7109375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2772.51806640625, 0.0, -232575.734375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 173201.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58449.80859375],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19483.26953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -38966.5390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 103146.7109375, 0.0, 0.0, -109326.8671875, 10906.15625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6180.1552734375, -10906.15625],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10906.15625, -19246.158203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10906.15625, 19246.158203125],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 173201.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -173201.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 173201.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -173201.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 173201.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -173201.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 173201.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -173201.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 173201.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -173201.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9559.6123046875, -1075.35009765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -9559.6123046875, 1075.35009765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1075.3499755859375, 120.96492767333984, 0.0, 0.0, 173201.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1075.3499755859375, -173322.71875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [9055.3349609375, 4398.30517578125, 7761.71484375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -18796.96875, -4398.30517578125, -7761.71484375, 0.0, 0.0, 0.0, 9741.634765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [4398.30517578125, 2136.319580078125, 3769.975830078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6180.1552734375, 10906.15625, 0.0, 0.0, 0.0, 0.0, 8317.5537109375, -2772.517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4398.30517578125, -26375.6640625, -11903.6142578125, 0.0, 9741.634765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [7761.7158203125, 3769.97607421875, 6652.89892578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10906.15625, 19246.158203125, 0.0, 0.0, 58449.80859375, 0.0, -2772.51806640625, 924.1725463867188, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -7761.7158203125, -11903.6142578125, -85273.0390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -9741.634765625, 0.0, 0.0, 0.0, 0.0, 0.0, 9741.634765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8317.5537109375, 2772.517578125, 0.0, 0.0, 0.0, 0.0, 6180.1552734375, -10906.15625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9741.634765625, 0.0, 0.0, -24239.34375, 8133.638671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2772.51806640625, 924.1725463867188, 0.0, 0.0, 58449.80859375, 0.0, -10906.15625, 19246.158203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8133.63818359375, -78620.140625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8317.5537109375, 0.0, 2772.517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9741.634765625, 0.0, 0.0, 0.0, 0.0, 0.0, -27800.822265625, 0.0, -2772.517578125, 0.0, 0.0, 0.0, 9741.634765625, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6180.1552734375, 10906.15625, 0.0, 0.0, 0.0, 0.0, 8317.5537109375, -2772.517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -24239.34375, -8133.638671875, 0.0, 9741.634765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2772.51806640625, 0.0, 924.1725463867188, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10906.15625, 19246.158203125, 0.0, 0.0, 58449.80859375, 0.0, -2772.51806640625, 924.1725463867188, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2772.51806640625, -8133.63818359375, -79544.3125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8317.5537109375, 0.0, 2772.517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9741.634765625, 0.0, 0.0, 0.0, 0.0, 0.0, -27800.822265625, 0.0, -2772.517578125, 0.0, 0.0, 0.0, 9741.634765625, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8317.5537109375, 2772.517578125, 0.0, 0.0, 0.0, 0.0, 6180.1552734375, -10906.15625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9741.634765625, 0.0, 0.0, -24239.34375, 8133.638671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2772.51806640625, 0.0, 924.1725463867188, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2772.51806640625, 924.1725463867188, 0.0, 0.0, 58449.80859375, 0.0, -10906.15625, 19246.158203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2772.51806640625, 8133.63818359375, -79544.3125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8317.5537109375, 0.0, 2772.517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9741.634765625, 0.0, 0.0, 0.0, 0.0, 0.0, -27800.822265625, 0.0, -2772.517578125, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6180.1552734375, 10906.15625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -15921.7900390625, -10906.15625, 0.0, 9741.634765625, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2772.51806640625, 0.0, 924.1725463867188, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10906.15625, 19246.158203125, 0.0, 0.0, 58449.80859375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2772.51806640625, -10906.15625, -78620.140625, 0.0, 0.0, 0.0],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8317.5537109375, 0.0, 2772.517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9741.634765625, 0.0, 0.0, 0.0, 0.0, 0.0, -27800.822265625, 0.0, -2772.517578125],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6180.1552734375, -10906.15625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9741.634765625, 0.0, 0.0, -15921.7900390625, 10906.15625],
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2772.51806640625, 0.0, 924.1725463867188, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58449.80859375, 0.0, -10906.15625, 19246.158203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2772.51806640625, 10906.15625, -78620.140625]]

B = [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 2500.0, -0.0, -0.0, 2500.0, -0.0, -0.0, 2500.0, -0.0, -0.0, 2500.0, -0.0, -0.0, 2500.0, -0.0, -0.0, 2500.0, -0.0, -0.0, 2500.0, -0.0, -0.0, 2500.0, -0.0, -0.0, 2500.0, -0.0, -0.0, 2500.0, -0.0, -0.0, 2500.0, -0.0, -0.0, 2500.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0]


import torch as t
import numpy as np

Xt = t.linalg.solve(t.Tensor(A),t.Tensor(B))
print('torch ',t.__version__,Xt.min(),Xt.max(),(t.Tensor(A) @ Xt - t.Tensor(B)).pow(2).sum())
Xt32 = t.linalg.solve(t.Tensor(A).to(t.float32),t.Tensor(B).to(t.float32))
print('torch 32',t.__version__,Xt32.min(),Xt32.max(),(t.Tensor(A).to(t.float32) @ Xt32 - t.Tensor(B).to(t.float32)).pow(2).sum())
Xt64 = t.linalg.solve(t.Tensor(A).to(t.float64),t.Tensor(B).to(t.float64))
print('torch 64',t.__version__,Xt64.min(),Xt64.max(),(t.Tensor(A).to(t.float64) @ Xt64 - t.Tensor(B).to(t.float64)).pow(2).sum())

Xn = np.linalg.solve(np.array(A),np.array(B))
print('numpy',np.__version__,Xn.min(),Xn.max(),((np.array(A) @ Xn - np.array(B))**2).sum())
Xn32 = np.linalg.solve(np.array(A,dtype=np.float32),np.array(B,dtype=np.float32))
print('numpy 32',np.__version__,Xn32.min(),Xn32.max(),((np.array(A,dtype=np.float32) @ Xn32 - np.array(B,dtype=np.float32))**2).sum())
Xn64 = np.linalg.solve(np.array(A,dtype=np.float64),np.array(B,dtype=np.float64))
print('numpy 64',np.__version__,Xn64.min(),Xn64.max(),((np.array(A,dtype=np.float64) @ Xn64 - np.array(B,dtype=np.float64))**2).sum())



Xt32cu = t.linalg.solve(t.Tensor(A).to(t.float32).cuda(),t.Tensor(B).to(t.float32).cuda())
print('torch 32 cuda',t.__version__,Xt32cu.min(),Xt32cu.max(),(t.Tensor(A).to(t.float32).cuda() @ Xt32cu - t.Tensor(B).to(t.float32).cuda()).pow(2).sum())
Xt64cu = t.linalg.solve(t.Tensor(A).to(t.float64).cuda(),t.Tensor(B).to(t.float64).cuda())
print('torch 64 cuda',t.__version__,Xt64cu.min(),Xt64cu.max(),(t.Tensor(A).to(t.float64).cuda() @ Xt64cu - t.Tensor(B).to(t.float64).cuda()).pow(2).sum())

#fp16 - does not run

#Xt16 = t.linalg.solve(t.Tensor(A).to(t.float16),t.Tensor(B).to(t.float16))
#print('torch 16',t.__version__,Xt16.min(),Xt16.max(),(t.Tensor(A).to(t.float16) @ Xt16 - t.Tensor(B).to(t.float16)).pow(2).sum())
#Xt16cu = t.linalg.solve(t.Tensor(A).to(t.float16).cuda(),t.Tensor(B).to(t.float16).cuda())
#print('torch 16 cuda',t.__version__,Xt16cu.min(),Xt16cu.max(),(t.Tensor(A).to(t.float16).cuda() @ Xt16cu - t.Tensor(B).to(t.float16).cuda()).pow(2).sum())




import tensorflow as tf

Xtf32 = tf.linalg.solve(tf.convert_to_tensor(A,dtype=tf.float32),tf.convert_to_tensor(B,dtype=tf.float32)[:,None])
print('tensorflow 32',tf.__version__,tf.reduce_min(Xtf32),tf.reduce_max(Xtf32),
    tf.reduce_sum((tf.convert_to_tensor(A,dtype=tf.float32) @ Xtf32 - tf.convert_to_tensor(B,dtype=tf.float32)[:,None])**2))
Xtf64 = tf.linalg.solve(tf.convert_to_tensor(A,dtype=tf.float64),tf.convert_to_tensor(B,dtype=tf.float64)[:,None])
print('tensorflow 64',tf.__version__,tf.reduce_min(Xtf64),tf.reduce_max(Xtf64),
    tf.reduce_sum((tf.convert_to_tensor(A,dtype=tf.float64) @ Xtf64 - tf.convert_to_tensor(B,dtype=tf.float64)[:,None])**2))
```


### Relevant log output

```shell
tensorflow 32 2.17.0 tf.Tensor(-7224.5776, shape=(), dtype=float32) tf.Tensor(12481.284, shape=(), dtype=float32) tf.Tensor(608.6341, shape=(), dtype=float32)

tensorflow 64 2.17.0 tf.Tensor(-114.8141409765533, shape=(), dtype=float64) tf.Tensor(4.718772190885021, shape=(), dtype=float64) tf.Tensor(1.1391063518181607e-16, shape=(), dtype=float64)
```
"
2500674342,74972,Tensorflow/Keras_nlp bug,closed,2024-09-02 11:08:08+00:00,2024-09-20T01:59:57Z,2024-09-20T01:59:54Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/74972,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', '2.17']","['@Humbulani1234,\r\nThough the backend is the tensorflow, it contains the Keras3.0 by default and also Unable to register cuBLAS factory error is the known issue in the tensorflow. \r\nCould you please check with the keras-nlp or keras-team/keras for the quick resolution. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74972"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74972"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

tf 2.17.0

### Custom code

No

### OS platform and distribution

Ubuntu 22.04

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I have experienced this error while running KerasNLP with Tensorflow as the backend. I tried to thoroughly investigate the issue, and I think the error is essentially with Tensorflow code and not KerasNLP. The following is a detailed description of the error:

**Describe the bug**

I encountred an error/bug while trying to execute a docstring code example from the file `keras_nlp.src.models.gpt2.causal_lm.py` and I have reproduced the example code below:

``` python

features = [""a quick fox."", ""a fox quick.""]
vocab = {""<|endoftext|>"": 0, ""a"": 4, ""Ġquick"": 5, ""Ġfox"": 6}
merges = [""Ġ q"", ""u i"", ""c k"", ""ui ck"", ""Ġq uick""]
merges += [""Ġ f"", ""o x"", ""Ġf ox""]

tokenizer = keras_nlp.models.GPT2Tokenizer(
    vocabulary=vocab,
    merges=merges,
)
preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor(
    tokenizer=tokenizer,
    sequence_length=128,
)
backbone = keras_nlp.models.GPT2Backbone(
    vocabulary_size=30552,
    num_layers=4,
    num_heads=4,
    hidden_dim=256,
    intermediate_dim=512,
    max_sequence_length=128,
)
gpt2_lm = keras_nlp.models.GPT2CausalLM(
    backbone=backbone,
    preprocessor=preprocessor,
)
gpt2_lm.fit(x=features, batch_size=2)
```
The following is a comprehensive description of the error, reproduced below and debugging using `pdb`:

```
> /home/humbulani/keras-master/env/lib/python3.10/site-packages/keras_nlp/src/models/causal_lm.py(79)__init__()
-> super().__init__(*args, **kwargs)
(Pdb) c
> /home/humbulani/keras-master/env/lib/python3.10/site-packages/keras_nlp/src/models/causal_lm.py(140)compile()
-> super().compile(
(Pdb) c
> /home/humbulani/keras-master/nlp_example.py(94)<module>()
-> gpt2_lm.fit(x=features, batch_size=2)
(Pdb) c
> /home/humbulani/keras-master/env/lib/python3.10/site-packages/keras_nlp/src/utils/pipeline_model.py(196)fit()
-> return super().fit(
(Pdb) c
> /home/humbulani/keras-master/keras/src/backend/tensorflow/trainer.py(269)fit()
-> self._assert_compile_called(""fit"")
(Pdb) c
> /home/humbulani/keras-master/keras/src/trainers/epoch_iterator.py(66)__init__()
-> self.data_adapter = data_adapters.get_data_adapter(
(Pdb) c
> /home/humbulani/keras-master/keras/src/backend/tensorflow/trainer.py(331)fit()
-> logs = self.train_function(iterator)
(Pdb) c
> /home/humbulani/keras-master/keras/src/backend/tensorflow/trainer.py(125)one_step_on_iterator()
-> """"""Runs a single training step given a Dataset iterator.""""""
(Pdb) c
> /home/humbulani/keras-master/keras/src/backend/tensorflow/trainer.py(50)train_step()
-> x, y, sample_weight = data_adapter_utils.unpack_x_y_sample_weight(data)
(Pdb) c
> /home/humbulani/keras-master/keras/src/losses/losses.py(1724)sparse_categorical_crossentropy()
-> res = ops.sparse_categorical_crossentropy(
(Pdb) c
2024-08-19 12:03:15.742874: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at sparse_xent_op.cc:103 : INVALID_ARGUMENT: Received a label value of -1 which is outside the valid range of [0, 30552).  Label values: 4 5 6 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 6 5 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
2024-08-19 12:03:15.742930: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Received a label value of -1 which is outside the valid range of [0, 30552).  Label values: 4 5 6 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 6 5 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Traceback (most recent call last):
  File ""/home/humbulani/keras-master/nlp_example.py"", line 94, in <module>
    gpt2_lm.fit(x=features, batch_size=2)
  File ""/home/humbulani/keras-master/env/lib/python3.10/site-packages/keras_nlp/src/utils/pipeline_model.py"", line 196, in fit
    return super().fit(
  File ""/home/humbulani/keras-master/keras/src/utils/traceback_utils.py"", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/home/humbulani/keras-master/env/lib/python3.10/site-packages/tensorflow/python/framework/ops.py"", line 5983, in raise_from_not_ok_status
    raise core._status_to_exception(e) from None  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__SparseSoftmaxCrossEntropyWithLogits_device_/job:localhost/replica:0/task:0/device:CPU:0}} Received a label value of -1 which is outside the valid range of [0, 30552).  Label values: 4 5 6 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 6 5 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 [Op:SparseSoftmaxCrossEntropyWithLogits] name: 
```
Th error is clear:  `the -1 value`. I've traced the error to the following function from the file `keras.src.backend.tensorflow.trainer`:

```python
@tf.autograph.experimental.do_not_convert
    def one_step_on_iterator(iterator):
        """"""Runs a single training step given a Dataset iterator.""""""
        data = next(iterator) 
        outputs = self.distribute_strategy.run(
            one_step_on_data, args=(data,)
        )
        outputs = reduce_per_replica(
            outputs,
            self.distribute_strategy,
            reduction=""auto"",
        )
        return outputs
```
The line `data=next(iterator)` computes the labels and therefore the -1 value is created here. The `iterator` argument is a tensorflow `OwnedIterator` and executes from the file `tensorflow.python.data.ops.iterator_ops` and the executed function reproduced below:

```python
def _next_internal(self):
    autograph_status = autograph_ctx.control_status_ctx().status
    autograph_disabled = autograph_status == autograph_ctx.Status.DISABLED
    if not context.executing_eagerly() and autograph_disabled:
      self._get_next_call_count += 1
      if self._get_next_call_count > GET_NEXT_CALL_ERROR_THRESHOLD:
        raise ValueError(GET_NEXT_CALL_ERROR_MESSAGE)

    if not context.executing_eagerly():
      # TODO(b/169442955): Investigate the need for this colocation constraint.
      with ops.colocate_with(self._iterator_resource):
        ret = gen_dataset_ops.iterator_get_next(
            self._iterator_resource,
            output_types=self._flat_output_types,
            output_shapes=self._flat_output_shapes)
      return structure.from_compatible_tensor_list(self._element_spec, ret)
```
which executes `gen_dataset_ops.iterator_get_next` from the file `tensorflow.python.data.ops.gen_dataset_ops`, and from here to the relevant ops execution which I didn't trace further since it also leads to C++ execution code.

## Enviroment

```
Linux 6.5.0-26-generic #26~22.04.1-Ubuntu
keras - 3.5.0
python - 3.10.12
tensorflow - 2.17.0
kerasNLP - 0.14.4
```
 - Additional tensorflow info:
  ```
  2024-08-19 12:20:02.135293: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-08-19 12:20:02.154198: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-08-19 12:20:02.159831: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-19 12:20:02.174579: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-19 12:20:03.092334: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-08-19 12:20:04.517556: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
  ```
**To Reproduce**

Link to a [Colab Notebook](https://colab.research.google.com/drive/1EbFdLMpPiPRJoLMNwG42OR-ULyQBfsqp?authuser=0#scrollTo=tgFAiISLQ9zW)

**Expected behavior**

I expected the model to train normally by running the `fit()` function without any complications and return a `History` object.

**Would you like to help us fix it?**


### Standalone code to reproduce the issue

```shell
# Standard library dependenies
import os
!pip install keras_nlp

# Third party dependencies
import numpy as np

# Tensorflow dependencies
import tensorflow.data as tf_data
import tensorflow.strings as tf_strings
import tensorflow as tf

# Keras dependencies
import keras

# Keras_NLP dependencies
import keras_nlp

# Specific dependencies for GPT Model
from keras import ops

from keras_nlp.src.api_export import keras_nlp_export
from keras_nlp.src.models.causal_lm import CausalLM
from keras_nlp.src.models.gpt2.gpt2_backbone import GPT2Backbone
from keras_nlp.src.models.gpt2.gpt2_causal_lm_preprocessor import (
    GPT2CausalLMPreprocessor,
)
from keras_nlp.src.utils.tensor_utils import any_equal


features = [""a quick fox."", ""a fox quick.""]
vocab = {""<|endoftext|>"": 0, ""a"": 4, ""Ġquick"": 5, ""Ġfox"": 6}
merges = [""Ġ q"", ""u i"", ""c k"", ""ui ck"", ""Ġq uick""]
merges += [""Ġ f"", ""o x"", ""Ġf ox""]

tokenizer = keras_nlp.models.GPT2Tokenizer(
    vocabulary=vocab,
    merges=merges,
)
preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor(
    tokenizer=tokenizer,
    sequence_length=128,
)
backbone = keras_nlp.models.GPT2Backbone(
    vocabulary_size=30552,
    num_layers=4,
    num_heads=4,
    hidden_dim=256,
    intermediate_dim=512,
    max_sequence_length=128,
)
gpt2_lm = keras_nlp.models.GPT2CausalLM(
    backbone=backbone,
    preprocessor=preprocessor,
)

gpt2_lm.fit(x=features, batch_size=2)
```


### Relevant log output

```shell
> /home/humbulani/keras-master/env/lib/python3.10/site-packages/keras_nlp/src/models/causal_lm.py(79)__init__()
-> super().__init__(*args, **kwargs)
(Pdb) c
> /home/humbulani/keras-master/env/lib/python3.10/site-packages/keras_nlp/src/models/causal_lm.py(140)compile()
-> super().compile(
(Pdb) c
> /home/humbulani/keras-master/nlp_example.py(94)<module>()
-> gpt2_lm.fit(x=features, batch_size=2)
(Pdb) c
> /home/humbulani/keras-master/env/lib/python3.10/site-packages/keras_nlp/src/utils/pipeline_model.py(196)fit()
-> return super().fit(
(Pdb) c
> /home/humbulani/keras-master/keras/src/backend/tensorflow/trainer.py(269)fit()
-> self._assert_compile_called(""fit"")
(Pdb) c
> /home/humbulani/keras-master/keras/src/trainers/epoch_iterator.py(66)__init__()
-> self.data_adapter = data_adapters.get_data_adapter(
(Pdb) c
> /home/humbulani/keras-master/keras/src/backend/tensorflow/trainer.py(331)fit()
-> logs = self.train_function(iterator)
(Pdb) c
> /home/humbulani/keras-master/keras/src/backend/tensorflow/trainer.py(125)one_step_on_iterator()
-> """"""Runs a single training step given a Dataset iterator.""""""
(Pdb) c
> /home/humbulani/keras-master/keras/src/backend/tensorflow/trainer.py(50)train_step()
-> x, y, sample_weight = data_adapter_utils.unpack_x_y_sample_weight(data)
(Pdb) c
> /home/humbulani/keras-master/keras/src/losses/losses.py(1724)sparse_categorical_crossentropy()
-> res = ops.sparse_categorical_crossentropy(
(Pdb) c
2024-08-19 12:03:15.742874: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at sparse_xent_op.cc:103 : INVALID_ARGUMENT: Received a label value of -1 which is outside the valid range of [0, 30552).  Label values: 4 5 6 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 6 5 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
2024-08-19 12:03:15.742930: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Received a label value of -1 which is outside the valid range of [0, 30552).  Label values: 4 5 6 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 6 5 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Traceback (most recent call last):
  File ""/home/humbulani/keras-master/nlp_example.py"", line 94, in <module>
    gpt2_lm.fit(x=features, batch_size=2)
  File ""/home/humbulani/keras-master/env/lib/python3.10/site-packages/keras_nlp/src/utils/pipeline_model.py"", line 196, in fit
    return super().fit(
  File ""/home/humbulani/keras-master/keras/src/utils/traceback_utils.py"", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/home/humbulani/keras-master/env/lib/python3.10/site-packages/tensorflow/python/framework/ops.py"", line 5983, in raise_from_not_ok_status
    raise core._status_to_exception(e) from None  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__SparseSoftmaxCrossEntropyWithLogits_device_/job:localhost/replica:0/task:0/device:CPU:0}} Received a label value of -1 which is outside the valid range of [0, 30552).  Label values: 4 5 6 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 6 5 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 [Op:SparseSoftmaxCrossEntropyWithLogits] name:
```
"
2501595206,74993,TFLite Hexagon Delegate not working for QCOM SM6375 SOC.,closed,2024-09-02 21:21:47+00:00,2024-11-10T02:03:37Z,2024-11-10T02:03:34Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/74993,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite']","['Hi, @hholokai \r\n\r\nI apologize for the delayed response, The [NNAPI](https://www.tensorflow.org/lite/android/delegates/nnapi) and [Hexagon](https://www.tensorflow.org/lite/android/delegates/hexagon) delegates are deprecated and no longer supported by TensorFlow Lite. For more information, see the [NNAPI Migration Guide](https://developer.android.com/ndk/guides/neuralnetworks/migration-guide) and [TF Lite delegates documentation](https://www.tensorflow.org/lite/performance/delegates).\r\n\r\nThank you for your cooperation and patience.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74993"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74993"">No</a>\n']","I'm trying to get a quantized model running on the Qualcomm SM6375 DSP on a Zebra ET40 tablet, without success.  SOC info:

```
$ cat /sys/devices/soc0/soc_id
507
```

The FP32 model works fine on CPU and GPU.  However, when I try to run the INT8 model on the DSP, it falls back to running the XNNPack Delegate on CPU, which is slow:

```
$ ./benchmark_model --graph=model.tflite --use_hexagon=true                                                                
INFO: STARTING!
INFO: Log parameter values verbosely: [0]
INFO: Graph: [model.tflite]
INFO: Signature to run: []
INFO: Use Hexagon: [1]
INFO: Loaded model model.tflite
INFO: Initialized TensorFlow Lite runtime.
loaded libcdsprpc.so
WARNING: Failed to fetch Hexagon NN version. This might be because you're using incompatible versions of libhexagon_interface and libhexagon_nn_skel. You must use compatible versions. Refer to Tensorflow Lite Hexagon Delegate Guide.
INFO: Hexagon Delegate is not supported.

WARN: Could not create Hexagon delegate: platform may not support delegate or required libraries are missing
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
...
```

I've tried several different versions of the Hexagon libraries referred to below, but all fall back to the CPU:

https://www.tensorflow.org/lite/android/delegates/hexagon

This page above has the following warning:

> Caution: The currently released versions of the Hexagon delegate, up to version 1.20.0.1, are no longer supported. An updated version of this delegate is expected soon.

I've also tried the NNAPI (--use_nnapi=true), but that also falls back to the CPU.

Any help would be appreciated.
"
2502048804,74999,tensorflow.python.framework.errors_impl.InternalError,closed,2024-09-03 06:44:17+00:00,2024-10-25T01:49:51Z,2024-10-15T02:02:48Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/74999,"['stat:awaiting response', 'type:bug', 'stale', 'TF 1.13']","['Hi **@suoyike1** ,\r\nWe see that you are using old version of tensorflow (1.x) which is not actively supported, We recommend that you upgrade to 2.16.0 and let us know if the issue still persists in newer versions.\r\nThank you!', '\r\n\r\n> Hi **@suoyike1** , We see that you are using old version of tensorflow (1.x) which is not actively supported, We recommend that you upgrade to 2.6.0 and let us know if the issue still persists in newer versions. Thank you!\r\n\r\nThank your reply!OK. I try to upgrade tensorflow to 2.6.0', 'Hi @suoyike1 ,\r\nApologies for the delay. Actually, I meant to say that you need to upgrade to version 2.16.0 or 2.17.0. Please let us know if the issue still persists in the newer versions. However, I mistakenly typed 2.6.0 instead of 2.16.0. I apologize for this earlier miscommunication.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74999"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/74999"">No</a>\n', 'thank you all very much! I had address this problem for upgrading 2.6.0. Nothing more happy than code run correctly! thanks again!']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf-gpu 1.13.1

### Custom code

No

### OS platform and distribution

ubuntu18.04

### Mobile device

/

### Python version

3.7

### Bazel version

0.19.2

### GCC/compiler version

4.8

### CUDA/cuDNN version

10.0

### GPU model and memory

8G

### Current behavior?

when train a model it stop early then i get bug

### Standalone code to reproduce the issue

```shell
https://github.com/MarlonCajamarca/Keras-LSTM-Trajectory-Prediction/blob/5297ab5e649971ed42ca9f8efa9fe925b7da982b/Train_Test_Scripts/LSTM_trainer.py
```


### Relevant log output

```shell
(lstm) wd@wd-Lenovo-Legion-Y9000K2021H:~/cjy2024.3/Keras-LSTM-Trajectory-Prediction/Train_Test_Scripts$ python LSTM_trainer.py  /home/wd/cjy2024.3/Keras-LSTM-Trajectory-Prediction/output_folder/train-test.h5  /home/wd/cjy2024.3/Keras-LSTM-Trajectory-Prediction/output_folder  config_lstm.json
Using TensorFlow backend.
2024-09-03 14:49:26.341775: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2024-09-03 14:49:26.364931: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz
2024-09-03 14:49:26.365397: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55c1dcd26d90 executing computations on platform Host. Devices:
2024-09-03 14:49:26.365410: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2024-09-03 14:49:26.452693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-09-03 14:49:26.453128: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55c1dcbe8a90 executing computations on platform CUDA. Devices:
2024-09-03 14:49:26.453144: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Laptop GPU, Compute Capability 8.6
2024-09-03 14:49:26.453219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: NVIDIA GeForce RTX 3070 Laptop GPU major: 8 minor: 6 memoryClockRate(GHz): 1.56
pciBusID: 0000:01:00.0
totalMemory: 7.77GiB freeMemory: 6.92GiB
2024-09-03 14:49:26.453229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2024-09-03 14:49:26.453726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-09-03 14:49:26.453732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2024-09-03 14:49:26.453735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2024-09-03 14:49:26.453774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6733 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6)
 Datasets successfully loaded!
 X_train shape : (392399, 4, 15) 
 Y_train shape : (392399, 4, 30)
 --> LSTM model instantiation started!
WARNING:tensorflow:From /home/wd/anaconda3/envs/lstm/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
 --> LSTM model successfully created...
____________________________________________________________________________________________________________________________________________________________________________________
Layer (type)                                                                     Output Shape                                                            Param #                    
====================================================================================================================================================================================
lstm_inputs (InputLayer)                                                         (None, None, 15)                                                        0                          
____________________________________________________________________________________________________________________________________________________________________________________
Bidirectional_lstm_1 (Bidirectional)                                             (None, None, 1024)                                                      2166784                    
____________________________________________________________________________________________________________________________________________________________________________________
Bidirectional_lstm_2 (Bidirectional)                                             (None, None, 960)                                                       5783040                    
____________________________________________________________________________________________________________________________________________________________________________________
Bidirectional_lstm_3 (Bidirectional)                                             (None, None, 640)                                                       3281920                    
____________________________________________________________________________________________________________________________________________________________________________________
time_distributed_0 (TimeDistributed)                                             (None, None, 256)                                                       164096                     
____________________________________________________________________________________________________________________________________________________________________________________
time_distributed_1 (TimeDistributed)                                             (None, None, 128)                                                       32896                      
____________________________________________________________________________________________________________________________________________________________________________________
time_distributed_output (TimeDistributed)                                        (None, None, 30)                                                        3870                       
====================================================================================================================================================================================
Total params: 11,432,606
Trainable params: 11,432,606
Non-trainable params: 0
____________________________________________________________________________________________________________________________________________________________________________________
create_models have done_______
compile_models have done_______
Overview hyperparameters used on training :  ARCH--15i_30o_10sld_norm3_vill_cascade2-_Data-_final_concat512___bs-512_lr-0.01_loss-mae_opt-Ranger_BD-True_BDmrg-concat_amsG-False_DP-False_sw-0.9_sync-1_act-selu_minLR-1e-05_ptc-10_ep-100
[Errno 17] File exists: '/home/wd/cjy2024.3/Keras-LSTM-Trajectory-Prediction/output_folder/ARCH--15i_30o_10sld_norm3_vill_cascade2-_Data-_final_concat512___bs-512_lr-0.01_loss-mae_opt-Ranger_BD-True_BDmrg-concat_amsG-False_DP-False_sw-0.9_sync-1_act-selu_minLR-1e-05_ptc-10_ep-100'
WARNING:tensorflow:From /home/wd/anaconda3/envs/lstm/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Train on 333539 samples, validate on 58860 samples
Epoch 1/100
2024-09-03 14:52:29.476637: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
2024-09-03 15:03:24.097886: E tensorflow/stream_executor/cuda/cuda_dnn.cc:82] CUDNN_STATUS_EXECUTION_FAILED
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1477): 'cudnnRNNForwardTraining( cudnn.handle(), rnn_desc.handle(), model_dims.seq_length, input_desc.handles(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), rnn_desc.params_handle(), params.opaque(), output_desc.handles(), output_data->opaque(), output_h_desc.handle(), output_h_data->opaque(), output_c_desc.handle(), output_c_data->opaque(), workspace.opaque(), workspace.size(), reserve_space.opaque(), reserve_space.size())'
2024-09-03 15:03:24.097921: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at cudnn_rnn_ops.cc:1224 : Internal: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, seq_length, batch_size]: [1, 15, 512, 1, 4, 512] 
2024-09-03 15:03:24.097988: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at cudnn_rnn_ops.cc:1224 : Internal: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, seq_length, batch_size]: [1, 15, 512, 1, 4, 512] 
Traceback (most recent call last):
  File ""LSTM_trainer.py"", line 450, in <module>
    LstmTrainer(args.dataset, args.output, hyperparameters, args.use_checkpoint).run()
  File ""LSTM_trainer.py"", line 77, in run
    self.fit_models()
  File ""LSTM_trainer.py"", line 235, in fit_models
    callbacks=[early_stop, model_checkpoint])
  File ""/home/wd/anaconda3/envs/lstm/lib/python3.7/site-packages/keras/engine/training.py"", line 1039, in fit
    validation_steps=validation_steps)
  File ""/home/wd/anaconda3/envs/lstm/lib/python3.7/site-packages/keras/engine/training_arrays.py"", line 199, in fit_loop
    outs = f(ins_batch)
  File ""/home/wd/anaconda3/envs/lstm/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py"", line 2715, in __call__
    return self._call(inputs)
  File ""/home/wd/anaconda3/envs/lstm/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py"", line 2675, in _call
    fetched = self._callable_fn(*array_vals)
  File ""/home/wd/anaconda3/envs/lstm/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1439, in __call__
    run_metadata_ptr)
  File ""/home/wd/anaconda3/envs/lstm/lib/python3.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 528, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InternalError: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, seq_length, batch_size]: [1, 15, 512, 1, 4, 512] 
         [[{{node Bidirectional_lstm_1/CudnnRNN_1}}]]
         [[{{node loss/mul}}]]

```



Tue Sep  3 15:01:13 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.223.02   Driver Version: 470.223.02   CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |
| N/A   52C    P8    19W /  N/A |   1699MiB /  7957MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1269      G   /usr/lib/xorg/Xorg                 38MiB |
|    0   N/A  N/A      1341      G   /usr/bin/gnome-shell              106MiB |
|    0   N/A  N/A      1710      G   /usr/lib/xorg/Xorg                354MiB |
|    0   N/A  N/A      2184      G   /usr/bin/gnome-shell               50MiB |
|    0   N/A  N/A      2545      G   /usr/lib/firefox/firefox          156MiB |
|    0   N/A  N/A     14950      C   python                            987MiB |
+-----------------------------------------------------------------------------+"
2502146161,75002,Disk cache not caching entire dataset - weird behaviour,closed,2024-09-03 07:38:33+00:00,2024-10-15T02:02:49Z,2024-10-15T02:02:47Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/75002,"['stat:awaiting response', 'type:bug', 'stale', 'comp:data', '2.17']","['Hi **@nmilosev** ,\r\nSorry for the delay. I tried to run your code on Colab using TF 2.17.0 and the nightly versions, and I did not encounter any issues. Please find the [gist](https://colab.research.google.com/gist/Venkat6871/bd7f53c2cbd8ef1601f1245e6342a011/75002_tf_2-17-0-nightly-v.ipynb) here for reference. Correct me if I am wrong.\r\nThank you! ', 'Hi @Venkat6871 thanks for your help with this. Sorry for the delay on my side as well.\r\n\r\nI tried it in Colab and like you, no messages are printed. However I am not sure if `stderr` is shown on Colab.\r\n\r\n\r\nWhen running in Docker the image `tensorflow/tensorflow:2.17.0-gpu` I can replicate this behavior 100% of the time.\r\n\r\nHere is the log attached. [tf2_cache_log.txt](https://github.com/user-attachments/files/16959495/tf2_cache_log.txt)\r\n\r\nAnd a screenshot:\r\n\r\n![image](https://github.com/user-attachments/assets/2d5ec164-60b3-4f55-baa3-ef9b12d8613d)\r\n\r\nLet me know if there is something I should try to change or to test.\r\n\r\nThanks!\r\n', 'Hi **@nmilosev** ,\r\nSorry for the delay. The same issue is being tracked in another issue. Here I am adding that [issue](https://github.com/tensorflow/tensorflow/issues/56904) for your reference; please go through it once. I hope it will be useful for you.\r\nThank you!\r\n\r\n', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75002"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75002"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.17.0

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04 (in Docker)

### Mobile device

_No response_

### Python version

Python 3.11.0

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.3

### GPU model and memory

RTX3080

### Current behavior?

When using `tf.data` pipeline, caching to disk produces warnings that the cache will be discarded because the iterator didn't see the whole dataset.

When using in-memory cache, the issue is not there.

### Standalone code to reproduce the issue

```py
# test 1 - works
for s in tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5]).cache():
    print(s)

# test 2 - warning thrown
for s in tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5]).cache(""test_disk_cache""):
    print(s)
```


### Relevant log output

```shell
# test 1 - output

tf.Tensor(1, shape=(), dtype=int32)                                                                                                                                                                                                             
tf.Tensor(2, shape=(), dtype=int32)                                                                                                                                                                                                             
tf.Tensor(3, shape=(), dtype=int32)                                                                                                                                                                                                             
tf.Tensor(4, shape=(), dtype=int32)                                                                                                                                                                                                             
tf.Tensor(5, shape=(), dtype=int32)                                                                                                                                                                                                             
2024-09-03 07:32:36.163152: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence

# test 2 - issue

tf.Tensor(1, shape=(), dtype=int32)
tf.Tensor(2, shape=(), dtype=int32)
tf.Tensor(3, shape=(), dtype=int32)
tf.Tensor(4, shape=(), dtype=int32)
tf.Tensor(5, shape=(), dtype=int32)
2024-09-03 07:32:59.122496: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-09-03 07:32:59.122628: W tensorflow/core/kernels/data/cache_dataset_ops.cc:332] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
```
"
2502845355,75032,None gradients when using tf gradient tape,closed,2024-09-03 13:09:55+00:00,2024-09-19T01:59:57Z,2024-09-19T01:59:54Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/75032,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","['Hi **@Senantq** ,\r\nI tried to run your code on Colab using TF v2.17, but it is asking for a directory. Could you please provide the path related to your issue?\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75032"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75032"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

tf 2.17.0

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 24.04 LTS

### Mobile device

_No response_

### Python version

3.11.9

### Bazel version

binary

### GCC/compiler version

binary

### CUDA/cuDNN version

12.3 (pip install tensorflow[and-cuda)==2.17)

### GPU model and memory

RTX A4500 laptop, 16 gigs

### Current behavior?

I tried to load a trained model using tensorflow and keras in order to compute some saliency maps. To do so, I need to compute the gradients with respect to the inputs. However, it returns None gradients whereas it worked fine before, e.g., with tf 2.10.
A reprex with the model weights, a datafile and a minimal version of the code can be find using the following google drive link:

### Standalone code to reproduce the issue

```shell
https://drive.google.com/file/d/1fcind0XWxdghlKvN237y0L177JbEgOcV/view?usp=sharing
```


### Relevant log output

_No response_"
2504494247,75089,error: required argument is not an integer,closed,2024-09-04 07:11:33+00:00,2024-10-10T02:01:34Z,2024-10-10T02:01:32Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/75089,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'TFLiteConverter', 'TF 2.13']","[""Hi, @muhdaniyal252 \r\n\r\nThank you for bringing this issue to our attention and I see you've passed the `0 `value as argument while calling to `builder = flatbuffers.Builder(0)` that may be causing this issue as per documentation by default it sets to `initialSize=1024` which initializes a Builder of size 1024 bytes as `initialSize` and as per documentation string **`The internal buffer is grown as needed. flatbuffers: Cannot create Builder larger than 2 gigabytes.`**\r\n\r\nplease refer this source code [link](https://github.com/google/flatbuffers/blob/8db59321d9f02cdffa30126654059c7d02f70c32/python/flatbuffers/builder.py#L92) \r\n\r\nPlease set the initial size to a reasonable value based on your expected data size. Even if you're unsure of the exact size value like 1024 (1 KB) is often a good starting point. If your data size is unpredictable flatBuffers will automatically increase the buffer size as needed. \r\n\r\nPlease try with `initialSize=1024` bytes like `builder = flatbuffers.Builder(1024)` and see is it resolving your issue or not ? \r\n\r\nIf issue still persists please let us know with error log to investigate this issue further from our end. \r\n\r\nThank you for your cooperation and patience."", 'Hello @gaikwadrahul8, your response is really appreciated.\r\n\r\nThe error does not occur when I initialize the flatbuffer. It occurs after that right in the next line.\r\n\r\n```meta_offset = model_meta.Pack(builder)```\r\n\r\nAlthough I did change the initialSize to 1024, but the issue is as it is.\r\n\r\nI am attaching the logs to backtrack the error as well.\r\n\r\n```\r\nerror                                     Traceback (most recent call last)\r\nCell In[8], [line 2]\r\n      [1] builder = flatbuffers.Builder(1024)\r\n----> [2] meta_offset = model_meta.Pack(builder)\r\n      [3] builder.Finish(\r\n      [4]     meta_offset,\r\n      [5]     _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER\r\n      [6] )\r\n      [7] metadata_buf = builder.Output()\r\n\r\nFile /shareddrive/working/env/lib/python3.10/site-packages/tensorflow_lite_support/metadata/metadata_schema_py_generated.py:3212, in ModelMetadataT.Pack(self, builder)\r\n   [3210] subgraphMetadatalist = []\r\n   [3211] for i in range(len(self.subgraphMetadata)):\r\n-> [3212]     subgraphMetadatalist.append(self.subgraphMetadata[i].Pack(builder))\r\n   [3213] ModelMetadataStartSubgraphMetadataVector(builder, len(self.subgraphMetadata))\r\n   [3214] for i in reversed(range(len(self.subgraphMetadata))):\r\n\r\nFile /shareddrive/working/env/lib/python3.10/site-packages/tensorflow_lite_support/metadata/metadata_schema_py_generated.py:2912, in SubGraphMetadataT.Pack(self, builder)\r\n   [2910] outputTensorMetadatalist = []\r\n   [2911] for i in range(len(self.outputTensorMetadata)):\r\n-> [2912]     outputTensorMetadatalist.append(self.outputTensorMetadata[i].Pack(builder))\r\n   [2913] SubGraphMetadataStartOutputTensorMetadataVector(builder, len(self.outputTensorMetadata))\r\n   [2914] for i in reversed(range(len(self.outputTensorMetadata))):\r\n\r\nFile /shareddrive/working/env/lib/python3.10/site-packages/tensorflow_lite_support/metadata/metadata_schema_py_generated.py:2325, in TensorMetadataT.Pack(self, builder)\r\n   [2323]     dimensionNames = builder.EndVector()\r\n   [2324] if self.content is not None:\r\n-> [2325]     content = self.content.Pack(builder)\r\n   [2326] if self.processUnits is not None:\r\n   [2327]     processUnitslist = []\r\n\r\nFile /shareddrive/working/env/lib/python3.10/site-packages/tensorflow_lite_support/metadata/metadata_schema_py_generated.py:925, in ContentT.Pack(self, builder)\r\n    [923]     contentProperties = self.contentProperties.Pack(builder)\r\n    [924] if self.range is not None:\r\n--> [925]     range = self.range.Pack(builder)\r\n    [926] ContentStart(builder)\r\n    [927] ContentAddContentPropertiesType(builder, self.contentPropertiesType)\r\n\r\nFile /shareddrive/working/env/lib/python3.10/site-packages/tensorflow_lite_support/metadata/metadata_schema_py_generated.py:811, in ValueRangeT.Pack(self, builder)\r\n    [809] ValueRangeStart(builder)\r\n    [810] ValueRangeAddMin(builder, self.min)\r\n--> [811] ValueRangeAddMax(builder, self.max)\r\n    [812] valueRange = ValueRangeEnd(builder)\r\n    [813] return valueRange\r\n\r\nFile /shareddrive/working/env/lib/python3.10/site-packages/tensorflow_lite_support/metadata/metadata_schema_py_generated.py:769, in ValueRangeAddMax(builder, max)\r\n    [768] def ValueRangeAddMax(builder, max):\r\n--> [769]     builder.PrependInt32Slot(1, max, 0)\r\n\r\nFile /shareddrive/working/env/lib/python3.10/site-packages/flatbuffers/builder.py:621, in Builder.PrependInt32Slot(self, *args)\r\n--> [621] def PrependInt32Slot(self, *args): self.PrependSlot(N.Int32Flags, *args)\r\n\r\nFile /shareddrive/working/env/lib/python3.10/site-packages/flatbuffers/builder.py:602, in Builder.PrependSlot(self, flags, o, x, d)\r\n    [600]     N.enforce_number(d, flags)\r\n    [601] if x != d or (self.forceDefaults and d is not None):\r\n--> [602]     self.Prepend(flags, x)\r\n    [603]     self.Slot(o)\r\n\r\nFile /shareddrive/working/env/lib/python3.10/site-packages/flatbuffers/builder.py:594, in Builder.Prepend(self, flags, off)\r\n    [592] def Prepend(self, flags, off):\r\n    [593]     self.Prep(flags.bytewidth, 0)\r\n--> [594]     self.Place(off, flags)\r\n\r\nFile /shareddrive/working/env/lib/python3.10/site-packages/flatbuffers/builder.py:762, in Builder.Place(self, x, flags)\r\n    [760] N.enforce_number(x, flags)\r\n    [761] self.head = self.head - flags.bytewidth\r\n--> [762] encode.Write(flags.packer_type, self.Bytes, self.Head(), x)\r\n\r\nFile /shareddrive/working/env/lib/python3.10/site-packages/flatbuffers/encode.py:42, in Write(packer_type, buf, head, n)\r\n     [40] def Write(packer_type, buf, head, n):\r\n     [41]     """""" Write encodes `n` at buf[head] using `packer_type`. """"""\r\n---> [42]     packer_type.pack_into(buf, head, n)\r\n\r\nerror: required argument is not an integer\r\n```\r\n\r\n', 'Hi, @muhdaniyal252\r\n\r\nThank you for trying, if possible could you please help us with Google colab notebook along with dataset to replicate the same behavior from our end to investigate this issue further ? Thank you.', 'Hi, @gaikwadrahul8 \r\n\r\nhttps://colab.research.google.com/drive/1daZ95UcBm2UQbRLh-d76ySDctTSd8Ydi#scrollTo=o2-hvIyBhmkk\r\n\r\nThis is the link of the colab notebook. \r\n\r\nThe only difference between this and my working environment is that I am using actual audios for Keyword spotting and in this case, I have created dummy data. \r\n\r\nThe error is same here as well.', 'Hey @gaikwadrahul8,\r\n\r\nI were wondering if there is any update regarding the issue I am facing,\r\n', ""Hi, @muhdaniyal252\r\n\r\nI apologize for the delayed response, thank you for providing the Google colab notebook and I am able to replicate the same behavior from our end so we'll have to dig more into this issue. \r\n\r\nHere is [gist-file](https://colab.sandbox.google.com/gist/gaikwadrahul8/6e77d8830d50d89f0ea1a309d34c8b94/test-issue-75089.ipynb) for reference\r\n\r\nThank you for your cooperation and patience."", ""Hello @gaikwadrahul8 . \r\nThank you for the update.\r\n\r\nAnd since you are already on thing thing. I were wondering if you  could solve thing thing for latest versions of tensorflow as well? Upon looking at the last update of 'tflite-support' library, it was back in July 2013. at that time, tensorflow 2.13 was the latest version. But since then, many versions of Tensorflow has been out in public but no update on tflite-support end. \r\n\r\nMy suggestion is to either remove dependency of 3rd party package and add metadata directly at the time of conversion from main model to tflite model. or make make tensorflow compatible with older versions of tflite-support as well.\r\n\r\nThankyou in advance for taking this into consideration."", 'Hello @gaikwadrahul8,\r\n\r\nI was wondering if there is any update regarding the issue.', 'Hi, @pkgoogle\r\n\r\nPlease take look into this issue. Thank you', 'Hi @muhdaniyal252, tfllite_support is a little out-dated, do you absolutely need to add metadata to your model? Or do you just care about inferencing on your mobile or edge device?', ""Hi @pkgoogle. \r\nI don't really care about metadata. I just need to run the model on the edge device. \r\nBut it happens to raise error without the metadata, according to the android dev.\r\nDo let me know if it is possible to run the model on mobile (both android and iOS) without adding metadata.\r\n\r\n++ loop in: @farhajkhan88\r\n"", ""Hi @muhdaniyal252, it seems like you already have a .tflite model? Where does it mention that an error will be raised? (it may not be incorrect but I need to understand the entire context better). You should be able to run a model on mobile w/o this step -- you may wish to look at some of our examples at LiteRT: https://github.com/google-ai-edge/litert-samples/tree/main/examples but let us know if you get stuck or an error is raised. It's possible this is a prior requirement and a new version of TF/Keras/TFLite will resolve this. Is there a reason you aren't on a more recent version?"", ""Hi @pkgoogle, apologies for delayed response\r\nOne of the devs of android (who has done this before) told me to add metadata to the model when I provided the one without metadata. He mentioned that the error he is facing on the current model (the one without metadata) as also been previously observed and that was resolved by adding metadata to it. \r\nUpon investigating, I found that the tflite-support is a little back on time, which is obviously the reason of incompatibility with latest tensorflow version. \r\nTo overcome the version compatibility conflict, I downgraded to 2.13, the latest version at the time of tflite-support last release.\r\nThat's the reason I am using the old version of Tensorflow. \r\n\r\nBut as you said, I wouldn't need to add metadata to the model, I'll share the link with the dev and update on you very in a short while. \r\n\r\nThankyou for your patience. "", 'No worries, thanks for your cooperation. I would say try your best to update everything to the most up to date versions for now as everything is changing quite rapidly.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75089"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75089"">No</a>\n']","# 1. System information

- Ubuntu 22.04 (L40 GPU)
- pip package
- Tensorflow 2.13.0, tflite-support 0.4.4

# 2. Code

## Input and Output shape

 Input: \[128,32,1\]

 Output: \[1\]

## Model Architecture and Training and saving
```
import tensorflow as tf

def get_model(
        input_shape,
        output_neurons=1,
        output_activation='sigmoid',
        loss=tf.keras.losses.binary_crossentropy,
        lr=0.0001
):
    _input = tf.keras.layers.Input(shape=input_shape)
    x = tf.keras.layers.Conv2D(512,kernel_size=3,padding='valid',activation='relu')(_input)
    x = tf.keras.layers.Conv2D(256,kernel_size=3,padding='valid',activation='relu')(x)
    x = tf.keras.layers.MaxPool2D((2,2))(x)
    x = tf.keras.layers.Conv2D(128,kernel_size=3,padding='valid',activation='relu')(x)
    x = tf.keras.layers.Dropout(0.5)(x)
    x = tf.keras.layers.Conv2D(128,kernel_size=3,padding='valid',activation='relu')(x)
    x = tf.keras.layers.MaxPool2D((2,2))(x)
    x = tf.keras.layers.Conv2D(64,kernel_size=3,padding='valid',activation='relu')(x)
    x = tf.keras.layers.MaxPool2D((2,2))(x)
    x = tf.keras.layers.Flatten()(x)
    x = tf.keras.layers.Dense(1024,activation='relu')(x)
    x = tf.keras.layers.Dropout(0.3)(x)
    x = tf.keras.layers.Dense(1024,activation='relu')(x)
    x = tf.keras.layers.Dropout(0.5)(x)
    x = tf.keras.layers.Dense(1024,activation='relu')(x)
    x = tf.keras.layers.Dropout(0.7)(x)
    x = tf.keras.layers.Dense(1024,activation='relu')(x)
    x = tf.keras.layers.Dense(10,activation='relu')(x)
    outputs = tf.keras.layers.Dense(output_neurons,activation=output_activation,kernel_regularizer=tf.keras.regularizers.L2(l2=0.01))(x)
    model = tf.keras.Model(inputs=_input,outputs=outputs)

    model.compile(
        loss=loss,
        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),
        metrics=['accuracy'],
    )

    return model

model = get_model(
        input_shape=input_shape,
        lr=0.001
)

reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',factor=0.1,patience=5,mode='max')
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=1,mode='max',restore_best_weights=True,start_from_epoch=10)
with tf.device('/gpu'):
    history = model.fit(train,epochs=3,validation_data=val,verbose=1,callbacks=[reduce_lr,early_stopping])

model.save('model.keras')

```

## Conversion to tf lite model

```
import tensorflow as tf

model_path = 'model.keras'
lite_model_path = model_path.replace('keras','tflite')

model = tf.keras.models.load_model(model_path)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

with open(lite_model_path, 'wb') as f:
    f.write(tflite_model)
```

## Adding metadata

```
actual_model = ""model.keras""
model_file = ""model.tflite""
export_model_file = ""model_meta.tflite""

from tflite_support import metadata_schema_py_generated as _metadata_fb
from tflite_support import metadata as _metadata
from tflite_support.metadata_writers import writer_utils
import flatbuffers

model_meta = _metadata_fb.ModelMetadataT()
model_meta.name = ""Binary Classification Model""
model_meta.description = ""A CNN-based binary classification model for audio data.""
model_meta.version = ""v1""

input_meta = _metadata_fb.TensorMetadataT()
input_meta.name = ""Input Tensor""
input_meta.description = (
    ""Input to the model is a Mel spectrogram of audio, represented as an array of shape [1,128,32,1].""
)
input_meta.content = _metadata_fb.ContentT()
input_meta.content.contentProperties = _metadata_fb.AudioPropertiesT()
input_meta.content.contentProperties.sampleRate = 16000  # Update based on your actual sample rate
input_meta.content.contentPropertiesType = _metadata_fb.ContentProperties.AudioProperties
input_meta.shape = [1, 128, 32, 1]
input_meta.dtype = 'float32'

output_meta = _metadata_fb.TensorMetadataT()
output_meta.name = ""Output Tensor""
output_meta.description = ""Output is a float value between 0 and 1 representing the probability of the positive class.""
output_meta.content = _metadata_fb.ContentT()
output_meta.content.contentPropertiesType = _metadata_fb.ContentProperties.FeatureProperties
output_meta.content.range = _metadata_fb.ValueRangeT()
output_meta.content.range.min = 0.0
output_meta.content.range.max = 1.0
output_meta.shape = [1]
output_meta.dtype = 'float32'

subgraph = _metadata_fb.SubGraphMetadataT()
subgraph.inputTensorMetadata = [input_meta]
subgraph.outputTensorMetadata = [output_meta]

model_meta.subgraphMetadata = [subgraph]

builder = flatbuffers.Builder(0)
meta_offset = model_meta.Pack(builder)
builder.Finish(
    meta_offset,
    _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER
)
metadata_buf = builder.Output()

populator = _metadata.MetadataPopulator.with_model_file(model_file)
populator.load_metadata_buffer(metadata_buf)
populator.load_associated_files([""labels.txt""])
populator.populate()

displayer = _metadata.MetadataDisplayer.with_model_file(export_model_file)
export_json_file = os.path.join(os.path.dirname(export_model_file), ""metadata.json"")
json_file = displayer.get_metadata_json()
with open(export_json_file, ""w"") as f:
    f.write(json_file)

```

# Description

I am developing a keyword spotting (binary classification) model that is later needed to be converted to tf lite and used in mobile device. 

For that, I built a model architecture (given above in code section). Trained is on mel spectrogram (generated using librosa). After training, I saved the model, converted to tf lite using the code mentioned above. 

Now I am at the point where i need to add metadata to the model. For that, I am refering the code given on official [documentation](https://ai.google.dev/edge/litert/models/metadata), with some necessory changes.

# Error Facing

I am facing the error at the time of adding meta data to the tflite model. When it comes to this point 
```
builder = flatbuffers.Builder(0)
meta_offset = model_meta.Pack(builder)
builder.Finish(
    meta_offset,
    _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER
)
metadata_buf = builder.Output()
```

It raises the error and exits. 

The error is 
```error: required argument is not an integer ```

I am unable to sort that error. Kindly assist me regarding that and provide me some solution for my problem.

"
2507526020,75176,Problem with tf.keras.layers.SimpleRNNCell ,closed,2024-09-05 11:31:33+00:00,2024-09-23T05:43:19Z,2024-09-21T01:58:28Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/75176,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', '2.17']","['Hi **@Zofns** ,\r\nI tried to run your code on Colab using TF v2.17.0 & nightly and faced the same issue. Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/f46d151660710da513bad3623a3fa39d/75176_tf-2-17-0-and-nightly-v.ipynb) here for reference.\r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues) as this issue is more related to keras\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75176"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75176"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.17.0

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.11.0

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.3

### GPU model and memory

NVIDIA GeForce RTX 4070Ti

### Current behavior?

Current behavior is I get error message 'InaccessibleTensorError' due to line 'out0, state0 = self.RNNCell0(word, states=state0, training=training)'

### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = ""2""

import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

tf.random.set_seed(22)
np.random.seed(22)
assert tf.__version__.startswith('2.')

batch_size = 128
total_words = 10000
max_review_len = 80
embedding_len = 100

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=total_words)
x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)
x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)

train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_data = train_data.shuffle(10000).batch(batch_size, drop_remainder=True)

test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))
test_data = test_data.batch(batch_size, drop_remainder=True)

print('x_train_shape:', x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))
print('x_test_shape:', x_test.shape)

class RNN_Build(tf.keras.Model):
    def __init__(self, units):
        super(RNN_Build, self).__init__()
        self.state0 = [tf.zeros([batch_size, units])]
        self.state1 = [tf.zeros([batch_size, units])]
        self.embedding = tf.keras.layers.Embedding(total_words, embedding_len,
                                                   input_length=max_review_len)
        self.RNNCell0 = tf.keras.layers.SimpleRNNCell(units, dropout=0.2)
        self.RNNCell1 = tf.keras.layers.SimpleRNNCell(units, dropout=0.2)
        self.RNNCell1 = tf.keras.layers.SimpleRNNCell(units, dropout=0.2)
    def call(self, inputs, training=None):
        x = inputs
        x = self.embedding(x)
        state0 = self.state0
        state1 = self.state1
        for word in tf.unstack(x, axis=1):
            out0, state0 = self.RNNCell0(word, states=state0, training=training)
            out1, state1 = self.RNNCell1(out0, states=state1, training=training)
        x = self.outlayer(out1)
        prob = tf.sigmoid(x)
        return prob
import time
units = 64
epochs = 4
t0 = time.time()
model = RNN_Build(units)
model.compile(optimizer=tf.keras.optimizers.Adam(0.001),
              loss=tf.losses.BinaryCrossentropy(),
              metrics=['accuracy'])
model.fit(train_data, epochs=epochs, validation_data=test_data, validation_freq=2)
```


### Relevant log output

```shell
---------------------------------------------------------------------------
InaccessibleTensorError                   Traceback (most recent call last)
Cell In[5], line 9
      5 model = RNN_Build(units)
      6 model.compile(optimizer=tf.keras.optimizers.Adam(0.001),
      7               loss=tf.losses.BinaryCrossentropy(),
      8               metrics=['accuracy'])
----> 9 model.fit(train_data, epochs=epochs, validation_data=test_data, validation_freq=2)

File /usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:122, in filter_traceback.<locals>.error_handler(*args, **kwargs)
    119     filtered_tb = _process_traceback_frames(e.__traceback__)
    120     # To get the full stack trace, call:
    121     # `keras.config.disable_traceback_filtering()`
--> 122     raise e.with_traceback(filtered_tb) from None
    123 finally:
    124     del filtered_tb

Cell In[4], line 17
     15 state1 = self.state1
     16 for word in tf.unstack(x, axis=1):
---> 17     out0, state0 = self.RNNCell0(word, states=state0, training=training)
     18     out1, state1 = self.RNNCell1(out0, states=state1, training=training)
     19 x = self.outlayer(out1)

File /usr/local/lib/python3.11/dist-packages/tensorflow/core/function/capture/capture_container.py:144, in FunctionCaptures.capture_by_value(self, graph, tensor, name)
...

Arguments received by SimpleRNNCell.call():
  • sequence=tf.Tensor(shape=(128, 100), dtype=float32)
  • states=['tf.Tensor(shape=(128, 64), dtype=float32)']
  • training=True
Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...
```
"
2507573944,75177,Inference results mismatch for Keras model before serialization and after serialization into SavedModel,closed,2024-09-05 11:55:55+00:00,2024-09-25T02:02:06Z,2024-09-25T02:02:03Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/75177,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', '2.17']","['@rkazants,\r\nThank you for reporting the issue. Tensorflow v2.17 contains the keras3.0 which might be the reason for the mismatch. As this issue is more related to keras, could you please create the issue in the Keras-team/keras repo for the quick resolution. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75177"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75177"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.17.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I observe inference results mismatch for cases before and after serialization into SavedModel for Keras model with multiple inputs and outputs.
I have two examples of it. See below.

### Standalone code to reproduce the issue

```shell
# Example 1.

import numpy as np
import tensorflow as tf

np.random.seed(23235)

input_names = [""k"", ""b"", ""m"", ""c"", ""x""]
input_shapes = [[1, 1], [1, 3], [1, 2], [1, 5], [1, 4]]

inputs = []
outputs = []
for ind in range(len(input_names)):
    input = tf.keras.Input(shape=input_shapes[ind][1:], name=input_names[ind])
    inputs.append(input)
    outputs.append(tf.keras.layers.Activation(tf.nn.sigmoid)(input))

model_in_memory = tf.keras.Model(inputs=inputs, outputs=outputs)
model_in_memory.export('saved_model')
loaded = tf.saved_model.load('saved_model')
model_from_disk = loaded.signatures['serving_default']

test_list = []
for input_shape in input_shapes:
    test_list.append(np.random.rand(*input_shape))

test_dict = {}
for input_shape, input_name in zip(input_shapes, input_names):
    test_dict[input_name] = np.random.rand(*input_shape)

print('results for original model = ', model_in_memory(test_list))
print('results for saved model = ', model_from_disk(**test_dict))



#Example 2
import numpy as np
import tensorflow as tf

np.random.seed(23235)

input_names = [""k"", ""b"", ""m"", ""c"", ""x""]
input_shapes = [[1, 1], [1, 3], [1, 2], [1, 5], [1, 4]]

inputs = []
outputs = {}
for ind in range(len(input_names)):
    input = tf.keras.Input(shape=input_shapes[ind][1:], name=input_names[ind])
    inputs.append(input)
    outputs[""name"" + str(ind)] = tf.keras.layers.Activation(tf.nn.sigmoid)(input)

model_in_memory = tf.keras.Model(inputs=inputs, outputs=outputs)
model_in_memory.export('saved_model')
loaded = tf.saved_model.load('saved_model')
model_from_disk = loaded.signatures['serving_default']

test_list = []
for input_shape in input_shapes:
    test_list.append(np.random.rand(*input_shape))

test_dict = {}
for input_shape, input_name in zip(input_shapes, input_names):
    test_dict[input_name] = np.random.rand(*input_shape)

print('results for original model = ', model_in_memory(test_list))
print('results for saved model = ', model_from_disk(**test_dict))
```


### Relevant log output

```shell
Example 1.
results for original model =  [<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.57518655]], dtype=float32)>, <tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[0.6557526 , 0.6859775 , 0.64670473]], dtype=float32)>, <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.7017947 , 0.53047395]], dtype=float32)>, <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.5904319 , 0.7172047 , 0.52846706, 0.58635867, 0.6636075 ]],
      dtype=float32)>, <tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.57865363, 0.68113613, 0.7037658 , 0.6035671 ]], dtype=float32)>]
results for saved model =  {'output_2': <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.6410256 , 0.55847204]], dtype=float32)>, 'output_4': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.6274846 , 0.50716597, 0.5257206 , 0.58835816]], dtype=float32)>, 'output_1': <tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[0.64240766, 0.5903851 , 0.7065355 ]], dtype=float32)>, 'output_0': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.6045815]], dtype=float32)>, 'output_3': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.6407081 , 0.570733  , 0.5671946 , 0.65474033, 0.5883632 ]],
      dtype=float32)>}

Example 2.
results for original model =  {'name0': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.57518655]], dtype=float32)>, 'name1': <tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[0.6557526 , 0.6859775 , 0.64670473]], dtype=float32)>, 'name2': <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.7017947 , 0.53047395]], dtype=float32)>, 'name3': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.5904319 , 0.7172047 , 0.52846706, 0.58635867, 0.6636075 ]],
      dtype=float32)>, 'name4': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.57865363, 0.68113613, 0.7037658 , 0.6035671 ]], dtype=float32)>}
results for saved model =  {'name0': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.6045815]], dtype=float32)>, 'name4': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.6274846 , 0.50716597, 0.5257206 , 0.58835816]], dtype=float32)>, 'name2': <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.6410256 , 0.55847204]], dtype=float32)>, 'name3': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.6407081 , 0.570733  , 0.5671946 , 0.65474033, 0.5883632 ]],
      dtype=float32)>, 'name1': <tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[0.64240766, 0.5903851 , 0.7065355 ]], dtype=float32)>}
```
"
2508450981,75194,Overfit and Underfit Notebook fails on compile_and_fit,closed,2024-09-05 18:21:06+00:00,2024-09-24T02:01:40Z,2024-09-24T02:01:36Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/75194,"['stat:awaiting response', 'type:bug', 'stale', '2.17']","['Hi @dnoliver,\r\nI looked into this issue and have opened a pull request regarding the same - https://github.com/tensorflow/docs/pull/2325', 'Hi **@dnoliver** ,\r\nThe [pr](https://github.com/tensorflow/docs/pull/2325) has been assigned for reviewing and once it is merged this issue will move to closed status.\r\nThank You!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75194"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75194"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

v2.17.0-rc1-2-gad6d8cc177d 2.17.0

### Custom code

No

### OS platform and distribution

Windows 11 - WSL - Docker Container

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Trying to run the `overfit_and_underfit.ipynb` sample fails. Error log (and the full Traceback is below as well):

```
ValueError: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None,), output.shape=(None, 1)
```

### Standalone code to reproduce the issue

```shell
https://www.tensorflow.org/tutorials/keras/overfit_and_underfit
```


### Relevant log output

```shell
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[28], line 1
----> 1 size_histories['Tiny'] = compile_and_fit(tiny_model, 'sizes/Tiny')

Cell In[18], line 13
      4 model.compile(optimizer=optimizer,
      5               loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
      6               metrics=[
      7                 tf.keras.metrics.BinaryCrossentropy(
      8                     from_logits=True, name='binary_crossentropy'),
      9                 'accuracy'])
     11 model.summary()
---> 13 history = model.fit(
     14   train_ds,
     15   steps_per_epoch = STEPS_PER_EPOCH,
     16   epochs=max_epochs,
     17   validation_data=validate_ds,
     18   callbacks=get_callbacks(name),
     19   verbose=0)
     20 return history

File ~/.local/share/virtualenvs/com.docker.devenvironments.code-o74UYjc6/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122, in filter_traceback.<locals>.error_handler(*args, **kwargs)
    119     filtered_tb = _process_traceback_frames(e.__traceback__)
    120     # To get the full stack trace, call:
    121     # `keras.config.disable_traceback_filtering()`
--> 122     raise e.with_traceback(filtered_tb) from None
    123 finally:
    124     del filtered_tb

File ~/.local/share/virtualenvs/com.docker.devenvironments.code-o74UYjc6/lib/python3.9/site-packages/keras/src/backend/tensorflow/nn.py:694, in binary_crossentropy(target, output, from_logits)
    691 output = tf.convert_to_tensor(output)
    693 if len(target.shape) != len(output.shape):
--> 694     raise ValueError(
    695         ""Arguments `target` and `output` must have the same rank ""
    696         ""(ndim). Received: ""
    697         f""target.shape={target.shape}, output.shape={output.shape}""
    698     )
    699 for e1, e2 in zip(target.shape, output.shape):
    700     if e1 is not None and e2 is not None and e1 != e2:

ValueError: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None,), output.shape=(None, 1)
```
"
2508487094,75196,Save and Load Notebook use a bad checkpoint_path file name,closed,2024-09-05 18:42:39+00:00,2024-10-11T02:01:20Z,2024-10-11T02:01:17Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/75196,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', '2.17']","['Then it works after you change the line to `checkpoint_path = ""training_1/cp.ckpt.weights.h5""`', ""The sample runs into other problems as well. Like `trainning_2` folder needs to be created manually, `model.load_weights(latest)` complains about `ValueError: File format not supported: filepath=None. Keras 3 only supports V3 `.keras` and `.weights.h5` files, or legacy V1/V2 `.h5` files.`, similar problem in `model.save_weights('./checkpoints/my_checkpoint')`, the line `model.save('saved_model/my_model') ` complains with `ValueError: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=saved_model/my_model.`"", 'Hey @dnoliver , \r\n\r\nI looked into the issue and found out there was several errors in the specified notebook.\r\n\r\nI have created a pull request regarding same - https://github.com/tensorflow/docs/pull/2324', '@dnoliver,\r\nThe pr has been assigned for reviewing and once it is merged this issue will move to closed status. Thank you!', '@dnoliver,\r\nThe PR which was raised for the similar issue has been merged and also I tried to execute the official doc code and it was executed without any issues/errors. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/ef564a09b99e15531616ef4589b7362a/save_and_load.ipynb).\r\n\r\nhttps://github.com/tensorflow/docs/pull/2324\r\n\r\nThank you!\r\n\r\n', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75196"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75196"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

v2.17.0-rc1-2-gad6d8cc177d 2.17.0

### Custom code

No

### OS platform and distribution

Windows 11 - WSL - Docker Container

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

The cell:

```
checkpoint_path = ""training_1/cp.ckpt""
checkpoint_dir = os.path.dirname(checkpoint_path)

# Create a callback that saves the model's weights
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=1)

# Train the model with the new callback
model.fit(train_images, 
          train_labels,  
          epochs=10,
          validation_data=(test_images, test_labels),
          callbacks=[cp_callback])  # Pass callback to training

# This may generate warnings related to saving the state of the optimizer.
# These warnings (and similar warnings throughout this notebook)
# are in place to discourage outdated usage, and can be ignored.
```

Throws the following value error:

```
ValueError: When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=training_1/cp.ckpt
```


### Standalone code to reproduce the issue

```shell
https://www.tensorflow.org/tutorials/keras/save_and_load
```


### Relevant log output

```shell
{
	""name"": ""ValueError"",
	""message"": ""When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=training_1/cp.ckpt"",
	""stack"": ""---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[12], line 5
      2 checkpoint_dir = os.path.dirname(checkpoint_path)
      4 # Create a callback that saves the model's weights
----> 5 cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
      6                                                  save_weights_only=True,
      7                                                  verbose=1)
      9 # Train the model with the new callback
     10 model.fit(train_images, 
     11           train_labels,  
     12           epochs=10,
     13           validation_data=(test_images, test_labels),
     14           callbacks=[cp_callback])  # Pass callback to training

File ~/.local/share/virtualenvs/com.docker.devenvironments.code-o74UYjc6/lib/python3.9/site-packages/keras/src/callbacks/model_checkpoint.py:183, in ModelCheckpoint.__init__(self, filepath, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, initial_value_threshold)
    181 if save_weights_only:
    182     if not self.filepath.endswith(\"".weights.h5\""):
--> 183         raise ValueError(
    184             \""When using `save_weights_only=True` in `ModelCheckpoint`\""
    185             \"", the filepath provided must end in `.weights.h5` \""
    186             \""(Keras weights format). Received: \""
    187             f\""filepath={self.filepath}\""
    188         )
    189 else:
    190     if not self.filepath.endswith(\"".keras\""):

ValueError: When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=training_1/cp.ckpt""
}
```
"
2510688607,75256,incorrect result of sigmoid_cross_entropy_with_logits when input is np.inf,closed,2024-09-06 15:29:07+00:00,2024-09-08T16:40:09Z,2024-09-08T16:40:06Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/75256,['type:bug'],"[""Hi @maybeLee,\r\n\r\nThe behavior you're observing stems from TensorFlow's internal handling of extreme values like `np.inf`. While the manual computation results in `inf`, TensorFlow applies numerically stable operations that avoid overflow/underflow issues, which can lead to `NaN` in such cases.\r\n\r\nThe underlying formula in TensorFlow ensures stability for large values of x, which is likely why the API returns `NaN` instead of `inf`. Though this seems inconsistent with the documented formula, TensorFlow prioritizes stability over direct computation in edge cases.\r\n\r\nOne potential workaround is to manually handle extreme values before passing them to the API to avoid getting `NaN` in such cases.\r\n\r\n"", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75256"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75256"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.17.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Based on the documentation: https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits, this API's output should be consistent with this equation: `z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))`. However, when running the following code:

```
import tensorflow as tf
import numpy as np

x = tf.constant(np.inf)
z = tf.constant(0.9)
res1 = tf.nn.sigmoid_cross_entropy_with_logits(labels=z, logits=x)
print(f""TF's result: {res1}"")  # nan
log = tf.math.log
sigmoid = tf.math.sigmoid
res2 = z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))
print(f""Expected result: {res2}"")  # inf
```

The API's output is inconsistent with the equation's output as follows:

```
TF's result: nan
Expected result: inf
```

The possible reason is that the current implementation contains `inf - xx*inf` when `x=inf`, thus lead to `NaN`.

https://github.com/tensorflow/tensorflow/blob/e4e8ba1af3511dc749a9d9d8dbac0c4dc3c7eab5/tensorflow/python/ops/nn_impl.py#L143

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

x = tf.constant(np.inf)
z = tf.constant(0.9)
res1 = tf.nn.sigmoid_cross_entropy_with_logits(labels=z, logits=x)
print(f""TF's result: {res1}"")  # nan
log = tf.math.log
sigmoid = tf.math.sigmoid
res2 = z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))
print(f""Expected result: {res2}"")  # inf
```


### Relevant log output

_No response_"
2510909756,75269,AutoGraph error: OP_REQUIRES failed at strided_slice_op.cc:266,closed,2024-09-06 17:38:01+00:00,2024-09-30T09:40:01Z,2024-09-30T09:39:58Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/75269,"['stat:awaiting response', 'type:bug', 'comp:keras', 'comp:xla', 'TF 2.16']","['Here is a different (and simpler) version of the code. This version works in AutoGraph mode in TensorFlow 2.13.1 on Python 3.8.10, but produces the above error when run in TensorFlow 2.16.1 on Python 3.10.12.\r\n\r\n```\r\nimport keras\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\nclass UnAveragePooling2D(keras.layers.Layer):\r\n\r\n    def __init__(self, kernel, *, strides, name = \'co1\', dtype = None):\r\n        super().__init__(trainable=True, name=name, dtype=dtype)\r\n        self.kernel = kernel\r\n        self.strides = strides\r\n\r\n    def build(self, input_shape):\r\n        pass\r\n\r\n    def call(self, inputs):\r\n        inputs_shape = tf.shape(inputs)\r\n\r\n        # the averaged image had a minimum size of source.shape * strides, but it could have been larger if its size\r\n        # was not a multiple of stride. For now, assume it was a multiple of stride.\r\n        dest_shape = (inputs_shape[0], inputs.shape[1] * self.strides, inputs.shape[2] * self.strides, inputs_shape[3])\r\n        #dest = tf.zeros(dest_shape)\r\n\r\n        # width of destination invalid edges that need to be filled, again assuming that source size was a multiple of stride.\r\n        dest_start_invalid = (self.strides // 2, self.strides // 2)\r\n        dest_end_invalid = (self.strides // 2, self.strides // 2)\r\n\r\n        strides_f = tf.cast(self.strides, tf.float32)\r\n        dest_start_invalid_f = (tf.cast(dest_start_invalid[0], tf.float32), tf.cast(dest_start_invalid[1], tf.float32))\r\n        max_source_f = (tf.cast(inputs.shape[1] - 1, tf.float32), tf.cast(inputs.shape[2] - 1, tf.float32))\r\n\r\n        # biniliear interpolation with distorted edges\r\n        dest = tf.zeros((dest_shape[0], 0, dest_shape[2], dest_shape[3]))\r\n        for dest_r in range(dest_shape[1]):\r\n            dest_r_f = tf.cast(dest_r, tf.float32)\r\n            row = tf.zeros((dest_shape[0], 1, 0, dest_shape[3]))\r\n            for dest_c in range(dest_shape[2]):\r\n                dest_c_f = tf.cast(dest_c, tf.float32)\r\n                source_r = self._dest_to_rource(dest_r_f, strides_f, dest_start_invalid_f[0], max_source_f[0])\r\n                source_c = self._dest_to_rource(dest_c_f, strides_f, dest_start_invalid_f[1], max_source_f[1])\r\n                value = self._bilinear_interpolate(inputs, source_r, source_c)\r\n                #dest = self._assign_pixel_batch_values(dest, dest_r, dest_c, value)\r\n                value = tf.reshape(value, (inputs_shape[0], 1, 1, inputs_shape[3]))\r\n                row = tf.concat([row, value], axis=2)\r\n            dest = tf.concat([dest, row], axis=1)\r\n\r\n        return dest\r\n\r\n    @tf.function\r\n    def _dest_to_rource(self, dest, stride, dest_start_invalid, max_source):\r\n        """"""Given a destination pixel row or column position, work out the source\r\n        pixel location from which the value should be interpolated.""""""\r\n\r\n        if dest < dest_start_invalid + stride - 0.5:\r\n            return (dest - dest_start_invalid) / (stride - 0.5)\r\n        elif dest > dest_start_invalid + (max_source - 1.0) * stride - 0.5:\r\n            return ((dest - dest_start_invalid + 0.5) - (max_source - 1.0) * stride) / (stride - 0.5) + max_source - 1.0\r\n        else:\r\n            return (dest - dest_start_invalid + 0.5) / stride\r\n\r\n    @tf.function\r\n    def _bilinear_interpolate(self, source, r, c):\r\n        """"""Given a batch of source images, interpolate each from the four pixels surrounding point r,c.\r\n        Near the edge, fade to black.\r\n        """"""\r\n        # Algorithm (ignoring edges):\r\n        # 1. Round r,c down to get top-right source pixel r0, c0\r\n        # 2. Subtract r0, c0 from r, c get 0..1 proportions of a pixel fr, fc\r\n        # 3. The four pixels to be sampled are at p00=[r0, c0], p01=[r0,c0+1], p10=[r0+1, c0], and p11=[r0+1, c0+1]\r\n        # 4. For each channel, calculate a linear sum of the four pixels, as follows:\r\n        # 5. result =   p00.(1-fr).(1-fc)\r\n        #             + p01.(1-fr).fc\r\n        #             + p10.fr.(1-fc)\r\n        #             + p11.fr.fc\r\n        # To cope with edges and implement fade-to-black: if any of p00, p01, p10 or p11 would be outside the source\r\n        # image then use black instead\r\n        r0, c0 =  tf.cast(tf.floor(r), tf.int32), tf.cast(tf.floor(c), tf.int32)\r\n        fr, fc = r - tf.cast(r0, tf.float32), c - tf.cast(c0, tf.float32)\r\n        p00 = self._safe_lookup_pixel(source, r0, c0)\r\n        p01 = self._safe_lookup_pixel(source, r0, c0+1)\r\n        p10 = self._safe_lookup_pixel(source, r0+1, c0)\r\n        p11 = self._safe_lookup_pixel(source, r0+1, c0+1)\r\n        return p00*(1-fr)*(1-fc) + p01*(1-fr)*fc + p10*fr*(1-fc) + p11*fr*fc\r\n\r\n    @tf.function\r\n    def _safe_lookup_pixel(self, source, r, c):\r\n        """"""If x,y is a valid index into the source images then return the\r\n        batch of pixels at that location, otherwise return a batch of black pixels.""""""\r\n\r\n        source_shape = tf.shape(source)\r\n        if 0 <= r < source.shape[1] and 0 <= c < source.shape[2]:\r\n            return source[:, r, c, :]\r\n        else:\r\n            return tf.zeros((source_shape[0], source_shape[3]))\r\n\r\n\r\n\r\nTEST_SIZE = 16\r\n\r\ndata = [list(range(TEST_SIZE))] * TEST_SIZE\r\ndata = tf.convert_to_tensor(data, np.float32)\r\ndata = tf.reshape(data, (1, TEST_SIZE, TEST_SIZE, 1))\r\n\r\nmodel = keras.models.Sequential()\r\nmodel.add(keras.Input(shape=(TEST_SIZE, TEST_SIZE, 1), batch_size=1))\r\nmodel.add(keras.layers.AveragePooling2D((6, 6), padding=\'same\', strides=4))\r\nmodel.add(UnAveragePooling2D((6, 6), strides=4))\r\nmodel.compile(run_eagerly=False)\r\n\r\nexpanded = model.predict(data)\r\nprint(expanded[0,:,:,0])\r\n```', '@richardwhitehead,\r\nI tried to execute the code on the latest tensorflow v2.17 and it was executed without any issues. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/08d84020487a9abf51ada4c68c8528e2/untitled2127.ipynb) and try to update to 2.17. Thank you! ', 'Thank you very much for investigating this. \r\n\r\nI tried updating my docker container to the latest version provided by NVIDIA (24.09-tf2-py3) but that still seems to be TensorFlow v2.16.1.\r\n\r\nHaving lost many days fighting version incompatibilities in the past, and given that Nvidia has chosen not to upgrade yet, I am unwilling to try updating TensorFlow and will wait until Nvidia release a container image with a newer version.\r\n\r\n \r\n\r\nI have no doubt that what you say is true and so please feel free to close the issue.\r\n\r\n \r\n\r\nMany thanks,\r\n\r\n \r\n\r\nRichard\r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\nFrom: tilakrayal ***@***.***> \r\nSent: 25 September 2024 15:45\r\nTo: tensorflow/tensorflow ***@***.***>\r\nCc: richardwhitehead ***@***.***>; Mention ***@***.***>\r\nSubject: Re: [tensorflow/tensorflow] AutoGraph error: OP_REQUIRES failed at strided_slice_op.cc:266 (Issue #75269)\r\n\r\n \r\n\r\n@richardwhitehead <https://github.com/richardwhitehead> ,\r\nI tried to execute the code on the latest tensorflow v2.17 and it was executed without any issues. Kindly find the gist of it here <https://colab.research.google.com/gist/tilakrayal/08d84020487a9abf51ada4c68c8528e2/untitled2127.ipynb>  and try to update to 2.17. Thank you!\r\n\r\n—\r\nReply to this email directly, view it on GitHub <https://github.com/tensorflow/tensorflow/issues/75269#issuecomment-2374305020> , or unsubscribe <https://github.com/notifications/unsubscribe-auth/AFPFJLO55UDEAFUZKEUQPRLZYLD7HAVCNFSM6AAAAABNZAI4P2VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNZUGMYDKMBSGA> .\r\nYou are receiving this because you were mentioned.  <https://github.com/notifications/beacon/AFPFJLI33D7PIOQGCMFSAGDZYLD7HA5CNFSM6AAAAABNZAI4P2WGG33NNVSW45C7OR4XAZNMJFZXG5LFINXW23LFNZ2KUY3PNVWWK3TUL5UWJTUNQUCPY.gif> Message ID: ***@***.*** ***@***.***> >\r\n\r\n', '@richardwhitehead,\r\nGlad the issue was resolved. Could you please feel free to move this issue to closed status. Thank you!', 'Fixed in v2.17', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75269"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75269"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.16.1

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.10.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

The following code works and produces the expected output when run in eager mode, but when using AutoGraph it produces bizarre error messages. The line numbers reported are not the actual location of the errors.

Replacing the contents of _safe_lookup_pixel so it always returns zeros makes the error go away, though of course the output is not then correct. 

My installation is using docker image based on the NVIDIA image, details below.

### Standalone code to reproduce the issue

```shell
import keras
import tensorflow as tf
import numpy as np


class UnAveragePooling2D(keras.layers.Layer):

    def __init__(self, kernel, *, strides, name = 'co1', dtype = None):
        super().__init__(trainable=True, name=name, dtype=dtype)
        self.kernel = kernel
        self.strides = strides

    def build(self, input_shape):
        pass

    def call(self, inputs):
        inputs_shape = tf.shape(inputs)

        # the averaged image had a minimum size of source.shape * strides, but it could have been larger if its size
        # was not a multiple of stride. For now, assume it was a multiple of stride.
        dest_shape = (inputs_shape[0], inputs.shape[1] * self.strides, inputs.shape[2] * self.strides, inputs_shape[3])
        dest = tf.zeros(dest_shape)

        # width of destination invalid edges that need to be filled, again assuming that source size was a multiple of stride.
        dest_start_invalid = (self.strides // 2, self.strides // 2)
        dest_end_invalid = (self.strides // 2, self.strides // 2)

        strides_f = tf.cast(self.strides, tf.float32)
        dest_start_invalid_f = (tf.cast(dest_start_invalid[0], tf.float32), tf.cast(dest_start_invalid[1], tf.float32))
        max_source_f = (tf.cast(inputs_shape[1] - 1, tf.float32), tf.cast(inputs_shape[2] - 1, tf.float32))

        # biniliear interpolation with distorted edges
        for dest_r in range(dest_shape[1]):
            for dest_c in range(dest_shape[2]):
                source_r = self._dest_to_rource(dest_r, strides_f, dest_start_invalid_f[0], max_source_f[0])
                source_c = self._dest_to_rource(dest_c, strides_f, dest_start_invalid_f[1], max_source_f[1])
                value = self._bilinear_interpolate(inputs, source_r, source_c)
                dest = self._assign_pixel_batch_values(dest, dest_r, dest_c, value)

        # # nearest edge fill
        # first_valid_row = tf.reshape(dest[:, dest_start_invalid[0], :, :], (dest_shape[0], 1, dest_shape[2], dest_shape[3]))
        # last_valid_row = tf.reshape(dest[:, -dest_end_invalid[0] - 1, :, :], (dest_shape[0], 1, dest_shape[2], dest_shape[3]))
        # start_rows = tf.tile(first_valid_row, (1, dest_start_invalid[0], 1, 1))
        # middle_rows = dest[:, dest_start_invalid[0]:-dest_end_invalid[0], :, :]
        # end_rows = tf.tile(last_valid_row, (1, dest_end_invalid[0], 1, 1))

        # dest = tf.concat([start_rows, middle_rows, end_rows], axis=1)
        # first_valid_col = tf.reshape(dest[:, :, dest_start_invalid[1], :], (dest_shape[0], dest_shape[1], 1, dest_shape[3]))
        # last_valid_col = tf.reshape(dest[:, :, -dest_end_invalid[1] - 1, :], (dest_shape[0], dest_shape[1], 1, dest_shape[3]))
        # start_cols = tf.tile(first_valid_col, (1, 1, dest_start_invalid[1], 1))
        # middle_cols = dest[:, :, dest_start_invalid[1]:-dest_end_invalid[1], :]
        # end_cols = tf.tile(last_valid_col, (1, 1, dest_end_invalid[1], 1))
        # dest = tf.concat([start_cols, middle_cols, end_cols], axis=2)

        return dest

    @tf.function
    def _dest_to_rource(self, dest, stride, dest_start_invalid, max_source):
        """"""Given a destination pixel row or column position, work out the source
        pixel location from which the value should be interpolated.""""""

        if dest < dest_start_invalid + stride - 0.5:
            return (dest - dest_start_invalid) / (stride - 0.5)
        elif dest > dest_start_invalid + (max_source - 1.0) * stride - 0.5:
            return ((dest - dest_start_invalid + 0.5) - (max_source - 1.0) * stride) / (stride - 0.5) + max_source - 1.0
        else:
            return (dest - dest_start_invalid + 0.5) / stride

    @tf.function
    def _bilinear_interpolate(self, source, r, c):
        """"""Given a batch of source images, interpolate each from the four pixels surrounding point r,c.
        Near the edge, fade to black.
        """"""
        # Algorithm (ignoring edges):
        # 1. Round r,c down to get top-right source pixel r0, c0
        # 2. Subtract r0, c0 from r, c get 0..1 proportions of a pixel fr, fc
        # 3. The four pixels to be sampled are at p00=[r0, c0], p01=[r0,c0+1], p10=[r0+1, c0], and p11=[r0+1, c0+1]
        # 4. For each channel, calculate a linear sum of the four pixels, as follows:
        # 5. result =   p00.(1-fr).(1-fc)
        #             + p01.(1-fr).fc
        #             + p10.fr.(1-fc)
        #             + p11.fr.fc
        # To cope with edges and implement fade-to-black: if any of p00, p01, p10 or p11 would be outside the source
        # image then use black instead
        r0, c0 =  tf.cast(tf.floor(r), tf.int32), tf.cast(tf.floor(c), tf.int32)
        fr, fc = r - tf.cast(r0, tf.float32), c - tf.cast(c0, tf.float32)
        p00 = self._safe_lookup_pixel(source, r0, c0)
        p01 = self._safe_lookup_pixel(source, r0, c0+1)
        p10 = self._safe_lookup_pixel(source, r0+1, c0)
        p11 = self._safe_lookup_pixel(source, r0+1, c0+1)
        return p00*(1-fr)*(1-fc) + p01*(1-fr)*fc + p10*fr*(1-fc) + p11*fr*fc

    @tf.function
    def _safe_lookup_pixel(self, source, r, c):
        """"""If x,y is a valid index into the source images then return the
        batch of pixels at that location, otherwise return a batch of black pixels.""""""

        source_shape = tf.shape(source)
        if 0 <= r < source_shape[1] and 0 <= c < source_shape[2]:
            return source[:, r, c, :]
        else:
            return tf.zeros((source_shape[0], source_shape[3]))

    @staticmethod
    @tf.function
    def _assign_pixel_batch_values(tensor, r, c, value):
        """"""Given a 4d tensor, replace the batch of pixels at location r,c with the given batch of pixels.
        Equivalent to tensor[:, r, c, :] = value
        """"""

        # There has got to be an easier way!
        tensor_shape = tensor.shape
        ret = tensor[:, :r, :, :]  # rows before the update
        new_row = tf.reshape(tensor[:, r, :c, :], (tensor_shape[0], 1, c, tensor_shape[3])) # columns before the update, on the update row
        value = tf.reshape(value, (tensor_shape[0], 1, 1, tensor_shape[3]))
        new_row = tf.concat([new_row, value], axis=2)   # append the new value
        last_cols = tf.reshape(tensor[:, r, c+1:, :], (tensor_shape[0], 1, tensor_shape[2] - c - 1, tensor_shape[3]))
        new_row = tf.concat([new_row, last_cols], axis=2) # columns after the update, on the update row
        ret = tf.concat([ret, new_row], axis=1)  # the now row with the update in it
        ret = tf.concat([ret, tensor[:, r+1:, :, :]], axis=1) # rows after the update
        return ret



TEST_SIZE = 16

data = [list(range(TEST_SIZE))] * TEST_SIZE
data = tf.convert_to_tensor(data, np.float32)
data = tf.reshape(data, (1, TEST_SIZE, TEST_SIZE, 1))

model = keras.models.Sequential()
model.add(keras.layers.AveragePooling2D((6, 6), padding='same', strides=4))
model.add(UnAveragePooling2D((6, 6), strides=4))
model.compile(run_eagerly=False)

expanded = model.predict(data)
print(expanded[0,:,:,0])

```


Dockerfile:
```
FROM nvcr.io/nvidia/tensorflow:24.06-tf2-py3 AS base_image
ENV DEBIAN_FRONTEND=noninteractive
RUN apt-get update && apt-get install -y \
    wget \
    build-essential \
    cmake \
    git \
    unzip \
    pkg-config
WORKDIR /environment
RUN pip install --upgrade pip
RUN pip install -U numpy protobuf tensorflow-datasets tensorflow_graphics keras scikit-learn scikit-image pandas seaborn jupyter keras-tuner openml opencv-python typing-extensions pydot graphviz data-science-types adjustText
RUN apt-get update && apt-get install -y \
    graphviz
EXPOSE 8888
ENTRYPOINT [""jupyter"", ""notebook"", ""--no-browser"",""--ip=0.0.0.0""]
```
```


### Relevant log output

```shell
2024-09-06 17:35:56.430840: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at strided_slice_op.cc:266 : INVALID_ARGUMENT: slice index 4 of dimension 1 out of bounds.

Stack trace for op definition: 
File ""usr/lib/python3.10/runpy.py"", line 196, in _run_module_as_main
File ""usr/lib/python3.10/runpy.py"", line 86, in _run_code
File ""usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py"", line 18, in <module>
File ""usr/local/lib/python3.10/dist-packages/traitlets/config/application.py"", line 1043, in launch_instance
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py"", line 739, in start
File ""usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py"", line 205, in start
File ""usr/lib/python3.10/asyncio/base_events.py"", line 603, in run_forever
File ""usr/lib/python3.10/asyncio/base_events.py"", line 1909, in _run_once
File ""usr/lib/python3.10/asyncio/events.py"", line 80, in _run
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 545, in dispatch_queue
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 534, in process_one
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 437, in dispatch_shell
File ""usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py"", line 362, in execute_request
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 778, in execute_request
File ""usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py"", line 449, in do_execute
File ""usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py"", line 549, in run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3051, in run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3106, in _run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py"", line 129, in _pseudo_sync_runner
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3311, in run_cell_async
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3493, in run_ast_nodes
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3553, in run_code
File ""tmp/ipykernel_2107/74085429.py"", line 137, in <module>
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 508, in predict
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 208, in one_step_on_data_distributed
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 198, in one_step_on_data
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 96, in predict_step
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 807, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 1315, in _maybe_build
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 225, in build_wrapper
File ""usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py"", line 183, in build
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 882, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 46, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 156, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 58, in symbolic_call
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 1047, in compute_output_spec
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 78, in compute_output_spec
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py"", line 200, in compute_output_spec
File ""tmp/ipykernel_2107/74085429.py"", line 38, in call
File ""tmp/ipykernel_2107/3701247216.py"", line 88, in _bilinear_interpolate
File ""tmp/ipykernel_2107/2303768048.py"", line 100, in _safe_lookup_pixel
File ""tmp/ipykernel_2107/2303768048.py"", line 101, in _safe_lookup_pixel

2024-09-06 17:35:56.430922: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at if_op.cc:269 : INVALID_ARGUMENT: slice index 4 of dimension 1 out of bounds.

Stack trace for op definition: 
File ""usr/lib/python3.10/runpy.py"", line 196, in _run_module_as_main
File ""usr/lib/python3.10/runpy.py"", line 86, in _run_code
File ""usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py"", line 18, in <module>
File ""usr/local/lib/python3.10/dist-packages/traitlets/config/application.py"", line 1043, in launch_instance
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py"", line 739, in start
File ""usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py"", line 205, in start
File ""usr/lib/python3.10/asyncio/base_events.py"", line 603, in run_forever
File ""usr/lib/python3.10/asyncio/base_events.py"", line 1909, in _run_once
File ""usr/lib/python3.10/asyncio/events.py"", line 80, in _run
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 545, in dispatch_queue
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 534, in process_one
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 437, in dispatch_shell
File ""usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py"", line 362, in execute_request
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 778, in execute_request
File ""usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py"", line 449, in do_execute
File ""usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py"", line 549, in run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3051, in run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3106, in _run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py"", line 129, in _pseudo_sync_runner
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3311, in run_cell_async
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3493, in run_ast_nodes
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3553, in run_code
File ""tmp/ipykernel_2107/74085429.py"", line 137, in <module>
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 508, in predict
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 208, in one_step_on_data_distributed
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 198, in one_step_on_data
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 96, in predict_step
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 807, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 1315, in _maybe_build
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 225, in build_wrapper
File ""usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py"", line 183, in build
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 882, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 46, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 156, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 58, in symbolic_call
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 1047, in compute_output_spec
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 78, in compute_output_spec
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py"", line 200, in compute_output_spec
File ""tmp/ipykernel_2107/74085429.py"", line 38, in call
File ""tmp/ipykernel_2107/3701247216.py"", line 88, in _bilinear_interpolate
File ""tmp/ipykernel_2107/2303768048.py"", line 100, in _safe_lookup_pixel
File ""tmp/ipykernel_2107/2303768048.py"", line 101, in _safe_lookup_pixel

	 [[{{node cond_2/strided_slice}}]]
	tf2xla conversion failed while converting cond_2_true_603071_const_1002[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.

Stack trace for op definition: 
File ""usr/lib/python3.10/runpy.py"", line 196, in _run_module_as_main
File ""usr/lib/python3.10/runpy.py"", line 86, in _run_code
File ""usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py"", line 18, in <module>
File ""usr/local/lib/python3.10/dist-packages/traitlets/config/application.py"", line 1043, in launch_instance
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py"", line 739, in start
File ""usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py"", line 205, in start
File ""usr/lib/python3.10/asyncio/base_events.py"", line 603, in run_forever
File ""usr/lib/python3.10/asyncio/base_events.py"", line 1909, in _run_once
File ""usr/lib/python3.10/asyncio/events.py"", line 80, in _run
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 545, in dispatch_queue
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 534, in process_one
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 437, in dispatch_shell
File ""usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py"", line 362, in execute_request
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 778, in execute_request
File ""usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py"", line 449, in do_execute
File ""usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py"", line 549, in run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3051, in run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3106, in _run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py"", line 129, in _pseudo_sync_runner
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3311, in run_cell_async
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3493, in run_ast_nodes
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3553, in run_code
File ""tmp/ipykernel_2107/74085429.py"", line 137, in <module>
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 508, in predict
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 208, in one_step_on_data_distributed
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 198, in one_step_on_data
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 96, in predict_step
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 807, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 1315, in _maybe_build
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 225, in build_wrapper
File ""usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py"", line 183, in build
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 882, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 46, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 156, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 58, in symbolic_call
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 1047, in compute_output_spec
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 78, in compute_output_spec
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py"", line 200, in compute_output_spec
File ""tmp/ipykernel_2107/74085429.py"", line 38, in call
File ""tmp/ipykernel_2107/3701247216.py"", line 88, in _bilinear_interpolate
File ""tmp/ipykernel_2107/2303768048.py"", line 100, in _safe_lookup_pixel

2024-09-06 17:35:56.593132: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:580 : INVALID_ARGUMENT: slice index 4 of dimension 1 out of bounds.

Stack trace for op definition: 
File ""usr/lib/python3.10/runpy.py"", line 196, in _run_module_as_main
File ""usr/lib/python3.10/runpy.py"", line 86, in _run_code
File ""usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py"", line 18, in <module>
File ""usr/local/lib/python3.10/dist-packages/traitlets/config/application.py"", line 1043, in launch_instance
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py"", line 739, in start
File ""usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py"", line 205, in start
File ""usr/lib/python3.10/asyncio/base_events.py"", line 603, in run_forever
File ""usr/lib/python3.10/asyncio/base_events.py"", line 1909, in _run_once
File ""usr/lib/python3.10/asyncio/events.py"", line 80, in _run
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 545, in dispatch_queue
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 534, in process_one
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 437, in dispatch_shell
File ""usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py"", line 362, in execute_request
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 778, in execute_request
File ""usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py"", line 449, in do_execute
File ""usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py"", line 549, in run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3051, in run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3106, in _run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py"", line 129, in _pseudo_sync_runner
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3311, in run_cell_async
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3493, in run_ast_nodes
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3553, in run_code
File ""tmp/ipykernel_2107/74085429.py"", line 137, in <module>
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 508, in predict
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 208, in one_step_on_data_distributed
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 198, in one_step_on_data
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 96, in predict_step
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 807, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 1315, in _maybe_build
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 225, in build_wrapper
File ""usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py"", line 183, in build
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 882, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 46, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 156, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 58, in symbolic_call
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 1047, in compute_output_spec
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 78, in compute_output_spec
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py"", line 200, in compute_output_spec
File ""tmp/ipykernel_2107/74085429.py"", line 38, in call
File ""tmp/ipykernel_2107/3701247216.py"", line 88, in _bilinear_interpolate
File ""tmp/ipykernel_2107/2303768048.py"", line 100, in _safe_lookup_pixel
File ""tmp/ipykernel_2107/2303768048.py"", line 101, in _safe_lookup_pixel

	 [[{{node cond_2/strided_slice}}]]
	tf2xla conversion failed while converting cond_2_true_603071_const_1002[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.

Stack trace for op definition: 
File ""usr/lib/python3.10/runpy.py"", line 196, in _run_module_as_main
File ""usr/lib/python3.10/runpy.py"", line 86, in _run_code
File ""usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py"", line 18, in <module>
File ""usr/local/lib/python3.10/dist-packages/traitlets/config/application.py"", line 1043, in launch_instance
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py"", line 739, in start
File ""usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py"", line 205, in start
File ""usr/lib/python3.10/asyncio/base_events.py"", line 603, in run_forever
File ""usr/lib/python3.10/asyncio/base_events.py"", line 1909, in _run_once
File ""usr/lib/python3.10/asyncio/events.py"", line 80, in _run
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 545, in dispatch_queue
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 534, in process_one
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 437, in dispatch_shell
File ""usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py"", line 362, in execute_request
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 778, in execute_request
File ""usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py"", line 449, in do_execute
File ""usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py"", line 549, in run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3051, in run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3106, in _run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py"", line 129, in _pseudo_sync_runner
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3311, in run_cell_async
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3493, in run_ast_nodes
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3553, in run_code
File ""tmp/ipykernel_2107/74085429.py"", line 137, in <module>
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 508, in predict
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 208, in one_step_on_data_distributed
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 198, in one_step_on_data
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 96, in predict_step
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 807, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 1315, in _maybe_build
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 225, in build_wrapper
File ""usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py"", line 183, in build
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 882, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 46, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 156, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 58, in symbolic_call
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 1047, in compute_output_spec
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 78, in compute_output_spec
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py"", line 200, in compute_output_spec
File ""tmp/ipykernel_2107/74085429.py"", line 38, in call
File ""tmp/ipykernel_2107/3701247216.py"", line 88, in _bilinear_interpolate
File ""tmp/ipykernel_2107/2303768048.py"", line 100, in _safe_lookup_pixel

	 [[sequential_75_1/co1_1/PartitionedCall_1002/PartitionedCall_2/cond_2]]
	tf2xla conversion failed while converting __inference_one_step_on_data_615470[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.
2024-09-06 17:35:56.593189: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: slice index 4 of dimension 1 out of bounds.

Stack trace for op definition: 
File ""usr/lib/python3.10/runpy.py"", line 196, in _run_module_as_main
File ""usr/lib/python3.10/runpy.py"", line 86, in _run_code
File ""usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py"", line 18, in <module>
File ""usr/local/lib/python3.10/dist-packages/traitlets/config/application.py"", line 1043, in launch_instance
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py"", line 739, in start
File ""usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py"", line 205, in start
File ""usr/lib/python3.10/asyncio/base_events.py"", line 603, in run_forever
File ""usr/lib/python3.10/asyncio/base_events.py"", line 1909, in _run_once
File ""usr/lib/python3.10/asyncio/events.py"", line 80, in _run
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 545, in dispatch_queue
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 534, in process_one
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 437, in dispatch_shell
File ""usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py"", line 362, in execute_request
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 778, in execute_request
File ""usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py"", line 449, in do_execute
File ""usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py"", line 549, in run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3051, in run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3106, in _run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py"", line 129, in _pseudo_sync_runner
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3311, in run_cell_async
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3493, in run_ast_nodes
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3553, in run_code
File ""tmp/ipykernel_2107/74085429.py"", line 137, in <module>
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 508, in predict
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 208, in one_step_on_data_distributed
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 198, in one_step_on_data
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 96, in predict_step
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 807, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 1315, in _maybe_build
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 225, in build_wrapper
File ""usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py"", line 183, in build
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 882, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 46, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 156, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 58, in symbolic_call
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 1047, in compute_output_spec
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 78, in compute_output_spec
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py"", line 200, in compute_output_spec
File ""tmp/ipykernel_2107/74085429.py"", line 38, in call
File ""tmp/ipykernel_2107/3701247216.py"", line 88, in _bilinear_interpolate
File ""tmp/ipykernel_2107/2303768048.py"", line 100, in _safe_lookup_pixel
File ""tmp/ipykernel_2107/2303768048.py"", line 101, in _safe_lookup_pixel

	 [[{{node cond_2/strided_slice}}]]
	tf2xla conversion failed while converting cond_2_true_603071_const_1002[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.

Stack trace for op definition: 
File ""usr/lib/python3.10/runpy.py"", line 196, in _run_module_as_main
File ""usr/lib/python3.10/runpy.py"", line 86, in _run_code
File ""usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py"", line 18, in <module>
File ""usr/local/lib/python3.10/dist-packages/traitlets/config/application.py"", line 1043, in launch_instance
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py"", line 739, in start
File ""usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py"", line 205, in start
File ""usr/lib/python3.10/asyncio/base_events.py"", line 603, in run_forever
File ""usr/lib/python3.10/asyncio/base_events.py"", line 1909, in _run_once
File ""usr/lib/python3.10/asyncio/events.py"", line 80, in _run
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 545, in dispatch_queue
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 534, in process_one
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 437, in dispatch_shell
File ""usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py"", line 362, in execute_request
File ""usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 778, in execute_request
File ""usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py"", line 449, in do_execute
File ""usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py"", line 549, in run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3051, in run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3106, in _run_cell
File ""usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py"", line 129, in _pseudo_sync_runner
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3311, in run_cell_async
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3493, in run_ast_nodes
File ""usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3553, in run_code
File ""tmp/ipykernel_2107/74085429.py"", line 137, in <module>
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 508, in predict
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 208, in one_step_on_data_distributed
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 198, in one_step_on_data
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 96, in predict_step
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 807, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 1315, in _maybe_build
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 225, in build_wrapper
File ""usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py"", line 183, in build
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 882, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 46, in __call__
File ""usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 156, in error_handler
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 58, in symbolic_call
File ""usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"", line 1047, in compute_output_spec
File ""usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"", line 78, in compute_output_spec
File ""usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py"", line 200, in compute_output_spec
File ""tmp/ipykernel_2107/74085429.py"", line 38, in call
File ""tmp/ipykernel_2107/3701247216.py"", line 88, in _bilinear_interpolate
File ""tmp/ipykernel_2107/2303768048.py"", line 100, in _safe_lookup_pixel

	 [[sequential_75_1/co1_1/PartitionedCall_1002/PartitionedCall_2/cond_2]]
	tf2xla conversion failed while converting __inference_one_step_on_data_615470[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.
	 [[PartitionedCall]]
```
"
2511113211,75280,traceback issue,closed,2024-09-06 20:00:42+00:00,2024-09-24T02:01:37Z,2024-09-24T02:01:34Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/75280,"['stat:awaiting response', 'type:bug', 'stale', '2.17']","['@kevo200,\r\nCould you please provide the tensorflow and the compatible version which you are trying to install. Also there are at least 3 possible scenarios:\r\n\r\n```python\r\n- You need to install the MSVC 2019 redistributable\r\n- Your CPU does not support AVX2 instructions\r\n- Your CPU/Python is on 32 bits\r\n- There is a library that is in a different location/not installed on your system that cannot be loaded.\r\n```\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/61887\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75280"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75280"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.17.0

### Custom code

No

### OS platform and distribution

windows 10

### Mobile device

_No response_

### Python version

3.11.7

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

when trying to run the code shows

### Standalone code to reproduce the issue

```shell
.
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""C:\Users\PC\AppData\Roaming\Python\Python311\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 70, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: Error en una rutina de inicialización de biblioteca de vínculos dinámicos (DLL).
```
"
2511822049,75329,TypeError: `output_signature` must contain objects that are subclass of `tf.TypeSpec` but found <class 'list'> which is not.,closed,2024-09-07 16:03:37+00:00,2024-11-08T02:01:10Z,2024-11-08T02:01:07Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/75329,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.15']","['Hi **@Cherry130** ,\r\nSorry for the dealy, I reproduced the code shared but facing different error .Could you please share the colab gist with all the dependencies to analyze more of it.\r\nThank you!', 'It\'s okay. Below are the libraries this code introduced and their corresponding versions.\r\n*****\r\nimport pandas as pd\r\nimport os\r\nimport scipy.ndimage as nd\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.metrics import r2_score,mean_absolute_error\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport math\r\nimport sys\r\nfrom tensorflow.keras.models import load_model\r\nimport random\r\nimport glob\r\nimport nibabel as nib\r\nfrom collections import defaultdict\r\nfrom tensorflow.keras.optimizers import Adam, SGD,Adagrad\r\nfrom tensorflow.compat.v1 import reset_default_graph\r\nfrom sklearn.model_selection import KFold\r\n#from DataLoader import dataGenerator,getIcelandicData,getIXIData,getUKBData\r\n#from Util import plotData,getPredictions,loadMR,loadHeader,calculateMeanImg\r\n#from ResNet import generateAgePredictionResNet\r\nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\r\nfrom tensorflow.python.keras import backend as K\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_v2_behavior()\r\nfrom tensorflow.keras.models import load_model\r\nfrom tensorflow.keras.utils import Sequence\r\nimport operator\r\nfrom transformations import rotation_matrix\r\nfrom random import gauss\r\nfrom scipy.ndimage.interpolation import map_coordinates\r\n********\r\nName: transformations\r\nVersion: 2024.5.24\r\nName: pandas\r\nVersion: 2.2.2\r\nName: scipy\r\nVersion: 1.11.\r\nName: numpy\r\nVersion: 1.26.4\r\nName: matplotlib\r\nVersion: 3.7.5\r\nName: tensorflow\r\nVersion: 2.15.0\r\nName: nibabel\r\nVersion: 5.2.1\r\n******\r\nthe complete error code is below, but I think the sorce of error is the data_generator\r\nh = model.fit(dataGenerator([train.Loc.values,scanner_train,gender_train],train.AGE.values, batch_size = batchSize, meanImg=meanImg,\r\n                            dim=dataShape,shuffle=True,augment=True,maxAngle=maxAngle,maxShift=maxShift),\r\n                        validation_data=dataGenerator([val.Loc.values,scanner_val,gender_val],val.AGE.values, batch_size = batchSize, \r\n                                                      meanImg=meanImg,dim=dataShape,shuffle=False,augment=False),\r\n                        validation_steps=validation_steps,\r\n                        steps_per_epoch=steps_per_epoch, \r\n                        epochs=nEpochs,\r\n                        verbose=1,\r\n                        callbacks=[mc,early]\r\n                           )\r\n*******\r\nAgain it generated the same problem\r\nTypeError                                 Traceback (most recent call last)\r\nCell In[44], line 1\r\n----> 1 h = model.fit(dataGenerator([train.Loc.values,scanner_train,gender_train],train.AGE.values, batch_size = batchSize, meanImg=meanImg,\r\n      2                             dim=dataShape,shuffle=True,augment=True,maxAngle=maxAngle,maxShift=maxShift),\r\n      3                         validation_data=dataGenerator([val.Loc.values,scanner_val,gender_val],val.AGE.values, batch_size = batchSize, \r\n      4                                                       meanImg=meanImg,dim=dataShape,shuffle=False,augment=False),\r\n      5                         validation_steps=validation_steps,\r\n      6                         steps_per_epoch=steps_per_epoch, \r\n      7                         epochs=nEpochs,\r\n      8                         verbose=1,\r\n      9                         callbacks=[mc,early]\r\n     10                            )\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122, in filter_traceback.<locals>.error_handler(*args, **kwargs)\r\n    119     filtered_tb = _process_traceback_frames(e.__traceback__)\r\n    120     # To get the full stack trace, call:\r\n    121     # `keras.config.disable_traceback_filtering()`\r\n--> 122     raise e.with_traceback(filtered_tb) from None\r\n    123 finally:\r\n    124     del filtered_tb\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py:124, in _from_generator(generator, output_types, output_shapes, args, output_signature, name)\r\n    122   for spec in nest.flatten(output_signature):\r\n    123     if not isinstance(spec, type_spec.TypeSpec):\r\n--> 124       raise TypeError(f""`output_signature` must contain objects that are ""\r\n    125                       f""subclass of `tf.TypeSpec` but found {type(spec)} ""\r\n    126                       f""which is not."")\r\n    127 else:\r\n    128   if output_types is None:\r\n\r\nTypeError: `output_signature` must contain objects that are subclass of `tf.TypeSpec` but found <class \'list\'> which is not.', 'Hi @Cherry130 ,\r\nApologies for the delay, and thank you for your response. I tried running your code using Colab with TensorFlow 2.17.0 and encountered different issues. Please find the [gist](https://colab.research.google.com/gist/Venkat6871/92ad5b7dee121662f0c4811e4e51b03d/75329_tf-2-17-v.ipynb) here for reference. Could you please share the Colab gist with all the dependencies so we can analyze it further?\r\nThank you!', ""\r\n[IXI_MRI.docx](https://github.com/user-attachments/files/17045472/IXI_MRI.docx)\r\n[IXI_2_scanner.xlsx](https://github.com/user-attachments/files/17045476/IXI_2_scanner.xlsx)\r\n**************************\r\nThe first file above is all the code, under the environment configuration told before, due to some problems such as the network, I may not be able to log in to the Colab website, I'm very sorry\r\nThe second file is the incoming tabular data. What else that can't be passed in is the MRI data of the brain.\r\nI'm a newbie to machine learning and this issue has been bothering me for a month, thank you so much for your help.\r\n"", 'Hi @Cherry130 ,\r\nApologies for the delay. You provided a very large code snippet, which makes it hard for us to debug. Could you please try to provide a simpler code example where you are facing the issue?\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75329"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75329"">No</a>\n', 'Hi **@Cherry130** ,\r\nApologies for the delay, and thank you for your patience.\r\nI tried running your code on Colab using TensorFlow 2.17.0. I downloaded your files and added the paths as required, but the paths are still not being found. I am providing the [gist](https://colab.sandbox.google.com/gist/Venkat6871/ac221a7456d50dc689f4a62f5d7f6f24/75329_2-17-0.ipynb) here for reference. Please go through it and let me know if I need to make any changes.\r\nRegarding your TypeError issue, I suggest the following solution. In a TensorFlow data pipeline, the output_signature must contain objects that are subclasses of tf.TypeSpec, such as tf.TensorSpec or tf.RaggedTensorSpec. However, in your generator, you wrote a list. Instead, try using a tuple. I hope this resolves the issue.\r\nThank you!\r\n\r\n', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75329"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75329"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.15.0

### Custom code

Yes

### OS platform and distribution

Linux

### Mobile device

Linux

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I tried to rerun the code previously based on tf 2.1.0 by using tf 2.15.0 and I met a problem due to the wrong data format. Hope for some solutions. Thank you very much.

### Standalone code to reproduce the issue

```shell
class dataGenerator(Sequence):
    'Generates data for Keras'
    def __init__(self, features, labels, batch_size=32,meanImg=None, dim=(121, 145, 121),maxAngle=40,maxShift=10, shuffle=True,augment=False,includeScannerGender=True):
        'Initialization'
        self.batch_size = batch_size
        self.features = features
        self.labels = labels
        self.dim = dim
        self.meanImg = meanImg
        self.augment = augment
        self.maxAngle = maxAngle
        self.maxShift = maxShift
        self.shuffle = shuffle
        self.IncludeScannerGender = includeScannerGender
        self.on_epoch_end()  
    def __len__(self):
        'Denotes the number of batches per epoch'
        return int(np.floor(self.features[0].shape[0] / self.batch_size))
    
    def on_epoch_end(self):
        'Updates indexes after each epoch'
        self.indexes = np.arange(len(self.features[0]))
        if self.shuffle == True:
            np.random.shuffle(self.indexes)
            
    def __getitem__(self, index):
        'Generate one batch of data'
        # Generate indexes of the batch
        #print(index)
        index = index%self.__len__()
        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]

        # Find list of IDs
        #features_temp = [self.features[k] for k in indexes]

        # Generate data
        X, y = self.__data_generation(indexes)

        return X, y
    def __data_generation(self, indexes):
        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)
        # Initialization
        #X = np.empty((self.batch_size, self.dim[0],self.dim[1],self.dim[2]),dtype=np.uint8)
        X = np.empty((self.batch_size, self.dim[0],self.dim[1],self.dim[2], 1),dtype=np.uint8)
        age = np.empty((self.batch_size))
        if self.IncludeScannerGender: 
            sex = np.empty((self.batch_size))
            scanner = np.empty((self.batch_size))
        # Generate data
        for i, index in enumerate(indexes):
            X[i,:,:,:,:] = processing(self.features[0][index],self.dim,self.meanImg,augment=self.augment)
            age[i] = self.labels[index]
            if self.IncludeScannerGender: 
                scanner[i] = self.features[1][index]
                sex[i] = self.features[2][index]
                
        
        if self.IncludeScannerGender: 
            return [X,scanner,sex], np.array([age])
        else:
            return [X], np.array([age])
**************&AND

h = model.fit(dataGenerator([train.Loc.values,scanner_train,gender_train],train.AGE.values, batch_size = batchSize, meanImg=meanImg,
                            dim=dataShape,shuffle=True,augment=True,maxAngle=maxAngle,maxShift=maxShift),
                        validation_data=dataGenerator([val.Loc.values,scanner_val,gender_val],val.AGE.values, batch_size = batchSize, 
                                                      meanImg=meanImg,dim=dataShape,shuffle=False,augment=False),
                       
                           )
```


### Relevant log output

```shell
TypeError                                 Traceback (most recent call last)
Cell In[135], line 1
----> 1 h = model.fit(dataGenerator([train.Loc.values,scanner_train,gender_train],train.AGE.values, batch_size = batchSize, meanImg=meanImg,
      2                             dim=dataShape,shuffle=True,augment=True,maxAngle=maxAngle,maxShift=maxShift),
      3                         validation_data=dataGenerator([val.Loc.values,scanner_val,gender_val],val.AGE.values, batch_size = batchSize, 
      4                                                       meanImg=meanImg,dim=dataShape,shuffle=False,augment=False),
      5                        
      6                            )

File /opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122, in filter_traceback.<locals>.error_handler(*args, **kwargs)
    119     filtered_tb = _process_traceback_frames(e.__traceback__)
    120     # To get the full stack trace, call:
    121     # `keras.config.disable_traceback_filtering()`
--> 122     raise e.with_traceback(filtered_tb) from None
    123 finally:
    124     del filtered_tb

File /opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py:124, in _from_generator(generator, output_types, output_shapes, args, output_signature, name)
    122   for spec in nest.flatten(output_signature):
    123     if not isinstance(spec, type_spec.TypeSpec):
--> 124       raise TypeError(f""`output_signature` must contain objects that are ""
    125                       f""subclass of `tf.TypeSpec` but found {type(spec)} ""
    126                       f""which is not."")
    127 else:
    128   if output_types is None:

TypeError: `output_signature` must contain objects that are subclass of `tf.TypeSpec` but found <class 'list'> which is not.
```
"
2512499883,75353,Hermetic Cuda doesn't respect really aarch64(Tegra devices),closed,2024-09-08 17:50:20+00:00,2024-09-13T17:52:51Z,2024-09-13T17:52:48Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/75353,"['type:bug', 'comp:xla', '2.17']","['Hi **@johnnynunez** ,\r\nApologies for the delay. The [PR](https://github.com/openxla/xla/pull/16905) has been assigned for review, and once it is merged, this issue will be moved to closed status.\r\nThank you!', '> Hi **@johnnynunez** , Apologies for the delay. The [PR](https://github.com/openxla/xla/pull/16905) has been assigned for review, and once it is merged, this issue will be moved to closed status. Thank you!\r\n\r\nthanks to you and the entire JAX team', 'The fix in https://github.com/openxla/xla/pull/17149 is submitted.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75353"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75353"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.17

### Custom code

Yes

### OS platform and distribution

ubuntu 22.04

### Mobile device

jetson

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

https://github.com/openxla/xla/issues/16912
Hermetic Cuda doesn't respect really aarch64(Tegra devices)
SBSA is for aarch64 but for arm servers.
aarch64 for nvidia is formally tegra cpus, like jetson.

### Standalone code to reproduce the issue

```shell
compile with hermetic cuda
```


### Relevant log output

_No response_"
2515972165,75465,Custom `tf.keras.metrics.Metric` example fails on GPU in TF 2.17 (but not on nightly): is it possible to get it to work on 2.17?,closed,2024-09-10 09:55:00+00:00,2024-09-11T11:02:43Z,2024-09-11T11:02:40Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/75465,"['stat:awaiting response', 'type:bug', 'comp:keras', '2.17']","['Hi **@jchwenger** ,\r\nI tried to run your code on Colab using TF v2.16.1, 2.17.0 and faced the same issue. Please find the [gist](https://colab.research.google.com/gist/Venkat6871/134520654652320ce70b5dfb8e93f9d9/75465_tf-2-17-0-2-16-1-v.ipynb?authuser=1) here for reference.\r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues) as this issue is more related to keras.\r\nThank you!', 'Sounds good @Venkat6871, I will, thanks! ', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75465"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75465"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.17

### Custom code

Yes

### OS platform and distribution

Ubuntu 22.04

### Mobile device

_No response_

### Python version

3.10.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

T4

### Current behavior?

When running code (from *Deep Learning with Python*, for teaching) in Colab with the standard TF 2.17, defining a custom metric seems to fail to move variables to the GPU.

This goes away with TF nightly, but I wondered if there was something that could be specified in the class in 2.17 to solve the issue?

[Notebook here](https://drive.google.com/file/d/14rNRJnh6zHNHb14mcZA3F6nnywTk7LSu/view?usp=sharing).

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

def get_mnist_model():
    inputs = tf.keras.Input(shape=(28 * 28,))
    features = tf.keras.layers.Dense(512, activation=""relu"")(inputs)
    features = tf.keras.layers.Dropout(0.5)(features)
    outputs = tf.keras.layers.Dense(10, activation=""softmax"")(features)
    model = tf.keras.Model(inputs, outputs)
    return model

(images, labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()
images = images.reshape((60000, 28 * 28)).astype(""float32"") / 255
test_images = test_images.reshape((10000, 28 * 28)).astype(""float32"") / 255
train_images, val_images = images[10000:], images[:10000]
train_labels, val_labels = labels[10000:], labels[:10000]

class RootMeanSquaredError(tf.keras.metrics.Metric):
    def __init__(self, name=""rmse"", **kwargs):
        super().__init__(name=name, **kwargs)
        self.mse_sum = self.add_weight(name=""mse_sum"", initializer=""zeros"")
        self.total_samples = self.add_weight(
            name=""total_samples"", initializer=""zeros"", dtype=""int32""
        )

    def update_state(self, y_true, y_pred, sample_weight=None):
        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])
        mse = tf.reduce_sum(tf.square(y_true - y_pred))
        self.mse_sum.assign_add(mse)
        num_samples = tf.shape(y_pred)[0]
        self.total_samples.assign_add(num_samples)

    def result(self):
        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))

    def reset_state(self):
        self.mse_sum.assign(0.0)
        self.total_samples.assign(0)

model = get_mnist_model()
model.compile(
    optimizer=""rmsprop"",
    loss=""sparse_categorical_crossentropy"",
    metrics=[""accuracy"", RootMeanSquaredError()],
)
model.fit(
    train_images, train_labels, epochs=3, validation_data=(val_images, val_labels)
)
test_metrics = model.evaluate(test_images, test_labels)
```


### Relevant log output

```shell
Epoch 1/3
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-5-8c78bd9ca7c0> in <cell line: 7>()
      5     metrics=[""accuracy"", RootMeanSquaredError()],
      6 )
----> 7 model.fit(
      8     train_images, train_labels, epochs=3, validation_data=(val_images, val_labels)
      9 )

1 frames
/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     51   try:
     52     ctx.ensure_initialized()
---> 53     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
     54                                         inputs, attrs, num_outputs)
     55   except core._NotOkStatusException as e:

InvalidArgumentError: Graph execution error:

Detected at node StatefulPartitionedCall defined at (most recent call last):
  File ""/usr/lib/python3.10/runpy.py"", line 196, in _run_module_as_main

  File ""/usr/lib/python3.10/runpy.py"", line 86, in _run_code

  File ""/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py"", line 37, in <module>

  File ""/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py"", line 992, in launch_instance

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py"", line 619, in start

  File ""/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py"", line 195, in start

  File ""/usr/lib/python3.10/asyncio/base_events.py"", line 603, in run_forever

  File ""/usr/lib/python3.10/asyncio/base_events.py"", line 1909, in _run_once

  File ""/usr/lib/python3.10/asyncio/events.py"", line 80, in _run

  File ""/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py"", line 685, in <lambda>

  File ""/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py"", line 738, in _run_callback

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 825, in inner

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 786, in run

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 377, in dispatch_queue

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 250, in wrapper

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 748, in __init__

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 786, in run

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 361, in process_one

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 234, in wrapper

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 261, in dispatch_shell

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 234, in wrapper

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 539, in execute_request

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 234, in wrapper

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py"", line 302, in do_execute

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py"", line 539, in run_cell

  File ""/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 2975, in run_cell

  File ""/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3030, in _run_cell

  File ""/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py"", line 78, in _pseudo_sync_runner

  File ""/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3257, in run_cell_async

  File ""/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3473, in run_ast_nodes

  File ""/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3553, in run_code

  File ""<ipython-input-5-8c78bd9ca7c0>"", line 7, in <cell line: 7>

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 318, in fit

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 121, in one_step_on_iterator

Trying to access resource rmse/total_samples/29 (defined @ /usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py:31) located in device /job:localhost/replica:0/task:0/device:CPU:0 from device /job:localhost/replica:0/task:0/device:GPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
	 [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_iterator_18234]
```
"
2526435628,75785,    tf-nightly[and-cuda] depends on archived version of nvidia-cudnn-cu12==8.9.7.29,closed,2024-09-14 13:51:51+00:00,2024-09-14T15:57:39Z,2024-09-14T15:57:36Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/75785,['type:bug'],"['Nevermind, just realized I was going about this all wrong...I think.   I need to run the tensorflow-gpu docker image instead and run my models there. Sorry for wasting your time. ', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75785"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75785"">No</a>\n', ""Okay, so maybe not. \r\n\r\nStatus: Downloaded newer image for tensorflow/tensorflow:latest-gpu\r\nWARNING: The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested\r\nexec /usr/bin/python: exec format error\r\n\r\nHere's my issue, according to AWS the recommended instance type for deep learning model training is the G5G instance type, there is only one AMI that AWS publishes that supports the G5G instance type, and it's the Deep Learning ARM64 Base OSS Nvidia Driver GPU AMI (Ubuntu 22.04) 20240823 on a g5g.xlarge. \r\nami-0f3ed94d52ca29367.  And it seems like tensorflow only publishes docker images for amd64.   Do you have any guidance here?"", ""Nevermind, I spoke with AWS support and they said to use the G5 and not the G5G since tensorflow doesn't support it.   I'll leave this open, because it would be nice if tensorflow published ARM64 docker images. "", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75785"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75785"">No</a>\n', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75785"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75785"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.18.0.dev20240910-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64

### Custom code

No

### OS platform and distribution

Deep Learning ARM64 Base OSS Nvidia Driver GPU AMI (Ubuntu 22.04) 20240823

### Mobile device

_No response_

### Python version

Python 3.11.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

 12.2

### GPU model and memory

_No response_

### Current behavior?

I expected it to install a version of nvidia-cudnn-cu12 that is available. 

pip index versions nvidia-cudnn-cu12
nvidia-cudnn-cu12 (9.4.0.58)
Available versions: 9.4.0.58, 9.3.0.75, 9.2.1.18, 9.2.0.82, 9.1.1.17, 9.1.0.70.post1, 9.0.0.312.post1, 9.0.0.312

### Standalone code to reproduce the issue

```shell
Its very simple to reproduce.  Launch an instance of Deep Learning ARM64 Base OSS Nvidia Driver GPU AMI (Ubuntu 22.04) 20240823 on a g5g.xlarge. 
ami-0f3ed94d52ca29367 on AWS.  Try to install tensorflow[and-cuda] or tf-nightly[and-cuda] and it will fail because tf-nightly[and-cuda] 2.18.0.dev20240617 depends on nvidia-cudnn-cu12==8.9.7.29; extra == ""and-cuda"".  That version isn't available anymore...

pip index versions nvidia-cudnn-cu12
nvidia-cudnn-cu12 (9.4.0.58)
Available versions: 9.4.0.58, 9.3.0.75, 9.2.1.18, 9.2.0.82, 9.1.1.17, 9.1.0.70.post1, 9.0.0.312.post1, 9.0.0.312
```


### Relevant log output

_No response_"
2526731457,75815,ruy::CpuInfo::Initialize() Null pointer dereference: SIGSEGV  0x0000000000000008,closed,2024-09-15 04:21:34+00:00,2024-12-29T00:46:17Z,2024-11-26T06:32:12Z,arfaian,,https://github.com/tensorflow/tensorflow/issues/75815,"['stat:awaiting tensorflower', 'type:bug', 'comp:lite', 'TF 2.16']","['Hi, @pkgoogle\r\n\r\nCould you please take look into this issue? Thank you.', ""Hi @ninh-huynh, I am unfamiliar with how firebase crashlytics sets up its environments -- at first glance thats what it kind of looks like to me -- an issue with their environment setup -- since you can't figure out a way to reproduce it locally. Perhaps Firebase support will be a better starting point: https://firebase.google.com/support/troubleshooter/contact?visit_id=638621964296946057-4039620740&rd=1 until we can get more information."", 'Hi @pkgoogle\r\n\r\nWhat do you mean about ""Firebase crashlytics sets up its environments""? The Crashlytics library helps produce readable stack-trace from the native library from Firebase Console (a web service that helps our developer monitor crashes from user devices). We still need to build an unstripped library manually and then provide a path to Firebase Crashlytics.  \r\n\r\nYou can take a quick look at how it was easy to setup Crashlytics to an Android project here. https://firebase.google.com/docs/crashlytics/ndk-reports\r\n\r\nNot every crash/issue from users is always reproducible, as a developer we try to help them as much as possible. Can you take a look at the source code file, function name,... from stack-trace above and review the recent change of tensorflow to see if anything relates to the crash? \r\n', 'Hi @arfaian, can you please take a look? Thanks.', ""We're seeing perhaps a related issue with Redmi and Vivo devices. It's affecting a large number of users. Is there a plan to address this?"", 'Hi @sebouh00, do you have any of these error logs?', ""Here's a sample crash log I'm seeing:\r\n\r\n```\r\n*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\r\npid: 0, tid: 6913 >>> com.sentiance.journeys2 <<<\r\n\r\nbacktrace:\r\n  #00  pc 0x000000000024fc48  /data/app/~~G6Pm98TxHmmZaYljDtBtvw==/com.sentiance.journeys2-GwfAF6oW3sfoEBLO8RcMsw==/split_config.arm64_v8a.apk!libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n  #01  pc 0x000000000024fca4  /data/app/~~G6Pm98TxHmmZaYljDtBtvw==/com.sentiance.journeys2-GwfAF6oW3sfoEBLO8RcMsw==/split_config.arm64_v8a.apk!libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n  #02  pc 0x000000000024e7ac  /data/app/~~G6Pm98TxHmmZaYljDtBtvw==/com.sentiance.journeys2-GwfAF6oW3sfoEBLO8RcMsw==/split_config.arm64_v8a.apk!libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n  #03  pc 0x000000000024e83c  /data/app/~~G6Pm98TxHmmZaYljDtBtvw==/com.sentiance.journeys2-GwfAF6oW3sfoEBLO8RcMsw==/split_config.arm64_v8a.apk!libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n  #04  pc 0x00000000000d9f5c  /data/app/~~G6Pm98TxHmmZaYljDtBtvw==/com.sentiance.journeys2-GwfAF6oW3sfoEBLO8RcMsw==/split_config.arm64_v8a.apk!libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n  #05  pc 0x00000000000d93a4  /data/app/~~G6Pm98TxHmmZaYljDtBtvw==/com.sentiance.journeys2-GwfAF6oW3sfoEBLO8RcMsw==/split_config.arm64_v8a.apk!libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n  #06  pc 0x00000000000d5858  /data/app/~~G6Pm98TxHmmZaYljDtBtvw==/com.sentiance.journeys2-GwfAF6oW3sfoEBLO8RcMsw==/split_config.arm64_v8a.apk!libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n  #07  pc 0x000000000030205c  /data/app/~~G6Pm98TxHmmZaYljDtBtvw==/com.sentiance.journeys2-GwfAF6oW3sfoEBLO8RcMsw==/split_config.arm64_v8a.apk!libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n  #08  pc 0x0000000000301b5c  /data/app/~~G6Pm98TxHmmZaYljDtBtvw==/com.sentiance.journeys2-GwfAF6oW3sfoEBLO8RcMsw==/split_config.arm64_v8a.apk!libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n  #09  pc 0x00000000002f6124  /data/app/~~G6Pm98TxHmmZaYljDtBtvw==/com.sentiance.journeys2-GwfAF6oW3sfoEBLO8RcMsw==/split_config.arm64_v8a.apk!libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n  #10  pc 0x000000000007f9c0  /data/app/~~G6Pm98TxHmmZaYljDtBtvw==/com.sentiance.journeys2-GwfAF6oW3sfoEBLO8RcMsw==/split_config.arm64_v8a.apk!libtensorflowlite_jni.so (Java_org_tensorflow_lite_NativeInterpreterWrapper_run+88) (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n  #11  pc 0x00000000004bc2a0  /data/misc/apexdata/com.android.art/dalvik-cache/arm64/boot.oat (art_jni_trampoline+112)\r\n  #12  pc 0x000000000077f00c  /apex/com.android.art/lib64/libart.so (nterp_helper+1948)\r\n  #13  pc 0x000000000142f2f8  /data/app/~~G6Pm98TxHmmZaYljDtBtvw==/com.sentiance.journeys2-GwfAF6oW3sfoEBLO8RcMsw==/oat/arm64/base.vdex (org.tensorflow.lite.NativeInterpreterWrapper.run+124)\r\n  #14  pc 0x000000000077f7c4  /apex/com.android.art/lib64/libart.so (nterp_helper+3924)\r\n  #15  pc 0x000000000142e26e  /data/app/~~G6Pm98TxHmmZaYljDtBtvw==/com.sentiance.journeys2-GwfAF6oW3sfoEBLO8RcMsw==/oat/arm64/base.vdex (org.tensorflow.lite.InterpreterImpl.runForMultipleInputsOutputs+10)\r\n  #16  pc 0x000000000077f7c4  /apex/com.android.art/lib64/libart.so (nterp_helper+3924)\r\n  #17  pc 0x000000000142e5f4  /data/app/~~G6Pm98TxHmmZaYljDtBtvw==/com.sentiance.journeys2-GwfAF6oW3sfoEBLO8RcMsw==/oat/arm64/base.vdex (org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs)\r\n  #18  pc 0x000000000077f7c4  /apex/com.android.art/lib64/libart.so (nterp_helper+3924)\r\n  ...\r\n```"", 'Additional crash log that I obtained from a breakpad minidump. Unfortunately, no symbols to resolve the addresses.\r\n```\r\nOperating system: Android\r\n                  0.0.0 Linux 4.14.186-g9ce5b7f15-dirty #1 SMP PREEMPT Sun Apr 24 16:54:14 CST 2022 aarch64\r\nCPU: arm64\r\n     8 CPUs\r\n\r\nGPU: UNKNOWN\r\n\r\nCrash reason:  SIGSEGV /SEGV_MAPERR\r\nCrash address: 0x8\r\nProcess uptime: not available\r\n\r\nThread 40 (crashed)\r\n 0  libtensorflowlite_jni.so + 0x24fc48\r\n     x0 = 0x0000000000000000    x1 = 0x00000075f6f9b664\r\n     x2 = 0x00000075e4fb2020    x3 = 0x00000075e4fb2008\r\n     x4 = 0x0000000000000000    x5 = 0xb4000077785b8390\r\n     x6 = 0x00000075e4fb20e8    x7 = 0x000000b400000708\r\n     x8 = 0xb4000077b859a030    x9 = 0x0000000000000006\r\n    x10 = 0x0000000000000050   x11 = 0xfffffffffffffff7\r\n    x12 = 0x0000000000000009   x13 = 0xb4000077185a36f9\r\n    x14 = 0x00000000fffffff7   x15 = 0x00000075f6cdef5c\r\n    x16 = 0x00000075f6fe81d8   x17 = 0x000000796e17b430\r\n    x18 = 0x00000075e49f4000   x19 = 0xb4000077785b843c\r\n    x20 = 0x0000000000000006   x21 = 0x0000000000000002\r\n    x22 = 0xb4000076f85e3fe0   x23 = 0x0000000000020000\r\n    x24 = 0xb40000779857a540   x25 = 0xb40000779857a540\r\n    x26 = 0x0000000000000000   x27 = 0x0000000000000000\r\n    x28 = 0x0000000000000000    fp = 0x0000000000000003\r\n     lr = 0x00000075f6efdc48    sp = 0x00000075e4fb1cf0\r\n     pc = 0x00000075f6efdc48\r\n    Found by: given as instruction pointer in context\r\n 1  libtensorflowlite_jni.so + 0x24fca4\r\n     sp = 0x00000075e4fb1d08    pc = 0x00000075f6efdca8\r\n    Found by: stack scanning\r\n 2  libtensorflowlite_jni.so + 0x24e7ac\r\n     sp = 0x00000075e4fb1d48    pc = 0x00000075f6efc7b0\r\n    Found by: stack scanning\r\n 3  libtensorflowlite_jni.so + 0x2656ec\r\n     sp = 0x00000075e4fb1db8    pc = 0x00000075f6f136f0\r\n    Found by: stack scanning\r\n 4  libtensorflowlite_jni.so + 0x24e83c\r\n     sp = 0x00000075e4fb1dc8    pc = 0x00000075f6efc840\r\n    Found by: stack scanning\r\n 5  libtensorflowlite_jni.so + 0xd9f5c\r\n     sp = 0x00000075e4fb1e08    pc = 0x00000075f6d87f60\r\n    Found by: stack scanning\r\n 6  libtensorflowlite_jni.so + 0xd93a4\r\n     sp = 0x00000075e4fb1e48    pc = 0x00000075f6d873a8\r\n    Found by: stack scanning\r\n```\r\nWe heavily rely on TensorFlow Lite in our library, and unfortunately this is impacting a lot of users.', ""Could it be related to the issue that's been addressed [here](https://github.com/google/ruy/commit/690c14c441387a4ea6e07a9ed89657cec8200b92)?"", ""> Could it be related to the issue that's been addressed [here](https://github.com/google/ruy/commit/690c14c441387a4ea6e07a9ed89657cec8200b92)?\r\n\r\nThat sounds promising. Don't know if we could verify that issue locally. I can confirm that the issue affects our app mostly on Xiaomi & Vivo devices too."", '@ninh-huynh Is the crash that you experienced with the production build of TFL also at `libtensorflowlite_jni.so + 0x24fc48`?', '> @ninh-huynh Is the crash that you experienced with the production build of TFL also at `libtensorflowlite_jni.so + 0x24fc48`?\r\n\r\nOur team currently use custom TF Lite on production (with tflite_keep_symbols=true), so the report from Firebase is fully human readable (It crash at cpuinfo.cc - Line 66). Seem related to google/ruy#349', ""@ninh-huynh Thanks. I just want to be sure our issues are related. As I don't have human readable stack traces, I was wondering whether my crash resembles yours, when you originally got it with the production TFL build. And whether after you switched to the custom TFL build in your app, the crash log that you shared from Firebase is the only TFL crash that you're seeing."", ""> @ninh-huynh Thanks. I just want to be sure our issues are related. As I don't have human readable stack traces, I was wondering whether my crash resembles yours, when you originally got it with the production TFL build. And whether after you switched to the custom TFL build in your app, the crash log that you shared from Firebase is the only TFL crash that you're seeing.\r\n\r\nOur feature using TFL don't have any update recently. Just updating TFT to version 2.16.1 and bum, fresh crash appear without stacktrace. Also, I already suggest the TF team to turn that flag on (see #72877) but no response yet. As a client using the TFL library, I really really don't understand why they turn off that flag. As you can see, that crash non reproducable but user out there being impacted a lot. But they still don't have any suggestion to address this issue."", '> @ninh-huynh Is the crash that you experienced with the production build of TFL also at `libtensorflowlite_jni.so + 0x24fc48`?\r\n\r\nHere is the original crash when I upgraded TFL 2.16.1 (I got it from the user using the old version of the app, before I rebuilt TFL). It also crashes at 0x24fc48\r\n\r\n```\r\n         null pointer dereference: SIGSEGV  0x0000000000000008\r\n#00 pc 0x24fc48 libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#01 pc 0x24fca4 libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#02 pc 0x24e7ac libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#03 pc 0x335f44 libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#04 pc 0x335eb4 libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#05 pc 0x24e83c libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#06 pc 0xd9f5c libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#07 pc 0x10754c libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#08 pc 0x237fe libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#09 pc 0x27e5c4 libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#10 pc 0x1073d8 libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#11 pc 0x15d7e0 libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#12 pc 0x15c0dc libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#13 pc 0xb0e04 libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#14 pc 0x15a108 libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#15 pc 0x30205c libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#16 pc 0x30205c libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#17 pc 0x301b5c libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#18 pc 0x5af57c libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#19 pc 0x2fad4c libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#20 pc 0x2361c8 libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#21 pc 0x803b8 libtensorflowlite_jni.so (BuildId: 385d6d92f29b4b4cb3ffca33758d3471)\r\n#22 pc 0x351230 libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#23 pc 0x35119c libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#24 pc 0x5af57c libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#25 pc 0x5b879c libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#26 pc 0x5af57c libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#27 pc 0x5b8f54 libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#28 pc 0x5af57c libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#29 pc 0x5b8f54 libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#30 pc 0x5be120 libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#31 pc 0x5af57c libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#32 pc 0x5b8f54 libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#33 pc 0x5af57c libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#34 pc 0x5b9d74 libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#35 pc 0x5af57c libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#36 pc 0x5b9d74 libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#37 pc 0x5af57c libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#38 pc 0x5b8f54 libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#39 pc 0x236d80 libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#40 pc 0x5af57c libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#41 pc 0x5b9d74 libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#42 pc 0x5af57c libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#43 pc 0x5b8f54 libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#44 pc 0x72218558\r\n#45 pc 0x6ffb9b1f8c\r\n#46 pc 0x6ffb9fe180\r\n#47 pc 0x6ffb691830\r\n#48 pc 0x6ffba02988\r\n#49 pc 0x6ffb69fab4\r\n#50 pc 0x6ffb69c108\r\n#51 pc 0x3cbc50 libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#52 pc 0xc15ffc libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#53 pc 0x6ffb69d2c4\r\n#54 pc 0x33a7a4 libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#55 pc 0x23a01c libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#56 pc 0x480b4 libc.so (BuildId: 3908c7c57fa04c64df24425cf16523cf)\r\n#57 pc 0x539078 libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#58 pc 0x539108 libart.so (BuildId: 2452917c4ff69cbb6e75e5512260946b)\r\n#59 pc 0xd33ac libc.so (BuildId: 3908c7c57fa04c64df24425cf16523cf)\r\n#60 pc 0xfba4c libc.so (BuildId: 3908c7c57fa04c64df24425cf16523cf)\r\n#61 pc 0x326ffc libc.so (BuildId: 3908c7c57fa04c64df24425cf16523cf)\r\n#62 pc 0x8e5f0 libc.so (BuildId: 3908c7c57fa04c64df24425cf16523cf)\r\n#63 pc 0xfb97c libc.so (BuildId: 3908c7c57fa04c64df24425cf16523cf)\r\n\r\n```', 'Thanks. Then it seems we have the same issue, and your symbolicated stack trace applies to all cases. We will likely patch it ourselves and use that patched version.', ""Hi, @ninh-huynh \r\nThanks for raising this issue. Are you aware of the migration to [LiteRT](https://developers.googleblog.com/en/tensorflow-lite-is-now-litert/)? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/google-ai-edge/LiteRT/issues/36\r\n\r\nLet us know if you have any questions. Thanks."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75815"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75815"">No</a>\n', 'Hi @gaikwadrahul8 \r\nI tried LiteRT v.1.0.1 and it has the same issue. The crash is not fixed.', 'Hi @ninh-huynh \r\nDid you find a solution to avoid the crash? Maybe you downgraded tensorflow version?\r\nThanks!', ""> Thanks. Then it seems we have the same issue, and your symbolicated stack trace applies to all cases. We will likely patch it ourselves and use that patched version.\r\n\r\nHi @sebouh00 , perhaps you have found some working solution? I have the same problem and I can't reproduce it on my devices. My android app randomly crashes."", ""@prilaga Yes. We updated the `ruy` dependency to a version that fixes the crash, and rolled out our own TFL artifact. See [here](https://github.com/sentiance/tensorflow/commit/0aa8cf51def4232d777b56d56f4fe744f887ae1d). We first forked `ruy`, and applied some changes to the bazel build files to make it work with TFL's bazel version. See [here](https://github.com/sentiance/ruy/compare/c08ec52...cfa3b6f)."", '@sebouh00 Thank you for the detailed information!']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tensorflow-lite:2.16.1

### Custom code

No

### OS platform and distribution

_No response_

### Mobile device

Android

### Python version

_No response_

### Bazel version

6.5.0

### GCC/compiler version

Clang 8.0.7

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

We recently upgraded TensorFlow Lite from 2.9.0 to 2.16.1 (the latest version from MavenCentral) and received a fresh native crash issue on Firebase Crashlytic. (Possibly related to #74043). But since the official release of the shared library on MavenCentral was stripped (#72877), we can't investigate further. Our team decided to rebuild TensorFlow Lite 2.16.1 from source, with the flag `tflite_keep_symbols=true` to keep the stack trace info more readable. The issue has about 30k crash events, affecting 7k users. We still, can not reproduce the crash locally.

![crashlytics_report](https://github.com/user-attachments/assets/8a99cbed-06bf-40e9-9d37-f8473c6eb12b)



### Standalone code to reproduce the issue

```shell
We use only two main functions to infer the model, the crash happened in both cases.


org.tensorflow.lite.InterpreterApi#run
```


```
org.tensorflow.lite.Interpreter#runSignature(java.util.Map<java.lang.String,java.lang.Object>, java.util.Map<java.lang.String,java.lang.Object>, java.lang.String)
```
```


### Relevant log output

```shell
null pointer dereference: SIGSEGV  0x0000000000000008
#00 pc 0x23ddd8 libtensorflowlite_jni.so (ruy::CpuInfo::Initialize() [cpuinfo.cc:66]) (BuildId: 488448e6d222d2f499e4c2978695bdc8ea291e71)
#01 pc 0x23ddd4 libtensorflowlite_jni.so (ruy::CpuInfo::Initialize() [cpuinfo.cc:64]) (BuildId: 488448e6d222d2f499e4c2978695bdc8ea291e71)
#02 pc 0x23de6c libtensorflowlite_jni.so (ruy::CpuInfo::NeonDotprod() [cpuinfo.cc:35]) (BuildId: 488448e6d222d2f499e4c2978695bdc8ea291e71)
#03 pc 0x23c2c8 libtensorflowlite_jni.so (ruy::Ctx::GetRuntimeEnabledPaths() [ctx.cc:125]) (BuildId: 488448e6d222d2f499e4c2978695bdc8ea291e71)
#04 pc 0x23c3b4 libtensorflowlite_jni.so (ruy::Ctx::SelectPath(ruy::Path) [ctx.cc:177]) (BuildId: 488448e6d222d2f499e4c2978695bdc8ea291e71)
#05 pc 0xa63b4 libtensorflowlite_jni.so (void ruy::detail::CreateTrMulParamsAssumingColMajorDst<(ruy::Path)49, float, float, float, float>(ruy::Mat<float> const&, ruy::Mat<float> const&, ruy::Mat<float> const&, ruy::MulParams<float, float> const&, ruy::ChannelDimension, ruy::Ctx*, ruy::TrMulParams*) [create_trmul_params.h:423]) (BuildId: 488448e6d222d2f499e4c2978695bdc8ea291e71)
#06 pc 0xa626c libtensorflowlite_jni.so (void ruy::MulFrontEnd<(ruy::Path)49, float, float, float, float>(ruy::Mat<float> const&, ruy::Mat<float> const&, ruy::MulParams<float, float> const&, ruy::Ctx*, ruy::Mat<float>*) [create_trmul_params.h:472]) (BuildId: 488448e6d222d2f499e4c2978695bdc8ea291e71)
#07 pc 0xa5cb8 libtensorflowlite_jni.so (tflite::cpu_backend_gemm::detail::GemmImplUsingRuy<float, float, float, float, (tflite::cpu_backend_gemm::QuantizationFlavor)0>::Run(tflite::cpu_backend_gemm::MatrixParams<float> const&, float const*, tflite::cpu_backend_gemm::MatrixParams<float> const&, float const*, tflite::cpu_backend_gemm::MatrixParams<float> const&, float*, tflite::cpu_backend_gemm::GemmParams<float, float, (tflite::cpu_backend_gemm::QuantizationFlavor)0> const&, tflite::CpuBackendContext*) [ruy.h:46]) (BuildId: 488448e6d222d2f499e4c2978695bdc8ea291e71)
#08 pc 0x12c9bc libtensorflowlite_jni.so (tflite::optimized_ops::FullyConnected(tflite::FullyConnectedParams const&, tflite::RuntimeShape const&, float const*, tflite::RuntimeShape const&, float const*, tflite::RuntimeShape const&, float const*, tflite::RuntimeShape const&, float*, tflite::CpuBackendContext*) [optimized_ops.h:306]) (BuildId: 488448e6d222d2f499e4c2978695bdc8ea291e71)
#09 pc 0x12b108 libtensorflowlite_jni.so (TfLiteStatus tflite::ops::builtin::fully_connected::EvalFloat<(tflite::ops::builtin::fully_connected::KernelType)1>(TfLiteContext*, TfLiteNode*, TfLiteFullyConnectedParams*, tflite::ops::builtin::fully_connected::OpData*, TfLiteTensor const*, TfLiteTensor const*, TfLiteTensor const*, TfLiteTensor*) [fully_connected.cc:1563]) (BuildId: 488448e6d222d2f499e4c2978695bdc8ea291e71)
#10 pc 0x129aa0 libtensorflowlite_jni.so (TfLiteStatus tflite::ops::builtin::fully_connected::Eval<(tflite::ops::builtin::fully_connected::KernelType)1>(TfLiteContext*, TfLiteNode*) [fully_connected.cc:1605]) (BuildId: 488448e6d222d2f499e4c2978695bdc8ea291e71)
#11 pc 0x3403b0 libtensorflowlite_jni.so (tflite::Subgraph::InvokeImpl() [subgraph.cc:1396]) (BuildId: 488448e6d222d2f499e4c2978695bdc8ea291e71)
#12 pc 0x33fd98 libtensorflowlite_jni.so (tflite::Subgraph::Invoke() [subgraph.cc:1581]) (BuildId: 488448e6d222d2f499e4c2978695bdc8ea291e71)
#13 pc 0x333bc8 libtensorflowlite_jni.so (tflite::impl::SignatureRunner::Invoke() [signature_runner.cc:82]) (BuildId: 488448e6d222d2f499e4c2978695bdc8ea291e71)
#14 pc 0x28a4c libtensorflowlite_jni.so (Java_org_tensorflow_lite_NativeSignatureRunnerWrapper_nativeInvoke [nativesignaturerunner_jni.cc:268]) (BuildId: 488448e6d222d2f499e4c2978695bdc8ea291e71)
#15 pc 0x351e30 libart.so (BuildId: ddcc440d4609d2099db9d20895487a78)
```
"
2527272279,75823,CVE-2023-30767,closed,2024-09-15 23:59:59+00:00,2024-09-17T19:34:11Z,2024-09-17T19:34:08Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/75823,"['stat:awaiting response', 'type:bug', 'subtype:cpu-intel']","['There are no more TFSAs filed in this repo, only CVEs and only for advisories that match the updated security posture.\r\n\r\nFor this specific CVE, the vulnerable code is in OneDNN, with is contributed by Intel and not active in `tensorflow` itself. If you use oneDNN then you are affected, otherwise not.', 'Thank you for the prompt response.\r\n\r\nWhat confuses me is, if this CVE only affects code contributed by Intel OneDNN fixed [here](https://github.com/Intel-tensorflow/tensorflow/commit/37f8b09e93ca68f6c97e62794e064f4307a8e00b), why [these same code changes](https://github.com/tensorflow/tensorflow/pull/59581) are also part of TensorFlow release 2.13.0 without it being affected. \r\nEven the branch name [Intel-tensorflow:security_fix_quantiz](https://github.com/Intel-tensorflow/tensorflow/tree/security_fix_quantiz) may suggest something related to security. \r\n\r\nI will appreciate if you help me understand this situation 🙏', ""The code itself is not in use in production if you're not using OneDNN. It's similar to the following scenario\r\n\r\n```cc\r\nif (using_one_dnn) {\r\n  call_the_code_that_got_fixed();\r\n} else {\r\n  run_some_other_code();\r\n}\r\n```\r\n\r\nSince `using_one_dnn` is true only if using OneDNN, the vulnerability does not manifest anywhere else"", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75823"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75823"">No</a>\n']","Hello again!


[Public sources](https://www.intel.com/content/www/us/en/security-center/advisory/intel-sa-00903.html) say that CVE-2023-30767 affects versions of `intel-tensorflow` before than 2.13.0. Here the advisory:

> Improper buffer restrictions in Intel(R) Optimization for TensorFlow before version 2.13.0 may allow an authenticated user to potentially enable escalation of privilege via local access.

_I think_ [this is the related fix PR](https://github.com/tensorflow/tensorflow/pull/59581), which is indeed included in `intel-tensorflow` 2.13.0 **and also** in `tensorflow` itself. 
However, I don't see this security issue mentioned in this repository. It does not appears on https://github.com/tensorflow/tensorflow/security, nor I found a TFSA entry for it, nor it is mentioned in Tensorflow 2.13.0 Release Notes.

Could you clarify this situation? Is TensorFlow affected by CVE-2023-30767 in versions before 2.13.0?


Thank you in advance"
2527493619,75831,tensorflow lite `AllocateTensors()` breaks on raspberry pi pico w,closed,2024-09-16 04:47:52+00:00,2024-09-19T12:24:11Z,2024-09-19T12:24:08Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/75831,"['stat:awaiting response', 'type:bug', 'comp:lite', 'TF 2.15']","[""Hi, @Zlisch \r\n\r\nThank you for bringing this issue to our attention, as far I know there might be the MDN-RNN model you're using too complex for the limited memory of the raspberry pi pico w so please consider simplifying the model by reducing the number of layers, neurons or data types.\r\n\r\nThe `kTensorArenaSize` value might be insufficient. Experiment with increasing it gradually until allocation succeeds but be mindful of memory limitations and also check if there are any other processes or libraries consuming significant memory on raspberry pi pico w.\r\n\r\nPlease make sure that the input data you're providing to the model is valid and compatible with its expected format and dimensions. verify that the input tensor shape matches the model's expected input shape.\r\n\r\nIf possible optimize your model using techniques like quantization or pruning to reduce its memory footprint for that please follow our [official documentation](https://ai.google.dev/edge/litert/models/model_optimization) which will help help you to optimize your model. \r\n\r\nIf issue still persists could you please post this issue in the [tflite-micro](https://github.com/tensorflow/tflite-micro/issues) repo for further help ? \r\n\r\nThank you for your cooperation and patience.\r\n"", 'Thanks for the reply @gaikwadrahul8\r\n\r\nI will try the optimization you mentioned to make the model as small as possible. I also noticed though `model.tflite` can be quite small, e.g. 41KB, the `model.cc` created by hex dump can be 251KB large. Is there anything that can be done?', 'Hey @Zlisch ,\r\nRegarding your query on model size blow-up on conversion from Tflite to C data array. This is happening because HEX dump naturally takes more space than the Tflite optimised storing format, but once you compile the model.cc file your executable should be close the original .tflite file.\r\n\r\nHere is the original thread regarding this issue...\r\nhttps://github.com/tensorflow/tensorflow/issues/43749#issuecomment-703227741', ""I have tried with a much reduced [model](https://github.com/Zlisch/tflite-pico/blob/main/examples/impsy_model/musicMDRNN-dim4-layers1-units4-mixtures5-scale10.cc) (model size 13092B, # parameters = 369) but it still doesn't work. I've raised a [new issue](https://github.com/tensorflow/tflite-micro/issues/2686) to the tflite-micro repo."", ""Hi, @Zlisch\r\n\r\nThank you for the update and trying things, I see you've posted this issue here https://github.com/tensorflow/tflite-micro/issues/2686 for further help so please feel free to close this issue from your end\r\n\r\nIf you need any further help with TensorFlow core or TensorFlow Lite (now renamed as [LiteRT](https://ai.google.dev/edge/litert))  please feel free to post your [issue](https://github.com/tensorflow/tensorflow/issues/new/choose)\r\n\r\nThank you for your cooperation and patience."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75831"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75831"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.15.0

### Custom code

Yes

### OS platform and distribution

Raspberry Pi Pico W

### Mobile device

_No response_

### Python version

3.11.9

### Bazel version

_No response_

### GCC/compiler version

Apple clang version 14.0.3 (clang-1403.0.22.14.1)

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I'm trying to build a [Keras mdn-rnn model](https://pypi.org/project/keras-mdn-layer/) and get a very basic prediction program running on my Raspberry Pi Pico W, which has 264KB of SRAM, and 2MB of on-board flash memory. The Keras model is converted to a tflite model by `tflite_file = model_to_tflite(inference_mdrnn.model, model_keras_file)`. It's then converted to a `model.cc` by `xxd -i model.tflite > model.cc`.

I followed the tinyML book example to build my basic prediction program, but adding the line `TfLiteStatus allocate_status = interpreter->AllocateTensors();` breaks the program and I cannot see any serial output from the connected pico. I have included my program source. I'm wondering if `kTensorArenaSize` is not large enough or is too large. But I do not know whether this is the case and if it is how to set up a correct `kTensorArenaSize`. Any suggestions to clear the air will be greatly appreciated.

The converted `model.cc` file is [here](https://github.com/Zlisch/tflite-pico/blob/main/examples/impsy_model/musicMDRNN-dim4-layers2-units32-mixtures5-scale10.cc). The [CMakeList](https://github.com/Zlisch/tflite-pico/blob/main/examples/impsy_model/CMakeLists.txt) to generate uf2file.

### Standalone code to reproduce the issue

```shell
#include ""constants.h""
#include ""model.h""
#include ""main_functions.h""
#include ""tensorflow/lite/micro/micro_interpreter.h""
#include ""tensorflow/lite/micro/micro_log.h""
#include ""tensorflow/lite/micro/micro_mutable_op_resolver.h""
#include ""tensorflow/lite/micro/system_setup.h""
#include ""tensorflow/lite/schema/schema_generated.h""

// Globals, used for compatibility with Arduino-style sketches.
namespace {
const tflite::Model* model = nullptr;
tflite::MicroInterpreter* interpreter = nullptr;
TfLiteTensor* input = nullptr;
TfLiteTensor* output = nullptr;
int inference_count = 0;

constexpr int kTensorArenaSize = 60 * 1024; // 2 * 1024 for float model
uint8_t tensor_arena[kTensorArenaSize];
bool setupornot = false;
}  // namespace

// The name of this function is important for Arduino compatibility.
void setup() {
  printf(""Setting up ...... \n"");
  tflite::InitializeTarget();
}

void loop() {
  if (!setupornot) {
    printf(""Now setup ... \n"");

    tflite::InitializeTarget();

    // Map the model into a usable data structure. This doesn't involve any
    // copying or parsing, it's a very lightweight operation.
    model = tflite::GetModel(g_model_data);
    if (model->version() != TFLITE_SCHEMA_VERSION) {
      printf(
          ""Model provided is schema version %d not equal ""
          ""to supported version %d."",
          model->version(), TFLITE_SCHEMA_VERSION);
      return;
    }

    // This pulls in all the operation implementations we need.
    // NOLINTNEXTLINE(runtime-global-variables)
    static tflite::MicroMutableOpResolver<1> resolver;
    TfLiteStatus resolve_status = resolver.AddFullyConnected();
    if (resolve_status != kTfLiteOk) {
      printf(""Op resolution failed"");
      return;
    }

    // Build an interpreter to run the model with.
    static tflite::MicroInterpreter static_interpreter(
        model, resolver, tensor_arena, kTensorArenaSize);
    interpreter = &static_interpreter;

    // Allocate memory from the tensor_arena for the model's tensors.
    TfLiteStatus allocate_status = interpreter->AllocateTensors(); // broken
    if (allocate_status != kTfLiteOk) {
      printf(""AllocateTensors() failed"");
      return;
    }
    
    setupornot = true;
  }

  // Calculate an x value to feed into the model. We compare the current
  // inference_count to the number of inferences per cycle to determine
  // our position within the range of possible x values the model was
  // trained on, and use this to calculate a value.
  float position = static_cast<float>(inference_count) /
                   static_cast<float>(kInferencesPerCycle);
  float x = position * kXrange;
  printf(""x=%.6f\n"", x); 

  if (setupornot) {
    printf(""Has been setup ... \n"");
  } else {
    printf(""setupornot still false! \n"");
  }

  if (input == nullptr) {
    printf(""input is null!\n"");
  } else if (input->dims == nullptr) {
    printf(""input->dims is null!\n"");
  } else {
    printf(""Size of input->dims->size: %d\n"", input->dims->size);
  }

  if (interpreter == nullptr) {
    printf(""interpreter is null!\n"");
  } else {
    printf(""interpreter is NOT null!\n"");
  }

  // Increment the inference_counter, and reset it if we have reached
  // the total number per cycle
  // working
  inference_count += 1;
  if (inference_count >= kInferencesPerCycle) inference_count = 0;
}
```


### Relevant log output

```shell
serial output when excluding `tflite_file = model_to_tflite(inference_mdrnn.model, model_keras_file)`:

...
input is null!
interpreter is NOT null!
x=4.398230
Has been setup ...
input is null!
interpreter is NOT null!
x=4.712389
Has been setup ...
input is null!
interpreter is NOT null!
x=5.026548
Has been setup ...
...
```
"
2533528551,75983,Warning! ***HDF5 library version mismatched error***,closed,2024-09-18 11:54:53+00:00,2024-10-16T02:03:01Z,2024-10-16T02:02:50Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/75983,"['stat:awaiting response', 'type:bug', 'stale', 'TF 2.9']","['@abivelu-prem,\r\nHDF5 library version mismatched error will be resolved with pip install h5py --upgrade --no-dependencies --force. You can ignore the above CUDA warnings if you do not have a GPU set up on your machine.\r\n\r\nPlease can you install h5py as below\r\n\r\n```python\r\n  pip install h5py --upgrade --no-dependencies --force\r\n```\r\n\r\nAlso tensorflow v2.9 is a pretty old version, could you please upgrade to the latest tensorflow v2.17. Thank you!\r\n\r\n', '@tilakrayal  I have tried to install tensorflow with CUDA dependency using ""pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu118"" and have uninstalled h5py package by ""pip uninstall h5py"" which prevented the HDF5 warning to pop up on my application, I do have a GPU set up on my machine and I am trying to utilize GPU. But its not utilizing as of now, due to the tensorflow issue I guess. your suggestion would be highly appreciated.', '@abivelu-prem,\r\nFrom the above comment I can see that you are using to install tensorflow using a pip install torch which might be the reason for the error. Could you please try to install from the tensorflow official document.\r\nhttps://www.tensorflow.org/install/pip#step-by-step_instructions\r\n\r\nAnd also if you are facing issue while using the torch, please raise the issue in the respective forum. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75983"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/75983"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

tensorflow-gpu 2.9.0

### Custom code

Yes

### OS platform and distribution

Linux, ubuntu 22.04

### Mobile device

Linux, ubuntu 22.04

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

cuda 11.5

### GPU model and memory

_No response_

### Current behavior?

Hello,
I am trying to run my application and check GPU utilization, When trying to import h5py I get the following error. I have seen a lot of ""conda"" commands solving this issue,  but I am not supposed to use conda,  I don't use anaconda python on Ubuntu 22.04. HELP ME SOLVE THIS ISSUE, I HAVE TRIED TO UPDATE THE HDF5 TO LATEST VERSION i.e., 1.14.2 AS INDICATED IN THE WARNING MESSAGE , BUT STILL GET THE SAME WARNING. My LD_LIBRARY_PATH was set to a different location I changed it to ""/usr/local/hdf5/lib:"" but I get the same error.
Any help is greatly appreciated.

### Standalone code to reproduce the issue

```shell
- UserWarning: h5py is running against HDF5 1.10.7 when it was built against 1.14.2, this may cause problems
  _warn((""h5py is running against HDF5 {0} when it was built against {1}, ""
Warning! ***HDF5 library version mismatched error***
The HDF5 header files used to compile this application do not match
the version used by the HDF5 library to which this application is linked.
Data corruption or segmentation faults may occur if the application continues.
This can happen when an application was compiled by one version of HDF5 but
linked with a different version of static or shared HDF5 library.
You should recompile the application or check your shared library related
settings such as 'LD_LIBRARY_PATH'.
You can, at your own risk, disable this warning by setting the environment
variable 'HDF5_DISABLE_VERSION_CHECK' to a value of '1'.
Setting it to 2 or higher will suppress the warning messages totally.
Headers are 1.14.2, library is 1.10.7
            SUMMARY OF THE HDF5 CONFIGURATION
            =================================
```


### Relevant log output

```shell
Headers are 1.14.2, library is 1.10.7                                                                                                                                                   SUMMARY OF THE HDF5 CONFIGURATION                                                                                                                                           =================================                                                                                                                                                                                                                                                                                                           General Information:                                                                                                                                                        -------------------                                                                                                                                                                            HDF5 Version: 1.10.7                                                                                                                                                       Configured on: Wed, 08 Dec 2021 23:33:27 +0000                                                                                                                              Configured by: Debian                                                                                                                                                         Host system: x86_64-pc-linux-gnu                                                                                                                                      Uname information: Debian                                                                                                                                                            Byte sex: little-endian                                                                                                                                           Installation point: /usr   

            Using memory checker: no
 Memory allocation sanity checks: no
          Function stack tracing: no
                Use file locking: best-effort
       Strict file format checks: no
    Optimization instrumentation: no
Bye...
Aborted (core dumped)
```
"
2535823703,76038,GPU use,closed,2024-09-19 09:41:10+00:00,2024-10-10T02:01:30Z,2024-10-10T02:01:26Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/76038,"['stat:awaiting response', 'type:bug', 'stale', 'TF 2.10']","['Hi **@Tarun0000** ,\r\nThank you for bringing your issue here. First, you need to check all the compatibility versions, as there are version mismatches in your setup. I have provided the [documentation](https://www.tensorflow.org/install/source_windows) for your reference—please review it. After that install tensorflow(2.10) and compatible cuda versions and you can use tensorflow in native windows.\r\n\r\n\r\nThank you!', 'my cuda version is 12.6\r\n', 'Hi **@Tarun0000** ,\r\nThank you for your confirmation. Your CUDA version should be 11.2, and the cuDNN version should be 8.1 for TensorFlow 2.10. I have provided the [documentation](https://www.tensorflow.org/install/source_windows#gpu) for your reference.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76038"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76038"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.10

### Custom code

Yes

### OS platform and distribution

Window

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.5/9.2.1

### GPU model and memory

_No response_

### Current behavior?

hey i successfully setup cuda and able to use GPU in WSL , but my question is how i use it on my windows Conda Environment

### Standalone code to reproduce the issue

```shell
hey i successfully setup cuda and able to use GPU in WSL , but my question is how i use it on my windows Conda Environment
```


### Relevant log output

```shell
hey i successfully setup cuda and able to use GPU in WSL , but my question is how i use it on my windows Conda Environment
```
"
2540633536,76261,Reproducing Benchmark Tool performance in actual code,closed,2024-09-22 04:25:22+00:00,2024-09-23T15:52:43Z,2024-09-23T15:52:40Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/76261,"['type:bug', 'comp:lite', '2.17']","['Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76261"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76261"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.17

### Custom code

No

### OS platform and distribution

Ubuntu 22

### Mobile device

_No response_

### Python version

3.11

### Bazel version

7.3.1

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

```
adb shell taskset f0 /data/local/tmp/benchmark_model \                                                                                                                                                         master ✱
  --graph=/data/local/tmp/output.tflite \
--enable_op_profiling=false --input_layer_shape=1,32,32,1 --input_layer=inputs_0 --use_xnnpack=true --num_threads=1```
```
Timings:
Inference timings in us: Init: 18578, First inference: 3520, Warmup (avg): 3358.58, Inference (avg): **3403.45**

```
adb shell taskset f0 /data/local/tmp/benchmark_model \                                                                                                                                                         master ✱
  --graph=/data/local/tmp/output.tflite \
--enable_op_profiling=false --input_layer_shape=1,32,32,1 --input_layer=inputs_0 --use_xnnpack=true --num_threads=3```
```

Inference timings in us: Init: 20703, First inference: 2024, Warmup (avg): 1348.85, Inference (avg): **1363.29**


When i write the custom inference code with options to set the number of threads. 

1. Settings the number of threads > 1 using `builder.SetNumThreads(num_threads)` has no effect, while `benchmark_model` is able to reflect the improvements. 

```
        model_ = tflite::FlatBufferModel::BuildFromFile(model_path.c_str());
        if (!model_) {
            return false;
        }

        // Create the interpreter
        tflite::ops::builtin::BuiltinOpResolver resolver;
        tflite::InterpreterBuilder builder(*model_, resolver);
        if (builder.SetNumThreads(num_threads) != kTfLiteOk) {
            TFLITE_LOG(ERROR) << ""Failed to set thread number"";
            return kTfLiteError;
        }
        builder(&interpreter_);
        if (!interpreter_) {
            return false;
        }
        // Apply XNNPACK delegate if requested
        if (use_xnnpack) {
            TfLiteXNNPackDelegateOptions xnnpack_options =
                TfLiteXNNPackDelegateOptionsDefault();
            xnnpack_delegate_ = TfLiteXNNPackDelegateCreate(&xnnpack_options);
            if (interpreter_->ModifyGraphWithDelegate(xnnpack_delegate_) !=
                kTfLiteOk) {
                std::cerr << ""Failed to apply XNNPACK delegate."" << std::endl;
                return false;
            }
        }

```

### Standalone code to reproduce the issue

```shell
adb shell taskset f0 /data/local/tmp/benchmark_model \                                                                                                                                                         master ✱
  --graph=/data/local/tmp/output.tflite \
--enable_op_profiling=false --input_layer_shape=1,32,32,1 --input_layer=inputs_0 --use_xnnpack=true --num_threads=3```
```
```


### Relevant log output

_No response_"
2542425675,76315,"Using the c++ API,  how do  set  fp16 on  cpu？",closed,2024-09-23 12:03:26+00:00,2024-10-16T02:02:54Z,2024-10-16T02:02:44Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/76315,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'TF 2.13']","[""model = model.cast('float16')\r\n"", ""# Enable mixed precision in TensorFlow for GPU\r\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\r\npolicy = mixed_precision.Policy('mixed_float16')\r\nmixed_precision.set_policy(policy)\r\n"", ""Hi, @keke444 \r\n\r\nI apologize for the delayed response, I think you can use this [SetAllowFp16PrecisionForFp32](https://ai.google.dev/edge/api/tflite/cc/class/tflite/impl/interpreter)\r\n\r\n```\r\nvoid SetAllowFp16PrecisionForFp32(\r\n  bool allow\r\n)\r\n```\r\nAllow `float16` precision for `FP32` calculation when possible.\r\n\r\nDefault: not allow.\r\n\r\nWARNING: This API is deprecated: prefer controlling this via delegate options, e.g. `tflite::StatefulNnApiDelegate::Options::allow_fp16' or TfLiteGpuDelegateOptionsV2::is_precision_loss_allowed. This method will be removed in a future release.\r\n\r\nThank you for your cooperation and patience."", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76315"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76315"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.13

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

5.30

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Hi 
      using cpu backend,  we want to set fp16 to Invoke, 
using below code,  What setting parameters do I need to add 

thansk


### Standalone code to reproduce the issue

```shell
#include <memory>
#include <string>
#include <vector>

#include ""tensorflow/lite/c/c_api.h""
#include ""tensorflow/lite/c/c_api_experimental.h""
#include ""tensorflow/lite/core/c/common.h""


#define STB_IMAGE_IMPLEMENTATION
#include ""stb_image.h""

#define STB_IMAGE_WRITE_IMPLEMENTATION
#include ""stb_image_write.h""

int main(void)
{
uint8_t *image = stbi_load(""192.jpg"", 192, 192, 3, 3);
int tmpSize = (192* 192*3);
float *in = (float *)malloc(tmpSize**sizeof(float)); 
float *out = (float *)malloc(tmpSize**sizeof(float)); 
for (int i = 0; i < tmpSize; i++)
{
    in[i]   = (float)(image[i] - 0.0f) / 255.0f;
}
//init model
TfLiteModel model = TfLiteModelCreateFromFile(info->ld.model_name);
TfLiteInterpreterOptions options = TfLiteInterpreterOptionsCreate();
TfLiteInterpreterOptionsSetNumThreads(options, info->param.number_of_threads);
//
TfLiteInterpreter interpreter = TfLiteInterpreterCreate(model, options);
TfLiteInterpreterAllocateTensors(interpreter);

//invoke
TfLiteTensor* input_tensor = TfLiteInterpreterGetInputTensor(interpreter, 0);
TfLiteTensorCopyFromBuffer(input_tensor, (void *)in, tmpSize*sizeof(float));
TfLiteInterpreterInvoke(interpreter);

//get output
TfLiteTensor* output_tensor = TfLiteInterpreterGetOutputTensor(interpreter, 0);
TfLiteTensorCopyToBuffer(output_tensor, (void *)Out, tmpSize*sizeof(float) );

//deinit
TfLiteInterpreterDelete(interpreter);
TfLiteInterpreterOptionsDelete(options);
TfLiteModelDelete(model);

}
```


### Relevant log output

_No response_"
2544696386,76362,"gen_nn_ops.fractional_max_pool_grad aborts with ""malloc_consolidate(): invalid chunk size""",closed,2024-09-24 08:17:49+00:00,2024-10-11T02:01:13Z,2024-10-11T02:01:10Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/76362,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","['@cybersupersoap,\r\nThank you for reporting the issue. I request you to take a look at this [issue](https://github.com/tensorflow/tensorflow/issues/59394) and https://github.com/tensorflow/tensorflow/issues/59405 where a similar issue has been proposed and it is still open.Also I request to follow the similar issue which has been proposed to have the updates on the same. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76362"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76362"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

tf-nightly 2.18.0.dev20240817

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 20.04.3 LTS

### Mobile device

_No response_

### Python version

3.10.14

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I encountered an `crash issue` in TensorFlow when I used API `gen_nn_ops.fractional_max_pool_grad` . 
I have confirmed that above the code would crash on `tf-nightly 2.18.0.dev20240817` (nightly-build). Please find the [gist](https://colab.research.google.com/drive/16XRisnbPuTfwdeRHkdZsJIEaDs9RHYGs?usp=sharing) to reproduce the issue.

### Standalone code to reproduce the issue

```shell
import numpy as np
from tensorflow.python.ops import gen_nn_ops
from tensorflow.python.ops import nn_ops
import tensorflow as tf

_PRNG = np.random.RandomState(341261)
num_batches =1
row_window_size=2
col_window_size=2
num_rows = (row_window_size - 1) * 5 + 1
num_cols = (col_window_size - 1) * 7 + 1
input_shape = (num_batches, num_rows, num_cols, 1)
sess = tf.compat.v1.Session()
with sess.as_default():
    x = np.arange(48, dtype=np.float32)
    _PRNG.shuffle(x)
    input_tensor =  x.reshape(input_shape)
    window_size = [1, row_window_size, col_window_size, 1]
    stride_size = [1, 65536, col_window_size - 1, 1] 
    padding = 'VALID'
    output_tensor = nn_ops.max_pool(input_tensor, window_size, stride_size, padding)
    output_backprop = _PRNG.randint(100, size=output_tensor.shape)
    row_seq = list(range(0, num_rows, row_window_size - 1))
    col_seq = list(range(0, num_cols, col_window_size - 1))
    row_seq[-1] += 1
    col_seq[-1] += 1
    gen_nn_ops.fractional_max_pool_grad(input_tensor, output_tensor, output_backprop, row_seq, col_seq, overlapping=True)
```


### Relevant log output

```shell
malloc_consolidate(): invalid chunk size
Aborted (core dumped)
```
"
2551950150,76624,TF-Lite converter bug in 2.17 for TransposeConv with quantized weights,closed,2024-09-27 04:10:05+00:00,2024-11-06T07:20:33Z,2024-11-06T07:20:30Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/76624,"['stat:awaiting tensorflower', 'type:bug', 'comp:lite', 'TFLiteConverter', 'TFLiteGpuDelegate', 'awaiting PR merge', '2.17']","[""Hi, @bas-aarts\r\n\r\nI apologize for the delayed response, I was trying to replicate the same behavior from my end so to confirm, did you use [QAI Hub](https://app.aihub.qualcomm.com/docs/) with Samsung Galaxy S24 Ultra device or actual physical device ? \r\n\r\nIf you don't mind could you please guide me to replicate the same behavior from my end also. \r\n\r\nThank you for your cooperation and patience.\r\n"", ""Yes I did use AI Hub, but this does use an actual physical Samsung Galaxy S24 Ultra.\r\nThe AI Hub TFLite runtime uses theTF-Lite GPU delegate, as well as the QNN NPU delegate.\r\n\r\nTo reproduce you'll need a TF-Lite runtime that can use either of these, and possible opt-in using:\r\n`  interpreter.experimental_delegate = tf.lite.experimental.load_delegate('some delegate shared library')`\r\n\r\nI see a PR above, which aI hope means you were able to reproduce the issue.\r\n"", 'Hi, @pkgoogle \r\n\r\nPlease take look into this issue. Thank you', 'The current expectation is that the PR will resolve this issue.', 'since the PR is still in draft, any idea in which release I can expect the fix?\r\n', 'Hi @bas-aarts, feel free to take the code/diff from the PR if you need it sooner, I would expect the fix to land 1 or 2 releases from now.', 'Should be fixed with https://github.com/tensorflow/tensorflow/commit/dde56340610b37d2f2696b654be50a74dd25ff84', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76624"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76624"">No</a>\n']","On Apple M1 Pro with MacOs Sonoma 14.1.2 (23B92)
TensorFlow version 2.17.0 (not an issue with TF 2.16.1)
I ran this one a Samsung Galaxy S24 Ultra

sources + assets:
[TransposeConv_bug.zip](https://github.com/user-attachments/files/17158711/TransposeConv_bug.zip)

The zip contains a TF saved model and a convert.py script that converts it to a TF-Lite mode.
the zip file contains two TF-Lite models, and created with TF 2.16.1, and the other with 2.17.0.
convert.py also runs the TF-Lite model, but it needs to run on a target with GPU and/or NPU delegates to really see the issue.

When running the TF 2.16.1 TF-Lite model, the model runs on the NPU (Qualcomm QNN delegate).
When running the TF 2.17.0 TF-Lite model, the model runs on the CPU, using the XNNpack/TFLite delegates.

we see this log from TF-Lite on the device:
[tflite.log](https://github.com/user-attachments/files/17158819/tflite.log)
the interesting lines are:
`[27/Sept/2024:11:32:40 +08:00: profiler/warning] [job_id: j87gj31pd] [model.tflite] [tflite] tensorflow/lite/kernels/transpose_conv.cc:487 affine_quantization->scale->size != weights->dims->data[affine_quantization->quantized_dimension] (1 != 4)
`
and
`[27/Sept/2024:11:32:40 +08:00: profiler/warning] [job_id: j87gj31pd] [model.tflite] [tflite] tensorflow/lite/kernels/transpose_conv.cc:487 affine_quantization->scale->size != weights->dims->data[affine_quantization->quantized_dimension] (1 != 4)
`
the first one fails the NPU delegate check and the latter the GPU delegate check.

the check here is:
`https://github.com/tensorflow/tensorflow/blob/9e4fc3d09c298ca56bd11f72d2f1beb622a0f76b/tensorflow/lite/kernels/transpose_conv.cc#L485-L487`

This check is performed only when the Transpose Conv layer has float input but integral weights. This was not the case in TF 2.16, where the weights were first dequantized.
the check makes it looks like this must be a per channel quantized weight, which is clearly not the case.

So the converter generates code that the runtime forces back to the slower CPU delegates"
2553395369,76672,TF-Lite converter crashes when quantizing GRU layer,closed,2024-09-27 17:18:48+00:00,2025-01-22T21:52:38Z,2025-01-22T21:52:35Z,paulinesho,,https://github.com/tensorflow/tensorflow/issues/76672,"['stat:awaiting tensorflower', 'type:bug', 'comp:lite', 'TFLiteConverter', '2.17']","['@bas-aarts,\r\nI guess this might be due to Keras3.0 which contains with tensorflow v2.17. Could you please try to use **!pip install tf-keras** and **import tf_keras as keras** which imports Keras2.0 and try to execute the code. Thank you!', ""That's what I did from the start. The saved model is generated using tf_keras"", 'same happens for LSTM layers btw', ""Hi, @bas-aarts \r\n\r\nI apologize for the delayed response, I am able to replicate the same behavior from my end with `TensorFlow version 2.17.0` for reference I've added output log below and I also tried with TensorFlow version `2.16.2` and `2.15.1` so we'll have to dig more into this issue, thank you for bringing this issue to our attention\r\n\r\n**1. Output log with TensorFlow version `2.17.0`** \r\n\r\n```\r\ngaikwadrahul-macbookpro2:gru_crash gaikwadrahul$ python3 convert.py\r\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\nW0000 00:00:1727781369.076345   62413 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\r\nW0000 00:00:1727781369.076376   62413 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\r\n2024-10-01 16:46:09.076870: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: ./saved_model\r\n2024-10-01 16:46:09.078139: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\r\n2024-10-01 16:46:09.078145: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: ./saved_model\r\n2024-10-01 16:46:09.082964: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\r\n2024-10-01 16:46:09.083624: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\r\n2024-10-01 16:46:09.093334: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: ./saved_model\r\n2024-10-01 16:46:09.100636: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 23768 microseconds.\r\n2024-10-01 16:46:09.109433: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\r\n2024-10-01 16:46:09.133967: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3531] Estimated count of arithmetic ops: 3642  ops, equivalently 1821  MACs\r\nSegmentation fault: 11\r\n```\r\n**2. Output log with TensorFlow version `2.16.2`** \r\n\r\n```\r\n(tf-2.16) gaikwadrahul-macbookpro2:gru_crash gaikwadrahul$ python3 convert.py\r\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\nW0000 00:00:1727781968.787166   74219 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\r\nW0000 00:00:1727781968.787198   74219 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\r\n2024-10-01 16:56:08.787706: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: ./saved_model\r\n2024-10-01 16:56:08.788994: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\r\n2024-10-01 16:56:08.789000: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: ./saved_model\r\n2024-10-01 16:56:08.796175: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\r\n2024-10-01 16:56:08.796800: I tensorflow/cc/saved_model/loader.cc:234] Restoring SavedModel bundle.\r\n2024-10-01 16:56:08.806372: I tensorflow/cc/saved_model/loader.cc:218] Running initialization op on SavedModel bundle at path: ./saved_model\r\n2024-10-01 16:56:08.813352: I tensorflow/cc/saved_model/loader.cc:317] SavedModel load for tags { serve }; Status: success: OK. Took 25648 microseconds.\r\n2024-10-01 16:56:08.821567: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\r\n2024-10-01 16:56:08.845925: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3064] Estimated count of arithmetic ops: 3642  ops, equivalently 1821  MACs\r\nSegmentation fault: 11\r\n```\r\n**3. Output log with TensorFlow version `2.15.1`** \r\n\r\n```\r\n(tf-2.15) gaikwadrahul-macbookpro2:gru_crash gaikwadrahul$ python3 convert.py\r\n2024-10-01 16:59:25.527363: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\r\n2024-10-01 16:59:25.527391: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\r\n2024-10-01 16:59:25.527864: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: ./saved_model\r\n2024-10-01 16:59:25.529174: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\r\n2024-10-01 16:59:25.529180: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: ./saved_model\r\n2024-10-01 16:59:25.531466: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\r\n2024-10-01 16:59:25.532094: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\r\n2024-10-01 16:59:25.544428: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: ./saved_model\r\n2024-10-01 16:59:25.551775: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 23913 microseconds.\r\n2024-10-01 16:59:25.562335: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\r\nSummary on the non-converted ops:\r\n---------------------------------\r\n * Accepted dialects: tfl, builtin, func\r\n * Non-Converted Ops: 20, Total Ops 62, % non-converted = 32.26 %\r\n * 20 ARITH ops\r\n\r\n- arith.constant:   20 occurrences  (f32: 6, i32: 14)\r\n\r\n  (i1: 1, i32: 1)\r\n\r\n\r\n  (f32: 4, i32: 2)\r\n  (f32: 1, i32: 2)\r\n  (f32: 3)\r\n  (f32: 1)\r\n  (i1: 1)\r\n  (f32: 2)\r\n  (f32: 3)\r\n\r\n  (f32: 2, i32: 2)\r\n  (f32: 2)\r\n  (f32: 1)\r\n  (f32: 1)\r\n  (f32: 1)\r\n  (f32: 1)\r\n  (i32: 1)\r\n\r\n2024-10-01 16:59:25.590713: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 3642  ops, equivalently 1821  MACs\r\nSegmentation fault: 11\r\n```\r\n\r\nThank you for your cooperation and patience."", 'Hi, @pkgoogle \r\nPlease take look into this issue. Thank you', 'Hi @bas-aarts, are you willing to use transformers/LLMs? Those workflows are better supported.', ""That's not possible. This is triggered when converting an existing onnx model to TF. I do not control the model that is being converted"", 'I was also able to replicate on tf-nightly.\r\n\r\n@paulinesho can you please take a look? Thanks.', 'Hello, \n\nIs there an update on this issue ? \nGRU and LSTM can not be quantized with tensorflow 2.18 either. A segmentation fault still occurs.\n\nConverting LSTM to float is also not resulting ina Unidirectional Sequence LSTM operator anymore but a While operator. ', ""Hi All, we'll move this issue to LiteRT for now. "", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76672"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76672"">No</a>\n']","On Apple M1 Pro with MacOs Sonoma 14.1.2 (23B92)
TensorFlow version 2.16.1 (still an issue with TF 2.17.0)

sources + assets:
[Gru_quantization_bug.zip](https://github.com/user-attachments/files/17167511/Gru_quantization_bug.zip)

The zip contain a TF saved model and a convert.py script that converts it to a TF-Lite mode, but it crashes

removing either line 11 or 12 from the script makes the compilation pass

"
2554186006,76717,A crash is triggered when unknown flags are set.,closed,2024-09-28 12:03:04+00:00,2024-10-16T02:02:48Z,2024-10-16T02:02:40Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/76717,"['stat:awaiting response', 'type:bug', 'stale', 'comp:xla', '2.17']","['@x0w3n,\r\nAs mentioned when the unknown flags are set for **TF_XLA_FLAGS**  it was as providing the error **""Unknown flags in TF_XLA_FLAGS: --tf_xla_force_host_platform_device_count=8""** which was expected. Could you please provide the opinions on the same to debug the issue. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76717"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76717"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.18.0-dev20240925

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

A crash is triggered when unknown flags are set.

### Standalone code to reproduce the issue

```shell
import os
import tensorflow as tf
os.environ[""TF_XLA_FLAGS""] = ""--tf_xla_force_host_platform_device_count=8""
tensor = tf.random.normal([100, 100])
```


### Relevant log output

```shell
2024-09-28 12:01:04.057803: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-09-28 12:01:04.058256: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-09-28 12:01:04.060890: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-09-28 12:01:04.066512: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1727524864.075697     254 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1727524864.078793     254 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-09-28 12:01:04.088010: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/root/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4
  warnings.warn(f""A NumPy version >={np_minversion} and <{np_maxversion}""
2024-09-28 12:01:05.220749: F external/local_xla/xla/parse_flags_from_env.cc:224] Unknown flags in TF_XLA_FLAGS: --tf_xla_force_host_platform_device_count=8
Aborted (core dumped)
```
"
2554191777,76719,Aborted (core dumped) in `tf.math.bincount`,closed,2024-09-28 12:17:43+00:00,2024-10-16T02:02:46Z,2024-10-16T02:02:39Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/76719,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","['@x0w3n,\r\nI tried to execute the mentioned code on tensorflow v2.17, tf-nightly and observed that it was crashed due to memory allocation when trying the largest number ""Allocation of 8589938592 exceeds 10% of free system memory.""\r\nWhen I tried with the normal numerics it was working as expected. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/030446ffb118735ca3e746b12474c066/untitled2149.ipynb).\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76719"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76719"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.17

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

The crash was triggered when tf.math.bincount processed a large input.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

large_start_number = 2**31
large_end_number = large_start_number + 1000
large_numbers = tf.range(start=large_start_number, limit=large_end_number)
result = tf.math.bincount(large_numbers.numpy())
print(result)
```


### Relevant log output

```shell
2024-09-28 20:15:38.161313: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-09-28 20:15:38.225002: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-09-28 20:15:38.303991: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-09-28 20:15:38.328271: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-09-28 20:15:38.388883: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-09-28 20:15:42.209550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21471 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:1f:00.0, compute capability: 8.9
2024-09-28 20:15:42.210099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 1724 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:d4:00.0, compute capability: 8.9
2024-09-28 20:15:43.290480: F tensorflow/core/framework/tensor_shape.cc:201] Non-OK-status: InitDims(dim_sizes)
Status: INVALID_ARGUMENT: Expected shape dimensions to be non-negative, got -8589929985
Aborted (core dumped)
```
"
2554193143,76720,Segmentation fault (core dumped) in `tf.data.experimental.service.DispatchServer`,closed,2024-09-28 12:21:27+00:00,2024-11-07T13:25:51Z,2024-10-15T02:02:33Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/76720,"['stat:awaiting response', 'type:bug', 'stale', 'comp:data', '2.17']","['Hi **@x0w3n** ,\r\nI tried running your code on Colab using TensorFlow v2.17.0 & the nightly version and faced the same issue. I also tried an alternative approach. If we start the server manually, then it works fine. Here, I am providing the [gist](https://colab.sandbox.google.com/gist/Venkat6871/07d0c607c5221bc63813d6086604f37b/76720_tf-2-17-0-nightly-v.ipynb) for your reference. I hope it will be useful for you.\r\nThank you!\r\n\r\n', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76720"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76720"">No</a>\n', 'Tensorflow team how are you letting these segfaults through and not responding with proper fixes. Fix the problem. Fix your unit tests']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.18.0-dev20240925

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

tf.data.experimental.service.DispatchServer triggered a crash, when the start parameter is false.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

def test():
    tf.data.experimental.service.DispatchServer(start=False)
test()
```


### Relevant log output

```shell
2024-09-28 20:20:16.983171: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-09-28 20:20:17.013139: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-09-28 20:20:17.063675: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-09-28 20:20:17.087886: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-09-28 20:20:17.147364: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Segmentation fault (core dumped)
```
"
2554194048,76721,Segmentation fault (core dumped) in `tf.data.experimental.service.WorkerServer`,closed,2024-09-28 12:23:55+00:00,2024-11-07T13:18:11Z,2024-10-24T02:01:48Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/76721,"['stat:awaiting response', 'type:bug', 'stale', 'comp:data', '2.17']","['@x0w3n,\r\nCould you please confirm whether the same segmentation fault is happening when we use **tf.data.experimental.service.WorkerServer(config,start=True)**. I tried in another environment where with the True it was executed without the crash. \r\nhttps://www.tensorflow.org/api_docs/python/tf/data/experimental/service/WorkerServer\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76721"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76721"">No</a>\n', 'Please reopen. Problem persists\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nprint(tf.__version__)\r\n\r\ndispatcher = tf.data.experimental.service.DispatchServer()\r\ndispatcher_address = dispatcher.target.split(""://"")[1]\r\n\r\nworker = tf.data.experimental.service.WorkerServer(\r\n    tf.data.experimental.service.WorkerConfig(dispatcher_address=dispatcher_address)\r\n)\r\n\r\ndataset = tf.data.Dataset.range(10)\r\nprint(f""dataset: {dataset} {dataset.element_spec}"")\r\ndataset_id = tf.data.experimental.service.register_dataset(\r\n    dispatcher_address,\r\n    dataset,\r\n    compression=None,\r\n)\r\nprint(f""dataset_id: {dataset_id}"")\r\n\r\ndataset = tf.data.experimental.service.from_dataset_id(\r\n    processing_mode=""parallel_epochs"",\r\n    service=dispatcher.target,\r\n    dataset_id=dataset_id,\r\n    element_spec=dataset.element_spec,\r\n)\r\n\r\nprint(list(dataset.as_numpy_iterator()))\r\n\r\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\nE0000 00:00:1730985417.669184  115264 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\nE0000 00:00:1730985417.675189  115264 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\ntensorflow: 2.18.0\r\nI0000 00:00:1730985420.891233  115264 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20750 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:04.0, compute capability: 8.9\r\ndataset: <_RangeDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)> TensorSpec(shape=(), dtype=tf.int64, name=None)\r\ndataset_id: b\'1000\'\r\nSegmentation fault (core dumped)\r\n```\r\n\r\n\r\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.18.0-dev20240925

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

tf.data.experimental.service.WorkerServer triggered a crash, when the start parameter is false.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
config = tf.data.experimental.service.WorkerConfig(
    dispatcher_address='invalid_address',
    worker_address=None,
    port=0,
    protocol=None,
    heartbeat_interval_ms=None,
    dispatcher_timeout_ms=None,
    data_transfer_protocol=None,
    data_transfer_address=None
)
def test():
    tf.data.experimental.service.WorkerServer(config,start=False)
test()
```


### Relevant log output

```shell
2024-09-28 20:23:15.476342: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-09-28 20:23:15.538580: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-09-28 20:23:15.617490: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-09-28 20:23:15.641378: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-09-28 20:23:15.701061: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Segmentation fault (core dumped)
```
"
2554197998,76723,Segmentation fault (core dumped) in `tf.python.framework.importer`,closed,2024-09-28 12:34:35+00:00,2024-10-16T02:02:42Z,2024-10-16T02:02:37Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/76723,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","['@x0w3n,\r\nI request you to take a look at this https://github.com/tensorflow/tensorflow/issues/61570 where a similar issue has been proposed and it is still open. Also I request to follow the similar issue which has been proposed to have the updates on the similar issue. Thank you!\r\n', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76723"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76723"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.18.0-dev20240925

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Under specific inputs, tf.python.framework.importer triggered a crash.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
from tensorflow.python.framework import importer

try:
    arg_0_0 = ""Placeholder:0""
    arg_1_1 = ""add:0""
    arg_0 = [arg_0_0, arg_1_1]
    arg_1 = None
    arg_2 = None
    out = importer._GatherReturnElements(arg_0, arg_1, arg_2)
except Exception as e:
    print(""Error:"", str(e))
```


### Relevant log output

```shell
2024-09-28 20:31:16.069665: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-09-28 20:31:16.132409: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-09-28 20:31:16.209869: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-09-28 20:31:16.233126: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-09-28 20:31:16.292093: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Segmentation fault (core dumped)
```
"
2554202027,76725,Aborted (core dumped) in `tf.raw_ops.Einsum`,closed,2024-09-28 12:45:38+00:00,2024-10-15T02:02:35Z,2024-10-15T02:02:31Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/76725,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","[""@x0w3n,\r\nCould you please confirm whether the crash is happening with the 2-dimension input as well. I tried and the code was executed without any issues.\r\n\r\n```python\r\ng = tf.random.normal([10, 20])\r\nw = tf.random.normal([20, 30])\r\n\r\nres = tf.raw_ops.Einsum(equation='ij,jk->il', inputs=[g, w])\r\nprint(res.shape)\r\n```\r\n\r\nAlso this Op is not intended to be called by the user; instead users should call **tf.einsum** directly. It is a hidden Op used by [tf.einsum](https://www.tensorflow.org/api_docs/python/tf/einsum).\r\n\r\nAlso Operations are applied to the input(s) according to the rules which are documented here.\r\nhttps://www.tensorflow.org/api_docs/python/tf/raw_ops/Einsum  \r\n\r\nThank you!"", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76725"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76725"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.18.0-dev20240925

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Under specific inputs, tf.raw_ops.Einsum triggered a crash.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

# Define a 3D tensor
g = tf.random.normal([10, 20, 30])
w = tf.random.normal([20, 30])

res = tf.raw_ops.Einsum(equation='ijk,jk->ijl', inputs=[g, w])
print(res.shape)
```


### Relevant log output

```shell
2024-09-28 20:42:44.280244: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-09-28 20:42:44.343703: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-09-28 20:42:44.420579: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-09-28 20:42:44.441517: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-09-28 20:42:44.488538: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-09-28 20:42:51.666942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3114 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:1f:00.0, compute capability: 8.9
2024-09-28 20:42:51.667588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 1724 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:d4:00.0, compute capability: 8.9
2024-09-28 20:42:52.086477: F ./tensorflow/core/kernels/transpose_functor.h:171] Check failed: in.dims() == perm.size() (2 vs. 3)
Aborted (core dumped)
```
"
2554210767,76728,Aborted (core dumped) in `tf.raw_ops.BiasAdd/tf.nn.bias_add`,closed,2024-09-28 13:03:32+00:00,2024-10-16T02:02:40Z,2024-10-16T02:02:35Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/76728,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'comp:gpu', '2.17']","['@x0w3n,\r\nI request you to take a look at this https://github.com/tensorflow/tensorflow/issues/62146 where a similar issue has been proposed and it is still open. Also I request to follow the similar issue which has been proposed to have the updates on the similar issue. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76728"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76728"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.18.0-dev20240925

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Under specific inputs And the gpu is available, tf.raw_ops.BiasAdd/tf.nn.bias_add triggered a crash.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

input_tensor = tf.zeros([1, 2], dtype=tf.float32)
data_format = 'NCHW'
bias = tf.ones([2], dtype=tf.float32)
bias_add = tf.raw_ops.BiasAdd(value=input_tensor, bias=bias, data_format=data_format)
```


### Relevant log output

```shell
2024-09-28 21:01:39.889919: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-09-28 21:01:39.902000: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-09-28 21:01:39.916516: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-09-28 21:01:39.920867: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-09-28 21:01:39.931797: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-09-28 21:01:40.599888: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-09-28 21:01:41.259588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22456 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:18:00.0, compute capability: 8.6
2024-09-28 21:01:41.260235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22456 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:af:00.0, compute capability: 8.6
2024-09-28 21:01:41.612863: F tensorflow/core/framework/tensor_shape.cc:357] Check failed: d < dims() (2 vs. 2)
Aborted
```
"
2554221365,76732,Aborted (core dumped) in `tf.data.Dataset.from_generator`,closed,2024-09-28 13:25:51+00:00,2024-12-04T14:56:06Z,2024-10-15T02:02:29Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/76732,"['stat:awaiting response', 'type:bug', 'stale', 'comp:data', '2.17']","['@x0w3n,\r\nI request you to take a look at this [issue](https://github.com/tensorflow/tensorflow/issues/60149) where a similar issue has been proposed and it is still open. Also I request to follow the similar issue which has been proposed to have the updates on the similar issue. Thank you!\r\n', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76732"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76732"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.18.0-dev20240925

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Under specific inputs, tf.data.Dataset.from_generator triggered a crash.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
import random

def generate_invalid_dataset():
    data = []
    for _ in range(10):
        size = random.randint(1, 5)
        data.append(np.random.randint(10, size=(size,)))
    return data

def test():
    dataset = generate_invalid_dataset()
    dataset = tf.data.Dataset.from_generator(lambda: iter(dataset), output_types=tf.int32)
    dataset = dataset.unbatch()
    dataset = dataset.apply(tf.data.experimental.ignore_errors())
    iterator = iter(dataset)

    try:
        for _ in range(10):
            next_element = next(iterator)
    except Exception as e:
        print(f""Caught an error: {e}"")

test()
```


### Relevant log output

```shell
2024-09-28 21:22:49.792052: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-09-28 21:22:49.854705: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-09-28 21:22:49.933196: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-09-28 21:22:49.957165: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-09-28 21:22:50.015970: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:From *.py:17: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.
Instructions for updating:
Use output_signature instead
2024-09-28 21:22:57.817999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2158 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:1f:00.0, compute capability: 8.9
2024-09-28 21:22:57.820421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 1724 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:d4:00.0, compute capability: 8.9
WARNING:tensorflow:From *.py:19: ignore_errors (from tensorflow.python.data.experimental.ops.error_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.ignore_errors` instead.
2024-09-28 21:23:23.222693: F external/local_tsl/tsl/platform/default/env.cc:74] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
Aborted (core dumped)
```
"
2554247086,76734,Segmentation fault (core dumped) in `tf.raw_ops.FakeParam`,closed,2024-09-28 14:06:51+00:00,2024-10-16T02:02:36Z,2024-10-16T02:02:34Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/76734,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","['Hi **@x0w3n** ,\r\nI tried running your code on Colab using TensorFlow v2.17.0 and the nightly version. I am not facing any issue. Please find [gist](https://colab.sandbox.google.com/gist/Venkat6871/cc82aa67648260a385f607db5dec26e8/76734_tf-2-17-0-nightly-v.ipynb) here for reference.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76734"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76734"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.17

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

With invalid input, tf.raw_ops.FakeParam triggers a crash.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
fake_param = tf.raw_ops.FakeParam(dtype='string', shape=())
```


### Relevant log output

```shell
2024-09-28 22:02:02.412815: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-09-28 22:02:02.424900: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-09-28 22:02:02.439240: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-09-28 22:02:02.443601: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-09-28 22:02:02.454230: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-09-28 22:02:03.122361: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-09-28 22:02:03.765934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22456 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:18:00.0, compute capability: 8.6
2024-09-28 22:02:03.766553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22456 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:af:00.0, compute capability: 8.6
Segmentation fault (core dumped)
```
"
2555060290,76771,ExponentialMovingAverage doesn't work with KerasVariable,closed,2024-09-29 18:20:52+00:00,2024-10-01T10:36:58Z,2024-10-01T10:36:55Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/76771,"['stat:awaiting response', 'type:bug', 'comp:apis', '2.17']","['@Grizzzlyy,\r\nTensorflow 2.17 contains Keras3.0 which might be the reason for the error. Could you please try to install tf-keras i.e., keras2.0 which the code was executed without any issues/error. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/bb326b36728f4528e1016d384638090a/untitled2141.ipynb).\r\n\r\n```python\r\n!pip install tf-keras\r\nimport tf_keras as keras\r\n```\r\n\r\nThank you!', '@tilakrayal \nYep, that works. Thank you', '@Grizzzlyy,\r\nGlad the issue got resolved. Could you please feel free to move this issue to closed status? Thank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76771"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76771"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.17.0

### Custom code

No

### OS platform and distribution

Windows 10

### Mobile device

_No response_

### Python version

3.11.4

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

### Description
tf.train.ExponentialMovingAverage apply() method takes list of variables. It expects list of tf.Variable and doesn't work with list of KerasVariable because of dtypes
tf.keras.layers.Dense trainable_variables property returns list of `KerasVariable`, KerasVariable dtype is `str`
tf.Variable dtype is `tf.Dtype`

### Expected behavior
I suppose tf.keras layer or model should return list of KerasVariable, so tf.train.ExponentialMovingAverage.apply() should support list of KerasVariables as argument



### Standalone code to reproduce the issue

```shell
import tensorflow as tf

layer = tf.keras.layers.Dense(2)
ema = tf.train.ExponentialMovingAverage(decay=0.999)

x = tf.ones((3, 3))
y = layer(x)

# apply() works with tf.Variable, but doesn't work with KerasVariable
# because of dtype (tf.float32 (tf.Dtype) vs 'float32' (str) respectively)
ema.apply(layer.trainable_variables)
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""C:\TestProj\test.py"", line 11, in <module>
    ema.apply(layer.trainable_variables)
  File ""C:\TestProj\venv\Lib\site-packages\tensorflow\python\training\moving_averages.py"", line 542, in apply
    if var.dtype.base_dtype not in [
       ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'base_dtype'
```
"
2557559950,76826,TF model trained with 2.7 has error in later versions with no OpKernel error,closed,2024-09-30 20:16:43+00:00,2024-11-23T02:02:53Z,2024-11-23T02:02:51Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/76826,"['stat:awaiting response', 'type:bug', 'stale', 'TF 2.16']","['@zhaoting-wu,\r\nThere are multiple changes/updates that happened from tensorflow v2.7 to latest versions 2.16 and 2.17. Also from tensorflow 2.16 the Keras has been moved from Keras2.0 to Keras3.0. I suggest to convert the code to tensorflow v2.16, 2.17 apis and test the model.\r\n\r\nhttps://keras.io/keras_3/\r\n\r\nThank you!', ""Hi @tilakrayal, thanks for the response! \r\n\r\nBased on the log, we noticed the errored model called `bucketize` transform in Tensorflow so that it touched the `BoostedTreesBucketize` op (`[[transform/transform/bucketize/apply_buckets/assign_buckets_all_shapes/assign_buckets/BoostedTreesBucketize]]`), but `bucketize` transform doesn't show as deprecated as `BoostedTreesBucketize`. Does that mean `bucketize` just started to call other substitute ops after deprecating `BoostedTreesBucketize`? \r\n\r\nFrom the [release note](https://github.com/tensorflow/tensorflow/releases/tag/v2.8.0), `BoostedTreesBucketize` appears deprecated since TF 2.8 and removed since TF 2.9: ```\r\nDue to security issues (see section below), all boosted trees code has been deprecated. Users should switch to [TensorFlow Decision Forests](https://github.com/tensorflow/decision-forests). TF's boosted trees code will be eliminated before the branch cut for TF 2.9 and will no longer be present since that release.\r\n```.  We tried Triton image built on TF 2.9 and this error starts to show up. Does that mean this issue can be resolved by simply switching our TF dependency for model training to TF2.9+, but still keeping the call of `bucketize`?"", '@zhaoting-wu,\r\nAs mentioned in the release document, the BoostedTreesBucketize appears deprecated since TF 2.8 and removed since TF 2.9.  Switching from deprecated `tf.raw_ops.BoostedTreesBucketize` to `tf.searchsorted` in `tft.apply_buckets`. This fixes bug with large int64 values being incorrectly mapped and allows to simplify `tft.apply_buckets` implementation.\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76826"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76826"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.16.1

### Custom code

No

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Models trained with TF 2.7 is not able to run in later versions, like 2.16.1, with ""No OpKernel was registered to support Op 'BoostedTreesBucketize'"" error.

### Standalone code to reproduce the issue

We are using Nvidia's Triton model inference platform, when using the latest image which builds upon TF 2.16.1 to load certain models trained with TF 2.7, it runs into error as below
""No OpKernel was registered to support Op 'BoostedTreesBucketize' used by {{node transform/transform/bucketize/apply_buckets/assign_buckets_all_shapes/assign_buckets/BoostedTreesBucketize}} with these attrs: [_output_shapes=[[?]], num_features=1]""  

However, BoostedTreesBucketize shows unchanged since TF 2.7 to the latest version: https://github.com/tensorflow/tensorflow/blob/v2.17.0/tensorflow/core/ops/boosted_trees_ops.cc#L844. 

Is there any change around boosted tree ops or this specific op after 2.7 which leads to this error?

Detailed logs:
```shell
tensorflow/cc/saved_model/loader.cc:337] SavedModel load for tags { serve }; Status: fail: INVALID_ARGUMENT: No OpKernel was registered to support Op 'BoostedTreesBucketize' used by {{node transform/transform/bucketize/apply_buckets/assign_buckets_all_shapes/assign_buckets/BoostedTreesBucketize}} with these attrs: [_output_shapes=[[?]], num_features=1]
Registered devices: [CPU]
Registered kernels:
  <no registered kernels> [[transform/transform/bucketize/apply_buckets/assign_buckets_all_shapes/assign_buckets/BoostedTreesBucketize]]""
```


### Relevant log output

_No response_"
2561610080,76960,AttributeError when importing tensorflow in python 3.9 and django 4.2 project,closed,2024-10-02 13:07:02+00:00,2024-10-24T02:01:48Z,2024-10-24T02:01:45Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/76960,"['stat:awaiting response', 'type:bug', 'stale', '2.17']","['@bgriffin29,\r\nLooks like this issue is not related to tensorflow installation and during the import of tensorflow. I suspect that the error was occured due to unittest tries to set path variables and somehow it is passing them in as strings instead of path objects.\r\nhttps://github.com/joke2k/django-environ/issues/197\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76960"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/76960"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.17 and tf 2.13

### Custom code

Yes

### OS platform and distribution

Windows 11

### Mobile device

Ubuntu 22.04

### Python version

3.9.19

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When i try to run my server locally (windows 11) using manage.py runserver or on my ubuntu 22.04 server using uwsgi I am getting an error output from theenviron module as soon as tf tries to run to get the site package directories. If i remove tf and my new endpoint then everything runs and works if i add tf back it immediateloy starts failing again. I have tried this with tf 2.17.0 and tf 2.13.1 with the exact same result.

The code below i obviously have a whole project, but the endpoint in its own file set up like it is below causes it to fail to run with the same error. If I comment out the tf import then everything runs completely fine, but of course then i can't have my image classifier on my server.

It may be worth noting that whemn i had this as a script that iran directly it works just fine, this is only an issue when running it as part of my django rest framework api. 

Any help would be appreciated. 

### Standalone code to reproduce the issue

```shell
from rest_framework.decorators import api_view
from rest_framework.response import Response
import tensorflow as tf

@api_view(['POST'])
def MY_ENDPOINT(request):
    return Response()
```
```


### Relevant log output

```shell
File ""C:\Development\MY-SITE\views.py"", line 13, in <module>
    import tensorflow as tf
  File ""C:\Development\MY-SITE\venv3942\lib\site-packages\tensorflow\__init__.py"", line 415, in <module>
    _site_packages_dirs += [p for p in _sys.path if ""site-packages"" in p]
  File ""C:\Development\MY-SITE\venv3942\lib\site-packages\tensorflow\__init__.py"", line 415, in <listcomp>
    _site_packages_dirs += [p for p in _sys.path if ""site-packages"" in p]
  File ""C:\Development\MY-SITE\venv3942\lib\site-packages\environ\environ.py"", line 1068, in __contains__
    return item.__root__.startswith(base_path)
AttributeError: 'str' object has no attribute '__root__'
```


EDIT:

I can m ake it work by editing the tensorflow __init__.py locally to add a try/except like so, but i am not sure what other negative impacts that might have.

```
# Get sitepackages directories for the python installation.
_site_packages_dirs = []
if _site.ENABLE_USER_SITE and _site.USER_SITE is not None:
  _site_packages_dirs += [_site.USER_SITE]
try:
  _site_packages_dirs += [p for p in _sys.path if ""site-packages"" in p]
except:
  pass
```"
2566857445,77048,Custom activation functions cause TensorFlow to crash,closed,2024-10-04 17:17:45+00:00,2024-10-08T14:14:51Z,2024-10-08T14:14:47Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/77048,"['stat:awaiting response', 'type:bug', 'comp:keras', '2.17']","['@AtticusBeachy,\r\nLooks like this issue is more related to Keras. Could you please raise the request in the Keras-team/keras repo from [here](https://github.com/keras-team/keras/issues) for the quick resolution. Thank you!', 'Okay, I have reposted in the [Keras repo](https://github.com/keras-team/keras/issues/20333).', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77048"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77048"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.17.0

### Custom code

Yes

### OS platform and distribution

Linux Mint 22

### Mobile device

_No response_

### Python version

3.12.7

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I expected the code to run. Instead, TensorFlow crashes. 

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
from tensorflow.keras.utils import get_custom_objects
from tensorflow.keras.layers import Activation

def fourier_activation_lambda(freq):
    fn = lambda x : tf.sin(freq*x)
    return(fn)

freq = 1.0
fourier = fourier_activation_lambda(freq)

get_custom_objects()[""fourier""] = Activation(fourier)

print(3*""\n"")
print(f""After addition: {get_custom_objects()=}"")

x_input = tf.keras.Input(shape=[5])
activation = ""fourier""
layer_2 = tf.keras.layers.Dense(100, input_shape = [5],
                                activation=activation,
                                )(x_input)

model = tf.keras.Model(inputs=x_input, outputs=layer_2)
model.compile(optimizer='adam', loss='mse')
model.summary()
```


### Relevant log output

```shell
# Output of print statement:
get_custom_objects()={'fourier': <Activation name=activation, built=False>}

# Error message:
Traceback (most recent call last):
  File ""/home/orca/Downloads/minimal_tf_err.py"", line 20, in <module>
    layer_2 = tf.keras.layers.Dense(100, input_shape = [5],
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/orca/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py"", line 89, in __init__
    self.activation = activations.get(activation)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/orca/.local/lib/python3.12/site-packages/keras/src/activations/__init__.py"", line 104, in get
    raise ValueError(
ValueError: Could not interpret activation function identifier: fourier
```
"
2567265805,77057,MultiHeadAttention layer broken by exception when inside Model or Layer,closed,2024-10-04 20:13:16+00:00,2024-11-13T10:29:27Z,2024-11-13T10:29:23Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/77057,"['type:bug', 'comp:keras', 'TF 2.16']","['Hi **@jm-willy** ,\r\nI reproduced the code you shared but encountered a different error. Could you please share the Colab gist with all the dependencies so that we can analyze it further?\r\nThank you!', ""Here: https://colab.research.google.com/drive/1kd5_mrlNL-rSNFbBL0ReuUNnGUf7YYw_?usp=sharing\r\n\r\nAlso, what different error did you find??\r\n\r\n**PD**: I think I may know the origin of some errors of `MultiHeadAttention` layer. The layer call can take 3 arguments: `call(x,x,x)`, as far as I know, it's the only layer that takes more than one raw tensor. All other layers either take a list of inputs or take a concatenated input to then split it. \r\n\r\nThis difference in `MultiHeadAttention.call()` is probably confronting lots of shape checks and related errors all over `tensorflow` and `keras`.\r\n\r\n\r\n\r\n"", 'Hi **@jm-willy** ,\r\nApologies for the delay, and thank you for your patience. I tried running your code on Colab using TensorFlow version 2.18.0 and faced the same issue. I found an alternative solution that worked for me, which I hope will help you as well. Please refer to the [gist](https://colab.sandbox.google.com/gist/Venkat6871/cafe2daa591fb142ae85d57de158cad0/77057_tf-2-18-0-v.ipynb) here for more details.\r\nIf you have further questions, please consider raising this issue in the Keras repository, as it relates to Keras.\r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues) as this issue is more related to keras.\r\nThank you!', ""Thank you!! Can't believe it lacked a plain `compute_output_shape` with `layers.Layer`. Still gives a horrible warning, but it looks more like a keras implementation problem, probably lacking a more complex `compute_output_shape` method, which I tried the first but didn't got right."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77057"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77057"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.16.1

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

3.11.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Having MultiHeadAttention outside class works:
```
x = tf.keras.layers.MultiHeadAttention(
    num_heads=1,
    key_dim=1,
    attention_axes=-1,
)(x, x, x)
```
When organized inside custom Model/Layer traises exception located at `site-packages\tensorflow\python\ops\special_math_ops.py` line 1288. Commenting the exception makes `model.summary()` work:
```
if output_labels and len(set(output_labels)) != len(output_labels):
    raise ValueError(
        'Output subscripts contain a label appearing more than once: {}'.format(
            equation))

```
It doesn't happen with other layers.



### Standalone code to reproduce the issue

```shell
import tensorflow as tf


class Block(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.att = tf.keras.layers.MultiHeadAttention(
            num_heads=1,
            key_dim=1,
            attention_axes=-1,
            # output_shape=tuple((units,)),
        )
        return

    def call(self, inputs):
        x = self.att(inputs, inputs, inputs)
        return x


my_model_inputs = tf.keras.Input((8, 8, 8, 1))
x = my_model_inputs
x = tf.keras.layers.Flatten()(x)
x = Block()(x)
my_model = tf.keras.Model(my_model_inputs, x)
my_model.summary(expand_nested=True, show_trainable=True)
```


### Relevant log output

```shell
# Errors are like this:

Could not automatically infer the output shape / dtype of 'block' (of type Block). Either the `Block.call()` method is incorrect, or you need to implement the `Block.compute_output_spec() / compute_output_shape()` method. Error encountered:

Exception encountered when calling MultiHeadAttention.call().

Output subscripts contain a label appearing more than once: abcdef,abcdef->abcdeff
# this too:
Output subscripts contain a label appearing more than once: abc,abc->abcc
```
"
2568196602,77092,Import Module Error: Undefined Symbol in TensorFlow Lite Runtime After Build with Blaze and Flex support,closed,2024-10-05 16:01:39+00:00,2024-10-22T02:02:37Z,2024-10-22T02:02:33Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/77092,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', '2.17']","['Hi **@dev2xl** ,\r\nThank you for raising this issue. It seems there is a version mismatch, which is causing compatibility issues. I am providing the [documentation](https://www.tensorflow.org/install/source#gpu) for your reference. Please go through it and recheck all the compatibility versions.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77092"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77092"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.17

### Custom code

Yes

### OS platform and distribution

FROM public.ecr.aws/lambda/python:3.12

### Mobile device

_No response_

### Python version

3.12

### Bazel version

6.5

### GCC/compiler version

12.4

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I successfully built the TensorFlow Lite pip package with Flex using Blaze. However, when I attempted to load the TensorFlow Lite runtime, I encountered the following error:

`Runtime.ImportModuleError: Unable to import module 'entry': /var/lang/lib/python3.12/site-packages/tflite_runtime/_pywrap_tensorflow_interpreter_wrapper.so: undefined symbol: _ZN10tensorflow11CSRMatMulOpIN5Eigen16ThreadPoolDeviceEfEC2EPNS_20OpKernelConstructionE`

I built inside docker image with the following command

`CUSTOM_BAZEL_FLAGS=--define=tflite_pip_with_flex=true tensorflow/lite/tools/pip_package/build_pip_package_with_bazel.sh native`

### Standalone code to reproduce the issue

```shell
import tflite_runtime.interpreter as tflite

filepath = os.path.join(os.path.dirname(__file__), f""models/model.tflite"")
interpreter = tflite.Interpreter(model_path=filepath)
```


### Relevant log output

```shell
2024-10-05 11:50:35 [ERROR] Runtime.ImportModuleError: Unable to import module 'entry': /var/lang/lib/python3.12/site-packages/tflite_runtime/_pywrap_tensorflow_interpreter_wrapper.so: undefined symbol: _ZN10tensorflow11CSRMatMulOpIN5Eigen16ThreadPoolDeviceEfEC2EPNS_20OpKernelConstructionE
Traceback (most recent call last):
```
"
2568222170,77094,tflite conversion from tensorflow concrete function drops input argument names.,closed,2024-10-05 17:06:16+00:00,2024-10-31T19:08:17Z,2024-10-31T19:08:13Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/77094,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'TFLiteConverter', '2.17']","['Hi, @jonasrsv42\r\n\r\nI apologize for the delayed response, I replaced the dictionary input `(Dict[str, tf.Tensor])` with two separate tensor inputs `a and b`. These are passed using the `input_signature` of the `tf.function` which defines the `input shapes, types and names`. By explicitly naming the inputs in the `TensorSpec` of the `tf.function` TensorFlow Lite will retain these names when creating the TFLite model. The `get_concrete_function()` now does not require a dictionary as input. It automatically takes in the tensor a and b.\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nprint(""tf-version:"", tf.__version__)\r\n\r\nclass Test(tf.Module):\r\n    def __init__(self, encoder_dim: int):\r\n        super().__init__(name=None)\r\n\r\n        self.final_projection = tf.keras.layers.Dense(\r\n            encoder_dim, name=""final_projection""\r\n        )\r\n\r\n    @tf.function(input_signature=[\r\n        tf.TensorSpec(shape=(), dtype=tf.int32, name=""a""),\r\n        tf.TensorSpec(shape=(), dtype=tf.int32, name=""b"")\r\n    ])\r\n    def stats(self, a: tf.Tensor, b: tf.Tensor):\r\n        x = a + b\r\n\r\n        print(""x:"", x)\r\n        return {\r\n            ""x"": x,\r\n        }\r\n\r\nmodel = Test(32)\r\n\r\n# Convert the concrete function using TFLiteConverter\r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions(\r\n    [model.stats.get_concrete_function()], model\r\n)\r\ntflite_model = converter.convert()\r\ninterpreter = tf.lite.Interpreter(model_content=tflite_model)\r\nsignatures = interpreter.get_signature_list()\r\nprint(""[Interpreter] signatures: "", signatures)\r\n```\r\n\r\n**Output Log :**\r\n\r\n```\r\ntf-version: 2.17.0\r\nx: Tensor(""add:0"", shape=(), dtype=int32)\r\nx: Tensor(""add:0"", shape=(), dtype=int32)\r\n[Interpreter] signatures:  {\'serving_default\': {\'inputs\': [\'a\', \'b\'], \'outputs\': [\'x\']}}\r\n```\r\nIf I\'ve missed something please let me know.\r\n\r\nThank you for your cooperation and patience.', 'Thank you for the response! \r\n\r\nUnfortunately the reason why I am using a dictionary is because my real use-case involves ~50 variables. Typing them all out manually is not very feasible. I tried to rely on argument ordering but it seems it gets scrambled. \r\n\r\nI have also tried with *args and **kwargs but it seems to suffer from the same issue. \r\n\r\nWhat is the recommended approach for exporting tflite models with a large number of arguments, is manually typing the `TensorSpec` the only supported path? \r\n\r\nIt does seem dictionary output works fine', 'Hi, @jonasrsv42\r\n\r\nI tried something different approach so please refer this [gist-file](https://colab.sandbox.google.com/gist/gaikwadrahul8/4a8b6d7140f7fbdeaa2cf30cf62880ca/test-77094.ipynb) and please refer our official documentation for [Signatures in LiteRT](https://ai.google.dev/edge/litert/models/signatures) which may help you solve your issue.\r\n\r\nIf I have missed something here please let me know.\r\n\r\nThank you for your cooperation and patience.', ""In the gist your `input_x` tensor is being renamed to `inputs_y`. I believe the order is not preserved in tflite model, at-least that's what I have observed so that `input_x` != `inputs_x` in forall x. \r\n\r\nIs this a bug? Is your input argument supposed to get renamed? Is order supposed to be preserved?"", 'Hi, @jonasrsv42 \r\n\r\nI apologize for the delayed response, I did some code modifications so please refer this [gist-file](https://colab.sandbox.google.com/gist/gaikwadrahul8/7f0a894ff29168b46e11f0e00852af99/tflite-77094.ipynb) and let me know is it working as expected or not ?\r\n\r\nif I have missed something here or If issue still persists please let me know.\r\n\r\nThank you for your cooperation and patience.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', 'Yes this workaround seems to work! :) Thanks', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77094"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77094"">No</a>\n']","### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 24.04):
- TensorFlow installation (pip package or built from source): Pip
- TensorFlow library (version, if pip package or github SHA, if built from source): tf-version: 2.17.0

### 2. Code

```
import tensorflow as tf

    print(""tf-version:"", tf.__version__)

    class Test(tf.Module):
        def __init__(self, encoder_dim: int):
            super().__init__(name=None)

            self.final_projection = tf.keras.layers.Dense(
                encoder_dim, name=""final_projection""
            )

        @tf.function
        def stats(self, inputs: Dict[str, tf.Tensor]):
            x = inputs[""a""] + inputs[""b""]

            print(""x"", x)
            return {
                ""x"": x,
            }

    model = Test(32)

    inputs = {""a"": tf.constant(2), ""b"": tf.constant(5)}
    # Convert the concrete functions using TFLiteConverter
    converter = tf.lite.TFLiteConverter.from_concrete_functions(
        [model.stats.get_concrete_function(inputs)], model
    )
    tflite_model = converter.convert()
    interpreter = tf.lite.Interpreter(model_content=tflite_model)
    signatures = interpreter.get_signature_list()
    print(""[Interpreter] signatures: "", signatures)
```

This produces 

```
[Interpreter] signatures:  {'serving_default': {'inputs': ['inputs', 'inputs_1'], 'outputs': ['x']}}
```

I would expect it to produce 

[Interpreter] signatures:  {'serving_default': {'inputs': ['a', 'b'], 'outputs': ['x']}}


Full logs


```
.venv ❯  python3 src/train.py

2024-10-05 19:04:36.611417: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-10-05 19:04:37.118668: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
tf-version: 2.17.0
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
W0000 00:00:1728147877.548136  482617 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.
W0000 00:00:1728147877.548157  482617 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.
2024-10-05 19:04:37.548504: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpuxyu4mv2
2024-10-05 19:04:37.548619: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }
2024-10-05 19:04:37.548626: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpuxyu4mv2
2024-10-05 19:04:37.550161: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled
2024-10-05 19:04:37.550313: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.
2024-10-05 19:04:37.556608: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpuxyu4mv2
2024-10-05 19:04:37.559865: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 11361 microseconds.
2024-10-05 19:04:37.566004: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-10-05 19:04:37.573757: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3531] Estimated count of arithmetic ops: 1  ops, equivalently 0  MACs
[Interpreter] signatures:  {'serving_default': {'inputs': ['inputs', 'inputs_1'], 'outputs': ['x']}}
```"
2569668162,77131,Floating point exception (core dumped) with onednn opt,closed,2024-10-07 08:00:54+00:00,2024-10-09T08:19:47Z,2024-10-09T08:19:43Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/77131,"['type:bug', 'comp:keras', '2.17']","[""heyy, i think these are some suggestions from my side which could help, let me know which one would help you:\r\n1. try updating the tensorflow to latest version\r\n2. try disabling oneDNN optimization `TF_DISABLE_MKL=1`\r\n3. try checking tensor shapes before pooling, just ensure they've valid dim and dosen't have zero's in it"", ""@AdvaitDongre \r\nActually, I've tried them.\r\n1. I'v used the latest version tf 2.17\r\n2. Disabling oneDNN can avoid this problem but makes the executing process slow.\r\n3. I'm executing a random experiment, and the shape are not determined before execution.\r\n\r\nI thought the layer API could throw an exception which can be caught by 'try-except' block (as in Pytorch), but this floating point exception just makes the whole program crash."", 'ahh got it, \r\n1. can you try prechecking for zero dimensions? \r\ngpt code for it:\r\n`def safe_layer(layer, input_tensor):\r\n    shape = tf.shape(input_tensor)\r\n    if tf.reduce_any(shape == 0):\r\n        print(f""Skipping layer {layer.name} due to zero dimension in shape {shape}"")\r\n        return input_tensor\r\n    try:\r\n        return layer(input_tensor)\r\n    except Exception as e:\r\n        print(f""Error applying layer {layer.name}: {e}"")\r\n        return input_tensor`\r\n\r\n2. you could also try using tf.debugging.assert \r\ndocs: [https://www.tensorflow.org/api_docs/python/tf/debugging/Assert](tf.debugging.assert)\r\n\r\nbut i think pre-checking would fix your error, let me know whether it does or not', '@Shuo-Sun20,\r\nHi, By default the colab notebook is using tensorflow v2.17 which contains keras3.0 which was causing the error. Could you please try to import keras2.0 with the below commands.\r\n\r\n```python\r\n!pip install tf-keras\r\n\r\nimport tf_keras as keras\r\n```\r\n\r\nAlso I have changed some steps and the code was executed without crash/fail. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/99396471aaa4cf5e4d54cdb58dd808df/untitled2155.ipynb).\r\n\r\nThank you!', ""@AdvaitDongre \r\nThank you for your advice.\r\nUnfortunately, this error can not be caught by 'try-except' block. It just crashes the whole program. Therefore the code you provided can not work.\r\n\r\n@tilakrayal \r\nThank you for the check.\r\nIt seems that something goes wrongly when keras updating from 2.0 to 3.0. I'll turn to keras and report this issue."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77131"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77131"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.17

### Custom code

Yes

### OS platform and distribution

linux 

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I don't know why but tensorflow allows a layer generating tensor with shapes containing 0, which will lead to 'Floating point exception (core dumped)' when oneDNN Opt is on. 

In the code below a MaxPooling1D should have generate a tensor with shape [3,5,0], while the engine crashed due to the bug I mentioned above.

### Standalone code to reproduce the issue

```shell
https://colab.research.google.com/drive/1jkQOOOjU2B60Qe8MvaEISXObuHBxm-I9?usp=sharing
```


### Relevant log output

```shell
The colab engine crashed.
If running locally, the error msg is:

Floating point exception (core dumped)
```
"
2569936583,77137,TensorFlow Lite label_image fails to cross-compile with cmake,closed,2024-10-07 09:55:20+00:00,2025-01-09T09:50:38Z,2025-01-09T09:50:34Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/77137,"['type:bug', 'awaiting PR merge', '2.17']","['The problem is that label_image should link to built protobuf, but the target_link_libraries in tensorflow/lite/examples/label_image/CMakeLists.txt are filled with the wrong library name.\r\nIn the cmake files of protobuf, you can see that the built library is named libprotobuf instead of protobuf:\r\n```\r\n$ cd tflite_build/protobuf/cmake\r\n$ ag ""add_library""  \r\nlibprotobuf.cmake\r\n102:add_library(libprotobuf ${protobuf_SHARED_OR_STATIC}\r\n134:add_library(protobuf::libprotobuf ALIAS libprotobuf)\r\n\r\nlibprotobuf-lite.cmake\r\n89:add_library(libprotobuf-lite ${protobuf_SHARED_OR_STATIC}\r\n118:add_library(protobuf::libprotobuf-lite ALIAS libprotobuf-lite)\r\n\r\ntests.cmake\r\n30:  add_library(gmock STATIC\r\n35:  add_library(gmock_main STATIC ""${googlemock_source_dir}/src/gmock_main.cc"")\r\n38:  add_library(GTest::gmock ALIAS gmock)\r\n39:  add_library(GTest::gmock_main ALIAS gmock_main)\r\n127:add_library(protobuf-lite-test-common STATIC\r\n141:add_library(protobuf-test-common STATIC\r\n\r\nlibprotoc.cmake\r\n113:add_library(libprotoc ${protobuf_SHARED_OR_STATIC}\r\n136:add_library(protobuf::libprotoc ALIAS libprotoc)\r\n```\r\nI have confirmed that label_image can be built with the change shown below.\r\n```\r\ndiff --git a/tensorflow/lite/examples/label_image/CMakeLists.txt b/tensorflow/lite/examples/label_image/CMakeLists.txt\r\nindex 2fcb09ce96e..07ab2343ae5 100644\r\n--- a/tensorflow/lite/examples/label_image/CMakeLists.txt\r\n+++ b/tensorflow/lite/examples/label_image/CMakeLists.txt\r\n@@ -84,5 +84,5 @@ target_compile_options(label_image\r\n target_link_libraries(label_image\r\n   tensorflow-lite\r\n   profiling_info_proto\r\n-  protobuf\r\n+  libprotobuf\r\n )\r\n```\r\n', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77137"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77137"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

v2.18.0-rc0

### Custom code

No

### OS platform and distribution

WSL Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

clang 17.0.2

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I got the error

> [riscv64-linux/bin/ld: cannot find -lprotobuf: No such file or directory](riscv64-unknown-linux-gnu-clang++: error: linker command failed with exit code 1 (use -v to see invocation))


### Standalone code to reproduce the issue

```shell
$ mkdir workspace && cd workspace
$ mkdir flatc_build && mkdir tflite_build

$ wget https://raw.githubusercontent.com/google/XNNPACK/refs/heads/master/cmake/riscv64.toolchain
$ wget https://github.com/riscv-collab/riscv-gnu-toolchain/releases/download/2023.11.20/riscv64-glibc-ubuntu-20.04-llvm-nightly-2023.11.20-nightly.tar.gz
$ tar zxvf riscv64-glibc-ubuntu-20.04-llvm-nightly-2023.11.20-nightly.tar.gz

$ git clone https://github.com/tensorflow/tensorflow
$ cmake -B ./flatc_build -S ./tensorflow/tensorflow/lite/tools/cmake/native_tools/flatbuffers
$ cmake --build ./flatc_build -j6

$ cmake -B ./tflite_build \
-S ./tensorflow/tensorflow/lite/ \
-DCMAKE_TOOLCHAIN_FILE=$(pwd)/riscv64.toolchain \
-DRISCV_TOOLCHAIN_ROOT=$(pwd)/riscv \
-DRISCV_QEMU_ROOT=$(pwd)/riscv \
-DCMAKE_BUILD_TYPE=Release \
-DTFLITE_HOST_TOOLS_DIR=./flatc_build/flatbuffers-flatc/bin \
-DTFLITE_KERNEL_TEST=OFF

$ cmake --build ./tflite_build -j6
$ cmake --build ./tflite_build -t label_image -j6
```


### Relevant log output

```shell
[100%] Linking CXX executable label_image
/home/xxx/workspace/tflite_build/../riscv/bin/riscv64-unknown-linux-gnu-ld: cannot find -lprotobuf: No such file or directory
riscv64-unknown-linux-gnu-clang++: error: linker command failed with exit code 1 (use -v to see invocation)
```
"
2574149429,77283,ValueError Failued to convert a NumPy array to a tensor... using Embedding,closed,2024-10-08 20:32:11+00:00,2024-10-11T20:05:37Z,2024-10-11T20:05:33Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/77283,"['type:bug', 'TF 2.15']","['Hi **@gsexton** ,\r\nApologies for the delay. I tried running your code on Colab using TensorFlow v2.15.0 and encountered the same issue. Additionally, I tested with the latest versions and faced a different issue, but I found an alternative solution that worked for me. I am providing the [gist](https://colab.sandbox.google.com/gist/Venkat6871/e4ed8002e59627d6f6ef875542f43752/77283_tf-2-15-2-17-nightly-v.ipynb) here for your reference. Please try using the latest versions as they tend to provide more accurate results.\r\n\r\nThank you!', '@Venkat6871 Thank you so much for your help. I genuinely appreciate it. I incorporated your suggestion and it works well.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77283"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77283"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.15.0

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 20.04.6 LTS

### Mobile device

_No response_

### Python version

3.10.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

Deep Learning OSS Nvidia Driver AMI GPU TensorFlow 2.15 (Ubuntu 20.04) 20240319

### Current behavior?

When attempting to train a model with an embedding, I get the error: 

ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type float).

An example dataset demonstrating the problem is attached.

Additional Information:

OS: Ubuntu 20.04.6 LTS (Deep Learning OSS Nvidia Driver AMI GPU TensorFlow 2.15 (Ubuntu 20.04) 20240319)
TensorFlow Version: 2.15.0
NumPy: 1.26.4
Pandas: 2.2.3
Python: 3.10.13

[training_labels.csv](https://github.com/user-attachments/files/17298913/training_labels.csv)
[training.csv](https://github.com/user-attachments/files/17298917/training.csv)

I hunted around a lot to try to sort this out. In my initial effort, I could see the field was coming in as a string. I added the converter shown and it appears from the outputs that's now as expected. Everything else that I could find on this error suggested using dtype=np.float32 in the read_csv() call to cast the data, but I've done that without success.


### Standalone code to reproduce the issue

```shell
#!/usr/bin/env python3

import tensorflow as tf
import pandas as pd
import numpy as np


def convert(item):
    item = item[1:-1]    # remove `[ ]`
    item = item.strip()  # remove spaces at the end
    item = np.fromstring(item, sep=' ')  # convert string to `numpy.array`
    return item

print(""TensorFlow Version: ""+tf.__version__)

X_train = pd.read_csv('training.csv',converters={'fld7':convert})
y_train = pd.read_csv('training_labels.csv')
print(f""{X_train.shape=}"")
print(f""{y_train.shape=}"")

x_row=X_train.iloc[0]
x_val=x_row['fld7']
print(f""{type(x_row)=} {x_row=}"")
print(f""{type(x_val)=} {x_val=}"")


model = tf.keras.Sequential([
    tf.keras.layers.Dense(1024, activation='relu'),
    tf.keras.layers.Dense(2048, activation='relu'),
    tf.keras.layers.Dense(2048, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(
    loss=tf.keras.losses.binary_crossentropy,
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),
    metrics=[
        tf.keras.metrics.BinaryAccuracy(name='accuracy'),
        tf.keras.metrics.Precision(name='precision'),
        tf.keras.metrics.Recall(name='recall')
    ]
    )

history = model.fit(X_train, y_train, epochs=25)
```


### Relevant log output

```shell
TensorFlow Version: 2.15.0
X_train.shape=(10, 134)
y_train.shape=(10, 1)
type(x_row)=<class 'pandas.core.series.Series'> x_row=fld0      0.571351
fld1             1
fld2             1
fld3             0
fld4             0
            ...   
fld129           0
fld130           0
fld131           0
fld132           0
fld133           0
Name: 0, Length: 134, dtype: object
type(x_val)=<class 'numpy.ndarray'> x_val=array([0.0756, 0.0756, 0.1176, 0.0672, 0.0588, 0.0756, 0.0672, 0.0504,
       0.0336, 0.1008, 0.0252, 0.0252, 0.0252, 0.0672, 0.0252, 0.0252,
       0.0168, 0.0084, 0.    , 0.    , 0.    , 0.0084, 0.0084, 0.    ,
       0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,
       0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.042 ])

2024-10-08 20:14:52.337621: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-10-08 20:14:52.339066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20723 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6
2024-10-08 20:14:52.339066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20723 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6
Traceback (most recent call last):
  File ""/home/ubuntu/new_model/testcase.py"", line 44, in <module>
    history = model.fit(X_train, y_train, epochs=25)
  File ""/opt/tensorflow/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py"", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py"", line 103, in convert_to_eager_tensor
    return ops.EagerTensor(value, ctx.device_name, dtype)
ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type float).
```
"
2575769733,77363,Issue with Mask R-CNN and TFRecord containing both masks and bounding boxes,closed,2024-10-09 12:20:38+00:00,2024-10-11T10:45:10Z,2024-10-11T10:45:07Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/77363,"['stat:awaiting response', 'type:bug', 'comp:model', 'TF 2.10']","['Hi **@senaagacc** ,\r\nLooks like this is duplicate of issue #77365. Can you please close this issue, since it is already being tracked there?\r\nThank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77363"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77363"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.10

### Custom code

Yes

### OS platform and distribution

Windows 11

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I am working with Mask R-CNN from the TensorFlow Model Zoo, and I am facing an issue when training with TFRecord files that include both masks and bounding boxes. My dataset is formatted as follows:

Each image has a corresponding mask image, which is used for generating bounding boxes.
I have included both the bounding box coordinates and the encoded mask in the TFRecord files.
Here is a snippet of how I prepare the TFRecord:

```
# Utility function for bounding box extraction from a mask
def mask_to_bounding_box(mask_path):
    # Load the binary mask (segmented object should have pixel value > 0)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask is None:
        raise ValueError(f""Mask image {mask_path} could not be loaded."")
    
    # Find contours in the binary mask
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # List to store bounding boxes
    bounding_boxes = []

    # Iterate over each contour
    for contour in contours:
        # Get the bounding rectangle for each contour
        x, y, w, h = cv2.boundingRect(contour)
        bounding_boxes.append([x, y, x + w, y + h])  # (x_min, y_min, x_max, y_max)


    return bounding_boxes

def create_tf_example(image_path, mask_path, bboxes, labels):
    """"""
    Args:
      image_path (str): Path to the image file (JPEG or PNG).
      mask_path (str): Path to the corresponding mask file (PNG).
      bboxes (list of list): List of bounding boxes, each a list in [xmin, ymin, xmax, ymax] format, normalized to [0, 1].
      labels (list of int): List of integer labels corresponding to each bounding box.
    
    Returns:
      tf.train.Example: The TFRecord example containing image data and annotations.
    """"""

    # Read image
    with tf.io.gfile.GFile(image_path, 'rb') as fid:
        encoded_image = fid.read()
    
    image = cv2.imread(image_path, 0) 
    image_format = b'JPG'  # or b'png' depending on your image format
    height, width = image.shape  # You need to know the dimensions of your images
    
    # Read the mask (binary mask)
    with tf.io.gfile.GFile(mask_path, 'rb') as fid:
        encoded_mask = fid.read()

    # Prepare bounding box information
    xmins = []  # List of normalized xmin coordinates
    xmaxs = []  # List of normalized xmax coordinates
    ymins = []  # List of normalized ymin coordinates
    ymaxs = []  # List of normalized ymax coordinates
    sizes=[]

    class_text = [get_class_text_for_id(label_map_dict,labels).encode('utf-8')]
    class_id = [labels]

    #for bbox in bboxes:
    for bbox in bboxes:
        print(bbox)
        xmin, ymin, xmax, ymax = bbox
        size=(((xmax-xmin)/width)*((ymax-ymin)/height))
        assert xmin<xmax,""xmin<xmax olmalı""
        assert ymin<ymax,""ymin<ymax olmalı""
        assert size>0, ""Alan sıfırdan büyük olmalı""
        xmins.append(xmin/width)
        xmaxs.append(xmax/width)
        ymins.append(ymin/height)
        ymaxs.append(ymax/height)

        print(image_path,class_text,sizes)    
    # Prepare features for the TFRecord
    feature = {
        'image/height': dataset_util.int64_feature(height),
        'image/width': dataset_util.int64_feature(width),
        'image/filename': dataset_util.bytes_feature(tf.compat.as_bytes(image_path.encode('utf-8'))),
        'image/source_id': dataset_util.bytes_feature(tf.compat.as_bytes(image_path.encode('utf-8'))),
        'image/encoded': dataset_util.bytes_feature(encoded_image),
        'image/format': dataset_util.bytes_feature(image_format),
        
        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),
        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),
        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),
        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),
        'image/object/class/text': dataset_util.bytes_list_feature(class_text),
        'image/object/class/label': dataset_util.int64_list_feature(class_id),
        'image/encoded_mask': dataset_util.bytes_feature(encoded_mask)
    }

    example = tf.train.Example(features=tf.train.Features(feature=feature))
    return example
```

However, when I try to train Mask R-CNN with this setup, I get the following error:

```
See `tf.nn.softmax_cross_entropy_with_logits_v2`.

Traceback (most recent call last):
  File ""E:\PROJELER\DevamEden\DEN_IZ\tfgpu\models\research\object_detection\model_main_tf2.py"", line 114, in <module>
    tf.compat.v1.app.run()
  File ""C:\Users\caydoner\AppData\Local\anaconda3\envs\tfgpu\lib\site-packages\tensorflow\python\platform\app.py"", line 36, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\Users\caydoner\AppData\Local\anaconda3\envs\tfgpu\lib\site-packages\absl\app.py"", line 308, in run
    _run_main(main, args)
  File ""C:\Users\caydoner\AppData\Local\anaconda3\envs\tfgpu\lib\site-packages\absl\app.py"", line 254, in _run_main
    sys.exit(main(argv))
  File ""E:\PROJELER\DevamEden\DEN_IZ\tfgpu\models\research\object_detection\model_main_tf2.py"", line 105, in main
    model_lib_v2.train_loop(
  File ""C:\Users\caydoner\AppData\Local\anaconda3\envs\tfgpu\lib\site-packages\object_detection\model_lib_v2.py"", line 685, in train_loop
    losses_dict = _dist_train_step(train_input_iter)
  File ""C:\Users\caydoner\AppData\Local\anaconda3\envs\tfgpu\lib\site-packages\tensorflow\python\util\traceback_utils.py"", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""C:\Users\caydoner\AppData\Local\anaconda3\envs\tfgpu\lib\site-packages\tensorflow\python\eager\execute.py"", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

2 root error(s) found.
  (0) INVALID_ARGUMENT:  indices[0] = 0 is not in [0, 0)
         [[{{node GatherV2_7}}]]
         [[MultiDeviceIteratorGetNextFromShard]]
         [[RemoteCall]]
         [[while/body/_1/IteratorGetNext]]
         [[while/body/_1/Loss/RPNLoss/Loss/huber_loss/assert_broadcastable/is_valid_shape/else/_6000/Loss/RPNLoss/Loss/huber_loss/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/then/_6260/Loss/RPNLoss/Loss/huber_loss/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/concat/_410]]
  (1) INVALID_ARGUMENT:  indices[0] = 0 is not in [0, 0)
         [[{{node GatherV2_7}}]]
         [[MultiDeviceIteratorGetNextFromShard]]
         [[RemoteCall]]
         [[while/body/_1/IteratorGetNext]]
0 successful operations.
0 derived errors ignored. [Op:__inference__dist_train_step_93456]
```

The point that draws my attention is that this error does not appear when there are only masks in my TFRecord file, and I do not receive the error on models such as SSD that only work with bounding box. I get this error when I use both mask and bounding box information with Mask R-CNN. What could be the cause of this problem and how can I solve it?



### Standalone code to reproduce the issue

```shell
# Utility function for bounding box extraction from a mask
def mask_to_bounding_box(mask_path):
    # Load the binary mask (segmented object should have pixel value > 0)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask is None:
        raise ValueError(f""Mask image {mask_path} could not be loaded."")
    
    # Find contours in the binary mask
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # List to store bounding boxes
    bounding_boxes = []

    # Iterate over each contour
    for contour in contours:
        # Get the bounding rectangle for each contour
        x, y, w, h = cv2.boundingRect(contour)
        bounding_boxes.append([x, y, x + w, y + h])  # (x_min, y_min, x_max, y_max)


    return bounding_boxes

def create_tf_example(image_path, mask_path, bboxes, labels):
    """"""
    Args:
      image_path (str): Path to the image file (JPEG or PNG).
      mask_path (str): Path to the corresponding mask file (PNG).
      bboxes (list of list): List of bounding boxes, each a list in [xmin, ymin, xmax, ymax] format, normalized to [0, 1].
      labels (list of int): List of integer labels corresponding to each bounding box.
    
    Returns:
      tf.train.Example: The TFRecord example containing image data and annotations.
    """"""

    # Read image
    with tf.io.gfile.GFile(image_path, 'rb') as fid:
        encoded_image = fid.read()
    
    image = cv2.imread(image_path, 0) 
    image_format = b'JPG'  # or b'png' depending on your image format
    height, width = image.shape  # You need to know the dimensions of your images
    
    # Read the mask (binary mask)
    with tf.io.gfile.GFile(mask_path, 'rb') as fid:
        encoded_mask = fid.read()

    # Prepare bounding box information
    xmins = []  # List of normalized xmin coordinates
    xmaxs = []  # List of normalized xmax coordinates
    ymins = []  # List of normalized ymin coordinates
    ymaxs = []  # List of normalized ymax coordinates
    sizes=[]

    class_text = [get_class_text_for_id(label_map_dict,labels).encode('utf-8')]
    class_id = [labels]

    #for bbox in bboxes:
    for bbox in bboxes:
        print(bbox)
        xmin, ymin, xmax, ymax = bbox
        size=(((xmax-xmin)/width)*((ymax-ymin)/height))
        assert xmin<xmax,""xmin<xmax olmalı""
        assert ymin<ymax,""ymin<ymax olmalı""
        assert size>0, ""Alan sıfırdan büyük olmalı""
        xmins.append(xmin/width)
        xmaxs.append(xmax/width)
        ymins.append(ymin/height)
        ymaxs.append(ymax/height)

        print(image_path,class_text,sizes)    
    # Prepare features for the TFRecord
    feature = {
        'image/height': dataset_util.int64_feature(height),
        'image/width': dataset_util.int64_feature(width),
        'image/filename': dataset_util.bytes_feature(tf.compat.as_bytes(image_path.encode('utf-8'))),
        'image/source_id': dataset_util.bytes_feature(tf.compat.as_bytes(image_path.encode('utf-8'))),
        'image/encoded': dataset_util.bytes_feature(encoded_image),
        'image/format': dataset_util.bytes_feature(image_format),
        
        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),
        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),
        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),
        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),
        'image/object/class/text': dataset_util.bytes_list_feature(class_text),
        'image/object/class/label': dataset_util.int64_list_feature(class_id),
        'image/encoded_mask': dataset_util.bytes_feature(encoded_mask)
    }

    example = tf.train.Example(features=tf.train.Features(feature=feature))
    return example
```


### Relevant log output

_No response_"
2575807056,77365,Issue with Mask R-CNN and TFRecord containing both masks and bounding boxes,closed,2024-10-09 12:36:34+00:00,2024-10-27T02:05:49Z,2024-10-27T02:05:47Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/77365,"['stat:awaiting response', 'type:bug', 'stale', 'comp:model', 'TF 2.10']","['Also, could there be a problem with the parameters in the Mask RCNN pipeline.config file, My file is as follows. I just changed num_classes and Paths.\r\n\r\n```\r\n# Mask R-CNN with Inception Resnet v2 (no atrous)\r\n# Sync-trained on COCO (with 8 GPUs) with batch size 16 (1024x1024 resolution)\r\n# Initialized from Imagenet classification checkpoint\r\n# TF2-Compatible, *Not* TPU-Compatible\r\n#\r\n# Achieves XXX mAP on COCO\r\n\r\nmodel {\r\n  faster_rcnn {\r\n    number_of_stages: 3\r\n    num_classes: 11\r\n    image_resizer {\r\n      fixed_shape_resizer {\r\n        height: 1024\r\n        width: 1024\r\n        # pad_to_max_dimension: true\r\n      }\r\n    }\r\n    feature_extractor {\r\n      type: \'faster_rcnn_inception_resnet_v2_keras\'\r\n    }\r\n    first_stage_anchor_generator {\r\n      grid_anchor_generator {\r\n        scales: [0.25, 0.5, 1.0, 2.0]\r\n        aspect_ratios: [0.5, 1.0, 2.0]\r\n        height_stride: 16\r\n        width_stride: 16\r\n      }\r\n    }\r\n    first_stage_box_predictor_conv_hyperparams {\r\n      op: CONV\r\n      regularizer {\r\n        l2_regularizer {\r\n          weight: 0.0\r\n        }\r\n      }\r\n      initializer {\r\n        truncated_normal_initializer {\r\n          stddev: 0.01\r\n        }\r\n      }\r\n    }\r\n    first_stage_nms_score_threshold: 0.0\r\n    first_stage_nms_iou_threshold: 0.7\r\n    first_stage_max_proposals: 300\r\n    first_stage_localization_loss_weight: 2.0\r\n    first_stage_objectness_loss_weight: 1.0\r\n    initial_crop_size: 17\r\n    maxpool_kernel_size: 1\r\n    maxpool_stride: 1\r\n    second_stage_box_predictor {\r\n      mask_rcnn_box_predictor {\r\n        use_dropout: false\r\n        dropout_keep_probability: 1.0\r\n        fc_hyperparams {\r\n          op: FC\r\n          regularizer {\r\n            l2_regularizer {\r\n              weight: 0.0\r\n            }\r\n          }\r\n          initializer {\r\n            variance_scaling_initializer {\r\n              factor: 1.0\r\n              uniform: true\r\n              mode: FAN_AVG\r\n            }\r\n          }\r\n        }\r\n        mask_height: 33\r\n        mask_width: 33\r\n        mask_prediction_conv_depth: 0\r\n        mask_prediction_num_conv_layers: 4\r\n        conv_hyperparams {\r\n          op: CONV\r\n          regularizer {\r\n            l2_regularizer {\r\n              weight: 0.0\r\n            }\r\n          }\r\n          initializer {\r\n            truncated_normal_initializer {\r\n              stddev: 0.01\r\n            }\r\n          }\r\n        }\r\n        predict_instance_masks: true\r\n      }\r\n    }\r\n    second_stage_post_processing {\r\n      batch_non_max_suppression {\r\n        score_threshold: 0.0\r\n        iou_threshold: 0.6\r\n        max_detections_per_class: 100\r\n        max_total_detections: 100\r\n      }\r\n      score_converter: SOFTMAX\r\n    }\r\n    second_stage_localization_loss_weight: 2.0\r\n    second_stage_classification_loss_weight: 1.0\r\n    second_stage_mask_prediction_loss_weight: 4.0\r\n    resize_masks: false\r\n  }\r\n}\r\n\r\ntrain_config: {\r\n  batch_size: 16\r\n  num_steps: 200000\r\n  optimizer {\r\n    momentum_optimizer: {\r\n      learning_rate: {\r\n        cosine_decay_learning_rate {\r\n          learning_rate_base: 0.008\r\n          total_steps: 200000\r\n          warmup_learning_rate: 0.0\r\n          warmup_steps: 5000\r\n        }\r\n      }\r\n      momentum_optimizer_value: 0.9\r\n    }\r\n    use_moving_average: false\r\n  }\r\n  gradient_clipping_by_norm: 10.0\r\n  data_augmentation_options {\r\n    random_horizontal_flip {\r\n    }\r\n  }\r\n}\r\n\r\ntrain_input_reader: {\r\n  tf_record_input_reader {\r\n    input_path: ""PATH""\r\n  }\r\n  load_instance_masks: true\r\n  mask_type: PNG_MASKS\r\n}\r\n\r\neval_config: {\r\n  metrics_set: ""coco_detection_metrics""\r\n  metrics_set: ""coco_mask_metrics""\r\n  eval_instance_masks: true\r\n  use_moving_averages: false\r\n  batch_size: 1\r\n  include_metrics_per_category: true\r\n}\r\n\r\neval_input_reader: {\r\n  label_map_path: ""PATH""\r\n  shuffle: false\r\n  num_epochs: 1\r\n  tf_record_input_reader {\r\n    input_path: ""PATH""\r\n  }\r\n  load_instance_masks: true\r\n  mask_type: PNG_MASKS\r\n}   \r\n```', '@senaagacc,\r\nIn the given code snippet you have defined the class and its methods but are not calling them anywhere. Could you please provide the complete code or the colab gist which helps to debug the issue and also please try to upgrade to the latest TensorFlow v2.17. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77365"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77365"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.10

### Custom code

Yes

### OS platform and distribution

Windows 11

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I am working with Mask R-CNN from the TensorFlow Model Zoo, and I am facing an issue when training with TFRecord files that include both masks and bounding boxes. My dataset is formatted as follows:

Each image has a corresponding mask image, which is used for generating bounding boxes.
I have included both the bounding box coordinates and the encoded mask in the TFRecord files.
Here is a snippet of how I prepare the TFRecord:

```
# Utility function for bounding box extraction from a mask
def mask_to_bounding_box(mask_path):
    # Load the binary mask (segmented object should have pixel value > 0)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask is None:
        raise ValueError(f""Mask image {mask_path} could not be loaded."")
    
    # Find contours in the binary mask
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # List to store bounding boxes
    bounding_boxes = []

    # Iterate over each contour
    for contour in contours:
        # Get the bounding rectangle for each contour
        x, y, w, h = cv2.boundingRect(contour)
        bounding_boxes.append([x, y, x + w, y + h])  # (x_min, y_min, x_max, y_max)


    return bounding_boxes

def create_tf_example(image_path, mask_path, bboxes, labels):
    """"""
    Args:
      image_path (str): Path to the image file (JPEG or PNG).
      mask_path (str): Path to the corresponding mask file (PNG).
      bboxes (list of list): List of bounding boxes, each a list in [xmin, ymin, xmax, ymax] format, normalized to [0, 1].
      labels (list of int): List of integer labels corresponding to each bounding box.
    
    Returns:
      tf.train.Example: The TFRecord example containing image data and annotations.
    """"""

    # Read image
    with tf.io.gfile.GFile(image_path, 'rb') as fid:
        encoded_image = fid.read()
    
    image = cv2.imread(image_path, 0) 
    image_format = b'JPG'  # or b'png' depending on your image format
    height, width = image.shape  # You need to know the dimensions of your images
    
    # Read the mask (binary mask)
    with tf.io.gfile.GFile(mask_path, 'rb') as fid:
        encoded_mask = fid.read()

    # Prepare bounding box information
    xmins = []  # List of normalized xmin coordinates
    xmaxs = []  # List of normalized xmax coordinates
    ymins = []  # List of normalized ymin coordinates
    ymaxs = []  # List of normalized ymax coordinates
    sizes=[]

    class_text = [get_class_text_for_id(label_map_dict,labels).encode('utf-8')]
    class_id = [labels]

    #for bbox in bboxes:
    for bbox in bboxes:
        print(bbox)
        xmin, ymin, xmax, ymax = bbox
        size=(((xmax-xmin)/width)*((ymax-ymin)/height))
        assert xmin<xmax,""xmin<xmax olmalı""
        assert ymin<ymax,""ymin<ymax olmalı""
        assert size>0, ""Alan sıfırdan büyük olmalı""
        xmins.append(xmin/width)
        xmaxs.append(xmax/width)
        ymins.append(ymin/height)
        ymaxs.append(ymax/height)

        print(image_path,class_text,sizes)    
    # Prepare features for the TFRecord
    feature = {
        'image/height': dataset_util.int64_feature(height),
        'image/width': dataset_util.int64_feature(width),
        'image/filename': dataset_util.bytes_feature(tf.compat.as_bytes(image_path.encode('utf-8'))),
        'image/source_id': dataset_util.bytes_feature(tf.compat.as_bytes(image_path.encode('utf-8'))),
        'image/encoded': dataset_util.bytes_feature(encoded_image),
        'image/format': dataset_util.bytes_feature(image_format),
        
        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),
        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),
        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),
        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),
        'image/object/class/text': dataset_util.bytes_list_feature(class_text),
        'image/object/class/label': dataset_util.int64_list_feature(class_id),
        'image/encoded_mask': dataset_util.bytes_feature(encoded_mask)
    }

    example = tf.train.Example(features=tf.train.Features(feature=feature))
    return example
```

However, when I try to train Mask R-CNN with this setup, I get the following error:

```
See `tf.nn.softmax_cross_entropy_with_logits_v2`.

Traceback (most recent call last):
  File ""E:\PROJELER\DevamEden\DEN_IZ\tfgpu\models\research\object_detection\model_main_tf2.py"", line 114, in <module>
    tf.compat.v1.app.run()
  File ""C:\Users\caydoner\AppData\Local\anaconda3\envs\tfgpu\lib\site-packages\tensorflow\python\platform\app.py"", line 36, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\Users\caydoner\AppData\Local\anaconda3\envs\tfgpu\lib\site-packages\absl\app.py"", line 308, in run
    _run_main(main, args)
  File ""C:\Users\caydoner\AppData\Local\anaconda3\envs\tfgpu\lib\site-packages\absl\app.py"", line 254, in _run_main
    sys.exit(main(argv))
  File ""E:\PROJELER\DevamEden\DEN_IZ\tfgpu\models\research\object_detection\model_main_tf2.py"", line 105, in main
    model_lib_v2.train_loop(
  File ""C:\Users\caydoner\AppData\Local\anaconda3\envs\tfgpu\lib\site-packages\object_detection\model_lib_v2.py"", line 685, in train_loop
    losses_dict = _dist_train_step(train_input_iter)
  File ""C:\Users\caydoner\AppData\Local\anaconda3\envs\tfgpu\lib\site-packages\tensorflow\python\util\traceback_utils.py"", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""C:\Users\caydoner\AppData\Local\anaconda3\envs\tfgpu\lib\site-packages\tensorflow\python\eager\execute.py"", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

2 root error(s) found.
  (0) INVALID_ARGUMENT:  indices[0] = 0 is not in [0, 0)
         [[{{node GatherV2_7}}]]
         [[MultiDeviceIteratorGetNextFromShard]]
         [[RemoteCall]]
         [[while/body/_1/IteratorGetNext]]
         [[while/body/_1/Loss/RPNLoss/Loss/huber_loss/assert_broadcastable/is_valid_shape/else/_6000/Loss/RPNLoss/Loss/huber_loss/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/then/_6260/Loss/RPNLoss/Loss/huber_loss/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/concat/_410]]
  (1) INVALID_ARGUMENT:  indices[0] = 0 is not in [0, 0)
         [[{{node GatherV2_7}}]]
         [[MultiDeviceIteratorGetNextFromShard]]
         [[RemoteCall]]
         [[while/body/_1/IteratorGetNext]]
0 successful operations.
0 derived errors ignored. [Op:__inference__dist_train_step_93456]
```

The point that draws my attention is that this error does not appear when there are only masks in my TFRecord file, and I do not receive the error on models such as SSD that only work with bounding box. I get this error when I use both mask and bounding box information with Mask R-CNN. What could be the cause of this problem and how can I solve it?



### Standalone code to reproduce the issue

```shell
# Utility function for bounding box extraction from a mask
def mask_to_bounding_box(mask_path):
    # Load the binary mask (segmented object should have pixel value > 0)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask is None:
        raise ValueError(f""Mask image {mask_path} could not be loaded."")
    
    # Find contours in the binary mask
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # List to store bounding boxes
    bounding_boxes = []

    # Iterate over each contour
    for contour in contours:
        # Get the bounding rectangle for each contour
        x, y, w, h = cv2.boundingRect(contour)
        bounding_boxes.append([x, y, x + w, y + h])  # (x_min, y_min, x_max, y_max)


    return bounding_boxes

def create_tf_example(image_path, mask_path, bboxes, labels):
    """"""
    Args:
      image_path (str): Path to the image file (JPEG or PNG).
      mask_path (str): Path to the corresponding mask file (PNG).
      bboxes (list of list): List of bounding boxes, each a list in [xmin, ymin, xmax, ymax] format, normalized to [0, 1].
      labels (list of int): List of integer labels corresponding to each bounding box.
    
    Returns:
      tf.train.Example: The TFRecord example containing image data and annotations.
    """"""

    # Read image
    with tf.io.gfile.GFile(image_path, 'rb') as fid:
        encoded_image = fid.read()
    
    image = cv2.imread(image_path, 0) 
    image_format = b'JPG'  # or b'png' depending on your image format
    height, width = image.shape  # You need to know the dimensions of your images
    
    # Read the mask (binary mask)
    with tf.io.gfile.GFile(mask_path, 'rb') as fid:
        encoded_mask = fid.read()

    # Prepare bounding box information
    xmins = []  # List of normalized xmin coordinates
    xmaxs = []  # List of normalized xmax coordinates
    ymins = []  # List of normalized ymin coordinates
    ymaxs = []  # List of normalized ymax coordinates
    sizes=[]

    class_text = [get_class_text_for_id(label_map_dict,labels).encode('utf-8')]
    class_id = [labels]

    #for bbox in bboxes:
    for bbox in bboxes:
        print(bbox)
        xmin, ymin, xmax, ymax = bbox
        size=(((xmax-xmin)/width)*((ymax-ymin)/height))
        assert xmin<xmax,""xmin<xmax olmalı""
        assert ymin<ymax,""ymin<ymax olmalı""
        assert size>0, ""Alan sıfırdan büyük olmalı""
        xmins.append(xmin/width)
        xmaxs.append(xmax/width)
        ymins.append(ymin/height)
        ymaxs.append(ymax/height)

        print(image_path,class_text,sizes)    
    # Prepare features for the TFRecord
    feature = {
        'image/height': dataset_util.int64_feature(height),
        'image/width': dataset_util.int64_feature(width),
        'image/filename': dataset_util.bytes_feature(tf.compat.as_bytes(image_path.encode('utf-8'))),
        'image/source_id': dataset_util.bytes_feature(tf.compat.as_bytes(image_path.encode('utf-8'))),
        'image/encoded': dataset_util.bytes_feature(encoded_image),
        'image/format': dataset_util.bytes_feature(image_format),
        
        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),
        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),
        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),
        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),
        'image/object/class/text': dataset_util.bytes_list_feature(class_text),
        'image/object/class/label': dataset_util.int64_list_feature(class_id),
        'image/encoded_mask': dataset_util.bytes_feature(encoded_mask)
    }

    example = tf.train.Example(features=tf.train.Features(feature=feature))
    return example
```


### Relevant log output

_No response_"
2576397680,77386,filters and kernel are mentioned as different terms,closed,2024-10-09 16:24:28+00:00,2024-10-31T02:03:12Z,2024-10-31T02:03:07Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/77386,"['type:docs-bug', 'stat:awaiting response', 'type:bug', 'stale', 'comp:keras']","['@ShivamShinde27,\r\nFilters represent the number of output channels after convolution has been performed, while Kernel represents the size of a convolution filter being used to perform convolution on the image.\r\n A filter is a collection of kernels, although we use filter and kernels interchangeably. If you still need the change to happen, please raise the request in the keras-team/keras as this is related to keras. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77386"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77386"">No</a>\n']","### Issue type

Documentation Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.16.1

### Custom code

No

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

on the conv2d document kernels(as argument kernel_size) and filters(as argument filters) are mentioned as two different arguments despite referring to the same parameter in CNN's.Request to change the argument name both to filters or kernels to avoid any misinterpretation. 

### Standalone code to reproduce the issue

```shell
link to the aforementioned document:https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D
```


### Relevant log output

_No response_"
2581595249,77704,"Ho to deal with this Message : TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s): Flex ops: FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack",closed,2024-10-11 14:59:51+00:00,2024-11-08T02:01:02Z,2024-11-08T02:00:59Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/77704,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'TFLiteConverter', '2.17']","['Hi, @nassimus26 \r\n\r\nI apologize for the delayed response, if possible could you please help us with Google colab to reproduce the same bahavior from our end to investigate this issue further from our end ? \r\n\r\nThank you for your cooperation and patience.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', "">   tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\r\n\r\nTry removing that line?\r\n\r\nIn general that is needed for running on CPU, if your model contains TF ops that can't be converted into TF Lite ops.\r\nBut I don't think such ops will run on EdgeTPU.  If you remove that line, either it will now just work, or if not you should get some information from the converter about which ops can't be converted."", ""Hi, @nassimus26\r\nHi, @fergushenderson Thank you for your pointers\r\n\r\nAs far I know that  message indicates that your model contains TensorFlow operations that are not natively supported in TFLite and requires the Flex delegate. Try using a simpler architecture that is known to work with Edge TPU. Use the Edge TPU compatibility checker tool and quantize your model to **INT8**, you'll have to replace `TimeDistributed` and `LSTM` with supported operations mentioned [here](https://coral.ai/docs/edgetpu/models-intro/#supported-operations)\r\n\r\nYou can use Flex Delegate to avoid this message `TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):Flex ops: FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack` but as you mentioned in the issue template after converting the model to TFLite you want to run on Coral Edge TPU so which is not recommended for Edge TPU because the Edge TPU does not currently support the Flex Delegate\r\n\r\nPlease refer this [supported operations on the Edge TPU](https://coral.ai/docs/edgetpu/models-intro/#supported-operations) in that `TimeDistributed` is not supported operations and unidirectional `LSTM` only supported\r\n\r\nIf I have missed something here please let me know. \r\n\r\nThank you for your cooperation and patience.\r\n\r\n\r\n\r\n"", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77704"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77704"">No</a>\n']","### 1. System information

- Linux Ubuntu 16.04
- TensorFlow installation 2.17

I want to convert this model and check if it could run on a Coral Edge TPU

### 2. Code
```
num_classes = 2
base_model = tf.keras.applications.MobileNetV2(
    include_top=False, weights='imagenet', input_tensor=None,
    input_shape=input_shape,
    pooling=None, 
)
for layer in base_model.layers:
    layer.trainable = False
base_model.summary()
cnn = models.Sequential()
cnn.add(base_model)
cnn.add(layers.GlobalAveragePooling2D())
cnn.add(layers.Dropout(0.2))
base_model.trainable = False
model = models.Sequential()
print(full_input_shape)
model.add(layers.TimeDistributed(cnn, input_shape=full_input_shape))
model.add(layers.LSTM(nbr_frame, return_sequences=True))
model.add(layers.TimeDistributed(layers.Dense(nbr_frame, activation='relu')))
model.add(layers.Flatten())
model.add(layers.Dense(164, activation='relu', name=""filter1""))
model.add(layers.Dropout(0.2))
model.add(layers.Dense(24, activation='sigmoid', name=""filter2""))
model.add(layers.Dropout(0.1))
model.add(layers.Dense(num_classes, activation=""sigmoid"", name=""last""))
rms = optimizers.RMSprop()
metrics = [tf.keras.metrics.CategoricalAccuracy('accuracy', dtype=tf.float32)]
loss = tf.keras.losses.CategoricalCrossentropy()
model.compile(
    loss=loss,
    optimizer= rms,
    metrics=metrics
)
#####.....training the model ... ######
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.target_spec.supported_ops = [
  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.
  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.
]
converter.experimental_new_converter = True
tflite_model = converter.convert()
open(""fights.tflite"", ""wb"").write(tflite_model)
```

I am getting this message (I have no idea how to deal with this, I didn't find any relevant documentation about this message):

```
W0000 00:00:1728657905.522324    4234 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.
W0000 00:00:1728657905.522345    4234 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.
2024-10-11 16:45:05.522588: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpwe7b0rla
2024-10-11 16:45:05.543656: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }
2024-10-11 16:45:05.543697: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpwe7b0rla
2024-10-11 16:45:05.843740: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.
2024-10-11 16:45:06.979508: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpwe7b0rla
2024-10-11 16:45:07.522614: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 2000031 microseconds.
2024-10-11 16:45:10.755926: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3463] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):
Flex ops: FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack
Details:
	tf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x10xf32>>>) : {device = """"}
	tf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x10xf32>>>, tensor<i32>, tensor<?x10xf32>) -> (tensor<!tf_type.variant<tensor<?x10xf32>>>) : {device = """", resize_if_index_out_of_bounds = false}
	tf.TensorListStack(tensor<!tf_type.variant<tensor<?x10xf32>>>, tensor<2xi32>) -> (tensor<10x?x10xf32>) : {device = """", num_elements = 10 : i64}
See instructions: https://www.tensorflow.org/lite/guide/ops_select
```"
2582019084,77718,How to install the TfLite after succeed the cmake build ?,closed,2024-10-11 19:06:29+00:00,2024-10-29T02:03:11Z,2024-10-29T02:03:03Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/77718,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', '2.17']","[""Hi, @nassimus26 \r\n\r\nThank you for bringing this issue to our attention, as per [official documentation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/guide/build_cmake.md#build-installable-package) To build an installable package that can be used as a dependency by another CMake project with `find_package(tensorflow-lite CONFIG)`, in your projects `CMakeLists.txt` file and I do not believe these instructions are meant to be used with `cmake --install .`\r\n\r\nRefer to CMake documentation for [find_package](https://cmake.org/cmake/help/latest/command/find_package.html) to learn more about handling and locating packages.\r\n\r\nIf I've missed something here please let me know.\r\n\r\nThank you for your cooperation and patience."", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77718"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77718"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

Latest 2.17

### Custom code

Yes

### OS platform and distribution

Ubuntu 24.04.1 LTS

### Mobile device

_No response_

### Python version

3.9.20

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

After build the Lite project succesffuly with cmake :
```
-- Building for XNNPACK_TARGET_PROCESSOR: x86_64
-- Generating microkernels.cmake
-- 
-- 3.21.9.0
-- Configuring done (7.7s)
-- Generating done (1.5s)
-- Build files have been written to: /home/mac/PycharmProjects/RealTimeFightDetect/tensorflow/tensorflow/lite/build
```
I didn't find any doc about how to install it, so I tried 
`>>>sudo cmake --install .`
I got this error :

```
-- Up-to-date: /usr/local/include/eigen3/unsupported/Eigen/CXX11/src/TensorSymmetry/StaticSymmetry.h
CMake Error at _deps/fft2d-build/cmake_install.cmake:46 (file):
  file INSTALL cannot find
  ""/home/mac/PycharmProjects/RealTimeFightDetect/tensorflow/tensorflow/lite/build/_deps/fft2d-build/libfft2d_fftsg.a"":
  No such file or directory.
Call Stack (most recent call first):
  cmake_install.cmake:62 (include)
```
And before trying to compile the project I also tried to install directly without success with different Python version from 3.9.x to 3.12.x :


```
>> sudo apt-get install python3-tflite-runtime
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
Some packages could not be installed. This may mean that you have
requested an impossible situation or if you are using the unstable
distribution that some required packages have not yet been created
or been moved out of Incoming.
The following information may help to resolve the situation:

The following packages have unmet dependencies:
 python3-tflite-runtime : Depends: python3 (< 3.10) but 3.12.3-0ubuntu2 is to be installed
E: Unable to correct problems, you have held broken packages.
```


### Standalone code to reproduce the issue

```shell
`>>>sudo cmake --install .`
```


### Relevant log output

_No response_"
2583886295,77821,Bug: tf.math.angle returns 0.0 for real NaN input instead of NaN System information,closed,2024-10-13 11:11:38+00:00,2024-10-29T02:03:08Z,2024-10-29T02:03:01Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/77821,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.16']","['Hi **@LilyDong0127** ,\r\nI tried running your code on Colab using TensorFlow v2.17.0 and the nightly version, and I encountered the same issue. Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/d625a888c7d5ecd42a4709216e5e5353/77821_tf-2-17-0-nightly-v.ipynb) provided here for reference.\r\nSome related issues are already being tracked. Please review them as well, as they might be helpful. I am providing the [links](https://github.com/tensorflow/tensorflow/issues/50854) to those issues for your reference.\r\n\r\nThank you!\r\n\r\n\r\n\r\n', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77821"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77821"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.16.1

### Custom code

Yes

### OS platform and distribution

windows

### Mobile device

win32

### Python version

3.9.19

### Bazel version

bazel version

### GCC/compiler version

_No response_

### CUDA/cuDNN version

Not applicable (No GPU support)

### GPU model and memory

No GPU (using CPU)

### Current behavior?

Current Behavior:
When using `tf.math.angle` with a real NaN input, TensorFlow and Keras return `0.0`, while other frameworks such as PyTorch, JAX, and Chainer return `NaN`. Returning `0.0` for NaN is unexpected, as the angle of NaN is undefined and should return NaN.


### Standalone code to reproduce the issue

```shell
import torch
import tensorflow as tf
import jax.numpy as jnp
import numpy as np

# Create a scalar NaN tensor with dtype float32
input_tensor = tf.constant(float('nan'), dtype=tf.float32)

# PyTorch: angle function for real NaN input
def pytorch_angle(x):
    return torch.angle(torch.tensor(x, dtype=torch.float32)).numpy()

# JAX: angle function for real NaN input
def jax_angle(x):
    return jnp.angle(jnp.array(x)).item()

# Chainer: angle function for real NaN input
def chainer_angle(x):
    return np.angle(x)

# TensorFlow: angle function for real NaN input
def tf_angle(x):
    return tf.math.angle(x).numpy()

# Keras: using TensorFlow's angle function for real NaN input
def keras_angle(x):
    return tf.math.angle(x).numpy()

# Testing angle function across frameworks
print(f""PyTorch angle result: {pytorch_angle(float('nan'))}"")
print(f""JAX angle result: {jax_angle(float('nan'))}"")
print(f""Chainer angle result: {chainer_angle(np.array(float('nan')))}"")
print(f""TensorFlow angle result: {tf_angle(input_tensor)}"")
print(f""Keras angle result: {keras_angle(input_tensor)}"")
```


### Relevant log output

```shell
Generated input: nan

PyTorch angle result: nan
JAX angle result: nan
Chainer angle result: nan
TensorFlow angle result: 0.0
Keras angle result: 0.0
```
"
2583939874,77822,Traceback (most recent call last),closed,2024-10-13 12:36:51+00:00,2024-10-30T07:02:35Z,2024-10-29T02:02:59Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/77822,"['stat:awaiting response', 'type:bug', 'stale', '2.17']","['Hi **@rolandweb3** ,\r\nThere are at least 3 possible scenarios:\r\nYou need to install the MSVC 2019 redistributable\r\nYour CPU does not support AVX2 instructions\r\nYour CPU/Python is on 32 bits\r\nThere is a library that is in a different location/not installed on your system that cannot be loaded.\r\n\r\nAlso in order to expedite the trouble-shooting process, could you please provide the following information\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nTensorFlow installed from (source or binary):\r\nInstalled using virtualenv? pip? conda?:\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version:\r\nGPU model and memory:\r\nand the exact sequence of commands / steps that you executed before running into the problem.\r\nhttps://github.com/tensorflow/tensorflow/issues/61887\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77822"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77822"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.17.0

### Custom code

Yes

### OS platform and distribution

Windows 10

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I expect it to run without any problem

### Standalone code to reproduce the issue

```shell
Traceback (most recent call last):
  File ""C:\Users\Rolanddev\AppData\Local\Programs\Python\Python39\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 70, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization 
routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\Users\Rolanddev\Desktop\One.py"", line 24, in <module>
    from tensorflow.keras.models import Sequential
  File ""C:\Users\Rolanddev\AppData\Local\Programs\Python\Python39\lib\site-packages\tensorflow\__init__.py"", line 38, 
in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\Rolanddev\AppData\Local\Programs\Python\Python39\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 85, in <module>
    raise ImportError(
ImportError: Traceback (most recent call last):
  File ""C:\Users\Rolanddev\AppData\Local\Programs\Python\Python39\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 70, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization 
routine failed.


Failed to load the native TensorFlow runtime.
See https://www.tensorflow.org/install/errors for some common causes and solutions.
If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.
```


### Relevant log output

_No response_"
2583961541,77825,Aborted (core dumped) in tf.raw_ops.IRFFT,closed,2024-10-13 13:12:55+00:00,2024-10-29T02:03:03Z,2024-10-29T02:02:58Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/77825,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","['Hi **@LongZE666** ,\r\nI tried running your code on Colab using TensorFlow v2.17.0 and the nightly version. I faced the same issue. And I have provided an alternative solution for this issue, and I hope it will be helpful for you. Please find [gist](https://colab.sandbox.google.com/gist/Venkat6871/f854d589102f4a019bc06c93bfcbbb0f/77825_tf-2-17-0-nightly-v.ipynb) here for reference.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77825"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77825"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

tf2.17.0 tf2.16.1

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When the following code is entered, it will cause abort



### Standalone code to reproduce the issue

```shell
import tensorflow as tf

input_data = tf.constant(1, shape=5, dtype=tf.complex64)

fft_length = tf.constant(0, shape=[1], dtype=tf.int32)

output = tf.raw_ops.IRFFT(
    input=input_data,
    fft_length=fft_length
)
```


### Relevant log output

```shell
2024-10-13 13:12:27.281652: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-10-13 13:12:27.282449: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-10-13 13:12:27.286344: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-10-13 13:12:27.298014: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-10-13 13:12:27.316660: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-10-13 13:12:27.322124: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-10-13 13:12:27.335981: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-10-13 13:12:28.402423: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
DUCC FFT c2r failed:
bazel-out/k8-opt/bin/external/ducc/_virtual_includes/fft/ducc/src/ducc0/fft/fft1d_impl.h: 2948 (static Trpass<Tfs> ducc0::detail_fft::rfftpass<float>::make_pass(size_t, size_t, size_t, const Troots<Tfs> &, bool) [Tfs = float]):

Assertion failure
no zero-sized FFTs

Aborted (core dumped)
```
"
2584873781,77844,Import error with tensorflow 2.17,closed,2024-10-14 06:08:57+00:00,2024-10-29T02:02:59Z,2024-10-29T02:02:56Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/77844,"['stat:awaiting response', 'type:bug', 'stale', '2.17']","['Hi **@the-silent-geek** ,\r\nCould you please check all the compatibility versions and verify if you have imported all the necessary libraries? And In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here.\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77844"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77844"">No</a>\n']","### Issue type

Bug

### TensorFlow version

2.17

### Custom code

Yes

### OS platform and distribution

Windows 11

### Python version

3.9

### Current behavior?


`import tensorflow as tf`
`pip list | findstr tensorflow`
tensorflow                    2.17.0
tensorflow-intel              2.17.0
tensorflow-io-gcs-filesystem  0.31.0

Can anyone explain why am I encountering this error.

### Standalone code to reproduce the issue

![{7CA877A0-8409-496C-A979-8CD1D1C45FE5}](https://github.com/user-attachments/assets/3bca24b4-89af-4df0-883f-28d241fbca31)



### Relevant log output

_No response_"
2587999533,77946,TensorFlow argmin function returns incorrect index when dealing with subnormal float values.,closed,2024-10-15 08:15:27+00:00,2024-11-02T02:00:57Z,2024-11-02T02:00:52Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/77946,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.16']","['@LilyDong0127,\r\nLooks like this is similar to the another issue which was raised for the Argmax.\r\nhttps://github.com/tensorflow/tensorflow/issues/77853\r\n\r\nAnd also calculations performed on the CPU using floating-point numbers smaller than a certain threshold (like 1e-45) are rounded down to zero and subnormal numbers (like 1e-45) are flushed to zeros Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77946"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/77946"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.16.1

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When using the argmin function on an input array containing subnormal float values, TensorFlow incorrectly returns the index of 0.0 as the minimum value, even though a smaller subnormal value (-1.401298464324817e-45) exists in the array. Other deep learning frameworks (e.g., PyTorch, Chainer) correctly return the index of the subnormal value, but TensorFlow (and Keras) consistently return the index of 0.


### Standalone code to reproduce the issue

```shell
import torch
import tensorflow as tf
import numpy as np
from chainer import functions as F
import jax.numpy as jnp
import tensorflow.keras.backend as K

# Input data
input_data = [
    0.0,
    1.1754943508222875e-38,
    -1.401298464324817e-45,
    0.0,
    459367.0
]

# Test PyTorch
def test_pytorch_argmin(input_data):
    tensor = torch.tensor(input_data, dtype=torch.float32)
    result = torch.argmin(tensor).item()
    print(f""PyTorch argmin result: {result}"")
    return result

# Test TensorFlow
def test_tensorflow_argmin(input_data):
    tensor = tf.constant(input_data, dtype=tf.float32)
    result = tf.argmin(tensor).numpy()
    print(f""TensorFlow argmin result: {result}"")
    return result

# Test Keras using backend
def test_keras_argmin(input_data):
    tensor = K.constant(input_data, dtype=tf.float32)
    result = K.argmin(tensor, axis=-1).numpy()
    print(f""Keras argmin result: {result}"")
    return result

# Test Chainer
def test_chainer_argmin(input_data):
    tensor = np.array(input_data, dtype=np.float32)
    result = F.argmin(tensor).data
    print(f""Chainer argmin result: {result}"")
    return result

# Test JAX
def test_jax_argmin(input_data):
    tensor = jnp.array(input_data, dtype=jnp.float32)
    result = jnp.argmin(tensor).item()
    print(f""JAX argmin result: {result}"")
    return result

if __name__ == ""__main__"":
    pytorch_result = test_pytorch_argmin(input_data)
    tensorflow_result = test_tensorflow_argmin(input_data)
    keras_result = test_keras_argmin(input_data)
    chainer_result = test_chainer_argmin(input_data)
    jax_result = test_jax_argmin(input_data)

    print(""\nSummary of results:"")
    print(f""PyTorch argmin: {pytorch_result}"")
    print(f""TensorFlow argmin: {tensorflow_result}"")
    print(f""Keras argmin: {keras_result}"")
    print(f""Chainer argmin: {chainer_result}"")
    print(f""JAX argmin: {jax_result}"")

```
```


### Relevant log output

```shell
Summary of results:
PyTorch argmin: 2
TensorFlow argmin: 0
Keras argmin: 0
Chainer argmin: 2
JAX argmin: 0
```
```
"
2594947603,78111,ResNet model has wrong output shape,closed,2024-10-17 14:40:06+00:00,2024-10-23T10:32:05Z,2024-10-23T10:32:01Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/78111,"['stat:awaiting response', 'type:bug', 'comp:lite', 'TFLiteConverter', '2.17']","['/assign\r\n', 'Hi, @Lorsu \r\n\r\nI apologize for the delayed response, thank you for bringing this issue to our attention if possible could you please help us with exact Google colab notebook which you created with  **ResNet** model to replicate the same behavior from our end ? \r\n\r\nThank you for your cooperation and patience.', ""Hi, @Lorsu \r\n\r\nIt seems like the issue you're facing is because you're using `include_top=False` in the `ResNet50` model which removes the final classification layers. To get the **1000** element output vector we need to include the top layers by setting `include_top=True` so model includes the final classification layers with output 1000 element vector corresponding to the **1000** ImageNet classes.This is useful when you want to use the model for ImageNet classification tasks.\r\nPlease refer this [gist-file](https://colab.sandbox.google.com/gist/gaikwadrahul8/b871f283d9f579b03b6d959ca721b7f7/tflite-issue-78111.ipynb) \r\n\r\nIf I have missed something here please let me know.\r\n\r\nThank you for your cooperation and patience.\r\n"", ""> Hi, @Lorsu\r\n> \r\n> It seems like the issue you're facing is because you're using `include_top=False` in the `ResNet50` model which removes the final classification layers. To get the **1000** element output vector we need to include the top layers by setting `include_top=True` so model includes the final classification layers with output 1000 element vector corresponding to the **1000** ImageNet classes.This is useful when you want to use the model for ImageNet classification tasks. Please refer this [gist-file](https://colab.sandbox.google.com/gist/gaikwadrahul8/b871f283d9f579b03b6d959ca721b7f7/tflite-issue-78111.ipynb)\r\n> \r\n> If I have missed something here please let me know.\r\n> \r\n> Thank you for your cooperation and patience.\r\n\r\nyes, the issue is in the include_top parameter, thank you really much "", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78111"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78111"">No</a>\n']","###  Issue

I applied the [tutorial](https://ai.google.dev/edge/litert/models/post_training_integer_quant) for post-training integer quantization to a ResNet model, but the conversion leads to a model with a wrong output shape of [   1    7    7 2048], instead of a 1000-element vector

### 1. System information

Google Colab, with the default tensorlow 2.17

### 2. Code

the image_array is a numpy array of shape (n, 224, 224, 3) and dtype float32

```
model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

def representative_data_gen():
  for input_value in tf.data.Dataset.from_tensor_slices(image_array).batch(1).take(100):
    yield [input_value]

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_data_gen
# Ensure that if any ops can't be quantized, the converter throws an error
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
# Set the input and output tensors to uint8 (APIs added in r2.3)
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8

tflite_model_quant = converter.convert()

output_details = interpreter.get_output_details()[0]
for key in output_details.keys():
  print(key, output_details[key])
```"
2595681439,78125,Cannot include headers loader.h session.h,closed,2024-10-17 20:30:32+00:00,2024-10-22T06:53:04Z,2024-10-22T06:53:00Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/78125,"['stat:awaiting tensorflower', 'type:bug', 'comp:core', '2.17']","['The issue is related to fact that word ""singals"" occurs in Qt as signal mechanism. Both libraries use signals as a identifier which leads to a namespace collision.\r\n\r\nThe solution is:\r\n\r\n#undef signals\r\n\r\n#include ""tensorflow/cc/saved_model/loader.h""\r\n#include ""tensorflow/core/public/session.h""\r\n\r\n#define signals', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78125"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78125"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.17

### Custom code

No

### OS platform and distribution

Windows 10

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

6.5.0

### GCC/compiler version

Clang 17.0.6

### CUDA/cuDNN version

_No response_

### GPU model and memory

only CPU

### Current behavior?

During adding headers tensorflow/core/public/session.h and tensorflow/cc/saved_model/loader.h there are issues with EventCount.h from eigen libary.

Using MSVC 2022, but same error occurs while using LLVM/MSVC2019 compiler with my C++ application (in Qt 6.5.0)
and same thing happend when i was trying to use TF 2.9.3 GPU compiled with tested version of tools from TF official page .


### Standalone code to reproduce the issue

```shell
#include ""tensorflow/core/public/session.h""
#include ""tensorflow/cc/saved_model/loader.h""

which results in

1) C:\Users\Kuba\tensorflow\bazel-bin\tensorflow\include\Eigen\src\ThreadPool\EventCount.h:130: error: C2059: syntax error: 'public'

2) C:\Users\Kuba\tensorflow\bazel-bin\tensorflow\include\Eigen\src\ThreadPool\EventCount.h:130: error: C2513: 'const unsigned __int64': no variable declaration before '='

3) C:\Users\Kuba\tensorflow\bazel-bin\tensorflow\include\Eigen\src\ThreadPool\EventCount.h:137: error: C2143: syntax error: missing ';' before '{'

4) C:\Users\Kuba\tensorflow\bazel-bin\tensorflow\include\Eigen\src\ThreadPool\EventCount.h:140: error: C2181: illegal else without preceding if statement
```


### Relevant log output

```shell
Below is eventcount.h with indicated which error occur in which place

// This file is part of Eigen, a lightweight C++ template library
// for linear algebra.
//
// Copyright (C) 2016 Dmitry Vyukov <dvyukov@google.com>
//
// This Source Code Form is subject to the terms of the Mozilla
// Public License v. 2.0. If a copy of the MPL was not distributed
// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.

#ifndef EIGEN_CXX11_THREADPOOL_EVENTCOUNT_H
#define EIGEN_CXX11_THREADPOOL_EVENTCOUNT_H

// IWYU pragma: private
#include ""./InternalHeaderCheck.h""

namespace Eigen {

// EventCount allows to wait for arbitrary predicates in non-blocking
// algorithms. Think of condition variable, but wait predicate does not need to
// be protected by a mutex. Usage:
// Waiting thread does:
//
//   if (predicate)
//     return act();
//   EventCount::Waiter& w = waiters[my_index];
//   ec.Prewait(&w);
//   if (predicate) {
//     ec.CancelWait(&w);
//     return act();
//   }
//   ec.CommitWait(&w);
//
// Notifying thread does:
//
//   predicate = true;
//   ec.Notify(true);
//
// Notify is cheap if there are no waiting threads. Prewait/CommitWait are not
// cheap, but they are executed only if the preceding predicate check has
// failed.
//
// Algorithm outline:
// There are two main variables: predicate (managed by user) and state_.
// Operation closely resembles Dekker mutual algorithm:
// https://en.wikipedia.org/wiki/Dekker%27s_algorithm
// Waiting thread sets state_ then checks predicate, Notifying thread sets
// predicate then checks state_. Due to seq_cst fences in between these
// operations it is guaranteed than either waiter will see predicate change
// and won't block, or notifying thread will see state_ change and will unblock
// the waiter, or both. But it can't happen that both threads don't see each
// other changes, which would lead to deadlock.
class EventCount {
 public:
  class Waiter;

  EventCount(MaxSizeVector<Waiter>& waiters) : state_(kStackMask), waiters_(waiters) {
    eigen_plain_assert(waiters.size() < (1 << kWaiterBits) - 1);
  }

  ~EventCount() {
    // Ensure there are no waiters.
    eigen_plain_assert(state_.load() == kStackMask);
  }

  // Prewait prepares for waiting.
  // After calling Prewait, the thread must re-check the wait predicate
  // and then call either CancelWait or CommitWait.
  void Prewait() {
    uint64_t state = state_.load(std::memory_order_relaxed);
    for (;;) {
      CheckState(state);
      uint64_t newstate = state + kWaiterInc;
      CheckState(newstate);
      if (state_.compare_exchange_weak(state, newstate, std::memory_order_seq_cst)) return;
    }
  }

  // CommitWait commits waiting after Prewait.
  void CommitWait(Waiter* w) {
    eigen_plain_assert((w->epoch & ~kEpochMask) == 0);
    w->state = Waiter::kNotSignaled;
    const uint64_t me = (w - &waiters_[0]) | w->epoch;
    uint64_t state = state_.load(std::memory_order_seq_cst);
    for (;;) {
      CheckState(state, true);
      uint64_t newstate;
      if ((state & kSignalMask) != 0) {
        // Consume the signal and return immediately.
        newstate = state - kWaiterInc - kSignalInc;
      } else {
        // Remove this thread from pre-wait counter and add to the waiter stack.
        newstate = ((state & kWaiterMask) - kWaiterInc) | me;
        w->next.store(state & (kStackMask | kEpochMask), std::memory_order_relaxed);
      }
      CheckState(newstate);
      if (state_.compare_exchange_weak(state, newstate, std::memory_order_acq_rel)) {
        if ((state & kSignalMask) == 0) {
          w->epoch += kEpochInc;
          Park(w);
        }
        return;
      }
    }
  }

  // CancelWait cancels effects of the previous Prewait call.
  void CancelWait() {
    uint64_t state = state_.load(std::memory_order_relaxed);
    for (;;) {
      CheckState(state, true);
      uint64_t newstate = state - kWaiterInc;
      // We don't know if the thread was also notified or not,
      // so we should not consume a signal unconditionally.
      // Only if number of waiters is equal to number of signals,
      // we know that the thread was notified and we must take away the signal.
      if (((state & kWaiterMask) >> kWaiterShift) == ((state & kSignalMask) >> kSignalShift)) newstate -= kSignalInc;
      CheckState(newstate);
      if (state_.compare_exchange_weak(state, newstate, std::memory_order_acq_rel)) return;
    }
  }

  // Notify wakes one or all waiting threads.
  // Must be called after changing the associated wait predicate.
  void Notify(bool notifyAll) {
    std::atomic_thread_fence(std::memory_order_seq_cst);
    uint64_t state = state_.load(std::memory_order_acquire);
    for (;;) {
      CheckState(state);
      const uint64_t waiters = (state & kWaiterMask) >> kWaiterShift;
1) 2) 3)      const uint64_t signals = (state & kSignalMask) >> kSignalShift;
      // Easy case: no waiters.
1)      if ((state & kStackMask) == kStackMask && waiters == signals) return;
      uint64_t newstate;
      if (notifyAll) {
        // Empty wait stack and set signal to number of pre-wait threads.
        newstate = (state & kWaiterMask) | (waiters << kSignalShift) | kStackMask;
1) 3)      } else if (signals < waiters) {
        // There is a thread in pre-wait state, unblock it.
        newstate = state + kSignalInc;
4)      } else {
        // Pop a waiter from list and unpark it.
        Waiter* w = &waiters_[state & kStackMask];
        uint64_t next = w->next.load(std::memory_order_relaxed);
        newstate = (state & (kWaiterMask | kSignalMask)) | next;
      }
      CheckState(newstate);
      if (state_.compare_exchange_weak(state, newstate, std::memory_order_acq_rel)) {
 1)       if (!notifyAll && (signals < waiters)) return;  // unblocked pre-wait thread
        if ((state & kStackMask) == kStackMask) return;
        Waiter* w = &waiters_[state & kStackMask];
        if (!notifyAll) w->next.store(kStackMask, std::memory_order_relaxed);
        Unpark(w);
        return;
      }
    }
  }

  class Waiter {
    friend class EventCount;
    // Align to 128 byte boundary to prevent false sharing with other Waiter
    // objects in the same vector.
    EIGEN_ALIGN_TO_BOUNDARY(128) std::atomic<uint64_t> next;
    EIGEN_MUTEX mu;
    EIGEN_CONDVAR cv;
    uint64_t epoch = 0;
    unsigned state = kNotSignaled;
    enum {
      kNotSignaled,
      kWaiting,
      kSignaled,
    };
  };

 private:
  // State_ layout:
  // - low kWaiterBits is a stack of waiters committed wait
  //   (indexes in waiters_ array are used as stack elements,
  //   kStackMask means empty stack).
  // - next kWaiterBits is count of waiters in prewait state.
  // - next kWaiterBits is count of pending signals.
  // - remaining bits are ABA counter for the stack.
  //   (stored in Waiter node and incremented on push).
  static const uint64_t kWaiterBits = 14;
  static const uint64_t kStackMask = (1ull << kWaiterBits) - 1;
  static const uint64_t kWaiterShift = kWaiterBits;
  static const uint64_t kWaiterMask = ((1ull << kWaiterBits) - 1) << kWaiterShift;
  static const uint64_t kWaiterInc = 1ull << kWaiterShift;
  static const uint64_t kSignalShift = 2 * kWaiterBits;
  static const uint64_t kSignalMask = ((1ull << kWaiterBits) - 1) << kSignalShift;
  static const uint64_t kSignalInc = 1ull << kSignalShift;
  static const uint64_t kEpochShift = 3 * kWaiterBits;
  static const uint64_t kEpochBits = 64 - kEpochShift;
  static const uint64_t kEpochMask = ((1ull << kEpochBits) - 1) << kEpochShift;
  static const uint64_t kEpochInc = 1ull << kEpochShift;
  std::atomic<uint64_t> state_;
  MaxSizeVector<Waiter>& waiters_;

  static void CheckState(uint64_t state, bool waiter = false) {
    static_assert(kEpochBits >= 20, ""not enough bits to prevent ABA problem"");
    const uint64_t waiters = (state & kWaiterMask) >> kWaiterShift;
1) 2)    const uint64_t signals = (state & kSignalMask) >> kSignalShift;
    eigen_plain_assert(waiters >= signals);
    eigen_plain_assert(waiters < (1 << kWaiterBits) - 1);
    eigen_plain_assert(!waiter || waiters > 0);
    (void)waiters;
1)    (void)signals;
  }

  void Park(Waiter* w) {
    EIGEN_MUTEX_LOCK lock(w->mu);
    while (w->state != Waiter::kSignaled) {
      w->state = Waiter::kWaiting;
      w->cv.wait(lock);
    }
  }

  void Unpark(Waiter* w) {
    for (Waiter* next; w; w = next) {
      uint64_t wnext = w->next.load(std::memory_order_relaxed) & kStackMask;
      next = wnext == kStackMask ? nullptr : &waiters_[internal::convert_index<size_t>(wnext)];
      unsigned state;
      {
        EIGEN_MUTEX_LOCK lock(w->mu);
        state = w->state;
        w->state = Waiter::kSignaled;
      }
      // Avoid notifying if it wasn't waiting.
      if (state == Waiter::kWaiting) w->cv.notify_one();
    }
  }

  EventCount(const EventCount&) = delete;
  void operator=(const EventCount&) = delete;
};

}  // namespace Eigen

#endif  // EIGEN_CXX11_THREADPOOL_EVENTCOUNT_H
```
"
2595759154,78126,"`tf.keras.metrics.R2Score()`: ValueError: Tensor conversion requested dtype int32 for Tensor with dtype float32: <tf.Tensor: shape=(), dtype=float32, numpy=0.0>",closed,2024-10-17 21:10:22+00:00,2024-10-24T11:32:43Z,2024-10-24T11:32:39Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/78126,"['type:bug', 'comp:keras', 'TF 2.13']","['A simpler code that also gives the same error:\r\n\r\n```\r\nfrom tensorflow import keras\r\nimport numpy as np\r\n\r\nmodel = keras.Sequential()\r\nmodel.add(keras.layers.Dense(10, activation=""relu""))\r\nmodel.add(keras.layers.Dense(1))\r\n\r\nmodel.compile(\r\n    optimizer=""adam"",\r\n    loss=keras.losses.MeanSquaredError(),\r\n    metrics=[keras.metrics.R2Score()]\r\n)\r\n\r\ndata = np.random.random((1000, 5))\r\nlabels = data.sum(axis=1)\r\n\r\nmodel.fit(data, labels, epochs=10)\r\n```\r\nSource: [DataScience Stack Exchange](https://datascience.stackexchange.com/a/129793/159260)', '@A-Infor,\r\nI tried to execute both codes on the latest TensorFlow v2.17 which consists of Keras3.0 and observed that both are executed without any fail/error. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/2af1276474da4681ccee3cada4a2ab2b/untitled2185.ipynb). I request to upgrade to the latest TensorFlow v2.17. Thank you!', 'I tested on TensorFlow 2.15 and noticed that it works fine.\r\nSeems to be a bug with version 2.13 .', ""@A-Infor,\r\n It's unlikely for TF 2.13 version to receive any bug fixes except when we have security patches. There is a high possibility that this was fixed with later TF versions. Perhaps you can use the latest tf version 2.15 & 2.17 where the issue was resolved for your case. Thank you!"", '> Perhaps you can use the latest tf version 2.15 & 2.17 where the issue was resolved for your case. Thank you!\r\n\r\nThe latest version of TensorFlow for Windows 64 on https://anaconda.org/search?q=platform:win-64+tensorflow is 2.13 .\r\nThere is no obvious way to use a newer TensorFlow. (I tested TensorFlow 2.15 on another computer that have Linux)', '> The latest version of TensorFlow for Windows 64 on https://anaconda.org/search?q=platform:win-64+tensorflow is 2.13 . There is no obvious way to use a newer TensorFlow. (I tested TensorFlow 2.15 on another computer that have Linux)\r\n\r\nWrong. Just use `pip` instead of `conda` and you will be able to install TensorFlow 2.17.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78126"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78126"">No</a>\n']","As [also reported on Stack Overflow by another person](https://stackoverflow.com/questions/78056806/using-tf-keras-metrics-r2score-results-in-an-error-in-tensorflow).

### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.13

### Custom code

No

### OS platform and distribution

Windows 10 64-bit

### Mobile device

_No response_

### Python version

3.11.0

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I expected to use `tf.keras.metrics.R2Score()` as easily as `tf.keras.metrics.RootMeanSquaredError()`, but I'm getting this instead:

> ValueError: Tensor conversion requested dtype int32 for Tensor with dtype float32: <tf.Tensor: shape=(), dtype=float32, numpy=0.0>

This happens in the following line:
> history = model.fit(trainDataForPrediction, trainDataTrueValues, epochs=300, batch_size=1, verbose=0)

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

trainDataForPrediction = np.array([[[0.28358589],
  [0.30372512],
  [0.29780091],
  [0.33183642],
  [0.33120391],
  [0.33995099]],

 [[0.66235955],
  [0.35913154],
  [0.44153985],
  [0.32184616],
  [0.36265909],
  [0.3549683 ]],

 [[0.31142234],
  [0.66259034],
  [0.72903083],
  [0.77104302],
  [0.72910771],
  [0.75193211]],

 [[0.90720823],
  [0.72759569],
  [0.62614929],
  [0.69093327],
  [0.73826299],
  [0.72309858]],

 [[0.6095221 ],
  [0.77340943],
  [0.81678509],
  [0.80538922],
  [0.81804642],
  [0.8251804 ]],

 [[0.80261632],
  [0.71335692],
  [0.60358738],
  [0.64392465],
  [0.70798606],
  [0.68685222]],

 [[0.780457  ],
  [0.78226247],
  [0.90243802],
  [0.97144548],
  [0.94602405],
  [0.96125509]],

 [[0.79170093],
  [0.90229303],
  [0.8141366 ],
  [0.80853979],
  [0.78771087],
  [0.77839755]],

 [[0.61180146],
  [0.69044191],
  [0.5812535 ],
  [0.47918308],
  [0.46885173],
  [0.46438816]],

 [[0.62133159],
  [0.46832587],
  [0.45011011],
  [0.43797561],
  [0.46931518],
  [0.49728175]],

 [[0.59755109],
  [0.63108946],
  [0.64450683],
  [0.67581521],
  [0.66612456],
  [0.65878372]],

 [[0.71132382],
  [0.72192407],
  [0.71825596],
  [0.77809111],
  [0.71006228],
  [0.69495688]],

 [[0.4333941 ],
  [0.47057709],
  [0.46120598],
  [0.45281569],
  [0.44260477],
  [0.44248343]],

 [[0.52482055],
  [0.56745374],
  [0.65914372],
  [0.57337102],
  [0.69907015],
  [0.69499166]],

 [[0.51284886],
  [0.33358419],
  [0.31609008],
  [0.23997269],
  [0.08639418],
  [0.08413338]],

 [[0.26429119],
  [0.45916246],
  [0.44680846],
  [0.4449086 ],
  [0.52549847],
  [0.55313779]],

 [[0.4566679 ],
  [0.41502596],
  [0.66814448],
  [0.79515032],
  [0.82469515],
  [0.85223724]],

 [[0.8428317 ],
  [1.        ],
  [0.94682836],
  [0.95609914],
  [0.9859931 ],
  [0.95404273]],

 [[0.89188471],
  [0.92726165],
  [0.86781746],
  [0.8164678 ],
  [0.79838713],
  [0.79180823]],

 [[0.74514082],
  [0.63961743],
  [0.3959561 ],
  [0.65873789],
  [0.66951841],
  [0.69643851]],

 [[0.68831417],
  [0.74602272],
  [0.75794952],
  [0.62336891],
  [0.6014669 ],
  [0.57675219]],

 [[0.29146979],
  [0.41276609],
  [0.60938479],
  [0.7062046 ],
  [0.65504986],
  [0.66181513]],

 [[0.88358238],
  [0.72456903],
  [0.51257023],
  [0.40234096],
  [0.43700235],
  [0.42401991]],

 [[0.3591383 ],
  [0.69884845],
  [0.74231565],
  [0.72416779],
  [0.6708481 ],
  [0.6731879 ]],

 [[0.94124425],
  [0.83152508],
  [0.82366235],
  [0.80077871],
  [0.80614143],
  [0.79487525]],

 [[0.34668558],
  [0.23052622],
  [0.17238472],
  [0.2675286 ],
  [0.26344458],
  [0.28616361]],

 [[0.40986458],
  [0.35779146],
  [0.40335441],
  [0.44973167],
  [0.41253347],
  [0.37845105]],

 [[0.33203832],
  [0.27771177],
  [0.30814096],
  [0.16146156],
  [0.1718526 ],
  [0.18814805]],

 [[0.63741835],
  [0.66444711],
  [0.76911393],
  [0.7553838 ],
  [0.76645967],
  [0.76460272]],

 [[0.33085441],
  [0.44095143],
  [0.35532193],
  [0.43949481],
  [0.46892119],
  [0.4662825 ]],

 [[0.65113037],
  [0.91117417],
  [0.9335289 ],
  [0.89285049],
  [0.89504786],
  [0.91245301]],

 [[0.92886475],
  [0.7068268 ],
  [0.60644207],
  [0.57394975],
  [0.57464331],
  [0.54921686]],

 [[0.23284108],
  [0.22316557],
  [0.20152097],
  [0.45580923],
  [0.45287703],
  [0.45928762]],

 [[0.45123298],
  [0.39450794],
  [0.48112946],
  [0.32824454],
  [0.2944551 ],
  [0.30711642]],

 [[0.66849429],
  [0.6326308 ],
  [0.57193197],
  [0.50133743],
  [0.4672485 ],
  [0.44125429]],

 [[0.3493021 ],
  [0.43485091],
  [0.46408419],
  [0.75744247],
  [0.79000517],
  [0.80664802]],

 [[0.59350822],
  [0.55769807],
  [0.63017208],
  [0.26459647],
  [0.18448017],
  [0.14864757]],

 [[0.2809532 ],
  [0.22152394],
  [0.18470882],
  [0.23680976],
  [0.27114282],
  [0.28851017]],

 [[0.46479513],
  [0.52150761],
  [0.53962938],
  [0.56391452],
  [0.53710149],
  [0.5308821 ]],

 [[0.61977787],
  [0.53154372],
  [0.50561344],
  [0.48908166],
  [0.47152856],
  [0.48861851]],

 [[0.31765691],
  [0.5696298 ],
  [0.68688768],
  [0.611828  ],
  [0.59800787],
  [0.58199944]],

 [[0.59364795],
  [0.44172827],
  [0.31675594],
  [0.35414828],
  [0.36070871],
  [0.39298799]],

 [[0.19718846],
  [0.30401209],
  [0.51566878],
  [0.64076456],
  [0.65299798],
  [0.63290334]],

 [[0.72989215],
  [0.64011724],
  [0.60324933],
  [0.51062346],
  [0.45331722],
  [0.46125121]],

 [[0.549944  ],
  [0.34359706],
  [0.28630835],
  [0.37263408],
  [0.51816687],
  [0.53117809]],

 [[0.7357174 ],
  [0.82513636],
  [0.92903864],
  [0.83082154],
  [0.71830423],
  [0.68545151]]])

trainDataTrueValues = np.array([[0.33370854, 0.32896128, 0.338919  , 0.370148  , 0.41977692, 0.5521488 ],
 [0.365207  , 0.37061936, 0.37484066, 0.3478887 , 0.32885199, 0.30680109],
 [0.75690644, 0.76740645, 0.78093759, 0.80580592, 0.83506068, 0.9300879 ],
 [0.72214934, 0.71222063, 0.70721571, 0.72001991, 0.86853872, 0.78016653],
 [0.81758234, 0.81016924, 0.80366251, 0.81069042, 0.60300473, 0.67470109],
 [0.67958566, 0.68243936, 0.69163868, 0.74519473, 0.68240246, 0.657002  ],
 [0.96831789, 0.96380285, 0.967898  , 0.92530772, 0.9249375 , 0.93694259],
 [0.76195766, 0.74630911, 0.7047356 , 0.69865743, 0.64689554, 0.53129387],
 [0.47209114, 0.48193162, 0.50943131, 0.52597968, 0.65194851, 0.79167671],
 [0.52327628, 0.56134685, 0.60585979, 0.65919966, 0.59725093, 0.57757021],
 [0.65063778, 0.63845143, 0.6223349 , 0.59585136, 0.62452674, 0.66366742],
 [0.66665364, 0.644637  , 0.61860204, 0.60778969, 0.54817006, 0.53309155],
 [0.44629018, 0.43732508, 0.45198314, 0.40540066, 0.45934156, 0.44508884],
 [0.68928946, 0.69242095, 0.66407551, 0.65466724, 0.63588645, 0.62255665],
 [0.07655137, 0.07586849, 0.07615533, 0.09743152, 0.0912761 , 0.16081511],
 [0.57516233, 0.5752103 , 0.58274857, 0.60408212, 0.53677125, 0.38215918],
 [0.87645224, 0.89860724, 0.91237928, 0.90458273, 0.89167839, 0.86169194],
 [0.93496343, 0.91752935, 0.91871312, 0.93298075, 0.90635008, 0.93339182],
 [0.78620334, 0.77966131, 0.76595499, 0.80123668, 0.72281454, 0.67729982],
 [0.71433298, 0.73036564, 0.74620482, 0.71141186, 0.80361011, 0.84697337],
 [0.54462913, 0.5222716 , 0.51101144, 0.52252069, 0.42480727, 0.26657974],
 [0.6645752 , 0.66903111, 0.66718311, 0.66090196, 0.68263579, 0.85079916],
 [0.41923131, 0.42102118, 0.44039002, 0.48348755, 0.48306699, 0.36817135],
 [0.68148362, 0.67589061, 0.66555973, 0.69096076, 0.7228609 , 0.78776612],
 [0.7854791 , 0.78995575, 0.79338535, 0.72868889, 0.65642879, 0.55843462],
 [0.28512477, 0.27293793, 0.25881146, 0.26540709, 0.22930567, 0.33778585],
 [0.37266819, 0.37910424, 0.38644206, 0.36064735, 0.43564156, 0.35146986],
 [0.22257434, 0.23625543, 0.24991159, 0.28900138, 0.30654842, 0.42902441],
 [0.7425433 , 0.73684753, 0.73618661, 0.70964112, 0.67040764, 0.62850268],
 [0.45068071, 0.43816298, 0.4342914 , 0.45724268, 0.43607784, 0.55865807],
 [0.92236959, 0.93100085, 0.92969332, 0.93081777, 0.96367614, 0.89586521],
 [0.5410671 , 0.52699706, 0.52766478, 0.51691315, 0.43398716, 0.33637598],
 [0.46335955, 0.46776761, 0.46408167, 0.44867432, 0.43701596, 0.51659065],
 [0.30417175, 0.30733531, 0.30366558, 0.29330711, 0.36359768, 0.38749372],
 [0.42664812, 0.42056716, 0.43086576, 0.40887337, 0.42715668, 0.57628272],
 [0.82901749, 0.83238729, 0.82457459, 0.84872239, 0.79996528, 0.62709093],
 [0.12056511, 0.10651576, 0.10280307, 0.07995919, 0.07564526, 0.21194409],
 [0.30114611, 0.31115646, 0.31270446, 0.33757487, 0.40753736, 0.43746691],
 [0.52919291, 0.52264534, 0.51790728, 0.51318749, 0.44302725, 0.40943982],
 [0.48224635, 0.48409421, 0.48324061, 0.47385317, 0.55736301, 0.52762245],
 [0.57722016, 0.57718821, 0.5700168 , 0.59701639, 0.50802179, 0.44843445],
 [0.39456566, 0.38874   , 0.41657823, 0.39331915, 0.41278882, 0.39932694],
 [0.64290878, 0.65892973, 0.65161573, 0.61453231, 0.68637572, 0.70285098],
 [0.45496414, 0.43906435, 0.42968136, 0.4435593 , 0.38087753, 0.53327326],
 [0.53351884, 0.54998068, 0.56712283, 0.62159043, 0.74422592, 0.76377224],
 [0.67259377, 0.65934765, 0.64005251, 0.56716475, 0.41110739, 0.3281523 ]])

def createNeuralNetwork(hidden_units=9, dense_units=6, input_shape=(12-6,1), activation=['relu','sigmoid']):
    model = tf.keras.Sequential()
    model.add(tf.keras.layers.LSTM(hidden_units,input_shape=input_shape,activation=activation[0]))
    model.add(tf.keras.layers.Dense(units=dense_units,activation=activation[1]))
    model.add(tf.keras.layers.Dense(units=dense_units,activation=activation[1]))
    model.add(tf.keras.layers.Dense(units=dense_units,activation=activation[1]))
    model.compile(loss='mse', metrics=['mae', tf.keras.metrics.RootMeanSquaredError(), 'mse', tf.keras.metrics.R2Score()], optimizer='adam')
    return model

model   = createNeuralNetwork()
history = model.fit(trainDataForPrediction, trainDataTrueValues, epochs=300, batch_size=1, verbose=0)
```


### Relevant log output
```
Traceback (most recent call last):

  File C:\ProgramData\miniconda3\envs\secas3\Lib\site-packages\spyder_kernels\customize\utils.py:209 in exec_encapsulate_locals
    exec_fun(compile(code_ast, filename, ""exec""), globals)

  File e:\poscomp\python\redeneuralsecas\neuralnetwork\untitled3.py:383
    history = model.fit(trainDataForPrediction, trainDataTrueValues, epochs=300, batch_size=1, verbose=0)

  File C:\ProgramData\miniconda3\envs\secas3\Lib\site-packages\keras\src\utils\traceback_utils.py:70 in error_handler
    raise e.with_traceback(filtered_tb) from None

  File C:\ProgramData\miniconda3\envs\secas3\Lib\site-packages\tensorflow\python\framework\ops.py:965 in __tf_tensor__
    raise ValueError(

ValueError: Tensor conversion requested dtype int32 for Tensor with dtype float32: <tf.Tensor: shape=(), dtype=float32, numpy=0.0>
```"
2600171903,78396,android TensorFlow-Lite yolo11-obb run error,closed,2024-10-20 08:17:07+00:00,2025-01-27T22:12:48Z,2025-01-27T22:12:44Z,arfaian,,https://github.com/tensorflow/tensorflow/issues/78396,"['stat:awaiting tensorflower', 'type:bug', 'comp:lite']","['Hi, @sungerk \r\n\r\nThank you for bringing this issue to our attention, if possible could you please help us with minimum code example with your Github repo along with complete steps to replicate the same behavior from our end to investigate this issue further ?\r\n\r\nThank you for your cooperation and patience.', '@gaikwadrahul8 \r\n\r\n[YOLOv8-TfLite-Object-Detector.zip](https://github.com/user-attachments/files/17460899/YOLOv8-TfLite-Object-Detector.zip)\r\n\r\n\r\nthis is my source code ,you can edit the  Constants.MODEL_PATH to choose mode\r\n\r\n\r\nthis is my covert model code\r\n```\r\nimport os\r\nfrom ultralytics import YOLO\r\n\r\nmodel = YOLO(\'yolov8n-obb.pt\')  \r\n\r\nmodel.export(format=""tflite"", imgsz=(640, 640),\r\n             optimize=True,\r\n             int8=True)\r\n```', '>         options.setUseNNAPI(true);\r\n\r\nNNAPI is [deprecated now](https://developer.android.com/ndk/guides/neuralnetworks/migration-guide), so I recommend removing that line.\r\n', ""@fergushenderson \r\n\r\nI have tried commenting out this line of code. It's not useful, the key error is that \r\n\r\nGpuDelegate delegate=new GpuDelegate (compactList. getBestOptionsForThisDevice());\r\noptions.addDelegate(delegate);\r\n\ufeff\r\n.If the model converted from YOLOV8 does not generate errors, the model converted from YOLO11 will generate errors after loading the model for a while without inference"", ""Hi, @sungerk \r\n\r\nI apologize for the delayed response, I was trying to replicate the similar behavior with your provided source code with `yolo11_obb.tflite` model and i'm getting below runtime error for reference I've added error log below \r\n\r\n**Here is runtime error log for reference :**\r\n\r\n```\r\n2024-10-24 17:33:24.023 29019-29057 libc                                                         A  Fatal signal 6 (SIGABRT), code -1 (SI_QUEUE) in tid 29057 (bt_stack_manage), pid 29019 (droid.bluetooth)\r\n2024-10-24 17:33:24.712 31578-31578 DEBUG                                                        A        #04 pc 0000000000448860  /apex/com.android.btservices/lib64/libbluetooth_jni.so (void bluetooth::log::fatal<unsigned char>(fmt::v10::basic_format_string<char, fmt::v10::type_identity<unsigned char>::type>, unsigned char&&, bluetooth::log_internal::source_location)+76) (BuildId: d30e2e8307dbbe890368d1d0b791ed4b)\r\n2024-10-24 17:41:23.632 31730-31748 libc                                                         A  Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0xc in tid 31748 (pool-2-thread-1), pid 31730 (an.yolov8tflite)\r\n```\r\nIf I have missed something here to reproduce the exact behavior as you mentioned in the issue template from my end please do let me know with exact steps which I'll try from my end again\r\n\r\nThank you for your cooperation and patience\r\n"", ""@gaikwadrahul8  Sorry for the late reply. There are no other steps. What's strange is why you don't have the error libtensorflowlite_jni.so (offset 0x75c000)?\r\n\r\n"", ""Hi, @sungerk \r\nI apologize for the delayed response, even I'm not sure why I'm not getting the error related to **libtensorflowlite_jni.so (offset 0x75c000)** at the moment\r\n\r\nHi, @pkgoogle\r\nPlease take look into this issue. Thank you"", 'Hi @sungerk, I loaded your project and changed `const val MODEL_PATH = ""yolov8_obb.tflite""` to `const val MODEL_PATH = ""yolo11_obb.tflite""`, I was able to run it on emulator successfully.\r\n\r\nHere\'s my AVD settings. Have I missed something in reproducing this?\r\n\r\n![image](https://github.com/user-attachments/assets/3e8b007c-3716-4d6b-8bf1-244913ffa816)\r\n', '@pkgoogle  without ,but i use my mobile phone Redmi Note12 5G ', 'I am unable to reproduce on emulator as shown above, @arfaian, can you please take a look? Thanks.', 'I have same error on Xiaomi Redmi K20 Pro.\nyolov8 is ok. yolo11(test on yolo11n,yolo11s) failed with gpu,but it can run on cpu.\n', 'Thanks for the additional information, we will be moving this issue to [LiteRT](https://github.com/google-ai-edge/litert). Please follow progress on that repo.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78396"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78396"">No</a>\n']","**System information**
- OS Platform and Distribution (e.g., Android 14):
  implementation(""com.google.ai.edge.litert:litert-support:1.0.1"")
  implementation(""com.google.ai.edge.litert:litert-gpu:1.0.1"")
  implementation(""com.google.ai.edge.litert:litert-gpu-api:1.0.1"")
  implementation(""com.google.ai.edge.litert:litert-metadata:1.0.1"")


[
[best_int8.tflite.zip](https://github.com/user-attachments/files/17449551/best_int8.tflite.zip)
](url)
YOLO8n-obb.pt can run normally when converted to tflite model, but YOLO11n-obb.pt reports an error when converted to tflite model



source code

```
 public void init(Context context, String modelPath, List<String> labels) {
        this.labels = labels;
        CompatibilityList compatList = new CompatibilityList();
        Interpreter.Options options = new Interpreter.Options();
        options.setUseNNAPI(true);
        if (compatList.isDelegateSupportedOnThisDevice()) {
            GpuDelegate delegate = new GpuDelegate(compatList.getBestOptionsForThisDevice());
            options.addDelegate(delegate);
        } else {
            options.setNumThreads(4);
        }
        try {
            MappedByteBuffer mappedByteBuffer = FileUtil.loadMappedFile(context, modelPath);
            this.interpreter = new Interpreter(mappedByteBuffer, options);
            initializeTensorShapes();
        } catch (Exception e) {
            Log.e(""DetectorObb"", ""Error initializing TensorFlow Lite interpreter"", e);
            throw new RuntimeException(e);
        }
    }

```

```
If not calling 
GpuDelegate delegate=new GpuDelegate (compactList. getBestOptionsForThisDevice());
options.addDelegate(delegate); 

This code will not generate any errors



2024-10-20 16:00:34.037 13564-18621 libc                    com.example.opencv                   I  handling signal: 11
2024-10-20 16:00:34.037 13564-18621 libc                    com.example.opencv                   A  Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x18 in tid 18621 (pool-2-thread-1), pid 13564 (.example.opencv)
2024-10-20 16:00:34.037 13564-18621 libc                    com.example.opencv                   I  debuggerd_dispatch_pseudothread start. crashing tid: 18621
2024-10-20 16:00:34.048 13564-18621 libc                    com.example.opencv                   I  crash_dump pid: 18733
2024-10-20 16:00:34.377 18734-18734 DEBUG                   pid-18734                            A  Cmdline: com.example.opencv
2024-10-20 16:00:34.377 18734-18734 DEBUG                   pid-18734                            A  pid: 13564, tid: 18621, name: pool-2-thread-1  >>> com.example.opencv <<<
2024-10-20 16:00:34.377 18734-18734 DEBUG                   pid-18734                            A        #17 pc 00000000001650ac  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_gpu_jni.so (offset 0x56c000) (BuildId: 85ee85b3b999e40f77f5ec31b04e320c)
2024-10-20 16:00:34.377 18734-18734 DEBUG                   pid-18734                            A        #18 pc 0000000000164fe0  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_gpu_jni.so (offset 0x56c000) (BuildId: 85ee85b3b999e40f77f5ec31b04e320c)
2024-10-20 16:00:34.377 18734-18734 DEBUG                   pid-18734                            A        #19 pc 00000000001607e8  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_gpu_jni.so (offset 0x56c000) (BuildId: 85ee85b3b999e40f77f5ec31b04e320c)
2024-10-20 16:00:34.377 18734-18734 DEBUG                   pid-18734                            A        #20 pc 000000000010f80c  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_gpu_jni.so (offset 0x56c000) (BuildId: 85ee85b3b999e40f77f5ec31b04e320c)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #21 pc 0000000000105fe4  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_gpu_jni.so (offset 0x56c000) (BuildId: 85ee85b3b999e40f77f5ec31b04e320c)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #22 pc 0000000000105a4c  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_gpu_jni.so (offset 0x56c000) (BuildId: 85ee85b3b999e40f77f5ec31b04e320c)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #23 pc 00000000001057d8  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_gpu_jni.so (offset 0x56c000) (BuildId: 85ee85b3b999e40f77f5ec31b04e320c)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #24 pc 00000000000ffdf4  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_gpu_jni.so (offset 0x56c000) (BuildId: 85ee85b3b999e40f77f5ec31b04e320c)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #25 pc 00000000000b6cd4  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_gpu_jni.so (offset 0x56c000) (BuildId: 85ee85b3b999e40f77f5ec31b04e320c)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #26 pc 00000000000b6748  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_gpu_jni.so (offset 0x56c000) (BuildId: 85ee85b3b999e40f77f5ec31b04e320c)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #27 pc 00000000000b7748  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_gpu_jni.so (offset 0x56c000) (BuildId: 85ee85b3b999e40f77f5ec31b04e320c)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #28 pc 0000000000320f64  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_jni.so (offset 0x75c000) (BuildId: 850a925e891f910bae3c83095332764b)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #29 pc 0000000000320908  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_jni.so (offset 0x75c000) (BuildId: 850a925e891f910bae3c83095332764b)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #30 pc 0000000000320524  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_jni.so (offset 0x75c000) (BuildId: 850a925e891f910bae3c83095332764b)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #31 pc 00000000000b3174  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_gpu_jni.so (offset 0x56c000) (BuildId: 85ee85b3b999e40f77f5ec31b04e320c)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #32 pc 0000000000325400  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_jni.so (offset 0x75c000) (BuildId: 850a925e891f910bae3c83095332764b)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #33 pc 00000000003259a4  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_jni.so (offset 0x75c000) (BuildId: 850a925e891f910bae3c83095332764b)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #34 pc 00000000003189e0  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_jni.so (offset 0x75c000) (BuildId: 850a925e891f910bae3c83095332764b)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #35 pc 000000000031bcac  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_jni.so (offset 0x75c000) (BuildId: 850a925e891f910bae3c83095332764b)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #36 pc 000000000031c1c8  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_jni.so (offset 0x75c000) (BuildId: 850a925e891f910bae3c83095332764b)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #37 pc 0000000000084f80  /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!libtensorflowlite_jni.so (offset 0x75c000) (Java_org_tensorflow_lite_NativeInterpreterWrapper_createInterpreter+692) (BuildId: 850a925e891f910bae3c83095332764b)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #44 pc 000000000009c134  [anon:dalvik-classes6.dex extracted in memory from /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!classes6.dex] (org.tensorflow.lite.NativeInterpreterWrapper.init+0)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #50 pc 000000000009be34  [anon:dalvik-classes6.dex extracted in memory from /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!classes6.dex] (org.tensorflow.lite.NativeInterpreterWrapper.<init>+0)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #56 pc 000000000009b7ec  [anon:dalvik-classes6.dex extracted in memory from /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!classes6.dex] (org.tensorflow.lite.NativeInterpreterWrapperExperimental.<init>+0)
2024-10-20 16:00:34.378 18734-18734 DEBUG                   pid-18734                            A        #62 pc 000000000009b618  [anon:dalvik-classes6.dex extracted in memory from /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!classes6.dex] (org.tensorflow.lite.Interpreter.<init>+0)
2024-10-20 16:00:34.379 18734-18734 DEBUG                   pid-18734                            A        #68 pc 000000000000152c  /data/data/com.example.opencv/code_cache/.overlay/base.apk/classes2.dex (com.example.tflite.DetectorObb.init+0)
2024-10-20 16:00:34.379 18734-18734 DEBUG                   pid-18734                            A        #74 pc 00000000000019cc  [anon:dalvik-classes4.dex extracted in memory from /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!classes4.dex] (com.example.opencv.CameraTestActivity.lambda$onCreate$0$com-example-opencv-CameraTestActivity+0)
2024-10-20 16:00:34.379 18734-18734 DEBUG                   pid-18734                            A        #80 pc 00000000000014c0  [anon:dalvik-classes4.dex extracted in memory from /data/app/~~0cf_c_6kX4_zxIPTT_wnqQ==/com.example.opencv-kkHJ40uyAxIPy0dkRtusBQ==/base.apk!classes4.dex] (com.example.opencv.CameraTestActivity$$ExternalSyntheticLambda3.run+0)

```




"
2603779268,78466,ModuleNotFoundError: No module named 'tensorflow.python.client',closed,2024-10-21 22:18:51+00:00,2024-11-09T01:58:30Z,2024-11-09T01:58:27Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/78466,"['stat:awaiting response', 'type:bug', 'stale', 'TF 2.15']","['Hi **@metehanozdeniz** ,\r\nApologies for the delay. Could you please provide the model you are using? It would be helpful to replicate the issue.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78466"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78466"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.15.0

### Custom code

No

### OS platform and distribution

Linux Ubuntu 24.04.1 LTS

### Mobile device

_No response_

### Python version

3.10.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.7/12.0.140

### GPU model and memory

RTX 3050 4 GB

### Current behavior?

Whenever I try to convert onnx model to tensorflow I get this error.

~~~shell
$ onnx-tf convert -i yolov7.onnx -o tensorflow-model/
~~~

output:

~~~
Traceback (most recent call last):
  File ""/home/metehan/miniconda3/envs/yolov7/bin/onnx-tf"", line 5, in <module>
    from onnx_tf.cli import main
  File ""/home/metehan/miniconda3/envs/yolov7/lib/python3.10/site-packages/onnx_tf/__init__.py"", line 1, in <module>
    from . import backend
  File ""/home/metehan/miniconda3/envs/yolov7/lib/python3.10/site-packages/onnx_tf/backend.py"", line 25, in <module>
    from onnx_tf.common import data_type
  File ""/home/metehan/miniconda3/envs/yolov7/lib/python3.10/site-packages/onnx_tf/common/__init__.py"", line 14, in <module>
    from tensorflow.python.client import device_lib
ModuleNotFoundError: No module named 'tensorflow.python.client'
~~~

### Standalone code to reproduce the issue

```python
import onnx
from onnx_tf.backend import prepare

onnx_model = onnx.load(""yolov7-tinny.onnx"")
tf_rep = prepare(onnx_model)
tf_rep.export_graph(""tensorflow-model.pb"")
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""/home/metehan/miniconda3/envs/yolov7/bin/onnx-tf"", line 5, in <module>
    from onnx_tf.cli import main
  File ""/home/metehan/miniconda3/envs/yolov7/lib/python3.10/site-packages/onnx_tf/__init__.py"", line 1, in <module>
    from . import backend
  File ""/home/metehan/miniconda3/envs/yolov7/lib/python3.10/site-packages/onnx_tf/backend.py"", line 25, in <module>
    from onnx_tf.common import data_type
  File ""/home/metehan/miniconda3/envs/yolov7/lib/python3.10/site-packages/onnx_tf/common/__init__.py"", line 14, in <module>
    from tensorflow.python.client import device_lib
ModuleNotFoundError: No module named 'tensorflow.python.client'
```
"
2604113765,78475,"What does the tensor ""transformer_layer_0/BroadcastTo"" do, and why is it quantized to INT32?",closed,2024-10-22 03:18:29+00:00,2024-10-28T03:01:35Z,2024-10-28T03:01:33Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/78475,"['stat:awaiting response', 'type:bug', 'comp:lite', 'TFLiteConverter', 'TF 2.12']","['For documentation on the semantics of the BroadcastTo and ExpandDims operations, see the following:\r\n\r\n- https://www.tensorflow.org/api_docs/python/tf/broadcast_to\r\n\r\n- https://www.tensorflow.org/api_docs/python/tf/expand_dims', '@fergushenderson Thank you. I already know the operations, but I am asking why they have trainable parameters and why they are quantized to a higher bit width (int32 instead of int8).', ""Hi, @i3abghany\r\n\r\nAs far I know `BroadcastTo` and `ExpandDims` tensors operations are used in the attention mechanism of transformers specifically to create attention masks and handle batched inputs, Those are not trainable parameters but necessary runtime tensors saves memory compared to storing separate masks for each batch and attention head\r\n\r\nAs per my understanding the **INT32** quantization is necessary for numerical stability in attention computations (Q * K multiplications) which is needed for accumulating products across sequence dimension which preserves precision for mask values and attention weights, query and key are typically **INT8** after quantization ( INT8 values range (127 to -128) when multiplied together which exceeds **INT8** range (-128 to 127) to avoid overflow in cumulative operations may be using **INT32** if I'm not wrong\r\n\r\nThis behavior will depend upon which quantization technique you apply on the model for more details please refer this [official documentation](https://ai.google.dev/edge/litert/models/model_optimization)\r\n\r\nIf I have missed something here please let me know.\r\n\r\nThank you for your cooperation and patience."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78475"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78475"">No</a>\n']","### 1. System information

- Linux Ubuntu 22.04
- TensorFlow 2.12 installed via pip

### 2. Code

#### Option A: Reference colab notebooks

1)  Reference [TensorFlow Model Colab](https://colab.research.google.com/github/tensorflow/codelabs/blob/main/KerasNLP/io2023_workshop.ipynb): The KerasNLP workshop from IO2023

The link to the model I produced using the notebook is here: https://drive.google.com/file/d/1nSABgkHysrwkAn8K3H45Eqq646iNZOBp/view?usp=sharing

### Other info

I follow the IO 2023 workshop notebook above to use KerasNLP to produce a quantized GPT2 in the tflite format.

I then visualize the tflite model using `tensorflow/lite/tools/visualize.py`.

Most of the parameters are quantized to INT8, which is expected. I am confused about two things regarding the following tensors: `transformer_layer_0/BroadcastTo`, `transformer_layer_0/BroadcastTo1`, `transformer_layer_0/cached_multi_head_attention/ExpandDims`, (... for each ""transformer_layer"").

My first question is: What does a broadcast/ExpandDims ""tensor"" store? It seems to me that those are not trainable operations (e.g. doing broadcasting), so why would the tensors have a huge shape [1, 100, 100] (i.e. 10,000 elements)?

My second question is: Why are those tensors quantized to a higher precision (INT32 vs INT8 like other params)?

I really appreciate any help you can provide."
2604745499,78485,Failed to load the native TensorFlow runtime.,closed,2024-10-22 08:53:01+00:00,2024-11-08T02:00:59Z,2024-11-08T02:00:55Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/78485,"['stat:awaiting response', 'type:bug', 'stale', '2.17']","['Hi **@philipakomolafe** ,\r\nThere are at least 3 possible scenarios:\r\nYou need to install the MSVC 2019 redistributable\r\nYour CPU does not support AVX2 instructions\r\nYour CPU/Python is on 32 bits\r\nThere is a library that is in a different location/not installed on your system that cannot be loaded.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/61887\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78485"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78485"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.17

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

3.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

My custom classifier isn't running.

Expectation:
Wanted to run a custom classifier 

### Standalone code to reproduce the issue

```shell
Traceback (most recent call last):
File ""C:\Users\user\AppData\Local\Programs\Python\Python312\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 70, in
from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
File ""C:\Users\user\fer-project\src\train.py"", line 3, in
from model import create_cnn_model
File ""C:\Users\user\fer-project\src\model.py"", line 3, in
import tensorflow as tf
File ""C:\Users\user\AppData\Local\Programs\Python\Python312\Lib\site-packages\tensorflow_init_.py"", line 38, in
from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow # pylint: disable=unused-import
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
File ""C:\Users\user\AppData\Local\Programs\Python\Python312\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 85, in
raise ImportError(
ImportError: Traceback (most recent call last):
File ""C:\Users\user\AppData\Local\Programs\Python\Python312\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 70, in
from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.

Failed to load the native TensorFlow runtime.
```


### Relevant log output

_No response_"
2605125733,78508,OOM when running `tf.raw_ops.DenseBincount`,closed,2024-10-22 11:10:31+00:00,2024-11-11T02:01:46Z,2024-11-11T02:01:42Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/78508,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","['Hey, I have run the colab notebook. I came up with the solution that we can reduce the size value. This value should be near about 1000 so it could be managable.\r\n\r\nI like to fix the bug. ', '@LongZE666,\r\nI request you to take a look at this https://github.com/tensorflow/tensorflow/issues/65634 where a similar issue has been proposed and it is still open. Also I request to follow the similar issue which has been proposed to have the updates on the similar issue. Thank you!\r\n', '@tilakrayal Thank you very much for your reply, I will take a look', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78508"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78508"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf2.17.0 tf2.16.1

### Custom code

Yes

### OS platform and distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

All memory will be used up when running the following code

### Standalone code to reproduce the issue

```shell
https://colab.research.google.com/drive/1-me1CkT6-kEV9vhCsFRbygkVRNApaSM3?usp=sharing
```


### Relevant log output

```shell
Timestamp,Level,Message
""Oct 22, 2024, 7:05:36 PM"",WARNING,WARNING:root:kernel 82160fbc-3b27-42da-ad82-176fab1b542f restarted
""Oct 22, 2024, 7:05:36 PM"",INFO,""KernelRestarter: restarting kernel (1/5), keep random ports""
""Oct 22, 2024, 7:05:15 PM"",WARNING,2024-10-22 11:05:15.583047: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 10007999174112 exceeds 10% of free system memory.
""Oct 22, 2024, 7:05:12 PM"",WARNING,2024-10-22 11:05:12.027196: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
```
"
2609091053,78610,Accuracy is lost after save_weights/load_weights,closed,2024-10-23 15:51:00+00:00,2024-12-04T02:08:34Z,2024-12-04T02:08:31Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/78610,"['stat:awaiting response', 'type:bug', 'stale', 'TF 2.16']","['Hi **@Pandaaaa906** ,\r\nApologies for the delay. I tried running your code on Colab using TensorFlow 2.17.0 with GPU and faced the same issue. Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/6c8a8d3330291f01f3f462f033afa5e0/78610_tf_2-17-gpu-v.ipynb) here for reference. We may need to look deeper into this issue, and I will update you once we gain more clarity.\r\nThank you!', ""@Venkat6871 if i call it using dummy random data before load_weights, it will be ok. not sure it's meant to be or wht, should mention in document."", 'Hi **@Pandaaaa906** ,\r\nApologies for the delay, and thank you for your patience. Please post this issue on the [keras-team/keras repo.](https://github.com/keras-team/keras/issues)repository, as it seems to be more related to Keras.\r\n\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78610"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78610"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.16.1

### Custom code

Yes

### OS platform and distribution

WSL Ubuntu 22.04

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

8.9

### GPU model and memory

RTX 4060 TI

### Current behavior?

1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 354ms/step - accuracy: 0.5000 - loss: 1.1560
[1.1560312509536743, 0.5]
Epoch 1/10
1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 596ms/step - accuracy: 0.5000 - loss: 1.1560
Epoch 2/10
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 0.5000 - loss: 14.5018
Epoch 3/10
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 30ms/step - accuracy: 0.5000 - loss: 9.9714
Epoch 4/10
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 31ms/step - accuracy: 0.7500 - loss: 1.3363
Epoch 5/10
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 1.0000 - loss: 8.9407e-08
Epoch 6/10
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 29ms/step - accuracy: 1.0000 - loss: 4.7684e-07
Epoch 7/10
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 31ms/step - accuracy: 0.7500 - loss: 0.2545
Epoch 8/10
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.7500 - loss: 0.8729
Epoch 9/10
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 1.0000 - loss: 9.1682e-04
Epoch 10/10
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 1.0000 - loss: 2.6822e-07
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 1.0000 - loss: 0.0000e+00
[0.0, 1.0]
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 335ms/step - accuracy: 0.2500 - loss: 0.8475  # this should be acc 1.0 loss 0
[0.847506046295166, 0.25]


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

class CusModel(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.dense = tf.keras.layers.Dense(units=2, activation='softmax', name='output')

    def call(self, x):
        return self.dense(x)

dummy_data_x = tf.convert_to_tensor([[0, 0],
                [1, 0],
                [0, 1],
                [1, 1]])
dummy_data_y = tf.convert_to_tensor([0, 1, 0, 1])

model = CusModel()
model.compile(optimizer=tf.keras.optimizers.Adam(10.0),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
print(model.evaluate(x=dummy_data_x, y=dummy_data_y))
model.fit(x=dummy_data_x, y=dummy_data_y, epochs=10)
print(model.evaluate(x=dummy_data_x, y=dummy_data_y))
model.save_weights('test_model.weights.h5')

model = CusModel()
model.load_weights('test_model.weights.h5')
model.compile(optimizer=tf.keras.optimizers.Adam(10.0),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
print(model.evaluate(x=dummy_data_x, y=dummy_data_y))
```


### Relevant log output

_No response_"
2609737782,78621,Calling .batch() on a Dataset alters the input shape and leads to EfficientNet aborting training,closed,2024-10-23 20:13:20+00:00,2024-10-24T06:46:12Z,2024-10-24T06:46:09Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/78621,['type:bug'],"['Calling .batch() is unnecessary if you already declare batch size when first declaring the model', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78621"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78621"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.17

### Custom code

Yes

### OS platform and distribution

ArchLinux

### Mobile device

_No response_

### Python version

3.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

GeForce RTX 4080

### Current behavior?

Calling .batch() on a dataset as presented in the Prepare Inputs section of https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/#transfer-learning-from-pretrained-weights, leads to the input dataset changing shape from (None, 224, 224, 3) to (32, None, 224, 224, 3), where 32 is the chose batch size. This then gives a value error: ValueError: Input 0 of layer ""efficientnetb0"" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(32, None, 224, 224, 3).

If relevant, I am attempting to train a model on the IP102 dataset, which can be downloaded from https://www.kaggle.com/datasets/rtlmhjbn/ip02-dataset. 


### Standalone code to reproduce the issue

```shell
#Training and validation dataset locations
path_to_train_setbgr = pathlib.PosixPath(
    ""../Insect Pest Classification Dataset/classification/trainbgr"")
path_to_val_setbgr = pathlib.PosixPath(
    ""../Insect Pest Classification Dataset/classification/valbgr"")


IMG_SIZE = 224
size = (IMG_SIZE, IMG_SIZE)
BATCH_SIZE = 32
NUM_CLASSES = 102
epochs = 30

#Loading Dataset
train_ds = tf.keras.utils.image_dataset_from_directory(
    path_to_train_setbgr,
    label_mode=""int"",
    seed=1,
    batch_size=BATCH_SIZE,
    image_size=size)

val_ds = tf.keras.utils.image_dataset_from_directory(
    path_to_val_setbgr,
    label_mode=""int"",
    seed=1,
    batch_size=BATCH_SIZE,
    image_size=size)

#Data Augmentation Functions

img_augmentation_layers = [
    layers.Normalization(axis =-1, mean= [0.485, 0.456, 0.406], variance=[0.229, 0.224, 0.225]),                                                                            
    layers.RandomRotation(factor=0.15),
    layers.RandomTranslation(height_factor=0.1, width_factor=0.1),
    layers.RandomFlip(),
    layers.RandomContrast(factor=0.1),
    layers.RandomCrop(height=IMG_SIZE, width=IMG_SIZE),
    layers.RandomBrightness(factor=0.1),
    layers.RandomZoom(height_factor=0.1)
]

def img_augmentation(images):
    for layer in img_augmentation_layers:
        images = layer(images)
    return images


# One-hot / categorical encoding
def input_preprocess_train(image, label):
    image = img_augmentation(image)
    label = tf.one_hot(label, NUM_CLASSES)
    return image, label


def input_preprocess_val(image, label):
    label = tf.one_hot(label, NUM_CLASSES)
    return image, label

#Applying data augmentation

train_ds = train_ds.map(input_preprocess_train, num_parallel_calls=tf.data.AUTOTUNE)
train_ds = train_ds.batch(batch_size=BATCH_SIZE,
                          drop_remainder=True)
train_ds = train_ds.prefetch(tf.data.AUTOTUNE)

val_ds = val_ds.map(input_preprocess_val, num_parallel_calls=tf.data.AUTOTUNE)
val_ds = val_ds.batch(batch_size=BATCH_SIZE, drop_remainder=True,)

#Defining the mode;=
model_B0 = EfficientNetB0(include_top=True,
                          weights=None,
                          classes = NUM_CLASSES,
                          input_shape=(IMG_SIZE, IMG_SIZE, 3))


model_B0.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

#Fitting the model
hist_1= model_B0.fit(train_ds, epochs=epochs, validation_data=val_ds)
```


### Relevant log output

```shell
ValueError: Input 0 of layer ""efficientnetb0"" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(32, None, 224, 224, 3).
```
"
2612231102,78694,AttributeError: 'ModelCheckpoint' object has no attribute '_implements_train_batch_hooks' in MoViNet Streaming Model Training,closed,2024-10-24 17:51:15+00:00,2024-11-10T02:03:27Z,2024-11-10T02:03:24Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/78694,"['stat:awaiting response', 'type:bug', 'stale', 'comp:model', '2.17']","['Hi **@sailesh2710** ,\r\nThanks for raising your concern. The issue you are facing may be due to TensorFlow 2.17.0 automatically using Keras 3. This can cause compatibility errors. To resolve this, you can import Keras separately, which will avoid this issue.\r\nPlease make these changes:\r\nReplace:\r\n```\r\nimport tensorflow as tf\r\n```\r\n\r\nwith:\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.keras as tf_keras\r\n```\r\nUpdate all instances of `tf.keras` in your code to `tf_keras`.\r\n\r\nI have provided a [gist](https://colab.sandbox.google.com/gist/Venkat6871/5fe3e99f52771fb154608bda152d18c6/78694_tf-2-17-0-v.ipynb) here for reference. Let me know if this resolves the issue.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78694"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78694"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.17.0

### Custom code

No

### OS platform and distribution

Google Colab

### Mobile device

_No response_

### Python version

3.1

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I encountered an AttributeError while trying to fit the model using the MoViNet Streaming Model Training and Inference notebook provided in the TensorFlow Model Garden repository. The specific error message is as follows:
![image](https://github.com/user-attachments/assets/91b77694-ff6e-4cc7-8f87-1a481dc45562)

in addition, there is a minor adjustment needed to be done in this code:
![image](https://github.com/user-attachments/assets/e6875949-0e4d-4cf0-8570-28e3816eea76)


### Standalone code to reproduce the issue

```shell
The issue can be reproduced using the notebook from the official TensorFlow Models GitHub repository:

https://github.com/tensorflow/models/blob/f9fdc4faef47af76351204b6d8df576f0e79baab/official/projects/movinet/movinet_streaming_model_training_and_inference.ipynb
```


### Relevant log output

```shell
AttributeError                            Traceback (most recent call last)
<ipython-input-18-49dc73e1e0f6> in <cell line: 1>()
----> 1 results = model.fit(train_ds,
      2                     validation_data=val_ds,
      3                     epochs=2,
      4                     validation_freq=1,
      5                     verbose=1,

1 frames
/usr/local/lib/python3.10/dist-packages/tf_keras/src/callbacks.py in <genexpr>(.0)
    243             getattr(cb, ""_supports_tf_logs"", False)
    244             for cb in self.callbacks
--> 245             if cb._implements_train_batch_hooks()
    246             or cb._implements_test_batch_hooks()
    247             or cb._implements_predict_batch_hooks()

AttributeError: 'ModelCheckpoint' object has no attribute '_implements_train_batch_hooks'
```
"
2613143617,78735,`tf.io.encode_png` can cause a crash,closed,2024-10-25 05:49:19+00:00,2024-11-13T02:01:11Z,2024-11-13T02:01:09Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/78735,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","['Hi **@cybersupersoap** ,\r\nApologies for the delay. Thank you for reporting this issue. I suggest taking a look at issue [#76726](https://github.com/tensorflow/tensorflow/issues/76726), where a similar issue has been proposed and is still open. Following this related issue may also help you stay updated on potential solutions.\r\nI tried running your code on Colab using the TensorFlow nightly version and encountered the same issue. I have provided an alternative solution that I hope will be helpful. Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/125675589e3416610def4b0c67e37705/78735_tf-nightly-v.ipynb) here for your reference.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78735"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78735"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.19.0-dev20241023

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 20.04.3 LTS

### Mobile device

Linux Ubuntu 20.04.3 LTS

### Python version

3.10.14

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I have confirmed that above code would crash on `tf-nightly 22.19.0-dev20241023` (nightly-build)

Please find the [gist](https://colab.research.google.com/drive/1A2ONnR2DN5-gx6_H0byFy8jk3ZmgwiUn?usp=sharing) to reproduce the issue.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
import tensorflow
import numpy
    
image_tensor = tf.saturate_cast(tf.random.uniform([0, 28, 3], minval=0, maxval=256, dtype=tf.int64), dtype=tf.uint8)
image = tf.identity(image_tensor)
compression = -1
name = None
out = tf.io.encode_png(image=image,compression=compression,name=name,)
```


### Relevant log output

```shell
2024-10-25 05:46:33.066290: F tensorflow/core/lib/png/png_io.cc:350] 'image' Must be non NULL
Aborted (core dumped)
```
"
2613636513,78754,tf.keras.Input layer performs implicit data conversion when dtype is not specified,closed,2024-10-25 09:53:29+00:00,2024-11-28T02:06:45Z,2024-11-28T02:06:42Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/78754,"['type:docs-bug', 'stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'type:performance', 'TF2.14']","['Hi **@PhyllisJi** ,\r\nApologies for the delay. I tried to running your code on colab using Tensorflow 2.17.0 and nightly version and faced the same issue. Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/8dfc7a92d949dbb338e62c91a45f0423/78754_tf-2-17-0-nightly-v.ipynb) here for reference.\r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues) as this issue is more related to keras.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', 'can i work on fixing this issue?\r\nim new to the community and this could be a good starting point for me.', '> can i work on fixing this issue? im new to the community and this could be a good starting point for me.\r\n\r\nIt would be really great if you could!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78754"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78754"">No</a>\n']","### Issue type

Documentation Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.14.0

### Custom code

Yes

### OS platform and distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Since tf.keras.Input layer performs implicit data conversion when dtype is not specified, the model can still operate normally even if the input tensor is of bool type, whereas other frameworks will explicitly indicate that the user input data type does not match the data type of the weights. 
This feature is also not described in the documentation. https://www.tensorflow.org/api_docs/python/tf/keras/Input
As shown in the code, in TensorFlow, convolution-related operators (such as tf.nn.conv2d or tf.keras.layers.Conv2D) do not natively support bool type inputs. However, when a user provides a tensor of bool type, the framework performs an implicit type conversion, converting the boolean values to a supported numerical type (e.g., float32) without notifying the user. This implicit conversion can lead to several issues:

1. Unexpected Behavior: Users may mistakenly believe that convolution operators can process boolean data directly, unaware that the data has been converted, resulting in outcomes that do not align with their expectations.

2. Performance Overhead: Implicit type conversions introduce additional computational overhead, which can negatively impact performance, especially when handling large datasets.

3. Loss of Data Semantics: Converting bool values to numerical types (e.g., True to 1.0 and False to 0.0) may alter the original meaning of the data, potentially leading to incorrect inferences or training results.

4. Lack of Explicit Warnings: Since the framework does not warn users about the conversion, it can be difficult to identify and debug issues caused by unintended data type changes, affecting the reliability and maintainability of the model.

To mitigate these risks, it is recommended to introduce explicit type checks and error messages within the API. This would ensure that when an unsupported data type (such as bool) is provided, the framework immediately notifies the user, preventing unintended behavior and improving the clarity of TensorFlow’s operator behavior.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
import os

tf.random.set_seed(42)
tf.config.experimental.enable_op_determinism()

os.environ['CUDA_VISIBLE_DEVICES'] = '0'

def Model_WdZYze5JTnF3OjiUHVAKw_iFV2jkQLyL(input):
    input = tf.keras.Input(shape=input)
    print(input)
    _input = input
    conv1_output = tf.keras.layers.Conv2DTranspose(filters=6, kernel_size=(5, 5), strides=(1, 1), padding=""valid"", output_padding=(0, 0), data_format=""channels_last"", dilation_rate=(1, 1), use_bias=True, name=""conv1_mutated"")(input)
    model = tf.keras.models.Model(inputs=_input, outputs=conv1_output)
    return model


input_tensor = tf.random.uniform((1, 20, 3, 1), minval=0, maxval=2, dtype=tf.int32) > 0
tf_model = Model_WdZYze5JTnF3OjiUHVAKw_iFV2jkQLyL(input_tensor.shape[1:])
tf_output = tf_model(tf_input)
print(tf_output)

conv_transpose = tf.keras.layers.Conv2DTranspose(filters=6, kernel_size=(5, 5), strides=(1, 1), padding=""valid"", output_padding=(0, 0), data_format=""channels_last"", dilation_rate=(1, 1), use_bias=True)
cov_output = conv_transpose(input_tensor)
```


### Relevant log output

```shell
KerasTensor(type_spec=TensorSpec(shape=(None, 20, 3, 1), dtype=tf.float32, name='input_38'), name='input_38', description=""created by layer 'input_38'"")
tf.Tensor(
[[[[-7.40485862e-02  4.80350107e-02  7.99815208e-02 -4.41036373e-02
    -8.51454362e-02  1.62318498e-02]
   [-8.31062645e-02 -1.64438933e-01 -1.27500117e-01  1.00624129e-01
     3.34546417e-02  2.75535733e-02]
   [-1.96273416e-01  3.73793095e-02  1.25477001e-01  7.15976655e-02
    -1.04968920e-02 -1.54422924e-01]
   ...
   [-2.34454736e-01 -6.32669479e-02  7.60323107e-02  3.84105071e-02
     2.50659883e-01 -2.23536283e-01]
   [ 5.74071109e-02  1.42531544e-02  7.83358514e-03  1.72497943e-01
    -2.27022767e-02 -3.41754705e-02]
   [-1.12229913e-01 -5.26112467e-02  3.05368304e-02 -7.72907957e-02
     1.76011339e-01 -5.28815091e-02]]

  [[-7.56227598e-02  1.61828905e-01 -4.07438651e-02 -6.02847338e-03
    -1.76872984e-02 -1.39532030e-01]
   [-1.89279020e-01 -2.94572055e-01 -9.61521864e-02  7.07925856e-02
    -2.58026049e-02 -7.99539834e-02]
   [-4.37560976e-02 -6.63283467e-03 -8.16324800e-02  1.44223779e-01
     8.37134719e-02 -4.75612342e-01]
   ...
   [ 2.74093181e-01 -1.25522703e-01  1.30851418e-02 -2.42470428e-02
     1.46799758e-01 -9.69628543e-02]
   [-9.97005403e-03  1.31986856e-01 -1.31720647e-01  3.18675488e-03
    -8.20864737e-03  1.16216645e-01]
   [ 1.65766820e-01 -1.41832516e-01 -1.46382824e-01 -9.27735865e-03
     8.53385478e-02  1.66841403e-01]]

  [[ 1.02173470e-01  1.13967612e-01  2.87022665e-02 -3.41266394e-03
    -9.46889371e-02 -2.30735779e-01]
   [-3.66873085e-01 -3.19382042e-01 -2.55495101e-01  2.72331506e-01
    -1.18161269e-01 -1.09872714e-01]
   [-4.39989865e-02 -3.90910536e-01  1.62915736e-02 -9.38135237e-02
    -1.90863043e-01 -5.60778439e-01]
   ...
   [-7.09365085e-02 -8.18643421e-02 -4.83587027e-01  2.53073871e-02
    -7.42834732e-02 -1.70356929e-02]
   [ 1.98097110e-01 -3.59873474e-02  6.62651509e-02 -8.07644650e-02
     1.62230998e-01  1.17830709e-01]
   [-2.00704932e-01 -3.57379913e-02 -1.04680404e-01 -1.61345690e-01
     4.35111821e-02 -1.05926320e-01]]

  ...

  [[ 2.72406161e-01 -1.15699254e-01  5.33519685e-03  5.81376851e-02
    -2.22525075e-02 -6.04584739e-02]
   [ 1.86778411e-01 -1.63272589e-01  9.26669091e-02  6.83098435e-02
    -1.22894779e-01 -9.46379155e-02]
   [-2.92863995e-01 -3.90239120e-01  1.93792686e-01 -5.63800335e-02
    -3.73294979e-01 -1.53631270e-01]
   ...
   [ 6.70315847e-02 -3.92585546e-02 -3.23885053e-01 -2.71105677e-01
    -4.34245527e-01  1.10423237e-01]
   [ 9.87675264e-02  3.47033143e-04  8.33582431e-02 -1.04814813e-01
    -3.47234100e-01 -3.63905281e-02]
   [-8.84750113e-02  1.68732554e-02 -1.35217234e-01 -8.40548873e-02
    -1.32500157e-01 -5.30448109e-02]]

  [[ 2.72435993e-01 -9.19810012e-02 -6.43352866e-02  1.17616192e-01
     7.26721883e-02 -3.30447927e-02]
   [ 1.02649257e-02 -1.01452775e-01  1.17028326e-01 -7.20781535e-02
     1.56928256e-01 -4.90562171e-02]
   [ 9.31865275e-02 -1.70680910e-01  1.81988969e-01 -2.37688914e-01
     5.96717894e-02 -2.83467472e-01]
   ...
   [-4.82709706e-02 -3.13978195e-01  1.04269162e-01  2.43905872e-01
    -5.08092046e-01  9.15794671e-02]
   [-1.86816752e-02 -1.22914612e-01 -1.07511654e-01  1.79948762e-01
    -2.97979146e-01  2.44713187e-01]
   [ 1.09467044e-01 -5.24229556e-02 -7.40535706e-02  1.67156503e-01
    -1.21360570e-01  1.66974708e-01]]

  [[ 1.77826062e-01 -2.41430402e-02 -2.24351883e-04  6.20943159e-02
     1.79230571e-02 -6.37900755e-02]
   [ 8.63050297e-02 -1.05093494e-01  1.18852243e-01  9.43583250e-02
     2.41015851e-02 -7.81023428e-02]
   [ 2.07384348e-01 -2.24937975e-01  1.35406584e-01  4.29887921e-02
     4.81921434e-03 -1.95084155e-01]
   ...
   [ 2.53495753e-01 -3.35996687e-01 -1.04444146e-01  7.97981322e-02
    -1.90708429e-01 -1.37708083e-01]
   [ 1.32416457e-01 -2.16152206e-01 -1.20998487e-01  1.31167665e-01
    -1.71426058e-01 -2.07262784e-02]
   [ 1.00089446e-01 -1.60729483e-01  4.42979187e-02  1.45934328e-01
    -1.38317347e-01 -2.13920027e-02]]]], shape=(1, 24, 7, 6), dtype=float32)
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
Cell In[45], line 25
     23 # 定义一个 Conv2DTranspose 层
     24 conv_transpose = tf.keras.layers.Conv2DTranspose(filters=6, kernel_size=(5, 5), strides=(1, 1), padding=""valid"", output_padding=(0, 0), data_format=""channels_last"", dilation_rate=(1, 1), use_bias=True)
---> 25 cov_output = conv_transpose(input_tensor)

File ~/miniconda3/envs/myconda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)
     67     filtered_tb = _process_traceback_frames(e.__traceback__)
     68     # To get the full stack trace, call:
     69     # `tf.debugging.disable_traceback_filtering()`
---> 70     raise e.with_traceback(filtered_tb) from None
     71 finally:
     72     del filtered_tb

File ~/miniconda3/envs/myconda/lib/python3.10/site-packages/keras/src/backend.py:6270, in conv2d_transpose(x, kernel, output_shape, strides, padding, data_format, dilation_rate)
   6267     strides = (1, 1) + strides
   6269 if dilation_rate == (1, 1):
-> 6270     x = tf.compat.v1.nn.conv2d_transpose(
   6271         x,
   6272         kernel,
   6273         output_shape,
   6274         strides,
   6275         padding=padding,
   6276         data_format=tf_data_format,
   6277     )
   6278 else:
   6279     if dilation_rate[0] != dilation_rate[1]:

InvalidArgumentError: Exception encountered when calling layer 'conv2d_transpose_2' (type Conv2DTranspose).

cannot compute Conv2DBackpropInput as input #2(zero-based) was expected to be a float tensor but is a bool tensor [Op:Conv2DBackpropInput] name: 

Call arguments received by layer 'conv2d_transpose_2' (type Conv2DTranspose):
  • inputs=tf.Tensor(shape=(1, 20, 3, 1), dtype=bool)
```
We also tested inputs of type int and found that due to implicit conversions, the output often had ''nan''."
2615617721,78829,"data_flow_ops.FIFOQueue aborts with ""Check failed: 1 == NumElements() (1 vs. 4)""",closed,2024-10-26 07:12:18+00:00,2025-01-15T02:00:08Z,2025-01-15T02:00:05Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/78829,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.18']","['I was able to reproduce the issue on tensorflow 2.18 and tf-nightly. Kindly find the gist of it [here](https://colab.sandbox.google.com/gist/Venkat6871/b1149bd7e0620adf1a8549483f109525/78829_tf-2-18-0-nightly-v.ipynb)', 'The issue here is in the usage of FIFOQueue.dequeue_many(). The function expects a scalar or a scalar Tensor n corresponding to the number of elements to dequeue. Both dequeue_many() and dequeue_up_to() also expect all the queue elements to have a specific shape, which is set when the queue is initialized.\r\n\r\nFor example: \r\n```\r\n    >>> q = tf.queue.FIFOQueue(10, tf.int32, shapes=tf.TensorShape(2))\r\n    >>> q.enqueue(tf.constant([1, 2], dtype=tf.int32, shape=(2)))\r\n    >>> q.enqueue(tf.constant([3, 4], dtype=tf.int32, shape=(2)))\r\n    >>> q.enqueue(tf.constant([5, 6], dtype=tf.int32, shape=(2)))\r\n    >>> q.enqueue(tf.constant([7, 8], dtype=tf.int32, shape=(2)))\r\n    >>> q.dequeue_many(3)\r\n    <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\r\n    array([[1, 2],\r\n       [3, 4],\r\n       [5, 6]], dtype=int32)>\r\n```\r\n\r\nI can send out a PR to add this example, along with examples for the other functions of FIFOQueue, to the code.', 'The examples for FIFOQueue usage have been added to data_flow_ops.py through: https://github.com/tensorflow/tensorflow/commit/6337f9fb09a2b1b3da9a81d0aa7d65bea298d934. The code changes were merged to the internal Google fork and copied over by the copybara-service. \r\n\r\nThis should help clarify the usage of the FIFOQueue functions.', '@Venkat6871 Can you please mark this as resolved?', 'Hi **@cybersupersoap** ,\r\nPlease take a look at the PR which was raised has been merged https://github.com/tensorflow/tensorflow/pull/83570. Also the examples were added for the FIFOQueue API.\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/data_flow_ops.py#L504\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78829"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78829"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

tf-nightly  2.19.0-dev20241025

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 20.04.3 LTS

### Mobile device

_No response_

### Python version

3.10.14

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I have confirmed that below code would crash on `tf-nightly 2.19.0-dev20241025` (nightly-build)

Please find the [gist](https://colab.research.google.com/drive/1AlRfxK85FE1U5NB4xkSHdliDvG7IRC2_?usp=sharing) to reproduce the issue.

### Standalone code to reproduce the issue

```shell
from tensorflow.python.eager import context
from tensorflow.python.framework import dtypes as dtypes_lib
from tensorflow.python.ops import data_flow_ops
from tensorflow.python.eager import context
import tensorflow as tf
with context.graph_mode():
    q = data_flow_ops.FIFOQueue(10, dtypes_lib.float32, ())
    q.dequeue_many([1, 2, 3, 4])
```


### Relevant log output

```shell
Check failed: 1 == NumElements() (1 vs. 4)Must have a one element tensor
Aborted (core dumped)
```
"
2617981709,78869,libtensorflow libraries for >2.15,closed,2024-10-28 10:24:12+00:00,2024-12-06T10:19:59Z,2024-12-06T10:19:56Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/78869,"['type:docs-bug', 'stat:awaiting response', 'type:bug', 'TF 2.16']","['Hi, @MattiasDC \r\nI apologize for the delayed response, Thank you for reporting the issue regarding Nightly libtensorflow C packages availability. I see in this [official documentation](https://github.com/tensorflow/tensorflow?tab=readme-ov-file#official-builds) the status of Nightly Binary Official GCS marked as **Status Temporarily Unavailable** but we do have libtensorflow packages for stable version of TensorFlow available so at the moment I would suggest you to please go with stable libtensorflow C packages which you can download and extract it for more information please refer this [official documentation](https://www.tensorflow.org/install/lang_c)\r\n\r\nFor future update regarding Nightly libtensorflow C packages availability you can see the status here : https://github.com/tensorflow/tensorflow?tab=readme-ov-file#official-builds\r\n\r\nThank you for your cooperation and patience.', 'Hi, @MattiasDC\r\nCould you please confirm if this issue is resolved for you now, For future update regarding Nightly libtensorflow C packages availability you can see the status here : https://github.com/tensorflow/tensorflow?tab=readme-ov-file#official-builds ? \r\n\r\nPlease feel free to close the issue if it is resolved ? Thank you\r\n', 'Thanks for all the info!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78869"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78869"">No</a>\n']","### Issue type

Documentation Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Windows Linux

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Is libtensorflow still being built for every version?
According to the documentation [here](https://www.tensorflow.org/install/lang_c) it is, but according to the GCS bucket in that page which links to [the bucket](https://storage.googleapis.com/libtensorflow-nightly), there hasn't been any new builds for two years.

The last official version available is 2.15

### Standalone code to reproduce the issue

```shell
No code involved to reproduce
```


### Relevant log output

_No response_"
2622361161,78984,Grouped Conv3D convolutions don't work with some of the number of input filters,closed,2024-10-29 21:28:29+00:00,2024-11-21T02:04:12Z,2024-11-21T02:04:09Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/78984,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', 'TF 2.9']","['@dan-kazbek,\r\nLooks like this is an issue which is related to Keras. So, could you please raise the issue in the [Keras-team/Keras](https://github.com/keras-team/keras/issues) repo for the quick resolution. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78984"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/78984"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

tf 2.9.1

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

CUDA version 11.2, cuDNN version 8.1.0

### GPU model and memory

NVIDIA A100 80GB

### Current behavior?

As the title says, grouped 3D convolutions don't work if we have some specific combinations of input / output filters and batch size.  If I try to execute the standalone code I provided, the script crashes with the log output I provided. If I reduce the number of groups  to 1, the calculations proceed as expected.
If I reduce the `batch_size` to 8, the forward pass of the layers is performed successfully, but the following warning is shown:
```
2024-10-29 21:25:47.628087: W tensorflow/compiler/xla/service/gpu/gpu_conv_algorithm_picker.cc:727] None of the algorithms provided by cuDNN heuristics worked; trying fallback algorithms.  Conv: (f32[8,64,64,64,128]{3,2,1,4,0}, u8[0]{0}) custom-call(f32[8,64,64,64,512]{3,2,1,4,0}, f32[1,1,1,256,128]{2,1,0,3,4}), window={size=1x1x1}, dim_labels=b012f_012io->b012f, feature_group_count=2, custom_call_target=""__cudnn$convForward"", backend_config=""{\""conv_result_scale\"":1,\""activation_mode\"":\""0\"",\""side_input_scale\"":0}""
```

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
from keras import layers

conv_layer = layers.Conv3D(
    kernel_size=1,
    filters=128,
    groups=2,
)

batch_size = 16
layer_input = tf.random.normal((batch_size, 64, 64, 64, 512))
output = conv_layer(layer_input)
print(output.shape)
```


### Relevant log output

```shell
2024-10-29 21:18:03.441000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-10-29 21:18:04.710425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78924 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:35:00.0, compute capability: 8.0
2024-10-29 21:18:04.712408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 78924 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:36:00.0, compute capability: 8.0
2024-10-29 21:18:06.075880: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x47fb3520 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-10-29 21:18:06.075966: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0
2024-10-29 21:18:06.075979: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (1): NVIDIA A100 80GB PCIe, Compute Capability 8.0
2024-10-29 21:18:06.742974: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100
2024-10-29 21:18:08.492106: I tensorflow/compiler/jit/xla_compilation_cache.cc:478] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2024-10-29 21:18:08.492559: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at xla_ops.cc:296 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:
%cudnn-conv = (f32[16,64,64,64,128]{3,2,1,4,0}, u8[0]{0}) custom-call(f32[16,64,64,64,512]{3,2,1,4,0} %copy, f32[1,1,1,256,128]{2,1,0,3,4} %copy.1), window={size=1x1x1}, dim_labels=b012f_012io->b012f, feature_group_count=2, custom_call_target=""__cudnn$convForward"", metadata={op_type=""Conv3D"" op_name=""Conv3D"" source_file=""/home/ssh/.local/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py"" source_line=225}, backend_config=""{\""conv_result_scale\"":1,\""activation_mode\"":\""0\"",\""side_input_scale\"":0}""

Original error: UNKNOWN: CUDNN_STATUS_NOT_SUPPORTED
in tensorflow/stream_executor/cuda/cuda_dnn.cc(3520): 'op' CUDNN_BACKEND_OPERATION: cudnnFinalize Failed

To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.
Traceback (most recent call last):
  File ""xla_test.py"", line 12, in <module>
    output = conv_layer(layer_input)
  File ""/home/ssh/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/home/ssh/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py"", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError: Exception encountered when calling layer ""conv3d"" (type Conv3D).

Failed to determine best cudnn convolution algorithm for:
%cudnn-conv = (f32[16,64,64,64,128]{3,2,1,4,0}, u8[0]{0}) custom-call(f32[16,64,64,64,512]{3,2,1,4,0} %copy, f32[1,1,1,256,128]{2,1,0,3,4} %copy.1), window={size=1x1x1}, dim_labels=b012f_012io->b012f, feature_group_count=2, custom_call_target=""__cudnn$convForward"", metadata={op_type=""Conv3D"" op_name=""Conv3D"" source_file=""/home/ssh/.local/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py"" source_line=225}, backend_config=""{\""conv_result_scale\"":1,\""activation_mode\"":\""0\"",\""side_input_scale\"":0}""

Original error: UNKNOWN: CUDNN_STATUS_NOT_SUPPORTED
in tensorflow/stream_executor/cuda/cuda_dnn.cc(3520): 'op' CUDNN_BACKEND_OPERATION: cudnnFinalize Failed

To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning. [Op:__inference__jit_compiled_convolution_op_28]

Call arguments received by layer ""conv3d"" (type Conv3D):
  • inputs=tf.Tensor(shape=(16, 64, 64, 64, 512), dtype=float32)
```
"
2623495311,79029,TensorFlow Ignores Logging Configurations and Outputs Unwanted Warnings,closed,2024-10-30 09:58:53+00:00,2024-11-23T02:02:46Z,2024-11-23T02:02:42Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/79029,"['stat:awaiting response', 'type:bug', 'stale', 'comp:apis', '2.17']","['@arianmaghsoudnia,\r\nApologies for the delay. Could you please check whether you are facing with the latest tensorflow v2.18 and also please create a virtual environment and test your code again. Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/79029"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/79029"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.17.0

### Custom code

No

### OS platform and distribution

(Colab runtime) Ubuntu 22.04.4 LTS

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I'm encountering an issue where TensorFlow outputs runtime warnings messages despite configuring logging to suppress them. Messages are logged even though `TF_CPP_MIN_LOG_LEVEL` is set to ""3"" and `absl.logging` is configured to show only errors. Using a custom context manager to suppress the output doesn't work either, which suggests that certain TensorFlow modules might override these logging settings.

### Standalone code to reproduce the issue

You can try this snippet also on [this](https://colab.research.google.com/drive/1PRrDJo-K3n5U2zgTrH9_XeujVq3EySTX?usp=sharing) colab notebook. Please check the runtime warnings.

```python
import os
import sys
import io
from contextlib import contextmanager
from absl import logging as absl_logging

os.environ[""TF_CPP_MIN_LOG_LEVEL""] = ""3""

absl_logging.set_verbosity(absl_logging.ERROR)

import tensorflow as tf
from tensorflow.python.framework.convert_to_constants import (
    convert_variables_to_constants_v2,
)
from keras import Sequential
from keras.layers import Dense, Input


# Define a context manager to suppress both stdout and stderr
@contextmanager
def suppress_output():
    old_stdout = sys.stdout
    old_stderr = sys.stderr
    # Create temporary string buffers for both
    temp_stdout = io.StringIO()
    temp_stderr = io.StringIO()
    try:
        # Redirect stdout and stderr to the temporary buffers
        sys.stdout = temp_stdout
        sys.stderr = temp_stderr
        yield
    finally:
        # Restore the original stdout and stderr
        sys.stdout = old_stdout
        sys.stderr = old_stderr


# Define the model
input_shape = (1,)
keras_model = Sequential([Input(shape=input_shape), Dense(1)])
full_model = tf.function(lambda x: keras_model(x))
full_model = full_model.get_concrete_function(
    x=tf.TensorSpec(shape=input_shape, dtype=tf.float32)
)

# Even this suppression does not work
with suppress_output():
    frozen_func = convert_variables_to_constants_v2(
        full_model, lower_control_flow=False
    )
    # Output to STDERR here:
    # WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
    # I0000 00:00:1730280536.054103    6179 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0

print(f""TensorFlow Version: {tf.__version__}"")
```


### Relevant log output

```shell
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1730280536.054103    6179 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
```
"
2625343517,79060,Inconsistent Results Between CPU and GPU for `tf.math.pow`,closed,2024-10-30 21:06:26+00:00,2024-11-08T20:39:11Z,2024-11-08T20:39:08Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/79060,"['stat:awaiting response', 'type:bug', 'comp:ops', 'TF 2.18']","['@Cirno-2000,\r\nThe reason could be due to the optimized way of calculating numbers on Nvidia which is different compared to others, there will be a small amount of precision errors. The same behavior is not observed on Apple M1, using numpy or in CPU.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/58479\r\n\r\nThank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/79060"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/79060"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

v2.18.0-rc2-4-g6550e4bd802 2.18.0

### Custom code

Yes

### OS platform and distribution

Ubuntu 22.04 jammy

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.6

### GPU model and memory

_No response_

### Current behavior?

When running the `tf.math.pow` function with specific large exponent values on the CPU and GPU, the results are significantly different. Specifically, for the same input, the CPU returns zero, while the GPU produces an extremely large result.

### Standalone code to reproduce the issue

#### Code:
```python
import tensorflow as tf
import numpy as np
from safetensors.torch import load_file


def set_seed(seed_value=42):
    """"""Sets the random seed for reproducibility.""""""
    np.random.seed(seed_value)
    tf.random.set_seed(seed_value)


def tensorflow_pow_version(input, cpu=True):
    # Set seed for reproducibility
    set_seed()

    if cpu:
        device_string = ""/cpu:0""
    else:
        device_string = ""/gpu:0""

    with tf.device(device_string):
        # Unpack input dictionary
        input_tensor = tf.constant(input[""input""])
        exponent_tensor = tf.constant(input[""exponent""])

        # Apply TensorFlow equivalent
        result = tf.math.pow(input_tensor, exponent_tensor)

        return {""float_power_result"": result.numpy()}


def load_safe_tensor(file_path):
    """"""Loads the safe tensor from the specified file path using safetensors library.""""""
    safe_tensor_data = load_file(file_path)

    # Identify the correct keys for the tensors
    key_input = ""input""  # Assuming ""input"" is the key for the base tensor
    key_exponent = ""exponent""  # Assuming ""exponent"" is the key for the exponent tensor

    # Extract the tensors using the keys
    input_tensor = safe_tensor_data[key_input]
    exponent_tensor = safe_tensor_data[key_exponent]

    # Convert the loaded tensors to TensorFlow tensors
    return {
        ""input"": tf.convert_to_tensor(input_tensor.numpy()),
        ""exponent"": tf.convert_to_tensor(exponent_tensor.numpy()),
    }


def main():
    # Load the safe tensor file
    file_path = ""tensorflow_float_power_9.safetensors""  # Path to your safetensors file

    # Load the safe tensor
    input_data = load_safe_tensor(file_path)

    # Run on CPU
    result_cpu = tensorflow_pow_version(input_data, cpu=True)
    print(""CPU Result:"", result_cpu)

    # Run on GPU
    if tf.config.list_physical_devices(""GPU""):
        result_gpu = tensorflow_pow_version(input_data, cpu=False)
        print(""GPU Result:"", result_gpu)
    else:
        print(""GPU not available."")


if __name__ == ""__main__"":
    main()

```

#### Colab:
```shell
https://colab.research.google.com/drive/1GCUvc_FXk5p9nbFD2G_OOxhDx6Usp5uN?usp=sharing
```

The safetensors can be found here at: [Google Drive](https://drive.google.com/file/d/19k9IJAijb0wAOkYPKmlm44zTzXBWEPMS/view?usp=sharing)

### Relevant log output

```shell
CPU Result: {'float_power_result': array([0])}
GPU Result: {'float_power_result': array([402509216696238080])}
```
```
"
2625410751,79063,Discrepancy in Error Handling for `tf.gather` on CPU vs GPU Leading to Undefined Behavior,closed,2024-10-30 21:42:38+00:00,2024-11-28T02:06:43Z,2024-11-28T02:06:40Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/79063,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.18']","['Hi **@Cirno-2000** ,\r\nApologies for the delay, and thank you for raising your concern here. I tried running your code on Colab with TensorFlow version 2.17.0 and faced a different issue. Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/51bf6c259d927c91c52b2bbdade20b97/79063_tf_2-18-cpu-v.ipynb) here for reference. Let me know if I made any mistakes. Thank you!', 'Hi @Venkat6871, sorry for the delay. I tried your [gist](https://colab.research.google.com/gist/Venkat6871/51bf6c259d927c91c52b2bbdade20b97/79063_tf_2-18-cpu-v.ipynb) and it returned results successfully.\r\n\r\nHave you run the code with a GPU runtime, based on the error message?', 'Hi **@Cirno-2000** ,\r\nApologies for the delay. I tried using the GPU runtime also, but I am facing the same issue as with the CPU. Please refer to the [gist](https://colab.sandbox.google.com/gist/Venkat6871/b69e4558c53ba2e8d56096a2560135ec/79063_tf-nightly-2-19-0-v.ipynb) here for more details. Let me know if I made any mistakes.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/79063"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/79063"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

v2.18.0-rc2-4-g6550e4bd802 2.18.0

### Custom code

Yes

### OS platform and distribution

Ubuntu 22.04 jammy

### Mobile device

_No response_

### Python version

3.10.0

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When running a custom implementation of `tf_as_strided` on TensorFlow using `tf.gather` to simulate the behavior of creating a strided tensor, a significant discrepancy in error handling between CPU and GPU is observed. The CPU raises an `INVALID_ARGUMENT` error when indices are out of range, whereas the GPU produces unexpected outputs without raising an error. This lack of consistent error handling on the GPU could lead to silent data corruption or undefined behavior.

### Reproduction Steps:

  - Create a tensor with some data and define a size and stride pattern that leads to out-of-bounds index access.
  - Implement the `tf_as_strided` function using tf.gather to simulate a custom striding mechanism.
  - Run the function on both CPU and GPU using TensorFlow's `tf.device` context.

### Standalone code to reproduce the issue


Colab: [link](https://colab.research.google.com/drive/1vQkXo3T-2cROEd31yySVsOTIq4Rw2isC?usp=sharing)

Safe Tensors: [Google Drive](https://drive.google.com/file/d/1SmfHggjjPF2fEyVMCtBWB_NFE-MVRhb-/view?usp=sharing)

```python
import tensorflow as tf
import numpy as np
from safetensors.torch import load_file


def set_seed(seed_value=42):
    """"""Sets the random seed for reproducibility.""""""
    np.random.seed(seed_value)
    tf.random.set_seed(seed_value)


def tensorflow_version(input, cpu=True):
    # Set seed for reproducibility
    set_seed()

    if cpu:
        device_string = ""/cpu:0""
    else:
        device_string = ""/gpu:0""

    with tf.device(device_string):
        input_tensor = input[""input""]
        size = input[""size""]
        stride = input[""stride""]
        storage_offset = input.get(""storage_offset"", 0)

        def tf_as_strided(x, size, stride, storage_offset):
            flat_tensor = tf.reshape(x, [-1])
            start_idx = storage_offset
            idxs = []
            for i in range(size[0]):
                for j in range(size[1]):
                    idxs.append(start_idx + i * stride[0] + j * stride[1])

            strided_tensor = tf.gather(flat_tensor, idxs)
            strided_tensor = tf.reshape(strided_tensor, size)
            return strided_tensor

        strided_tensor = tf_as_strided(input_tensor, size, stride, storage_offset)

        return {""as_strided_result"": strided_tensor.numpy()}


def load_safe_tensor(file_path):
    """"""Loads the safe tensor from the specified file path using safetensors library.""""""
    safe_tensor_data = load_file(file_path)

    # Assuming the input tensor is stored with key ""input""
    input_tensor = safe_tensor_data[""input""]

    # Convert the loaded tensor to TensorFlow tensor
    return {""input"": tf.convert_to_tensor(input_tensor.numpy())}


def main():
    # File location
    file_path = ""tensorflow_as_strided_1.safetensors""

    # Load the safe tensor
    input_data = load_safe_tensor(file_path)

    # Add non-tensor arguments to the input data
    input_data[""size""] = (2, 3)
    input_data[""stride""] = (0, 1)
    input_data[""storage_offset""] = 0

    # Run on CPU
    try:
        result_cpu = tensorflow_version(input_data, cpu=True)
        print(""CPU Result:"")
        print(result_cpu)
    except Exception as e:
        print(""CPU Error:"")
        print(e)

    # Check if GPU is available
    if tf.config.list_physical_devices(""GPU""):
        try:
            result_gpu = tensorflow_version(input_data, cpu=False)
            print(""GPU Result:"")
            print(result_gpu)
            
        except Exception as e:
            print(""GPU Error:"")
            print(e)
    else:
        print(""GPU not available."")


if __name__ == ""__main__"":
    main()
```

### Observed Behavior:

  - CPU Output: Local rendezvous is aborting with status: `INVALID_ARGUMENT: indices[1] = 1 is not in [0, 1)`
  - GPU Output: Produces an output tensor with unexpected values without raising any exception, e.g., `{'as_strided_result': array([[4468, 0, 0], [4468, 0, 0]])}.`
  - Additional Details: The resulting tensor contains repeated elements of 4468 along with zeros, indicating that the GPU did not properly handle out-of-bounds indices. The input data provided during the GPU run included a tensor that was incorrectly created due to this discrepancy: `{'input': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([4468])>}`.

### Expected Behavior:

Both CPU and GPU should raise an INVALID_ARGUMENT error if indices are out of range to ensure consistent behavior and avoid silent failures or undefined values. Specifically, no tensor should be created with values like [4468, 0, 0] without any validation error.


### Relevant log output

```shell
2024-10-30 17:39:27.333559: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: indices[1] = 1 is not in [0, 1)
CPU Error:
{{function_node __wrapped__GatherV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[1] = 1 is not in [0, 1) [Op:GatherV2]
GPU Result:
{'as_strided_result': array([[4468,    0,    0],
       [4468,    0,    0]])}
```"
2625939517,79083,Discrepancy in `tf.experimental.numpy.nansum` with `dtype=float16` on CPU vs GPU,closed,2024-10-31 04:22:27+00:00,2024-11-08T20:39:24Z,2024-11-08T20:39:21Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/79083,"['stat:awaiting response', 'type:bug', 'comp:ops', 'TF 2.18']","['@Cirno-2000,\r\nThe reason could be due to the optimized way of calculating numbers on Nvidia which is different compared to others, there will be a small amount of precision errors. The same behavior is not observed on Apple M1, using numpy or in CPU.\r\n\r\nThank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/79083"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/79083"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

v2.18.0-rc2-4-g6550e4bd802 2.18.0

### Custom code

Yes

### OS platform and distribution

Ubuntu 22.04.4 LTS x86_64

### Mobile device

_No response_

### Python version

3.10.0

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

#### **Bug Description:**

When using `tf.experimental.numpy.nansum` with a specified `dtype` of `float16`, there is a significant discrepancy between the CPU and GPU results. On the CPU, the operation produces a normal float16 value, while on the GPU, it results in an `inf` value, indicating a potential issue in handling float16 precision on the GPU.

When switching to `float32` for the dtype, the results between the CPU and GPU align closely, which suggests that the discrepancy is specifically related to the handling of float16 values.



### Standalone code to reproduce the issue

[colab](https://colab.research.google.com/drive/14b31pm1EDgivd-xcIxugFVuJc8D7_4a2?usp=sharing)
[safe tensors](https://drive.google.com/file/d/1sg_bCRlhow5VYenkFKARRe2Matuw7owq/view?usp=sharing)


```shell
import tensorflow as tf
import numpy as np
from safetensors.torch import load_file

def set_seed(seed_value=42):
    """"""Sets the random seed for reproducibility.""""""
    np.random.seed(seed_value)
    tf.random.set_seed(seed_value)

def tensorflow_version(input, cpu=True):
    set_seed()
    if cpu:
        device_string = ""/cpu:0""
    else:
        device_string = ""/gpu:0""

    with tf.device(device_string):
        # Enable NumPy behavior in TensorFlow
        tf.experimental.numpy.experimental_enable_numpy_behavior()

        # Unpack input dictionary
        x1 = tf.constant(input[""input""])
        x2 = input[""dim""]
        keepdim = input.get(""keepdim"", False)
        dtype = input.get(""dtype"", None)

        if dtype is not None:
            dtype = tf.as_dtype(dtype)

        # Perform the nansum operation
        y = tf.experimental.numpy.nansum(x1, axis=x2, keepdims=keepdim, dtype=dtype)

        return {""nansum"": y.numpy()}

def load_safe_tensor(file_path):
    """"""Loads the safe tensor from the specified file path using safetensors library.""""""
    safe_tensor_data = load_file(file_path)

    # Assuming the input tensor is stored with key ""input""
    input_tensor = safe_tensor_data[""input""]

    # Convert the loaded tensor to TensorFlow tensor
    return {""input"": tf.convert_to_tensor(input_tensor.numpy())}

def main():
    # File location
    file_path = (
        ""tensorflow_nansum_2.safetensors""
    )

    # Load the safe tensor
    input_data = load_safe_tensor(file_path)

    # Add non-tensor arguments to the input data
    input_data[""dim""] = (1,)
    input_data[""keepdim""] = True
    input_data[""dtype""] = np.float16  # np.float32 will work

    # Run on CPU
    result_cpu = tensorflow_version(input_data, cpu=True)
    print(""CPU Result:"")
    print(result_cpu)

    # Check if GPU is available
    if tf.config.list_physical_devices(""GPU""):
        result_gpu = tensorflow_version(input_data, cpu=False)
        print(""GPU Result:"")
        print(result_gpu)

        # Calculate and print the differences
        if result_gpu:
            diff = np.abs(result_cpu[""nansum""] - result_gpu[""nansum""])
            print(
                ""Maximum Absolute Difference between CPU and GPU results:"", np.max(diff)
            )
    else:
        print(""GPU not available."")

if __name__ == ""__main__"":
    main()
```

#### **Issue Summary:**
- When `dtype` is set to `float16`, the GPU calculation produces an `inf` value, while the CPU results in a proper float16 output. This discrepancy is not observed with `float32`.
- The unexpected `inf` value suggests that the GPU implementation for `tf.experimental.numpy.nansum` with `float16` has numerical precision or overflow issues.
- Switching to `float32` resolves the issue, indicating that this is specific to float16 precision handling.



### Relevant log output

```shell
CPU Result:
{'nansum': array([[[2048. , -473.5]]], dtype=float16)}
GPU Result:
{'nansum': array([[[   inf, -471.5]]], dtype=float16)}
Maximum Absolute Difference between CPU and GPU results: inf
```
"
2632401813,79317,`unresolved external symbol TfLiteGpuDelegateV2Create` linker error with Visual Studio,closed,2024-11-04 10:20:25+00:00,2025-01-13T09:14:18Z,2025-01-13T09:14:15Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/79317,"['awaiting review', 'stat:awaiting tensorflower', 'type:bug', 'comp:lite', 'TF 2.16']","['Hi, @pkgoogle \r\nPlease take a look into this issue. Thank you', ""Hi @misterBart, I noticed you are using GeForce GPU's ... CUDA isn't supported for Windows past TF 2.11, please review this note: https://www.tensorflow.org/install/source_windows#gpu to ensure your setup is supported. That being said I see you are trying in nightly, 2.16, and 2.10 ... which version do you wish to try? (If you want to try with WSL2 or tensorflow-cpu with TensorFlow-DirectML-Plugin). Alternatively, you can make a PR with your suggestions and we can see how the review goes."", 'I\'m not using CUDA. This issue is completely unrelated to CUDA and Nvidia GPUs. And aside from testing with Geforce GPUs I also tested with an Intel HD 520 GPU, as I wrote down under ""GPU model and memory"" in my opening post. This issue is about a linker error with the Visual Studio compiler, and I already posted a PR to solve this issue (see above).\r\n\r\nThis issue is present in TfLite 2.10, 2.16 and in Nightly.', 'My PR to solve this issue has been accepted, therefore I close this issue.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/79317"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/79317"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

TfLite nightly, 2.16, 2.10

### Custom code

No

### OS platform and distribution

Windows 10 Pro & Home

### Mobile device

_No response_

### Python version

Irrelevant, C++ API is used

### Bazel version

_No response_

### GCC/compiler version

Microsoft Visual Studio 2022 C++ compiler

### CUDA/cuDNN version

_No response_

### GPU model and memory

Geforce RTX 2080 (8 GB), Geforce GT 1030 (2 GB GDDR5), Intel HD Graphics 520

### Current behavior?

The function `TfLiteGpuDelegateV2Create` in the minimal-working example below yields the linker error `unresolved external symbol __imp_TfLiteGpuDelegateV2Create` with Visual Studio.

Why?
Short answer:
Function `TfLiteGpuDelegateV2Create` is prefixed with preprocessor macro `TFL_CAPI_EXPORT` as `TFL_CAPI_EXPORT TfLiteDelegate* TfLiteGpuDelegateV2Create(const TfLiteGpuDelegateOptionsV2* options);` (see `tensorflow/lite/delegates/gpu/delegate.h`) When *building* TfLite, `TFL_CAPI_EXPORT` is empty. When *using* `delegate.h` in my application, `TFL_CAPI_EXPORT` contains `__declspec(dllimport)`. This `__declspec(dllimport)` causes the linker error.

Long answer:
Function `TfLiteGpuDelegateV2Create` is prefixed with preprocessor macro `TFL_CAPI_EXPORT`. `TFL_CAPI_EXPORT` is defined in `tensorflow\lite\core\c\c_api_types.h` as
```
// Define TFL_CAPI_EXPORT macro to export a function properly with a shared
// library.
#ifdef SWIG
    #define TFL_CAPI_EXPORT
#elif defined(TFL_STATIC_LIBRARY_BUILD)
    #define TFL_CAPI_EXPORT
#else  // not definded TFL_STATIC_LIBRARY_BUILD
    #if defined(_WIN32)
        #ifdef TFL_COMPILE_LIBRARY
            #define TFL_CAPI_EXPORT __declspec(dllexport)
        #else
            #define TFL_CAPI_EXPORT __declspec(dllimport)
        #endif  // TFL_COMPILE_LIBRARY
    #else
        #define TFL_CAPI_EXPORT __attribute__((visibility(""default"")))
    #endif  // _WIN32
#endif  // SWIG
```
`TFL_CAPI_EXPORT` is empty when building TfLite with the defaults via CMake. `TFL_CAPI_EXPORT` is empty because `TFL_STATIC_LIBRARY_BUILD` is defined in TfLite's `CMakeLists.txt`. `TFL_CAPI_EXPORT` is not empty when `tensorflow\lite\core\c\c_api_types.h` is being included in my application, e.g. indirectly in the minimum-working example by including `tensorflow/lite/delegates/gpu/delegate.h`. `TFL_CAPI_EXPORT` then expands to `__declspec(dllimport)` because `TFL_STATIC_LIBRARY_BUILD` is not defined. This leads to the linker error `unresolved external symbol __imp_TfLiteGpuDelegateV2Create`.

Work-around:
Define `TFL_STATIC_LIBRARY_BUILD` before including the TfLite headers in my application. Then `TFL_CAPI_EXPORT` is empty when `tensorflow\lite\core\c\c_api_types.h` is included in my application. But `TFL_STATIC_LIBRARY_BUILD` is an internal macro, the user should not be aware of this macro.

Proposed solution:
Remove `__declspec(dllimport)` from `TFL_CAPI_EXPORT`. It is optional for functions, it is merely a small optimization when calling functions and not of significant impact in compute-intensive applications as DNN processing.
Alternative: remove prefix `TFL_CAPI_EXPORT` from function declarations that are part not of the C API. Because I believe the TfLite C API by default builds to a .dll and the regular TfLite by default builds to a static lib.
Alternative2: Rethink this design with `TFL_CAPI_EXPORT`.

N.B. I build the regular TfLite, not the TfLite C API.

(Possibly) Related:
https://github.com/tensorflow/tensorflow/issues/61442
https://github.com/tensorflow/flutter-tflite/issues/83
https://github.com/tensorflow/flutter-tflite/issues/82
https://github.com/am15h/tflite_flutter_plugin/issues/60
https://groups.google.com/g/angleproject/c/xKmUgKZFpgY/m/65FHXZJjBwAJ

### Standalone code to reproduce the issue

```shell
Minimal working example:
Build commands (in Windows Command Prompt):
git clone --single-branch --branch nightly https://github.com/tensorflow/tensorflow tensorflow_src
mkdir tflite_x64_release
cd tflite_x64_release
cmake -G ""Visual Studio 17 2022"" -A x64 -DCMAKE_MSVC_RUNTIME_LIBRARY=MultiThreaded -DBUILD_SHARED_LIBS=OFF -DCMAKE_BUILD_TYPE=release -DTFLITE_ENABLE_GPU=ON ..\tensorflow_src\tensorflow\lite
cmake --build . -j 8 --config release


//#define TFL_STATIC_LIBRARY_BUILD  //Define this macro to avoid unresolved external symbol of TfLiteGpuDelegateV2Create
#include ""tensorflow/lite/logger.h""
#include ""tensorflow/lite/model.h""
#include ""tensorflow/lite/kernels/register.h""
#include ""tensorflow/lite/interpreter.h""
#include ""tensorflow/lite/delegates/gpu/delegate.h""
#include <iostream>

int main() {
    tflite::LoggerOptions::SetMinimumLogSeverity(tflite::TFLITE_LOG_VERBOSE);

    std::unique_ptr<tflite::FlatBufferModel> model = tflite::FlatBufferModel::BuildFromFile(""./lite-model_deeplabv3_1_metadata_2.tflite"");  //Model from https://storage.googleapis.com/download.tensorflow.org/models/tflite/task_library/image_segmentation/rpi/lite-model_deeplabv3_1_metadata_2.tflite
    tflite::ops::builtin::BuiltinOpResolver resolver;
    tflite::InterpreterBuilder interpreter_builder(*model, resolver);
    interpreter_builder.SetNumThreads(1);
    TfLiteDelegate* gpu_delegate = TfLiteGpuDelegateV2Create(nullptr);
    interpreter_builder.AddDelegate(gpu_delegate);

    std::cout << ""Done\n"";
    return EXIT_SUCCESS;
}
```


### Relevant log output

_No response_"
2645784206,79736,Error when inferencing on a tflite model,closed,2024-11-09 08:04:07+00:00,2024-11-27T02:06:58Z,2024-11-27T02:06:54Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/79736,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'TF 2.13']","[""Hi, @trieu1162000 \r\n\r\nThank you for bringing this issue to our attention, if possible could you please help us with your model and image to replicate the similar behavior from our end ? If you're okay could you please give a try with AI Edge Torch package to convert a PyTorch model to the LiteRT format because there is no need to go with this conversion process **Pytorch model -> ONNX -> TF -> TF lite** please refer this [official documentation ](https://ai.google.dev/edge/litert/models/pytorch_to_tflite)\r\n\r\nThank you for your cooperation and understanding"", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/79736"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/79736"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.13.1

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I am facing this error when trying to test inference of a tflite model on an image. Could you please help take a look and give your appropriate support?
Error invoking model: output size must be non-negativeNode number 14 (TfLiteFlexDelegate) failed to invoke.Node number 7 (WHILE) failed to invoke.Node number 590 (WHILE) failed to invoke.

### Standalone code to reproduce the issue

```shell
My pipeline converting: Pytorch model -> ONNX -> TF -> TF lite
My script to test the .tflite model:
import tensorflow as tf
import numpy as np
import cv2
import matplotlib.pyplot as plt
import matplotlib.patches as patches

# Function to preprocess the image (resizing, normalization, etc.)
def preprocess_image(image_path, target_size=(320, 320)):
    # Load the image and resize
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image = cv2.resize(image, target_size)
    
    # Normalize the image: you can adjust this step depending on your model's requirements
    image = image / 255.0
    
    # Ensure the shape is [height, width, channels]
    return image

# Post-process the YOLOv5 Lite output
def postprocess_yolov5lite_output(output):
    # Assuming output shape is (num_boxes, 6) [x1, y1, x2, y2, score, class_id]
    boxes = output[:, :4]  # First 4 are the bounding box coordinates
    scores = output[:, 4]  # 5th is the score
    class_ids = output[:, 5].astype(int)  # 6th is the class id

    # Apply some thresholding to remove low-confidence boxes (if needed)
    confidence_threshold = 0.5
    mask = scores > confidence_threshold
    boxes = boxes[mask]
    scores = scores[mask]
    class_ids = class_ids[mask]

    return {'boxes': boxes, 'scores': scores, 'class_ids': class_ids}

# Function to run the TensorFlow Lite model without using delegates
def run_tflite_model_no_delegate(tflite_file, test_image):
    # Initialize the interpreter without using delegates
    interpreter = tf.lite.Interpreter(model_path=str(tflite_file))
    
    # Allocate tensors
    interpreter.allocate_tensors()
    
    # Get input and output details
    input_details = interpreter.get_input_details()[0]
    output_details = interpreter.get_output_details()[0]

    # Check if input is quantized (for uint8 input), rescale to uint8 if needed
    if input_details['dtype'] == np.uint8:
        input_scale, input_zero_point = input_details[""quantization""]
        test_image = test_image / input_scale + input_zero_point

    # Add the batch dimension
    test_image = np.expand_dims(test_image, axis=0).astype(input_details[""dtype""])  # Shape becomes [1, 320, 320, 3]
    
    # Permute the image to [1, 3, 320, 320] if needed
    test_image = np.transpose(test_image, (0, 3, 1, 2))

    # Set the input tensor and invoke the interpreter
    interpreter.set_tensor(input_details[""index""], test_image)
    
    try:
        interpreter.invoke()
    except Exception as e:
        print(f""Error invoking model: {e}"")
        return None

    # Get the output (bounding boxes, scores, and class IDs)
    output = interpreter.get_tensor(output_details[""index""])[0]

    # Post-processing step for YOLOv5 Lite output
    predictions = postprocess_yolov5lite_output(output)

    return predictions

# Function to test the model and visualize the output
def test_model_no_delegate(tflite_file, test_image, model_type):
    # Run the model without delegates
    predictions = run_tflite_model_no_delegate(tflite_file, test_image)

    if predictions is None:
        print(""Model inference failed."")
        return

    # Plot the image with predictions
    plt.imshow(test_image[0])  # test_image has batch dimension, so use test_image[0]
    ax = plt.gca()

    predicted_boxes = predictions['boxes']
    predicted_scores = predictions['scores']
    predicted_class_ids = predictions['class_ids']

    for i in range(len(predicted_boxes)):
        box = predicted_boxes[i]
        score = predicted_scores[i]
        class_id = predicted_class_ids[i]

        rect = patches.Rectangle(
            (box[0], box[1]), box[2] - box[0], box[3] - box[1], linewidth=2, edgecolor='r', facecolor='none'
        )
        ax.add_patch(rect)

        label = f""Class: {class_id} Score: {score:.2f}""
        plt.text(box[0], box[1], label, color='red', fontsize=10, verticalalignment='top', horizontalalignment='left')

    plt.title(f""{model_type} Model"")
    plt.grid(False)
    plt.show()

# Load and preprocess the image
test_image_path = '/home/ngerr/Workspace/Thesis/YOLOv5-Lite/cpp_demo/ort/images/000000001000.jpg'
test_image = preprocess_image(test_image_path)

# Set the TensorFlow Lite model path
tflite_model_path = ""/home/ngerr/Workspace/Thesis/YOLOv5-Lite/model_zoo/tflite_model/v5lite_quant_model.tflite""

# Testing the model without delegates
test_model_no_delegate(tflite_model_path, test_image, model_type=""Quantized"")
```


### Relevant log output

_No response_"
2650158836,79798,JIT compliation failed,closed,2024-11-11 19:13:11+00:00,2024-12-16T12:04:11Z,2024-12-16T12:04:08Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/79798,"['stat:awaiting response', 'type:bug', 'TF 2.16']","[""By the way, I'm using ROCm version 6.2.2"", 'Hi **@MrYoavon** ,\r\nApologies for the delay, and thank you for raising your concern here. I am trying to replicate your code on Colab but am encountering a different issue. Could you please provide your Colab gist? It would make troubleshooting your issue easier.\r\nThank you!', 'I could but I encounter the same issue when running a simple code from ROCm tensorflow configuration guide.\n\nimport tensorflow as tf\nprint(""TensorFlow version:"", tf.__version__)\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n  tf.keras.layers.Dense(128, activation=\'relu\'),\n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(10)\n])\npredictions = model(x_train[:1]).numpy()\ntf.nn.softmax(predictions).numpy()\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nloss_fn(y_train[:1], predictions).numpy()\nmodel.compile(optimizer=\'adam\',\n              loss=loss_fn,\n              metrics=[\'accuracy\'])\nmodel.fit(x_train, y_train, epochs=5)\nmodel.evaluate(x_test,  y_test, verbose=2)\n\n\n\nThis code is meant to help you check if you can run Tensorflow on your AMD GPU, and this too doesn\'t work with the same error message (the line that crashes is a different one but the error code is still the same)', 'Okay... I have made some odd progress. I can run the code perfectly fine if I use the terminal to run the main.py file. The ""Run File"" button in Pycharm Professional 2024.2.3 somehow causes it to not work properly.\r\nI would like to be able to use the button but if it\'s an issue with Pycharm then I guess I\'ll just use the terminal. Maybe it\'s something with the run configuration of Pycharm?', 'Hi **@MrYoavon** ,\r\nApologies for the delay. I tried running your code on Colab using TensorFlow 2.17.0 and the nightly versions, and it worked fine for me. Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/ce2bb22feb799d2f54ea4a782ba1b85f/79798_tf_2-17-0-nightly-v.ipynb) here for your reference. Let me know if I missed anything.\r\nThank you!', ""This wouldn't cause an issue on Colab since the problem is with the use of Tensorflow with ROCm. The code itself isn't problematic. According to ROCm documentation, my ROCm version is only compatible with Tensorflow versions 2.14.1, 2.15.1, 2.16.1. I'm using Tensorflow 2.16.1 and ROCm 6.2.4."", 'Hi, \r\nI follow the topic, I have the same problem with 7900XTX ubuntu 24.04 rocm 6.2.4 and tensorflow-rocm 2.16.2 and python 3.10 in a venv.', 'Hi **@MrYoavon** ,\r\nCould you please provide the ROCm documentation you are following? Also, try using the latest TensorFlow versions (2.17.0 or 2.18.0), as they may help you run more smoothly.\r\nThank you!', ""Hi,\nThis is the ROCm documentation I followed: https://rocm.docs.amd.com/projects/install-on-linux/en/latest/install/3rd-party/tensorflow-install.html\n\nUsing Tensorflow 2.17 or 2.18 isn't possible, according to the documentation."", 'Hi,\r\ni had the same issue and fixed it. The hint came from: https://github.com/ROCm/ROCm/issues/3835\r\nI just set the following environment variable: `ROCM_PATH=/opt/rocm` before executing the script', ""Hi, @MrYoavon, @Gika-0\r\nI apologize for the delayed response, Hi, @patrick-praher thank you for your pointers, it is known issue please refer this original issue https://github.com/ROCm/ROCm/issues/1796#issuecomment-1447710413 and setting `ROCM_PATH` to `/opt/rocm` should fix this issue and also make sure that you're using correct supported versions of `ROCm` and `TensorFlow` mentioned [here](https://rocm.docs.amd.com/projects/install-on-linux/en/latest/install/3rd-party/tensorflow-install.html#installing-tensorflow-for-rocm)\r\n\r\n**Note :** As of **ROCm 6.1**, tensorflow-rocm packages are found at https://repo.radeon.com/rocm/manylinux. Prior to ROCm 6.1, packages were found at https://pypi.org/project/tensorflow-rocm.\r\n\r\nPlease let us know after setting `ROCM_PATH` to `/opt/rocm` resolving your issue or not ? if issue still persists please let us know. \r\n\r\nThank you for your cooperation and patience.\r\n\r\n\r\n\r\n"", 'This worked. Thanks to everyone who has taken their time to help :)', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/79798"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/79798"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.16.1

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 24.04

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

Radeon 7900XT

### Current behavior?

I tried to run some tensorflow code to process a few videos in a model I have. When running this code on the CPU, everything works fine. It doesn't work when running it on the GPU.

### Standalone code to reproduce the issue

```shell
# main.py

import numpy as np
import tensorflow as tf
import imageio

from data_processing.data_processing import DatasetPreparer, DataLoader, num_to_char, char_to_num
from data_processing.mouth_detection import MouthDetector
from model.model import LipReadingModel

physical_devices = tf.config.list_physical_devices('GPU')
try:
    tf.config.experimental.set_memory_growth(physical_devices[0], True)
except:
    pass


def main():
    base_dir = ""data/A_U_EE_E/temp/""
    original_video_dir = base_dir + ""videos""
    original_subtitle_dir = base_dir + ""subtitles""
    output_dir = base_dir + ""separated""
    video_dir = output_dir + ""/videos""
    subtitle_dir = output_dir + ""/subtitles""

    mouth_detector = MouthDetector()

    # Instantiate DataLoader (or appropriate class) and DatasetPreparer
    data_loader = DataLoader(detector=mouth_detector)  # Initialize with any necessary parameters

    data_loader.process_all_videos(original_video_dir, original_subtitle_dir, output_dir)

    dataset_preparer = DatasetPreparer(video_directory=video_dir, data_loader=data_loader)  # Provide data_loader here

    dataset = dataset_preparer.prepare_dataset()

    # Fetch a batch of data
    data_iterator = dataset.as_numpy_iterator()
    video_frames, subtitle_tokens = data_iterator.next()

    # # Process frames for saving as a GIF
    # processed_frames = []
    # for frame in video_frames[0]:  # Access the first video in the batch
    #     # Convert normalized frame to uint8
    #     frame = (frame.numpy() * 255).astype(np.uint8)
    #
    #     # Check and reshape if necessary
    #     if frame.shape[-1] == 1:  # Grayscale with singleton dimension
    #         frame = np.squeeze(frame, axis=-1)  # Remove the last dimension for display
    #
    #     processed_frames.append(frame)
    #
    # # Save frames as GIF
    # imageio.mimsave(""./animation.gif"", processed_frames, fps=30)

    # # Decode subtitle tokens to text for verification
    # decoded_subtitles = tf.strings.reduce_join(
    #     [tf.compat.as_str_any(x) for x in num_to_char(subtitle_tokens[0]).numpy()])
    # print(""Decoded Subtitles:"", decoded_subtitles.numpy().decode('utf-8'))


    model = LipReadingModel(char_to_num.vocabulary_size())

    yhat = model.predict(video_frames)
    print(tf.strings.reduce_join([num_to_char(tf.argmax(x)) for x in yhat[0]]))
    print(model.input_shape)


if __name__ == ""__main__"":
    main()


# data_processing/data_processing.py
import csv
import os
import cv2
import tensorflow as tf
import pandas as pd
from data_processing.mouth_detection import MouthDetector

# Define vocabulary for character mapping
vocab = [""A"", ""U"", ""EE"", ""E"", "" ""]
char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token="""")
num_to_char = tf.keras.layers.StringLookup(vocabulary=char_to_num.get_vocabulary(), oov_token="""", invert=True)


class DataLoader:
    def __init__(self, detector: MouthDetector):
        self.detector = detector

    def load_video(self, path: str) -> tf.Tensor:
        """"""
        Load video frames, apply mouth detection, convert to grayscale, and normalize.
        """"""
        cap = cv2.VideoCapture(path)
        frames = []

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            frame = self.detector.detect_and_crop_mouth(frame)  # Crop to mouth region
            if frame is not None:
                frame = tf.image.rgb_to_grayscale(frame)
                frames.append(frame)

        cap.release()
        if len(frames) == 0:
            raise ValueError(f""No valid frames found in video {path}"")

        # Normalize frames
        # mean = tf.math.reduce_mean(frames)
        # std = tf.math.reduce_std(tf.cast(frames, tf.float32))
        # return tf.cast((frames - mean), tf.float32) / std

        # return tf.image.per_image_standardization(frames)

        mean = tf.math.reduce_mean(frames, axis=[0, 1, 2], keepdims=True)
        std = tf.math.reduce_std(tf.cast(frames, tf.float32), axis=[0, 1, 2], keepdims=True)
        frames = tf.cast(frames, tf.float32)
        normalized_frames = (frames - mean) / std
        return normalized_frames

    def load_subtitles(self, path: str) -> tf.Tensor:
        """"""
        Load subtitles and map them to character indices.
        """"""
        df = pd.read_csv(path, header=None, names=['start_time', 'end_time', 'subtitle'])
        tokens = []

        for _, row in df.iterrows():
            subtitle = row['subtitle'].strip().upper()
            if subtitle and subtitle != 'IDLE':
                tokens.extend(list(subtitle) + [' '])

        tokens = tokens[:-1]
        tokenized = tf.strings.unicode_split(tokens, input_encoding='UTF-8')
        return char_to_num(tf.reshape(tokenized, [-1]))

    def split_video_by_frames(self, video_path, subtitles_path, output_dir, max_frames=120):
        """"""
        Split video into chunks of `max_frames` or fewer, keeping word boundaries intact.
        """"""
        # Load video and subtitle data
        cap = cv2.VideoCapture(video_path)
        df = pd.read_csv(subtitles_path, header=None, names=['start_time', 'end_time', 'subtitle'])

        fps = cap.get(cv2.CAP_PROP_FPS)
        part_num = 1
        chunk_frames = []
        chunk_subtitles = []
        current_frame_count = 0
        start_time = 0

        for index, row in df.iterrows():
            start_ms, end_ms, subtitle = row['start_time'], row['end_time'], row['subtitle']

            # Convert start and end times to frame indices
            start_frame = int((start_ms / 1000) * fps)
            end_frame = int((end_ms / 1000) * fps)
            word_frame_count = end_frame - start_frame

            if current_frame_count + word_frame_count > max_frames:
                # Save current chunk if adding this word exceeds the max frame count
                self.save_chunk(chunk_frames, chunk_subtitles, video_path, output_dir, part_num, fps)
                part_num += 1
                chunk_frames = []
                chunk_subtitles = []
                current_frame_count = 0
                start_time = start_ms  # New start time for the new chunk

            # Add word frames and subtitle
            chunk_subtitles.append((start_ms - start_time, end_ms - start_time, subtitle))

            # Extract frames for this word
            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
            for _ in range(word_frame_count):
                ret, frame = cap.read()
                if not ret:
                    break
                chunk_frames.append(frame)
                current_frame_count += 1

        # Save the last chunk
        if chunk_frames:
            self.save_chunk(chunk_frames, chunk_subtitles, video_path, output_dir, part_num, fps)

        cap.release()

    def save_chunk(self, chunk_frames, chunk_subtitles, video_path, output_dir, part_num, fps):
        """"""
        Save a chunk of frames and its corresponding subtitles.
        """"""
        # Define output video and CSV paths
        file_name = os.path.splitext(os.path.basename(video_path))[0]
        output_video_path = os.path.join(output_dir, ""videos"", f""{file_name}_{part_num}.mp4"")
        output_csv_path = os.path.join(output_dir, ""subtitles"", f""{file_name}_{part_num}.csv"")

        # Save the video chunk
        height, width, _ = chunk_frames[0].shape
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))
        for frame in chunk_frames:
            out.write(frame)
        out.release()

        # Save the CSV chunk with adjusted timestamps
        with open(output_csv_path, mode='w', newline='') as csvfile:
            writer = csv.writer(csvfile)
            for start_ms, end_ms, subtitle in chunk_subtitles:
                writer.writerow([start_ms, end_ms, subtitle])

    def process_all_videos(self, video_directory, subtitles_directory, output_directory):
        """"""
        Process each video in the video_directory, split it, and generate output.
        """"""
        for video_file in os.listdir(video_directory):
            if video_file.endswith("".mp4""):
                video_path = os.path.join(video_directory, video_file)
                subtitle_path = os.path.join(subtitles_directory, f""{os.path.splitext(video_file)[0]}.csv"")
                self.split_video_by_frames(video_path, subtitle_path, output_directory)


class PreProcessor:
    @staticmethod
    def prepare_video_and_subtitles(video_path: tf.Tensor, data_loader: DataLoader):
        """"""
        Prepares video and subtitle tensors.
        """"""
        video_path = video_path.numpy().decode('utf-8')
        base_dir = os.path.dirname(os.path.dirname(video_path))
        file_name = os.path.splitext(os.path.basename(video_path))[0]

        subtitles_path = os.path.join(base_dir, 'subtitles', f'{file_name}.csv')
        video_tensor = data_loader.load_video(video_path)
        subtitle_tensor = data_loader.load_subtitles(subtitles_path)

        return video_tensor, subtitle_tensor

    @staticmethod
    def mappable_fn(video_path: tf.Tensor, data_loader: DataLoader):
        """"""
        A wrapper function that maps video path to frames and alignments.
        """"""
        return tf.py_function(lambda x: PreProcessor.prepare_video_and_subtitles(x, data_loader), [video_path], [tf.float32, tf.int64])


class Augmentor:
    @staticmethod
    def augment_video(frames: tf.Tensor) -> tf.Tensor:
        """"""
        Augment video frames by applying transformations such as flipping and concatenating.
        """"""
        if frames.shape.rank == 5:
            # Apply flipping to each frame in the video sequence
            flipped_frames = tf.map_fn(lambda x: tf.image.flip_left_right(x), frames)
        elif frames.shape.rank == 4:
            # Apply flipping directly if frames already have 4D shape
            flipped_frames = tf.image.flip_left_right(frames)
        else:
            raise ValueError(""Expected frames to have 4 or 5 dimensions, got shape: {}"".format(frames.shape))

        # Concatenate original and flipped frames along the batch dimension
        return tf.concat([frames, flipped_frames], axis=0)


class DatasetPreparer:
    def __init__(self, video_directory: str, data_loader: DataLoader):
        self.video_directory = video_directory
        self.data_loader = data_loader

    def prepare_dataset(self) -> tf.data.Dataset:
        """"""
        Prepare a dataset that reads videos and subtitles, applies augmentations, and batches data.
        """"""
        dataset = tf.data.Dataset.list_files(f""{self.video_directory}/*.mp4"")
        dataset = dataset.shuffle(100)
        dataset = dataset.map(lambda path: PreProcessor.mappable_fn(path, self.data_loader))

        # 5400 frames in each training video (assuming 3 minutes 30 fps)
        # 240 tokens in each video (120 letters plus space token to separate)
        frames, alignments = dataset.as_numpy_iterator().next()
        print(frames.shape, alignments.shape)
        dataset = dataset.padded_batch(2, padded_shapes=([120, None, None, None], [12]))
        dataset = dataset.prefetch(tf.data.AUTOTUNE)
        dataset = dataset.map(lambda frames, alignments: (Augmentor.augment_video(frames), alignments))

        return dataset


# data_processing/mouth_detection.py

import cv2
import mediapipe as mp
from mediapipe import solutions
from mediapipe.framework.formats import landmark_pb2
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
import numpy as np


class MouthDetector:
    def __init__(self, model_path='assets/face_landmarker.task', num_faces=1):
        base_options = python.BaseOptions(model_asset_path=model_path, delegate=""GPU"")
        options = vision.FaceLandmarkerOptions(base_options=base_options,
                                               output_face_blendshapes=True,
                                               output_facial_transformation_matrixes=True,
                                               num_faces=num_faces)
        self.detector = vision.FaceLandmarker.create_from_options(options)

    def expand_bounding_box(self, xmin, ymin, xmax, ymax, padding_ratio=0.4):
        width = xmax - xmin
        height = ymax - ymin
        pad_w = int(width * padding_ratio)
        pad_h = int(height * padding_ratio)
        xmin = max(xmin - pad_w, 0)
        ymin = max(ymin - pad_h, 0)
        xmax = xmax + pad_w
        ymax = ymax + pad_h
        return xmin, ymin, xmax, ymax

    def draw_landmarks_on_image(self, rgb_image, detection_result):
        face_landmarks_list = detection_result.face_landmarks
        annotated_image = np.copy(rgb_image)

        for idx in range(len(face_landmarks_list)):
            face_landmarks = face_landmarks_list[idx]

            face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()
            face_landmarks_proto.landmark.extend([
                landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks
            ])

            solutions.drawing_utils.draw_landmarks(
                image=annotated_image,
                landmark_list=face_landmarks_proto,
                connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,
                landmark_drawing_spec=None,
                connection_drawing_spec=mp.solutions.drawing_styles
                .get_default_face_mesh_tesselation_style())
            solutions.drawing_utils.draw_landmarks(
                image=annotated_image,
                landmark_list=face_landmarks_proto,
                connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,
                landmark_drawing_spec=None,
                connection_drawing_spec=mp.solutions.drawing_styles
                .get_default_face_mesh_contours_style())
            solutions.drawing_utils.draw_landmarks(
                image=annotated_image,
                landmark_list=face_landmarks_proto,
                connections=mp.solutions.face_mesh.FACEMESH_IRISES,
                landmark_drawing_spec=None,
                connection_drawing_spec=mp.solutions.drawing_styles
                .get_default_face_mesh_iris_connections_style())

        return annotated_image

    def crop_mouth_from_landmarks(self, rgb_image, detection_result, target_size=(250, 100)):
        if detection_result and detection_result.face_landmarks:
            try:
                face_landmarks = detection_result.face_landmarks[0]
                # These are the landmarks for the mouth
                mouth_landmarks = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409,
                                   146, 91, 181, 84, 17, 314, 405, 321, 375, 291,
                                   78, 191, 80, 81, 82, 13, 312, 311, 310, 415,
                                   95, 88, 178, 87, 14, 317, 402, 318, 324, 308]

                x_coords = [face_landmarks[landmark].x for landmark in mouth_landmarks]
                y_coords = [face_landmarks[landmark].y for landmark in mouth_landmarks]
                xmin, xmax = int(min(x_coords) * rgb_image.shape[1]), int(max(x_coords) * rgb_image.shape[1])
                ymin, ymax = int(min(y_coords) * rgb_image.shape[0]), int(max(y_coords) * rgb_image.shape[0])

                xmin, ymin, xmax, ymax = self.expand_bounding_box(xmin, ymin, xmax, ymax)
                cropped_mouth = rgb_image[ymin:ymax, xmin:xmax]
                return cv2.resize(cropped_mouth, target_size, interpolation=cv2.INTER_AREA)
            except cv2.error:
                return None
        return None

    def detect_and_crop_mouth(self, frame, target_size=(250, 100)):
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        mp_image_input = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
        detection_result = self.detector.detect(mp_image_input)
        return self.crop_mouth_from_landmarks(mp_image_input.numpy_view(), detection_result, target_size=target_size)


# model/model.py

import tensorflow as tf
from tensorflow.keras import layers, models


class LipReadingModel:
    def __init__(self, input_shape=(250, 100), num_classes=5):
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.model = self.create_model()

    def create_model(self):
        """"""
        Creates and compiles the lip-reading model using the Sequential API.
        """"""
        model = models.Sequential()

        model.add(layers.Conv3D(128, 3, input_shape=(120, 100, 250, 1), padding='same'))
        model.add(layers.Activation('relu'))
        model.add(layers.MaxPool3D((1, 2, 2)))

        model.add(layers.Conv3D(256, 3, padding='same'))
        model.add(layers.Activation('relu'))
        model.add(layers.MaxPool3D((1, 2, 2)))

        model.add(layers.Conv3D(120, 3, padding='same'))
        model.add(layers.Activation('relu'))
        model.add(layers.MaxPool3D((1, 2, 2)))

        model.add(layers.TimeDistributed(layers.Flatten()))

        model.add(layers.Bidirectional(layers.LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))
        model.add(layers.Dropout(.5))

        model.add(layers.Bidirectional(layers.LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))
        model.add(layers.Dropout(.5))

        model.add(layers.Dense(self.num_classes + 1, kernel_initializer='he_normal', activation='softmax'))

        print(model.summary())

        return model

    def load(self, model_path):
        """"""
        Load a pre-trained model from a given path.
        """"""
        self.model = tf.keras.models.load_model(model_path)

    def predict(self, frames):
        """"""
        Predict the sequence of characters from video frames.
        """"""
        # frames = frames / 255.0  # Normalize frames
        return self.model.predict(frames)

    def save(self, model_path):
        """"""
        Save the trained model to the specified path.
        """"""
        self.model.save(model_path)
```


### Relevant log output

```shell
2024-11-11 20:01:52.496107: E external/local_xla/xla/stream_executor/plugin_registry.cc:91] Invalid plugin kind specified: FFT
2024-11-11 20:01:52.522679: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-11-11 20:01:52.765609: E external/local_xla/xla/stream_executor/plugin_registry.cc:91] Invalid plugin kind specified: DNN
2024-11-11 20:01:53.766866: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:926] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-11-11 20:01:53.795159: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:926] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-11-11 20:01:53.795196: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:926] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-11-11 20:01:53.795770: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:926] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-11-11 20:01:53.795818: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:926] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-11-11 20:01:53.795838: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:926] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-11-11 20:01:53.795883: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:926] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-11-11 20:01:53.795905: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:926] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-11-11 20:01:53.795928: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:926] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-11-11 20:01:53.795938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19406 MB memory:  -> device: 0, name: Radeon RX 7900 XT, pci bus id: 0000:03:00.0
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1731348114.182076   76546 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5
I0000 00:00:1731348114.183730   76671 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.0-devel), renderer: Radeon RX 7900 XT (radeonsi, navi31, LLVM 18.1.7, DRM 3.57, 6.8.0-48-generic)
W0000 00:00:1731348114.184010   76546 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
W0000 00:00:1731348114.187960   76674 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.
W0000 00:00:1731348114.199152   76685 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.
2024-11-11 20:02:36.433486: E external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:243] bitcode module is required by this HLO module but was not found at ./opencl.bc
2024-11-11 20:02:36.433500: E external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:243] bitcode module is required by this HLO module but was not found at ./opencl.bc
2024-11-11 20:02:36.433510: E external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:243] bitcode module is required by this HLO module but was not found at ./opencl.bc
2024-11-11 20:02:36.433519: E external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:243] bitcode module is required by this HLO module but was not found at ./opencl.bc
2024-11-11 20:02:36.433533: E external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:243] bitcode module is required by this HLO module but was not found at ./opencl.bc
2024-11-11 20:02:36.433548: E external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:243] bitcode module is required by this HLO module but was not found at ./opencl.bc
2024-11-11 20:02:36.433562: E external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:243] bitcode module is required by this HLO module but was not found at ./opencl.bc
2024-11-11 20:02:36.433574: E external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:243] bitcode module is required by this HLO module but was not found at ./opencl.bc
error: Failure when generating HSACO
error: Failure when generating HSACO
error: Failure when generating HSACO
error: Failure when generating HSACO
error: Failure when generating HSACO
error: Failure when generating HSACO
error: Failure when generating HSACO
error: Failure when generating HSACO
2024-11-11 20:02:36.433878: E tensorflow/compiler/mlir/tools/kernel_gen/tf_framework_c_interface.cc:207] INTERNAL: Generating device code failed.
2024-11-11 20:02:36.434390: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.
2024-11-11 20:02:36.434402: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: UNKNOWN: JIT compilation failed.
Traceback (most recent call last):
  File ""/home/yoav/PycharmProjects/Lip-C/main.py"", line 70, in <module>
    main()
  File ""/home/yoav/PycharmProjects/Lip-C/main.py"", line 35, in main
    dataset = dataset_preparer.prepare_dataset()
  File ""/home/yoav/PycharmProjects/Lip-C/data_processing/data_processing.py"", line 205, in prepare_dataset
    dataset = tf.data.Dataset.list_files(f""{self.video_directory}/*.mp4"")
  File ""/home/yoav/PycharmProjects/Lip-C/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1338, in list_files
    buffer_size = math_ops.maximum(
  File ""/home/yoav/PycharmProjects/Lip-C/venv/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py"", line 142, in wrapper
    return op(*args, **kwargs)
  File ""/home/yoav/PycharmProjects/Lip-C/venv/lib/python3.10/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 6419, in maximum
    _ops.raise_from_not_ok_status(e, name)
  File ""/home/yoav/PycharmProjects/Lip-C/venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py"", line 5983, in raise_from_not_ok_status
    raise core._status_to_exception(e) from None  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.UnknownError: {{function_node __wrapped__Maximum_device_/job:localhost/replica:0/task:0/device:GPU:0}} JIT compilation failed. [Op:Maximum] name:
```
"
2656960354,79984,Flex lib not linked on Android for C code on usage Select TensorFlow op(s),closed,2024-11-13 22:10:38+00:00,2024-11-20T23:21:01Z,2024-11-20T23:20:58Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/79984,"['stat:awaiting response', 'type:bug', 'comp:lite', 'TF 2.16']","['Hi, @koranten2\r\n\r\nI apologize for the delayed response, You just need to make sure that `libtensorflow_flex.so` is linked in. It can be used in the same way as with C++ API. Just build https://www.tensorflow.org/lite/guide/ops_select#c and load it please refer this [TensorFlow Lite C++ minimal example](https://github.com/tensorflow/tensorflow/tree/v2.18.0/tensorflow/lite/examples/minimal) which may help you to solve your issue and If you\'re doing this in Bazel, adding `""//tensorflow/lite/delegates/flex:delegate""` to `""deps""` of the ""minimal"" cc_binary rule is the right approach that will instruct Bazel to build the flex delegate and then link it into the binary.\r\n\r\nit\'s recommended to use `find_library()` to locate `libtensorflowlite_flex.so` similar to the example in the minimal `CMakeLists.txt` file\r\n\r\nIf I have missed something please let me know. \r\n\r\nThank you for your cooperation and patience.', 'Thank you alot for advice! Clearing my current cmake to make it minimal like  [TensorFlow Lite C++ minimal example](https://github.com/tensorflow/tensorflow/tree/v2.18.0/tensorflow/lite/examples/minimal) resolved the issue.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/79984"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/79984"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tflight 2.16

### Custom code

Yes

### OS platform and distribution

Ubuntu 22.04, Android Studio

### Mobile device

Samsung S21, S10

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I tried to launch my custom tflite model (with select_op) on Android Studio using C API. I tried both libtensorflowlite.so and libtensorflowlite_c.so built from source code using Bazel but got the same error.  I have linked the libtensorflowlite_flex.so in Cmake as below (build follow the https://www.tensorflow.org/lite/guide/ops_select).
But occurred this error:
_E/tflite: Select TensorFlow op(s), included in the given model, is(are) not supported by this interpreter. Make sure you apply/link the Flex delegate before inference. For the Android, it can be resolved by adding ""org.tensorflow:tensorflow-lite-select-tf-ops"" dependency. See instructions: https://www.tensorflow.org/lite/guide/ops_select_

It looks that flex library was not applied therefore I provided some dubugging inside tflight library. As I could see the main function for Flex delegate initialization is  **AcquireFlexDelegate()**. It can be found both 
\tensorflow\tensorflow\lite\core\interpreter_builder.cc (Weak function version in tflight library) and 
\tensorflow\tensorflow\lite\delegates\flex\delegate_symbol.cc (Strong function version in flex library).

I also found correspondent symbols on **nm** command output
00000000050b53b8 T _ZN6tflite19AcquireFlexDelegateEv@@VERS_1.0  (libtensorflowlite_flex.so)
00000000003b8a4c W _ZN6tflite19AcquireFlexDelegateEv@@VERS_1.0  (libtensorflowlite.so)

As I understand from code for Android case weak linking mechanism should be used and  AcquireFlexDelegate() from libtensorflowlite_flex.so should be called instead of the same function from  libtensorflowlite.so. Correspondent code in \tensorflow\tensorflow\lite\core\interpreter_builder.cc:

___TfLiteStatus InterpreterBuilder::ApplyDelegates(Interpreter* interpreter) {_
  // Apply Flex delegate if applicable.
  if (has_flex_op_) {
    if (Interpreter::TfLiteDelegatePtr flex_delegate = **AcquireFlexDelegate())** {
...._

But on debugging I could see that  **ApplyDelegates()** from libtensorflowlite.so (in my case has_flex_op_ == true) is called and return trivial delegate. This is the reason of further error messages and crash as the function from flex library is not called.

On Ubuntu the same code works well but in this case ApplyDelegates() from libtensorflowlite.so is called and then flex lib is called clear by
_auto acquire_flex_delegate_func = reinterpret_cast<Interpreter::TfLiteDelegatePtr (*)()>(SharedLibrary::GetSymbol(""TF_AcquireFlexDelegate""));_
Unfortunatelly, from code comments I see that this approach is not appropriate for Android as ""TF_AcquireFlexDelegate"" is not defined for this os.

Please, clarify me the write way of using flex lib in native C/C++ on Android using Cmake in Android Studio. Possibly my linking procedure is not fully correct in Cmake, or I wrongly understand the above workflow or some other reason.
I will be very grateful for answer!

### Standalone code to reproduce the issue

```shell
CMakeLists.txt:
...

include_directories(myapp INTERFACE
   ...
   ""${TFLITE_INCLUDE_PATH}""
   ""${TFLITE_THIRDPARTY_DIR}/flatbuffers/include""
   ""${TFLITE_THIRDPARTY_DIR}/absl""
   ...
)

target_compile_options(myapp PRIVATE -Wno-deprecated-declarations)

target_link_libraries(myapp
        ...
        ${TFLITE_LIBRARY_DIR}/libtensorflowlite.so
        ${TFLITE_LIBRARY_DIR}/libtensorflowlite_gpu_delegate.so
        ...                        
)

add_library(TFLITE_FLEX SHARED IMPORTED)
set_target_properties(TFLITE_FLEX PROPERTIES IMPORTED_LOCATION ${TFLITE_LIBRARY_DIR2}/libtensorflowlite_flex.so)
target_link_libraries(myapp TFLITE_FLEX)
```


### Relevant log output

```shell
I/tflite: Created TensorFlow Lite XNNPACK delegate for CPU.
E/tflite: Select TensorFlow op(s), included in the given model, is(are) not supported by this interpreter. Make sure you apply/link the Flex delegate before inference. For the Android, it can be resolved by adding ""org.tensorflow:tensorflow-lite-select-tf-ops"" dependency. See instructions: https://www.tensorflow.org/lite/guide/ops_select
E/tflite: Node number 12 (FlexTranspose) failed to prepare.
E/tflite: Select TensorFlow op(s), included in the given model, is(are) not supported by this interpreter. Make sure you apply/link the Flex delegate before inference. For the Android, it can be resolved by adding ""org.tensorflow:tensorflow-lite-select-tf-ops"" dependency. See instructions: https://www.tensorflow.org/lite/guide/ops_select
E/tflite: Node number 12 (FlexTranspose) failed to prepare.
E/: Error at .../cpp/detector.cc, bool seeso::Detector::buildInterpreter(), line 98
```
"
2658206097,80019,"App Crash with YOLO11n TFLite Model on Android.  Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR) on GPU mode",closed,2024-11-14 09:35:00+00:00,2025-01-22T21:07:38Z,2025-01-22T21:07:35Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/80019,"['stat:awaiting tensorflower', 'type:bug', 'comp:lite', 'TF 2.16']","[""Hi, @emoo44566 \r\n\r\nI apologize for the delayed response, I am able to replicate the same behavior from my end with `YOLO11n` TFLite model on Android and app is getting crashed for reference I've recorded the screen here is [link ](https://drive.google.com/file/d/1odXw7cFyeWvMI1YKwGKphUrA3MPj4gwI/view?usp=sharing), Thank you for bringing this issue to our attention and will have to dig more into this issue. I see one of the user also reported the similar issue https://github.com/tensorflow/tensorflow/issues/78396\r\n\r\nThank you for your cooperation and patience."", 'Is there any fix yet? I am seeing the same issue', 'seems still an issue?\r\n', 'Hi, @pkgoogle \nPlease take a look into this issue. Thank you.', 'This does seem similar to that other issue... I will make a new issue for this in LiteRT for now. @hcdino Please open future issues in the LiteRT repo from now on. We will continue investigation to see if it is a duplicate or not.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80019"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80019"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.16.1 

### Custom code

Yes

### OS platform and distribution

Android

### Mobile device

Some Android Devices

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I converted the YOLO11n model to TensorFlow Lite (TFLite) and used it in my Android app. However, my app crashes on some Android devices, and the following error appears in Logcat:
`Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR)`

To create the TFLite model, I tried various conversion options in YOLO, as shown below:
```
# Load a model
model = YOLO(""yolo11n.pt"")  # load an official model
# model = YOLO(""path/to/best.pt"")  # load a custom trained model

# Export the model
# model.export(format=""tflite"", half = True, batch = 4)

model.export(format=""tflite"", half = True, int8 = True)
```
Despite testing different configurations, the app consistently crashes when using the model in GPU mode.

Interestingly, this issue only occurs with the YOLO11n TFLite model. When I use other TFLite models, such as YOLOv8n or YOLOv9t, everything works fine. This suggests there may be a compatibility issue or a bug in the TFLite Android library specific to the YOLO11n model.




### Standalone code to reproduce the issue

```shell
I'm testing my YOLO TFLite model with the code in this repository:
https://github.com/surendramaran/YOLO/tree/main/YOLOv9-Object-Detector-Android-Tflite
```


### Relevant log output

_No response_"
2665973288,80177,ImportError: DLL load failed while importing _pywrap_tensorflow_internal: ,closed,2024-11-17 14:43:50+00:00,2024-12-04T02:08:29Z,2024-12-04T02:08:26Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/80177,"['stat:awaiting response', 'type:bug', 'stale', 'TF 2.18']","['Hi **@noteandcode** ,\r\nThe error you are facing, `DLL load failed`, is likely due to incompatible versions. Could you please check all the compatible versions and let us know which OS platform you are using? Additionally, please try to fill out all the required templates as it will help us troubleshoot more effectively. And here i am providing [documentation](https://www.tensorflow.org/install/source#linux) for your reference.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80177"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80177"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.18

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

3.11,8

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I cant run my streamlit file that contains pipline element.

### Standalone code to reproduce the issue

```shell
It is in visual studio code.
```


### Relevant log output

```shell
RuntimeError: Failed to import transformers.pipelines because of the following error (look up to see its traceback): Traceback (most recent call last): File ""C:\Users\Piroska\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 70, in <module> from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: Nem sikerült egy dinamikus csatolású függvénytár (DLL) inicializáló rutinját végrehajtani. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors for some common causes and solutions. If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.
```
"
2671052079,80237,Improve Documentation for TensorFlow Setup on Windows,closed,2024-11-19 07:19:44+00:00,2024-12-06T02:07:50Z,2024-12-06T02:07:46Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/80237,"['type:docs-bug', 'stat:awaiting response', 'type:bug', 'stale']","['@kayladoann,\r\nIf you are specifically asking for the Windows, TensorFlow 2.10 was the last TensorFlow release that supported GPU on native-Windows. Starting with TensorFlow 2.11, you will need to install [TensorFlow in WSL2](https://tensorflow.org/install/pip#windows-%5Bwsl2%5D), or install tensorflow-cpu and, optionally, try the [TensorFlow-DirectML-Plugin](https://github.com/microsoft/tensorflow-directml-plugin#tensorflow-directml-plugin-). Instead you can use WSL2 - https://www.tensorflow.org/install/pip#windows-wsl2_1\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80237"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80237"">No</a>\n']","### Issue type

Documentation Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.16

### Custom code

Yes

### OS platform and distribution

Windows 10/11

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

The TensorFlow installation guide for Windows does not include detailed troubleshooting guidance for:
- Resolving PATH environment variable conflicts.
- Managing mismatches in CUDA and cuDNN versions during GPU setup.
- Debugging pip installation errors in virtual environments.
This creates challenges for new users trying to install TensorFlow on Windows, especially when dealing with GPU setup.



### Standalone code to reproduce the issue

```shell
A bare minimum reproducible test case to identify TensorFlow installation and GPU setup issues on Windows:

import tensorflow as tf

# Check TensorFlow version
print(""TensorFlow version:"", tf.__version__)

# Check GPU availability
gpu_devices = tf.config.list_physical_devices('GPU')
if gpu_devices:
    print(f""Number of GPUs detected: {len(gpu_devices)}"")
    for gpu in gpu_devices:
        print(f""GPU: {gpu}"")
else:
    print(""No GPUs detected. TensorFlow will run on CPU."")

# Perform a simple TensorFlow operation
try:
    print(""\nRunning a simple computation..."")
    a = tf.constant([[1, 2], [3, 4]])
    b = tf.constant([[5, 6], [7, 8]])
    c = tf.matmul(a, b)
    print(""Matrix multiplication result:\n"", c.numpy())
except Exception as e:
    print(""Error during TensorFlow computation:"", e)
```


### Relevant log output

_No response_"
2674073773,80312,Aborted (core dumped) in `tf.raw_ops.Cholesky`,closed,2024-11-20 01:59:39+00:00,2024-12-10T02:09:26Z,2024-12-10T02:09:19Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/80312,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","['Hi **@x0w3n** ,\r\nApologies for the delay, and thank you for raising your concern here. I tried running your code on Colab using TensorFlow 2.18.0 and the nightly versions and faced the same issue. As an alternative, I used a Hermitian matrix instead of a scalar matrix, and it worked fine. I hope this helps you. Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/5d049835658b4eab15f1eb8788725385/80312_tf-2-18-0-nightly-v.ipynb) here for your reference.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80312"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80312"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.17

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When the shape of the input argument is empty and the gpu is available, tf.raw_ops.Cholesky triggers a crash.
It can be reproduced on tf-nightly when the gpu is available.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
tf.raw_ops.Cholesky(input=tf.cast(tf.random.uniform([], dtype=tf.dtypes.float32, maxval=10), dtype=tf.complex64),)
```


### Relevant log output

```shell
2024-11-20 09:57:25.507816: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-11-20 09:57:25.568143: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-11-20 09:57:25.643565: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-11-20 09:57:25.666794: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-11-20 09:57:25.694104: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-11-20 09:57:33.643380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21903 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:1f:00.0, compute capability: 8.9
2024-11-20 09:57:33.645593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 71 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:d4:00.0, compute capability: 8.9
2024-11-20 09:57:34.517615: F tensorflow/core/framework/tensor_shape.cc:356] Check failed: d >= 0 (0 vs. -1)
Aborted (core dumped)
```
"
2674103396,80314,Aborted (core dumped) in `tf.raw_ops.CropAndResizeGradBoxes`,closed,2024-11-20 02:24:56+00:00,2024-11-26T00:37:07Z,2024-11-26T00:37:04Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/80314,"['stat:awaiting response', 'type:bug', 'comp:ops', '2.17']","['@x0w3n,\r\nI request you to take a look at this https://github.com/tensorflow/tensorflow/issues/65721 where a similar issue has been proposed and it is still open. Also I request to follow the similar issue which has been proposed to have the updates on the similar issue. Thank you!', ""Thanks for pointing out #65721. I’ll go ahead and close this issue since it's covered by the other one. Thanks!"", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80314"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80314"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.17

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

With specific input, tf.raw_ops.CropAndResizeGradBoxes triggers a crash.
It can be reproduced on tf-nightly.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
grads = tf.random.uniform([0, 8, 1, 2], dtype=tf.dtypes.float32, maxval=100000000)
image = tf.random.uniform([0, 8, 1, 2], dtype=tf.dtypes.int32, minval=-100000, maxval=1000000)
boxes = tf.random.uniform([0], dtype=tf.dtypes.float32, maxval=100000000)
box_ind = tf.random.uniform([1, 8, 0, 0], dtype=tf.dtypes.int32, minval=-100000, maxval=1000000)
tf.raw_ops.CropAndResizeGradBoxes(grads=grads,image=image,boxes=boxes,box_ind=box_ind,method=""bilinear"",)
```


### Relevant log output

```shell
2024-11-20 10:20:02.514545: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-11-20 10:20:02.535316: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-11-20 10:20:02.549411: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-11-20 10:20:02.553443: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-11-20 10:20:02.586202: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-11-20 10:20:09.256556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21903 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:1f:00.0, compute capability: 8.9
2024-11-20 10:20:09.256908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 71 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:d4:00.0, compute capability: 8.9
2024-11-20 10:20:10.096248: F tensorflow/core/framework/tensor_shape.cc:45] Check failed: NDIMS == dims() (1 vs. 4)Asking for tensor of 1 dimensions from a tensor of 4 dimensions
Aborted (core dumped)
```
"
2674116576,80315,Aborted (core dumped) in `tf.raw_ops.MatrixDeterminant/tf.raw_ops.LogMatrixDeterminant`,closed,2024-11-20 02:36:50+00:00,2024-12-12T02:08:10Z,2024-12-12T02:08:05Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/80315,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","['Hi **@x0w3n** ,\r\nApologies for the delay, and thank you for raising your concern here. I tried running your code on Colab using TensorFlow 2.18.0 and the nightly versions and faced the same issue. As an alternative, I used a non empty argument and it worked fine. I hope this helps you. Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/ad1be2264c5c69dc4c073de9b4824766/80315_tf-2-18-0-nightly-v.ipynb) here for your reference.\r\nThank you!', 'Thank you for the suggestion.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80315"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80315"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.17

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When the shape of the input argument is empty and the gpu is available, tf.raw_ops.MatrixDeterminant/ tf.raw_ops.LogMatrixDeterminant triggers a crash.
It can be reproduced on tf-nightly when the gpu is available.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
tf.raw_ops.LogMatrixDeterminant(input=tf.cast(tf.random.uniform([], dtype=tf.dtypes.float32, maxval=60000), dtype=tf.complex64),)


import tensorflow as tf
tf.raw_ops.MatrixDeterminant(input=tf.cast(tf.random.uniform([], dtype=tf.dtypes.float32, maxval=60000), dtype=tf.complex64),)
```


### Relevant log output

```shell
2024-11-20 10:33:29.999480: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-11-20 10:33:30.059256: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-11-20 10:33:30.136255: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-11-20 10:33:30.160665: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-11-20 10:33:30.216533: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-11-20 10:33:37.860746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21903 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:1f:00.0, compute capability: 8.9
2024-11-20 10:33:37.863142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 71 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:d4:00.0, compute capability: 8.9
2024-11-20 10:33:38.666859: F tensorflow/core/framework/tensor_shape.cc:356] Check failed: d >= 0 (0 vs. -1)
Aborted (core dumped)
```
"
2674701175,80332,Aborted (core dumped) in `tf.raw_ops.RaggedTensorToVariantGradient`,closed,2024-11-20 07:05:56+00:00,2024-12-12T02:08:06Z,2024-12-12T02:08:03Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/80332,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","['Hi **@x0w3n** ,\r\nApologies for the delay, and thank you for raising your concern here. I tried running your code on Colab using TensorFlow 2.18.0 and the nightly versions and faced the same issue. However, I tried an alternative approach, and it worked fine for me. I hope this will be helpful to you. Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/9567e5c2f1e3167ad1f713397432c00a/80332_tf-2-18-0-nightly-v.ipynb) here for your reference.\r\nThank you!\r\n', 'Thank you for the suggestion.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80332"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80332"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.17

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

With a specific input and the gpu available, tf.raw_ops.RaggedTensorToVariantGradient triggers a crash.
It can be reproduced on tf-nightly when the gpu is available.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf


encoded_ragged_grad = tf.data.experimental.to_variant(
    tf.data.Dataset.from_tensor_slices([1, 2, 3])
)
row_splits = tf.random.uniform(
    [2, 2, 2, 1, 8, 8, 2, 1],
    dtype=tf.dtypes.int32,
    minval=-100000,
    maxval=1000000
)
dense_values_shape = tf.random.uniform(
    [0, 0, 4, 1],
    dtype=tf.dtypes.int32,
    minval=-100000,
    maxval=1000000
)
Tvalues = tf.dtypes.int32


result = tf.raw_ops.RaggedTensorToVariantGradient(
    encoded_ragged_grad=encoded_ragged_grad,
    row_splits=row_splits,
    dense_values_shape=dense_values_shape,
    Tvalues=Tvalues
)

print(result)
```


### Relevant log output

```shell
2024-11-20 14:54:41.997416: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-11-20 14:54:42.057982: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-11-20 14:54:42.134026: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-11-20 14:54:42.158043: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-11-20 14:54:42.178297: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-11-20 14:54:49.604912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22290 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:1f:00.0, compute capability: 8.9
2024-11-20 14:54:49.607192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 234 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:d4:00.0, compute capability: 8.9
2024-11-20 14:54:50.489456: F tensorflow/core/framework/tensor_shape.cc:45] Check failed: NDIMS == dims() (1 vs. 4)Asking for tensor of 1 dimensions from a tensor of 4 dimensions
Aborted (core dumped)
```
"
2674727663,80334,Aborted (core dumped) in `tf.raw_ops.TridiagonalSolve`,closed,2024-11-20 07:21:35+00:00,2024-12-10T02:09:24Z,2024-12-10T02:09:17Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/80334,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","['@x0w3n,\r\nHave you got the chance to check the commit which was created for the tf.raw_ops.TridiagonalSolve has been implemented. \r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/8b742f8559e88474735d0a2c03e00da65e40b412\r\n\r\n```python\r\n  OP_REQUIRES_OK(context, TensorShape::BuildTensorShape({num_rows, num_cols},\r\n                                                          &input_shape));\r\n    input_matrix_shapes->push_back(std::move(input_shape));\r\n```', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80334"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80334"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.17

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.3 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When the shape of the diagonals argument is empty and the gpu is available, tf.raw_ops.TridiagonalSolve triggers a crash.
It can be reproduced on tf-nightly when the gpu is available.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf


diagonals = tf.cast(
    tf.random.uniform([], dtype=tf.dtypes.float32, maxval=60000), dtype=tf.complex64
)
rhs = tf.cast(
    tf.random.uniform([2], dtype=tf.dtypes.float32, maxval=60000), dtype=tf.complex64
)
partial_pivoting = False
perturb_singular = False

result = tf.raw_ops.TridiagonalSolve(
    diagonals=diagonals,
    rhs=rhs,
    partial_pivoting=partial_pivoting,
    perturb_singular=perturb_singular
)

print(result)
```


### Relevant log output

```shell
2024-11-20 15:07:55.059745: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-11-20 15:07:55.070582: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-11-20 15:07:55.108323: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-11-20 15:07:55.132372: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-11-20 15:07:55.187323: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-11-20 15:08:02.847006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22290 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:1f:00.0, compute capability: 8.9
2024-11-20 15:08:02.849328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 234 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:d4:00.0, compute capability: 8.9
2024-11-20 15:08:03.744404: F tensorflow/core/framework/tensor_shape.cc:356] Check failed: d >= 0 (0 vs. -1)
Aborted (core dumped)
```
"
2681571264,80528,Aborted (core dumped) in `SparseTensorDenseMatMul`,closed,2024-11-22 02:49:05+00:00,2024-12-10T02:09:20Z,2024-12-10T02:09:16Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/80528,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","['I request you to take a look at this #65724 where a similar issue has been proposed and it is still open. Also I request to follow the similar issue which has been proposed to have the updates on the similar issue. Thank you!', 'Thank you for your reply, I will pay attention to this issue', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80528"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80528"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf2.17.0

### Custom code

Yes

### OS platform and distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Under specific inputs, `SparseTensorDenseMatMul` triggered a crash.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

a_indices = tf.constant(1879048192, shape=[2,2], dtype=tf.int64)
a_values = tf.constant(0, shape=[2], dtype=tf.float32)
a_shape = tf.constant([-1, 5], dtype=tf.int64)
b = tf.constant(0, shape=[5, 5], dtype=tf.float32)

result = tf.raw_ops.SparseTensorDenseMatMul(
    a_indices=a_indices,
    a_values=a_values,
    a_shape=a_shape,
    b=b
)
```


### Relevant log output

```shell
Status: INVALID_ARGUMENT: Expected shape dimensions to be non-negative, got -1
Aborted (core dumped)
```
"
2687469548,80682,heap-buffer-overflow in `ConjugateTranspose`,closed,2024-11-24 09:39:44+00:00,2024-12-13T02:08:48Z,2024-12-13T02:08:45Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/80682,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","['@LongZE666,\r\nI request you to take a look at this https://github.com/tensorflow/tensorflow/issues/69213 and https://github.com/tensorflow/tensorflow/issues/63033 where a similar issue has been proposed and it is still open. Also I request to follow the similar issue which has been proposed to have the updates on the similar issue. Thank you!\r\n', 'Okay, I will pay attention to these issues, thank you', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80682"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80682"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf2.17.0 tf2.16.1

### Custom code

Yes

### OS platform and distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Under specific inputs,`ConjugateTranspose` triggered a crash.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

x = tf.constant(0, shape=[1,3], dtype=tf.complex128)
perm = tf.constant([0,-1], dtype=tf.int32)

tf.raw_ops.ConjugateTranspose(x=x, perm=perm)
```


### Relevant log output

```shell
=================================================================
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizerAddressSanitizer:DEADLYSIGNAL
AddressSanitizerAddressSanitizerAddressSanitizerAddressSanitizer:DEADLYSIGNAL
AddressSanitizerAddressSanitizerAddressSanitizer:DEADLYSIGNAL
:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
:DEADLYSIGNAL
AddressSanitizerAddressSanitizerAddressSanitizer:DEADLYSIGNAL
:DEADLYSIGNAL
:DEADLYSIGNAL
:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
:DEADLYSIGNAL
:DEADLYSIGNAL
:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizerAddressSanitizerAddressSanitizerAddressSanitizer:DEADLYSIGNAL
:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizerAddressSanitizerAddressSanitizer:DEADLYSIGNAL
AddressSanitizerAddressSanitizerAddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
:DEADLYSIGNAL
:DEADLYSIGNAL
:DEADLYSIGNAL
AddressSanitizerAddressSanitizerAddressSanitizerAddressSanitizer:DEADLYSIGNAL
AddressSanitizerAddressSanitizerAddressSanitizerAddressSanitizer:DEADLYSIGNAL
:DEADLYSIGNAL
:DEADLYSIGNAL
:DEADLYSIGNAL
:DEADLYSIGNAL
:DEADLYSIGNAL
:DEADLYSIGNAL
:DEADLYSIGNAL
:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizerAddressSanitizer:DEADLYSIGNAL
:DEADLYSIGNAL
==2084475==ERROR: AddressSanitizer: heap-buffer-overflow on address 0x609000000320 at pc 0x7fc342398a73 bp 0x7fc2ad518360 sp 0x7fc2ad518350
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
READ of size 16 at 0x609000000320 thread T143
AddressSanitizerAddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizerAddressSanitizer:DEADLYSIGNAL
:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
AddressSanitizerAddressSanitizerAddressSanitizer:DEADLYSIGNAL
:DEADLYSIGNAL
AddressSanitizer:DEADLYSIGNAL
:DEADLYSIGNAL
    #0 0x7fc342398a72 in std::_Function_handler<void (long, long), Eigen::internal::TensorExecutor<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<std::complex<double>, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorShufflingOp<Eigen::array<int, 2ul> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_conjugate_op<std::complex<double> const>, Eigen::TensorMap<Eigen::Tensor<std::complex<double> const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::ThreadPoolDevice, false, (Eigen::internal::TiledEvaluation)0>::run(Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<std::complex<double>, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorShufflingOp<Eigen::array<int, 2ul> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_conjugate_op<std::complex<double> const>, Eigen::TensorMap<Eigen::Tensor<std::complex<double> const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const&, Eigen::ThreadPoolDevice const&)::{lambda(long, long)#1}>::_M_invoke(std::_Any_data const&, long&&, long&&) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x482b6a72)
    #1 0x7fc30fb37250 in std::_Function_handler<void (long, long), Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda(long, long)#1}>::_M_invoke(std::_Any_data const&, long&&, long&&) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x15a55250)
    #2 0x7fc30fa9f2f6 in std::_Function_handler<void (), Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda()#2}>::_M_invoke(std::_Any_data const&) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x159bd2f6)
    #3 0x7fc36666b121 in Eigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x41fd121)
    #4 0x7fc366660326 in void absl::lts_20230802::internal_any_invocable::RemoteInvoker<false, void, tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}&>(absl::lts_20230802::internal_any_invocable::TypeErasedState*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x41f2326)
    #5 0x7fc364f8625c in tsl::(anonymous namespace)::PThread::ThreadFn(void*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x2b1825c)
    #6 0x7fc41020eac2  (/lib/x86_64-linux-gnu/libc.so.6+0x94ac2)
    #7 0x7fc41029fa03 in __clone (/lib/x86_64-linux-gnu/libc.so.6+0x125a03)

0x609000000320 is located 112 bytes to the right of 48-byte region [0x609000000280,0x6090000002b0)
allocated by thread T0 here:
    #0 0x7fc41059257c in __interceptor_posix_memalign ../../../../src/libsanitizer/asan/asan_malloc_linux.cpp:226
    #1 0x7fc3676556de in tsl::port::AlignedMalloc(unsigned long, int) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x51e76de)
    #2 0x7fc36413f0aa in tensorflow::MklCPUAllocator::AllocateRaw(unsigned long, unsigned long) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x1cd10aa)
    #3 0x7fc364e4f566 in tensorflow::Tensor::Tensor(tsl::Allocator*, tensorflow::DataType, tensorflow::TensorShape const&, tsl::AllocationAttributes const&) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x29e1566)
    #4 0x7fc364571922 in tensorflow::OpKernelContext::allocate_tensor(tensorflow::DataType, tensorflow::TensorShape const&, tensorflow::Tensor*, tsl::AllocatorAttributes, tsl::AllocationAttributes const&) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x2103922)
    #5 0x7fc364574cdb in tensorflow::OpKernelContext::allocate_output(int, tensorflow::TensorShape const&, tensorflow::Tensor**, tsl::AllocatorAttributes) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x2106cdb)
    #6 0x7fc364576a5b in tensorflow::OpKernelContext::allocate_output(int, tensorflow::TensorShape const&, tensorflow::Tensor**) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x2108a5b)
    #7 0x7fc33f988f27 in tensorflow::TransposeOp::Compute(tensorflow::OpKernelContext*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x458a6f27)
    #8 0x7fc36414a14a in tensorflow::ThreadPoolDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x1cdc14a)
    #9 0x7fc363cd0fe6 in tensorflow::(anonymous namespace)::SingleThreadedExecutorImpl::Run(tensorflow::Executor::Args const&) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x1862fe6)
    #10 0x7fc363bad306 in tensorflow::FunctionLibraryRuntimeImpl::RunSync(tensorflow::FunctionLibraryRuntime::Options, unsigned long, absl::lts_20230802::Span<tensorflow::Tensor const>, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x173f306)
    #11 0x7fc363c0af74 in tensorflow::ProcessFunctionLibraryRuntime::RunMultiDeviceSync(tensorflow::FunctionLibraryRuntime::Options const&, unsigned long, std::vector<std::variant<tensorflow::Tensor, tensorflow::TensorShape>, std::allocator<std::variant<tensorflow::Tensor, tensorflow::TensorShape> > >*, std::function<absl::lts_20230802::Status (tensorflow::ProcessFunctionLibraryRuntime::ComponentFunctionData const&, tensorflow::ProcessFunctionLibraryRuntime::InternalArgs*)>) const (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x179cf74)
    #12 0x7fc363c188b1 in tensorflow::ProcessFunctionLibraryRuntime::RunSync(tensorflow::FunctionLibraryRuntime::Options const&, unsigned long, absl::lts_20230802::Span<tensorflow::Tensor const>, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*) const (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x17aa8b1)
    #13 0x7fc32bd3a2eb in tensorflow::KernelAndDeviceFunc::Run(tensorflow::ScopedStepContainer*, tensorflow::EagerKernelArgs const&, std::vector<std::variant<tensorflow::Tensor, tensorflow::TensorShape>, std::allocator<std::variant<tensorflow::Tensor, tensorflow::TensorShape> > >*, tsl::CancellationManager*, std::optional<tensorflow::EagerFunctionParams> const&, std::optional<tensorflow::ManagedStackTrace> const&, tsl::CoordinationServiceAgent*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x31c582eb)
    #14 0x7fc32bbcfc2c in tensorflow::EagerKernelExecute(tensorflow::EagerContext*, absl::lts_20230802::InlinedVector<tensorflow::TensorHandle*, 4ul, std::allocator<tensorflow::TensorHandle*> > const&, std::optional<tensorflow::EagerFunctionParams> const&, tsl::core::RefCountPtr<tensorflow::KernelAndDevice> const&, tensorflow::GraphCollector*, tsl::CancellationManager*, absl::lts_20230802::Span<tensorflow::TensorHandle*>, std::optional<tensorflow::ManagedStackTrace> const&) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x31aedc2c)
    #15 0x7fc32bbd266a in tensorflow::ExecuteNode::Run() (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x31af066a)
    #16 0x7fc32bd0c939 in tensorflow::EagerExecutor::SyncExecute(tensorflow::EagerNode*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x31c2a939)
    #17 0x7fc32bbbfde4 in tensorflow::(anonymous namespace)::EagerLocalExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x31addde4)
    #18 0x7fc32bbc3dd4 in tensorflow::DoEagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x31ae1dd4)
    #19 0x7fc32bbcdd26 in tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x31aebd26)
    #20 0x7fc31abb6c33 in tensorflow::EagerOperation::Execute(absl::lts_20230802::Span<tensorflow::AbstractTensorHandle*>, int*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x20ad4c33)
    #21 0x7fc32bd01e5e in tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x31c1fe5e)
    #22 0x7fc30a73445b in TFE_Execute (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x1065245b)
    #23 0x7fc3620e2274 in TFE_Py_FastPathExecute_C(_object*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../_pywrap_tensorflow_internal.so+0x3c2274)
    #24 0x7fc2f60a2ccb in pybind11::cpp_function::initialize<pybind11_init__pywrap_tfe(pybind11::module_&)::{lambda(pybind11::args)#61}, pybind11::object, pybind11::args, pybind11::name, pybind11::scope, pybind11::sibling>(pybind11_init__pywrap_tfe(pybind11::module_&)::{lambda(pybind11::args)#61}&&, pybind11::object (*)(pybind11::args), pybind11::name const&, pybind11::scope const&, pybind11::sibling const&)::{lambda(pybind11::detail::function_call&)#3}::_FUN(pybind11::detail::function_call&) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/_pywrap_tfe.so+0xb7ccb)
    #25 0x7fc2f61b9899 in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/_pywrap_tfe.so+0x1ce899)
    #26 0x51ad66  (/usr/bin/python3.11+0x51ad66)

Thread T143 created by T0 here:
    #0 0x7fc410535685 in __interceptor_pthread_create ../../../../src/libsanitizer/asan/asan_interceptors.cpp:216
    #1 0x7fc364f93fbf in tsl::(anonymous namespace)::PThread::PThread(tsl::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, absl::lts_20230802::AnyInvocable<void ()>) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x2b25fbf)
    #2 0x7fc364f9450a in tsl::(anonymous namespace)::PosixEnv::StartThread(tsl::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, absl::lts_20230802::AnyInvocable<void ()>) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x2b2650a)
    #3 0x7fc3666693a8 in Eigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::ThreadPoolTempl(int, bool, tsl::thread::EigenEnvironment) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x41fb3a8)
    #4 0x7fc36666d498 in tsl::thread::ThreadPool::ThreadPool(tsl::Env*, tsl::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int, bool, Eigen::Allocator*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x41ff498)
    #5 0x7fc36414f278 in tensorflow::LocalDevice::EigenThreadPoolInfo::EigenThreadPoolInfo(tensorflow::SessionOptions const&, int, tsl::Allocator*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x1ce1278)
    #6 0x7fc3641505c5 in tensorflow::LocalDevice::LocalDevice(tensorflow::SessionOptions const&, tensorflow::DeviceAttributes const&) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x1ce25c5)
    #7 0x7fc364143111 in tensorflow::ThreadPoolDevice::ThreadPoolDevice(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tsl::gtl::IntType<tensorflow::Bytes_tag_, long>, tensorflow::DeviceLocality const&, tsl::Allocator*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x1cd5111)
    #8 0x7fc36413c1dd in tensorflow::ThreadPoolDeviceFactory::CreateDevices(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x1cce1dd)
    #9 0x7fc36430667c in tensorflow::DeviceFactory::AddCpuDevices(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x1e9867c)
    #10 0x7fc364306bbd in tensorflow::DeviceFactory::AddDevices(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2+0x1e98bbd)
    #11 0x7fc30a736db8 in TFE_NewContext (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x10654db8)
    #12 0x7fc2f61a1e70 in pybind11::cpp_function::initialize<pybind11_init__pywrap_tfe(pybind11::module_&)::{lambda(TFE_ContextOptions const*)#9}, pybind11::object, TFE_ContextOptions const*, pybind11::name, pybind11::scope, pybind11::sibling, pybind11::return_value_policy>(pybind11_init__pywrap_tfe(pybind11::module_&)::{lambda(TFE_ContextOptions const*)#9}&&, pybind11::object (*)(TFE_ContextOptions const*), pybind11::name const&, pybind11::scope const&, pybind11::sibling const&, pybind11::return_value_policy const&)::{lambda(pybind11::detail::function_call&)#3}::_FUN(pybind11::detail::function_call&) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/_pywrap_tfe.so+0x1b6e70)
    #13 0x7fc2f61b9899 in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/_pywrap_tfe.so+0x1ce899)
    #14 0x51ad66  (/usr/bin/python3.11+0x51ad66)

SUMMARY: AddressSanitizer: heap-buffer-overflow (/mnt/tensorflow-asan/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2+0x482b6a72) in std::_Function_handler<void (long, long), Eigen::internal::TensorExecutor<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<std::complex<double>, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorShufflingOp<Eigen::array<int, 2ul> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_conjugate_op<std::complex<double> const>, Eigen::TensorMap<Eigen::Tensor<std::complex<double> const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::ThreadPoolDevice, false, (Eigen::internal::TiledEvaluation)0>::run(Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<std::complex<double>, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorShufflingOp<Eigen::array<int, 2ul> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_conjugate_op<std::complex<double> const>, Eigen::TensorMap<Eigen::Tensor<s
Shadow bytes around the buggy address:
  0x0c127fff8010: fa fa fa fa fa fa fa fa fd fa fa fa fa fa fa fa
  0x0c127fff8020: fa fa fa fa fa fa fa fa 00 00 00 00 00 00 fa fa
  0x0c127fff8030: fa fa fa fa fa fa fa fa 00 fa fa fa fa fa fa fa
  0x0c127fff8040: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x0c127fff8050: 00 00 00 00 00 00 fa fa fa fa fa fa fa fa fa fa
=>0x0c127fff8060: fa fa fa fa[fa]fa fa fa fa fa fa fa fa fa fa fa
  0x0c127fff8070: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x0c127fff8080: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x0c127fff8090: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x0c127fff80a0: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x0c127fff80b0: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
Shadow byte legend (one shadow byte represents 8 application bytes):
  Addressable:           00
  Partially addressable: 01 02 03 04 05 06 07
  Heap left redzone:       fa
  Freed heap region:       fd
  Stack left redzone:      f1
  Stack mid redzone:       f2
  Stack right redzone:     f3
  Stack after return:      f5
  Stack use after scope:   f8
  Global redzone:          f9
  Global init order:       f6
  Poisoned by user:        f7
  Container overflow:      fc
  Array cookie:            ac
  Intra object redzone:    bb
  ASan internal:           fe
  Left alloca redzone:     ca
  Right alloca redzone:    cb
  Shadow gap:              cc
==2084475==ABORTING
```
"
2689651458,80729,Aborted (core dumped) in `ParameterizedTruncatedNormal`,closed,2024-11-25 08:00:02+00:00,2024-12-12T02:08:04Z,2024-12-12T02:08:01Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/80729,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","['Hi **@LongZE666** ,\r\nThank you for raising your concern here. I tried running your code on Colab using TensorFlow 2.17.0 and faced the same issue. However, with TensorFlow 2.18.0 and the nightly versions, it works fine. We always recommend using the latest versions for better results. Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/1a2cffe96ec3c88db94255ff598796d1/80729_tf-2-17-2-18-0-nightly-v.ipynb) here for your reference.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80729"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80729"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf2.17.0 tf2.16.1

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Under specific inputs, `ParameterizedTruncatedNormal` triggered a crash.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

shape = tf.constant([1610637938, 2], dtype=tf.int32)
means = tf.constant(7.89645e+16, shape=[], dtype=tf.float32)
stdevs = tf.constant(1.251e+12, shape=[], dtype=tf.float32)
minvals = tf.constant(1.23457e+13, shape=[], dtype=tf.float32)
maxvals = tf.constant(1.11111e+15, shape=[], dtype=tf.float32)
seed = 1618
seed2 = 0
tf.raw_ops.ParameterizedTruncatedNormal(shape=shape, means=means, stdevs=stdevs, minvals=minvals, maxvals=maxvals, seed=seed, seed2=seed2, name=None)
```


### Relevant log output

```shell
2024-11-25 07:56:01.911210: F tensorflow/core/util/work_sharder.cc:59] Check failed: total >= 0 (0 vs. -10736913)
Aborted (core dumped)
```
"
2689944864,80739,keras model does not learn if using tf.data pipeline,closed,2024-11-25 09:28:44+00:00,2024-11-26T16:56:39Z,2024-11-26T11:39:09Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/80739,"['stat:awaiting response', 'type:bug', 'comp:data', 'TF 2.16']","['@x1o,\r\nI tried to execute the mentioned code and observed the code was executed with a different error. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/71354affa216301557d3f760aa3665fd/untitled2252.ipynb) and please provide the complete code and the dependencies required which helps to debug the issue in an effective way. \r\n\r\nAlso the error might be  tf.function used with AutoGraph disabled. And in keras3 AutoGraph disabled by default. Please take a look for details about [AutoGraph](https://keras.io/guides/migrating_to_keras_3/#tf-autograph).\r\n\r\nYou need to use Eager execution mode model.compile(steps_per_execution=33,run_eagerly=True) to enable AutoGraph for keras3.\r\n\r\nThank you!', ""@tilakrayal,\r\n\r\nthank you for your time. I've discovered the problem was due to the implicit shuffling in fit() when working with Numpy array data, contrasting with the absence of such shuffling in the tf.data pipeline. Shuffling is suitable even in time series analysis since the data were pre-aggregated, thus preserving the internal temporal structure.\r\n"", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80739"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80739"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

tf 2.16.2

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 24.04

### Mobile device

_No response_

### Python version

3.12.3

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

8907

### GPU model and memory

_No response_

### Current behavior?

A `keras` model *does* learn using Numpy arrays as the input, but fails to make any progress if reading data from a `tf.data` pipeline.  What could be the reason potentially?

In particular, the model consumes batched multidimensional time series (so every point is an N x M tensor) and solves a classification problem.  If the data are prepared in advance, by aggregating the time series in a large Numpy array, then the model successfully learns as indicated by a significant increase in the accuracy.  However, when exactly the same input data is prepared using `tf.data` pipeline, the accuracy remains at the baseline level.

I compared the two sets of data by writing to disk, and they are identical.  Also the types match.

Tried disabling threading (IIUC) by setting

```
options.threading.private_threadpool_size = 1
```

and experimenting with a bunch of `options.experimental_optimization` options.

Could it be the case that the data are read in parallel from the `tf.data` dataset as opposed to being read sequentially from the Numpy array?

Apologies in advance for not providing a 100% reproducible case (cannot share data at the moment). Nevertheless, attaching the pipeline code (`np_array` contains ""raw"" data):

### Standalone code to reproduce the issue

```shell
ds = tf.data.Dataset.from_tensor_slices(np_array.T)
y_ds = (
    ds
   .skip(T - 1)
   .map(lambda s: s[-1] - 1)
   .map(lambda y: to_categorical(y, 3))
)
X_ds = (
    ds
    .map(lambda s: s[:n_features])
    .window(T, shift=1, drop_remainder=True)
    .flat_map(lambda x: x.batch(T, drop_remainder=True))
    .map(lambda x: tf.expand_dims(x, -1))
)
Xy_ds = (
    tf.data.Dataset.zip(X_ds, y_ds)
    .batch(size_batch)
    .repeat(n_epochs * size_batch)
    .prefetch(tf.data.AUTOTUNE)
)
model.fit(
    Xy_train,
    epochs=n_epochs,
    steps_per_epoch=199,  # correct
    verbose=2
)
```


### Relevant log output

_No response_"
2690530302,80751,Aborted (core dumped) in `UnBatch`,closed,2024-11-25 12:11:14+00:00,2024-12-13T02:08:45Z,2024-12-13T02:08:42Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/80751,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', '2.17']","['@LongZE666,\r\nI tried to execute the mentioned code on tf-nightly and TensorFlow v2.17, observed that the code was aborted in TF v2.17 and on tf-nigthly the code was executed with the expected error. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/36c1807f2037192d3ef3a32d156795ae/untitled2260.ipynb). Thank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80751"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80751"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf2.17.0 tf2.16.1

### Custom code

Yes

### OS platform and distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When `batch_index` is scalar,  `UnBatch` triggered a crash.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

batched_tensor = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
batch_index = tf.constant(1, dtype=tf.int64)
id = tf.constant(0, dtype=tf.int64) 

tf.raw_ops.Unbatch(
    batched_tensor=batched_tensor,
    batch_index=batch_index,
    id=id,
    timeout_micros=1000000
)
```


### Relevant log output

```shell
Check failed: d < dims() (1 vs. 0)
```
"
2693837162,80836,[MSVC] Compiler error in external/nsync/platform/c++11/platform.h,closed,2024-11-26 09:15:36+00:00,2024-12-09T07:21:19Z,2024-12-09T07:21:16Z,penpornk,,https://github.com/tensorflow/tensorflow/issues/80836,"['stat:awaiting tensorflower', 'type:bug', 'comp:core']","['this issue is no longer appears in the latest commit, closing this issue.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80836"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80836"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

latest commit

### Custom code

Yes

### OS platform and distribution

Windows 11

### Mobile device

_No response_

### Python version

3.12

### Bazel version

6.5

### GCC/compiler version

MSVC 19.43.34617.95

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I work on Microsoft Visual C++ testing, where we regularly build popular open-source projects, including yours, with development builds of our compiler and libraries to detect and prevent shipping regressions that would affect you. This also allows us to provide advance notice of breaking changes, which is the case here.

Recently this commit https://github.com/microsoft/STL/pull/5105 is revealing an issue in nysnc.

Compiler error with this STL change:
```
./external/nsync//platform/c++11\platform.h(67): error C2039: 'system_clock': is not a member of 'std::chrono'
C:\Program Files\Microsoft Visual Studio\2022\Enterprise\VC\Tools\MSVC\14.42.34433\include\__msvc_chrono.hpp(286): note: see declaration of 'std::chrono'
./external/nsync//platform/c++11\platform.h(67): error C3083: 'system_clock': the symbol to the left of a '::' must be a type
./external/nsync//platform/c++11\platform.h(67): error C2133: 'epoch': unknown size
./external/nsync//platform/c++11\platform.h(67): error C2512: 'std::chrono::time_point': no appropriate default constructor available
C:\Program Files\Microsoft Visual Studio\2022\Enterprise\VC\Tools\MSVC\14.42.34433\include\__msvc_chrono.hpp(200): note: see declaration of 'std::chrono::time_point'
./external/nsync//platform/c++11\platform.h(69): error C2676: binary '+': 'std::chrono::time_point' does not define this operator or a conversion to a type acceptable to the predefined operator
```

I have created an upstream PR (https://github.com/google/nsync/pull/25), which is currently awaiting their reponse.

In the meantime, would it possible for you to add this patch ([include_chrono.patch](https://github.com/user-attachments/files/17916641/include_chrono.patch)) to https://github.com/tensorflow/tensorflow/tree/master/third_party 

and update the following line in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/workspace2.bzl#L400:  
`patch_file = [""//third_party:nsync.patch"", ""//third_party:include_chrono.patch""],` ?

I have tested this change and confirmed that there are no issues when building Tensorflow from source.

build log: [tf.log](https://github.com/user-attachments/files/17916756/tf.log)


### Standalone code to reproduce the issue

```shell
#include <mutex>
// #include <chrono> this is necessary in next release

int main(){
	std::chrono::system_clock::time_point epoch; 
}
```


### Relevant log output

```shell
C:\Users\v-neilchua\Desktop>cl f.cpp
Microsoft (R) C/C++ Optimizing Compiler Version 19.43.34617.95 for x64
Copyright (C) Microsoft Corporation.  All rights reserved.

f.cpp
f.cpp(4): error C2039: 'chrono': is not a member of 'std'
predefined C++ types (compiler internal)(358): note: see declaration of 'std'
f.cpp(4): error C2039: 'system_clock': is not a member of 'std'
predefined C++ types (compiler internal)(358): note: see declaration of 'std'
f.cpp(4): error C3083: 'chrono': the symbol to the left of a '::' must be a type
f.cpp(4): error C3083: 'system_clock': the symbol to the left of a '::' must be a type
f.cpp(4): error C2039: 'time_point': is not a member of 'std'
predefined C++ types (compiler internal)(358): note: see declaration of 'std'
f.cpp(4): error C2065: 'time_point': undeclared identifier
f.cpp(4): error C2146: syntax error: missing ';' before identifier 'epoch'
f.cpp(4): error C2065: 'epoch': undeclared identifier
```
"
2698915980,80951,InvalidArgumentError when using MirroredStrategy but not with tf.distribute.get_strategy(),closed,2024-11-27 15:25:37+00:00,2024-12-28T01:59:53Z,2024-12-28T01:59:51Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/80951,"['stat:awaiting response', 'type:bug', 'stale', 'TF 2.18']","['Hi **@ArnauPujantellNavas** ,\r\nApologies for the delay, and thank you for raising your concern here. I tried running your code on Colab using TensorFlow 2.18.0, and I did not encounter any issues. Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/e75da5abb3d644c36a0927ebccaac89f/80951_tf_2-18-v.ipynb) here for your reference. Let me know if I missed anything or made any mistakes.\r\nThank you!', ""Hi @Venkat6871, thank you for your answer.\r\nWhen using one single GPU it works fine, same when using more than one GPU and tf.distribute.get_strategy(). The error shows up when using more than one GPU and MirroredStrategy(). In my case, I am using 2 NVIDIA Tesla V100. \r\nSorry if i didn't explain the issue correctly."", ""Hi, @ArnauPujantellNavas \r\nI apologize for the delayed response, I have tried your code with 02 T4 GPU's and it seems like working as expected please refer this [gist-file](https://colab.research.google.com/gist/gaikwadrahul8/d49c8cd6fc06da58cd64486e767b9d7e/tf-issue-80951.ipynb) or Am I missing something here if so please let me know ? \r\n\r\nThank you for your cooperation and patience."", 'Hi @gaikwadrahul8 \r\nThanks for your response, looking at the file I\'ve noticed we are using different versions of the packages. When I try to use yours tensorflow can\'t detect my GPUs properly.\r\n\r\nThis is the command I am using to install the required packages with the latest versions:\r\n`pip install tensorflow[and-cuda]==2.18.0 keras==3.7.0`\r\n\r\nI added some prints to the code to make sure it is using the 2 replicas and not just one of them:\r\n```\r\nimport tensorflow as tf\r\nimport keras\r\n\r\ndef create_dataset():\r\n    float_data = tf.constant([[1.0, 2.0], [3.0, 4.0]], dtype=tf.float32)\r\n    string_data = tf.constant([[""foo"", ""bar""], [""baz"", ""qux""]], dtype=tf.string)\r\n    labels = tf.constant([[1], [0]], dtype=tf.float32)\r\n    \r\n    dataset = tf.data.Dataset.from_tensor_slices(((float_data, string_data), labels))\r\n    return dataset\r\n\r\ndef create_model():\r\n    input_float = keras.Input(shape=(2,), dtype=tf.float32, name=\'float_input\')\r\n    input_string = keras.Input(shape=(2,), dtype=tf.string, name=\'string_input\')\r\n    \r\n    string_lookup = keras.layers.StringLookup(vocabulary=[""foo"", ""bar"", ""baz"", ""qux""], name=\'string_lookup\')\r\n    string_embedding = string_lookup(input_string)\r\n    \r\n    concatenated = keras.layers.Concatenate(name=\'concatenate\')([input_float, string_embedding])\r\n    \r\n    dense = keras.layers.Dense(10, activation=\'relu\', name=\'dense_1\')(concatenated)\r\n    output = keras.layers.Dense(1, activation=\'sigmoid\', name=\'output\')(dense)\r\n    \r\n    model = keras.Model(inputs=[input_float, input_string], outputs=output, name=\'simple_model\')\r\n    model.compile(optimizer=\'adam\', loss=\'binary_crossentropy\', metrics=[\'accuracy\'])\r\n    return model\r\n\r\ndef main():\r\n\r\n    print(""Single GPU strategy"")\r\n\r\n    strategy = tf.distribute.get_strategy()\r\n    n_gpu: int = len(tf.config.list_physical_devices(\'GPU\'))\r\n    n_replicas: int = strategy.num_replicas_in_sync\r\n \r\n    print(f\'GPU: {n_gpu}\')\r\n    print(f\'Replicas: {n_replicas}\')\r\n    \r\n    dataset = create_dataset()\r\n    \r\n    with strategy.scope():\r\n        model = create_model()\r\n        \r\n    model.fit(dataset.batch(2), epochs=5)\r\n\r\n    print(""Multiple GPUs strategy"")\r\n\r\n    strategy = tf.distribute.MirroredStrategy()\r\n\r\n    n_gpu: int = len(tf.config.list_physical_devices(\'GPU\'))\r\n    n_replicas: int = strategy.num_replicas_in_sync\r\n \r\n    print(f\'GPU: {n_gpu}\')\r\n    print(f\'Replicas: {n_replicas}\')\r\n    \r\n    dataset = create_dataset()\r\n    \r\n    with strategy.scope():\r\n        model = create_model()\r\n        \r\n    model.fit(dataset.batch(2), epochs=5)\r\n\r\nif __name__ == ""__main__"":\r\n    main()\r\n\r\n```\r\n\r\nAnd I am recieving the same original error:\r\n```\r\nSingle GPU strategy\r\nGPU: 2\r\nReplicas: 1\r\nI0000 00:00:1733759297.693816   24170 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14791 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0001:00:00.0, compute capability: 7.0\r\nI0000 00:00:1733759297.694337   24170 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14791 MB memory:  -> device: 1, name: Tesla V100-PCIE-16GB, pci bus id: 0002:00:00.0, compute capability: 7.0\r\nEpoch 1/5\r\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step - accuracy: 0.5000 - loss: 0.9865\r\nEpoch 2/5\r\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.5000 - loss: 0.9687\r\nEpoch 3/5\r\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.5000 - loss: 0.9513\r\nEpoch 4/5\r\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.5000 - loss: 0.9342\r\nEpoch 5/5\r\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.5000 - loss: 0.9174\r\nMultiple GPUs strategy\r\nGPU: 2\r\nReplicas: 2\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr \'T\' of string is not in the list of allowed values: float, double, int32, uint8, int16, int8, complex64, int64, qint8, quint8, qint32, bfloat16, qint16, quint16, uint16, complex128, half, uint32, uint64, variant\r\n        ; NodeDef: {{node AddN}}; Op<name=AddN; signature=inputs:N*T -> sum:T; attr=N:int,min=1; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_COMPLEX64, DT_INT64, DT_QINT8, DT_QUINT8, DT_QINT32, DT_BFLOAT16, DT_QINT16, DT_QUINT16, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_VARIANT]; is_commutative=true; is_aggregate=true> [Op:AddN] name:\r\n```\r\n\r\nCoult you try to execute it with those prints and the same package versions as me?\r\nThank you so much and sorry for the inconvenience.', ""Hi @ArnauPujantellNavas,\r\n\r\nAfter thorough investigation and version compatibility testing, I've identified a reliable solution for the encountered issue.\r\nInitially, I attempted installation with `pip install tensorflow[and-cuda]==2.18.0 keras==3.7.0` which reproduced the previous error scenario which you mentioned in the issue template. I discovered a compatible combination that resolves the current challenges so please try below recommended temporary workaround at the moment, please refer this [gist-file](https://colab.research.google.com/gist/gaikwadrahul8/60a77b7a78c0d95fa107b01defe086e8/tf-mirroredstrategy-issue-80951.ipynb)\r\n\r\n`pip install tensorflow[and-cuda]==2.16.1 keras==3.3.0\r\n`\r\n\r\nIf issue still persists with this `pip install tensorflow[and-cuda]==2.16.1 keras==3.3.0` versions combination please let us know for further investigation.\r\n\r\nThank you for your cooperation and patience."", ""Hi @gaikwadrahul8,\r\nI've tested it and it works as a workaround. Are you planning to fix it for the next releases?\r\n\r\nThank you so much for your time.\r\n"", ""Hi, @ArnauPujantellNavas\r\n\r\nThank you for your confirmation. We're glad to hear that the issue has been resolved by installing TensorFlow and Keras versions `2.16.1` and `3.3.0` respectively using `pip`.\r\n\r\nWe'll investigate this issue further and work on a permanent fix for an upcoming release.\r\n\r\nPlease let us know if you encounter any further problems. If the temporary workaround has successfully resolved the issue, feel free to close this issue for now.\r\n\r\nThank you for your cooperation and patience."", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80951"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/80951"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

tf 2.18

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.12

### Bazel version

_No response_

### GCC/compiler version

gcc 9.4.0

### CUDA/cuDNN version

12.5.1

### GPU model and memory

2 x NVIDIA Tesla V100 (12 cores, 224 GB RAM, 1474 GB disk)

### Current behavior?

**Problem**: I am encountering an InvalidArgumentError when using MirroredStrategy in TensorFlow. This error does not occur when I use tf.distribute.get_strategy(). Below is the error message I receive and the standalone code to reproduce it.

**Expected Behavior**: The code should run without errors when using MirroredStrategy, similar to when using tf.distribute.get_strategy().

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import keras

def create_dataset():
    float_data = tf.constant([[1.0, 2.0], [3.0, 4.0]], dtype=tf.float32)
    string_data = tf.constant([[""foo"", ""bar""], [""baz"", ""qux""]], dtype=tf.string)
    labels = tf.constant([[1], [0]], dtype=tf.float32)
    
    dataset = tf.data.Dataset.from_tensor_slices(((float_data, string_data), labels))
    return dataset

def create_model():
    input_float = keras.Input(shape=(2,), dtype=tf.float32, name='float_input')
    input_string = keras.Input(shape=(2,), dtype=tf.string, name='string_input')
    
    string_lookup = keras.layers.StringLookup(vocabulary=[""foo"", ""bar"", ""baz"", ""qux""], name='string_lookup')
    string_embedding = string_lookup(input_string)
    
    concatenated = keras.layers.Concatenate(name='concatenate')([input_float, string_embedding])
    
    dense = keras.layers.Dense(10, activation='relu', name='dense_1')(concatenated)
    output = keras.layers.Dense(1, activation='sigmoid', name='output')(dense)
    
    model = keras.Model(inputs=[input_float, input_string], outputs=output, name='simple_model')
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

def main():
    print(""Single GPU strategy"")
    strategy = tf.distribute.get_strategy()
    
    dataset = create_dataset()
    
    with strategy.scope():
        model = create_model()
        
    model.fit(dataset.batch(2), epochs=5)

    print(""Multiple GPUs strategy"")

    strategy = tf.distribute.MirroredStrategy()
    
    dataset = create_dataset()
    
    with strategy.scope():
        model = create_model()
        
    model.fit(dataset.batch(2), epochs=5)

if __name__ == ""__main__"":
    main()
```


### Relevant log output

```shell
tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of string is not in the list of allowed values: float, double, int32, uint8, int16, int8, complex64, int64, qint8, quint8, qint32, bfloat16, qint16, quint16, uint16, complex128, half, uint32, uint64, variant
        ; NodeDef: {{node AddN}}; Op<name=AddN; signature=inputs:N*T -> sum:T; attr=N:int,min=1; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_COMPLEX64, DT_INT64, DT_QINT8, DT_QUINT8, DT_QINT32, DT_BFLOAT16, DT_QINT16, DT_QUINT16, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_VARIANT]; is_commutative=true; is_aggregate=true> [Op:AddN] name:
```
"
2716764782,82146,Unable to Install TensorFlow on Raspberry Pi Zero W (ARMv6),closed,2024-12-04 07:18:44+00:00,2025-01-11T02:01:34Z,2025-01-11T02:01:30Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/82146,"['stat:awaiting response', 'type:bug', 'type:build/install', 'stale', 'TF 2.10']","[""Hi, @chaudhariraj\r\nI apologize for the delayed response, I see community-built TensorFlow binaries which provides an official wheel for `Python3.5` on `Raspberry Pi 1-3 and Pi Zero`. if you're looking for an official wheel for Python3.5 on Raspberry Pi Zero please download it from [here](https://github.com/bitsy-ai/tensorflow-arm-bin?tab=readme-ov-file#community-built-tensorflow-binaries) and install it on your Raspberry Pi Zero W (ARMv6)\r\n\r\nYou can also build from source for the Raspberry Pi Zero (ARMv6) so we recommend cross-compiling the TensorFlow Raspbian package. Cross-compilation is using a different platform to build the package than deploy to. Instead of using the Raspberry Pi's limited RAM and comparatively slow processor, it's easier to build TensorFlow on a more powerful host machine running Linux, macOS, or Windows. Please refer this [documentation](https://github.com/tensorflow/build/tree/master/raspberry_pi_builds#build-from-source-for-the-raspberry-pi).\r\n\r\nIf I have missed something here please let me know.\r\n\r\nThank you for your cooperation and patience."", 'Hi, @gaikwadrahul8 \r\nI recently purchased a Raspberry Pi 4 Model B (2018), installed a 64-bit OS (Bookworm, aarch64 architecture), and the default Python version is 3.11. I installed TensorFlow version 2.17 in a virtual environment (venv). However, I\'m encountering issues accessing the Pi Camera using the picamera2 library. The error states that the libcamera module cannot be found, even though I have installed picamera2 and its dependencies, including libcamera-apps.\r\n\r\nWhen I attempt to install TensorFlow directly in the root environment (outside of the virtual environment), I encounter errors. How can I resolve these issues to successfully access the Pi Camera while using TensorFlow and also how i install tensor flow specific version like 2.10 in root or is possible to install tensor flow with apt command?\r\n\r\n\r\nError:\r\nraspberrypi4b@raspberrypi:~ $ pip install tensorflow-2.18.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\r\nerror: externally-managed-environment\r\n\r\n× This environment is externally managed\r\n╰─> To install Python packages system-wide, try apt install\r\n    python3-xyz, where xyz is the package you are trying to\r\n    install.\r\n\r\n    If you wish to install a non-Debian-packaged Python package,\r\n    create a virtual environment using python3 -m venv path/to/venv.\r\n    Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\r\n    sure you have python3-full installed.\r\n\r\n    For more information visit http://rptl.io/venv\r\n\r\nnote: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\r\nhint: See PEP 668 for the detailed specification.\r\n\r\nOS Details:\r\nraspberrypi4b@raspberrypi:~ $ uname -m\r\naarch64\r\nraspberrypi4b@raspberrypi:~ $ uname -r\r\n6.6.62+rpt-rpi-v8\r\nraspberrypi4b@raspberrypi:~ $  cat /etc/os-release\r\nPRETTY_NAME=""Debian GNU/Linux 12 (bookworm)""\r\nNAME=""Debian GNU/Linux""\r\nVERSION_ID=""12""\r\nVERSION=""12 (bookworm)""\r\nVERSION_CODENAME=bookworm\r\nID=debian\r\nHOME_URL=""https://www.debian.org/""\r\nSUPPORT_URL=""https://www.debian.org/support""\r\nBUG_REPORT_URL=""https://bugs.debian.org/""\r\nraspberrypi4b@raspberrypi:~ $\r\n\r\nWheel: link - https://www.tensorflow.org/install/pip\r\nhttps://storage.googleapis.com/tensorflow/versions/2.18.0/tensorflow-2.18.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl', 'Hi, @chaudhariraj \r\nI apologize for the delayed response, could you please follow the below instructions before installing the TensorFlow and see is it resolving your issue or not ?\r\n\r\n```\r\n1. sudo apt install python3-venv\r\n2. python3 -m venv ~/tf\r\n3. source ~/tf/bin/activate\r\n4. pip install tensorflow-2.18.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\r\n```\r\nAfter trying above instructions if issue still persists please let us know with updated error log to investigate this issue further from our end. \r\n\r\nThank you for your cooperation and patience.', 'Hi, @chaudhariraj \r\nTo confirm, have you got chance to try above provided instructions ? If so please let us know is it working as expected or not ? \r\n\r\nThank you for your cooperation and patience.', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82146"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82146"">No</a>\n']","### Issue type

Build/Install

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.10.1

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I'm trying to install TensorFlow on a Raspberry Pi Zero W with ARMv6 architecture with 32-bit bookworm. However, the installation fails, and I cannot find a version of TensorFlow compatible with ARMv6 architecture. I would appreciate guidance or an official release for ARMv6 support.

raspberrypiwh@raspberrypi:~ $ uname -m
armv6l
raspberrypiwh@raspberrypi:~ $ cat /etc/os-release
PRETTY_NAME=""Raspbian GNU/Linux 12 (bookworm)""
NAME=""Raspbian GNU/Linux""
VERSION_ID=""12""
VERSION=""12 (bookworm)""
VERSION_CODENAME=bookworm
ID=raspbian
ID_LIKE=debian
HOME_URL=""http://www.raspbian.org/""
SUPPORT_URL=""http://www.raspbian.org/RaspbianForums""
BUG_REPORT_URL=""http://www.raspbian.org/RaspbianBugs""

### Standalone code to reproduce the issue

```shell
I'm trying to install TensorFlow on a Raspberry Pi Zero W with ARMv6 architecture with 32-bit bookworm. However, the installation fails, and I cannot find a version of TensorFlow compatible with ARMv6 architecture. I would appreciate guidance or an official release for ARMv6 support.

raspberrypiwh@raspberrypi:~ $ uname -m
armv6l
raspberrypiwh@raspberrypi:~ $ cat /etc/os-release
PRETTY_NAME=""Raspbian GNU/Linux 12 (bookworm)""
NAME=""Raspbian GNU/Linux""
VERSION_ID=""12""
VERSION=""12 (bookworm)""
VERSION_CODENAME=bookworm
ID=raspbian
ID_LIKE=debian
HOME_URL=""http://www.raspbian.org/""
SUPPORT_URL=""http://www.raspbian.org/RaspbianForums""
BUG_REPORT_URL=""http://www.raspbian.org/RaspbianBugs""
```


### Relevant log output

_No response_"
2719667595,82281,Model with dropout in MirroredStrategy not work,closed,2024-12-05 08:00:52+00:00,2025-01-24T01:59:53Z,2025-01-24T01:59:49Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/82281,"['stat:awaiting response', 'type:bug', 'stale', 'comp:keras', '2.17']","['It seems that the problem is in the keras version: with `3.5.0` everything is fine, but `3.7.0` gives the error', ""I've been having the same issue after updating my libraries."", 'Hi **@jamm1985** ,\r\nApologies for the delay, and thank you for raising your concern. I tried running your code on Colab using TensorFlow 2.17.0 with Keras version 3.5.0, and it worked fine. However, when using version 3.7.0, I encountered the same issue as you. Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/4cacd4192b9716aca81d5e54984198d6/82281_tf-2-17-0-v.ipynb) here for reference.\r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues) as this issue is more related to keras\r\nThank you!', 'Hi @Venkat6871 !\r\nThe Keras team quickly fixed the bug. At this point, it looks like the working version of keras needs to be fixed in the dependencies for the latest tf 2.16, 2.17, 2.18.\r\n', 'Hi **@jamm1985** ,\r\nI tried running your code on Colab using TensorFlow 2.17.0 with Python 3.7.0, and it is working fine. The issue might be update in the upcoming versions. For your reference, please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/73890cee650887a22ab128b2ff36a8f1/82281_tf-2-17-0-v.ipynb) here.\r\nThank you!', '> For your reference, please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/73890cee650887a22ab128b2ff36a8f1/82281_tf-2-17-0-v.ipynb) here. \r\n\r\nThis is because the keras dev version. Note that the dev version is not usually installed by default as a requirement for tf.\r\n\r\n', 'Hi @jamm1985,\r\nYeah, as mentioned dev version is not installed by default. If dev version is needed then we need to install explicitly for now. As this issue has been resolved in both tensorflow and keras-nightly it will be updated in the upcoming versions.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', 'class TPUSafeDropout(layers.Layer):\r\n    def __init__(self, rate, **kwargs):\r\n        super(TPUSafeDropout, self).__init__(**kwargs)\r\n        self.rate = rate\r\n\r\n    def call(self, inputs, training=None):\r\n        if not training or self.rate == 0.0:\r\n            return inputs\r\n        noise_shape = tf.shape(inputs)\r\n        random_tensor = tf.random.uniform(noise_shape, dtype=inputs.dtype)\r\n        dropout_mask = tf.cast(random_tensor >= self.rate, inputs.dtype)\r\n        return inputs * dropout_mask / (1.0 - self.rate)\r\n        \r\n      ', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82281"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82281"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.17.1

### Custom code

No

### OS platform and distribution

ubuntu22.04

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

It is impossible to init model with dropout under any MirroredStrategy using tf API.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
STRATEGY = tf.distribute.MirroredStrategy()
with STRATEGY.scope():
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(128, activation=""gelu""),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(128),
    ])
```
```


### Relevant log output

```shell
2024-12-05 18:17:02.002493: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-12-05 18:17:02.016573: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-12-05 18:17:02.030709: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-12-05 18:17:02.034759: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-12-05 18:17:02.046477: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-12-05 18:17:05.066676: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
2024-12-05 18:17:10.507032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22502 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:3b:00.0, compute capability: 8.6
2024-12-05 18:17:10.507896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22502 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:5e:00.0, compute capability: 8.6
/opt/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[1], line 6
      2 STRATEGY = tf.distribute.MirroredStrategy()
      3 with STRATEGY.scope():
      4     model = tf.keras.Sequential([
      5         tf.keras.layers.Dense(128, activation=""gelu"", input_shape=(28, 28, 1)),
----> 6         tf.keras.layers.Dropout(0.2),
      7         tf.keras.layers.Dense(128),
      8     ])

File /opt/venv/lib/python3.10/site-packages/keras/src/layers/regularization/dropout.py:53, in Dropout.__init__(self, rate, noise_shape, seed, **kwargs)
     51 self.noise_shape = noise_shape
     52 if rate > 0:
---> 53     self.seed_generator = backend.random.SeedGenerator(seed)
     54 self.supports_masking = True
     55 self.built = True

File /opt/venv/lib/python3.10/site-packages/keras/src/random/seed_generator.py:75, in SeedGenerator.__init__(self, seed, name, **kwargs)
     72     return self.backend.convert_to_tensor([seed, 0], dtype=dtype)
     74 with self.backend.name_scope(self.name, caller=self):
---> 75     self.state = self.backend.Variable(
     76         seed_initializer,
     77         shape=(2,),
     78         dtype=self.backend.random_seed_dtype(),
     79         trainable=False,
     80         name=""seed_generator_state"",
     81     )

File /opt/venv/lib/python3.10/site-packages/keras/src/backend/common/variables.py:170, in Variable.__init__(self, initializer, shape, dtype, trainable, autocast, aggregation, name)
    168 if callable(initializer):
    169     self._shape = self._validate_shape(shape)
--> 170     self._initialize_with_initializer(initializer)
    171 else:
    172     self._initialize(initializer)

File /opt/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/core.py:47, in Variable._initialize_with_initializer(self, initializer)
     46 def _initialize_with_initializer(self, initializer):
---> 47     self._value = tf.Variable(
     48         lambda: initializer(self._shape, dtype=self._dtype),
     49         dtype=self._dtype,
     50         trainable=self.trainable,
     51         name=self.name,
     52         aggregation=self._map_aggregation(self.aggregation),
     53     )

File /opt/venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153, in filter_traceback.<locals>.error_handler(*args, **kwargs)
    151 except Exception as e:
    152   filtered_tb = _process_traceback_frames(e.__traceback__)
--> 153   raise e.with_traceback(filtered_tb) from None
    154 finally:
    155   del filtered_tb

File /opt/venv/lib/python3.10/site-packages/tensorflow/python/distribute/values.py:513, in DistributedVariable.__init__(self, strategy, values, aggregation, var_policy)
    510 def __init__(self, strategy, values, aggregation, var_policy=None):
    511   if (aggregation == variables_lib.VariableAggregation.MEAN and
    512       not values[0].dtype.is_floating):
--> 513     raise ValueError(
    514         ""creating distributed tf.Variable with aggregation=MEAN and a ""
    515         ""non-floating dtype is not supported, please use a different ""
    516         ""aggregation or dtype"")
    517   self._distribute_strategy = strategy
    518   self._aggregation = aggregation

ValueError: creating distributed tf.Variable with aggregation=MEAN and a non-floating dtype is not supported, please use a different aggregation or dtype
```
"
2720398284,82316,`TimeDistributed.call()` does not work correctly with `Masking`,closed,2024-12-05 13:18:48+00:00,2024-12-06T14:56:35Z,2024-12-06T14:39:58Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/82316,['type:bug'],"['The Masking layer in Keras is designed to work with 3D input tensors that have the shape (batch_size, timesteps, features). This is because the Masking layer is typically used in the context of sequence models like RNNs, LSTMs, and GRUs, which process data sequentially over time. As your input is missing at least one dimension this is expected.', 'My input to the masking layer is 3D, see the model summary below:\r\n\r\n```Model: ""sequential""\r\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\r\n┃ Layer (type)                    ┃ Output Shape              ┃    Param # ┃\r\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\r\n│ masking (Masking)               │ (None, 8, 1)              │          0 │\r\n├─────────────────────────────────┼───────────────────────────┼────────────┤\r\n│ lstm (LSTM)                     │ (None, 8, 8)              │        320 │\r\n├─────────────────────────────────┼───────────────────────────┼────────────┤\r\n│ time_distributed                │ (None, 8, 1)              │          9 │\r\n│ (TimeDistributed)               │                           │            │\r\n└─────────────────────────────────┴───────────────────────────┴────────────┘\r\n Total params: 329 (1.29 KB)\r\n Trainable params: 329 (1.29 KB)\r\n Non-trainable params: 0 (0.00 B)\r\n```\r\n\r\n`None` is the placeholder for the batchsize dimension, 8 is the number of time steps, and 1 is the feature dimension.', 'I see, Let me check.', ""Try this : \r\n```python \r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Masking, Input, LSTM, Dense, TimeDistributed\r\nfrom keras.src.models.sequential import Sequential\r\nfrom keras._tf_keras.keras.utils import pad_sequences\r\n\r\n# Create sequences\r\nlength = 8\r\nn_batch = length\r\nn_neurons = length\r\nseq = [round(i / float(length), 2) for i in range(length)]\r\n\r\n# Outputs same as inputs, just as an example\r\nX = [seq, [xx * 2 for xx in seq[:4]]]\r\ny = [seq, [yy * 2 for yy in seq[:4]]]\r\n\r\n# Pad the sequences to be of the same length\r\nmaxlen = max([len(xx) for xx in X])\r\npadded_X = pad_sequences(X, dtype='float', maxlen=maxlen, padding='post', value=-1)\r\npadded_y = pad_sequences(y, dtype='float', maxlen=maxlen, padding='post', value=-1)\r\n\r\n# Expand dimensions to have shape (batch_size, timesteps, features)\r\npadded_X = np.expand_dims(padded_X, axis=-1)\r\npadded_y = np.expand_dims(padded_y, axis=-1)\r\n\r\n# Ensure Eager Execution is enabled\r\ntf.config.run_functions_eagerly(True)\r\n\r\n# Make a sample LSTM model\r\nmodel = Sequential()\r\nmodel.add(Input(shape=(maxlen, 1)))  # Adjust the input shape\r\nmodel.add(Masking(mask_value=-1.))\r\nmodel.add(LSTM(n_neurons, return_sequences=True))\r\nmodel.add(TimeDistributed(Dense(1)))\r\nmodel.summary()\r\n\r\n# Compile the model\r\nmodel.compile(loss='mean_squared_error', optimizer='adam')\r\n\r\n# Train the model\r\nhistory = model.fit(padded_X, padded_y, epochs=5, verbose=1)\r\n```"", '![image](https://github.com/user-attachments/assets/2fcaa7c4-5ea4-4561-9b2f-263e82f3200e)\r\n', 'Thanks! Explicitly switching on eager execution in this line did the trick: `tf.config.run_functions_eagerly(True)`', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82316"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82316"">No</a>\n', 'Really felt so nice helping you out :) ']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.16.1

### Custom code

Yes

### OS platform and distribution

Mac OS Sequoia 15.1.1

### Mobile device

Macbook Pro

### Python version

3.11.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I am trying to use a `Masking` layer to deal with variable-sized sequences being fed to an LSTM layer. Using `TimeDistributed` with `Masking` gives the following error:

```
ValueError: Exception encountered when calling TimeDistributed.call().

`TimeDistributed` Layer should be passed a `mask` of shape (None, None, ...), received: mask.shape=(None, 8)

Arguments received by TimeDistributed.call():
  • inputs=tf.Tensor(shape=(None, None, 8), dtype=float32)
  • training=True
  • mask=tf.Tensor(shape=(None, 8), dtype=bool)
```

Tensorflow version: 2.16.1
Tensorflow-metal version: 1.1.0
Keras version: 3.0.0


### Standalone code to reproduce the issue

```shell
from keras.layers import Masking, Input, LSTM, Dense, TimeDistributed
from keras.models import Sequential
from keras.utils import pad_sequences

# Create sequences
length = 8
n_batch = length
n_neurons = length
seq = [round(i/float(length), 2) for i in range(length)]

# Outputs same as inputs, just as an example
X = [seq, [xx * 2 for xx in seq[:4]]]
y = [seq, [yy * 2 for yy in seq[:4]]]

# Pad the sequences to be of the same length
maxlen = max([len(xx) for xx in X])
padded_X = pad_sequences(
    X, dtype='float', maxlen=maxlen, padding='post', value=-1
)

padded_y = pad_sequences(
    y, dtype='float', maxlen=maxlen, padding='post', value=-1
)

# Make a sample LSTM model
model = Sequential()
model.add(Input(shape=(length, 1)))
model.add(Masking(mask_value=-1.))
model.add(LSTM(n_neurons, return_sequences=True))
model.add(TimeDistributed(Dense(1)))
model.summary()

# Fit the model
model.compile(loss='mean_squared_error', optimizer='adam')
history = model.fit(padded_X, padded_y, epochs=5, verbose=1)
```


### Relevant log output

```shell
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[1], line 35
     33 # Fit the model
     34 model.compile(loss='mean_squared_error', optimizer='adam')
---> 35 history = model.fit(padded_X, padded_y, epochs=500, verbose=1) #, batch_size=2)

File ~/venvs/sat-etl-tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:123, in filter_traceback.<locals>.error_handler(*args, **kwargs)
    120     filtered_tb = _process_traceback_frames(e.__traceback__)
    121     # To get the full stack trace, call:
    122     # `keras.config.disable_traceback_filtering()`
--> 123     raise e.with_traceback(filtered_tb) from None
    124 finally:
    125     del filtered_tb

File ~/venvs/sat-etl-tf/lib/python3.11/site-packages/keras/src/layers/rnn/time_distributed.py:81, in TimeDistributed.call(self, inputs, training, mask)
     78 timesteps = input_shape[1]
     80 if mask_shape is not None and mask_shape[:2] != (batch_size, timesteps):
---> 81     raise ValueError(
     82         ""`TimeDistributed` Layer should be passed a `mask` of shape ""
     83         f""({batch_size}, {timesteps}, ...), ""
     84         f""received: mask.shape={mask_shape}""
     85     )
     87 def time_distributed_transpose(data):
     88     """"""Swaps the timestep and batch dimensions of a tensor.""""""

ValueError: Exception encountered when calling TimeDistributed.call().

`TimeDistributed` Layer should be passed a `mask` of shape (None, None, ...), received: mask.shape=(None, 8)

Arguments received by TimeDistributed.call():
  • inputs=tf.Tensor(shape=(None, None, 8), dtype=float32)
  • training=True
  • mask=tf.Tensor(shape=(None, 8), dtype=bool)
```
"
2721528831,82349,GPU delegate error for Flex models in Android C++ level,closed,2024-12-05 22:05:10+00:00,2025-01-01T02:06:18Z,2025-01-01T02:06:16Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/82349,"['stat:awaiting response', 'type:bug', 'stale', 'comp:lite', 'TF 2.16']","['Thank you for reply! Do you mean that I need to initialize flex delegate directly, like auto* flex_delegate = tflite::FlexDelegate::Create();? As I could see from documentations only linking is needed for Android. And, please, tell your code is for android or running on android is impossible due to flex unsupporting?\r\n', 'I used similar code as yours previously on android but not successfully. So my question is it possible to use Flex + GPU on android at all/', ""Hi, @koranten2\r\nI apologize for the delayed response, As far I know Flex operations (TensorFlow operations that are not natively supported by TensorFlow Lite) can't be run on the GPU delegate. Specifically, when you try to apply the GPU delegate and Flex delegate together the operations required by Flex are not supported by the GPU delegate leading to the error.\r\n\r\nThe GPU delegate in TensorFlow Lite requires the operations to be offloaded to the GPU and it has specific kernels implemented for operations like Conv2D, DepthwiseConv2D, Add, etc. However, Flex operations may involve more complex or custom operations that either don’t have GPU kernels or require CPU-based execution. This results in the error you're facing when you attempt to apply both delegates. Please refer official documentation for supported operations of [GPU delegates for LiteRT](https://ai.google.dev/edge/litert/performance/gpu#quantized_models)\r\n\r\nYou'll need to work around this limitation either by splitting the model using CPU for Flex ops or preprocessing the model to remove Flex operations.The best course of action for your use case would be to separate operations that require Flex from those that can run on the GPU. Use the GPU delegate only for supported ops and run Flex operations on the CPU which can be slower. \r\n\r\nIf I have missed something here please let me know. \r\n\r\nThank you for your cooperation and patience.\r\n\r\n"", 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82349"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82349"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.16

### Custom code

Yes

### OS platform and distribution

Ubuntu 22.04

### Mobile device

Android

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Hello. I am trying to use GPU delegate on Android C++ level for model that need Flex support. On runtime an error is returned on ModifyGraphWithDelegate. Please, tell if Flex + GPU is possible for Android C++? What corrections should I do to proceed? 

### Standalone code to reproduce the issue

```shell
auto* delegate = TfLiteGpuDelegateV2Create(nullptr);
int res = interpreter->ModifyGraphWithDelegate(delegate)
```


### Relevant log output

```shell
""res"" variable is returned as kTfLiteApplicationError = 3 value
```
"
2722478099,82385,Kernel crash in optimizer.apply_gradient for complex-valued gradients,closed,2024-12-06 09:06:49+00:00,2024-12-26T02:01:00Z,2024-12-26T02:00:55Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/82385,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.18']","['Hi, \r\n\r\nI am slightly confused. this is exactly the code that I already provided above as ""real-valued"" equivalent. It unfortunately does not solve the issue. The complex-valued variant worked prior to TF 2.17 and now it does not work anymore.', 'Hi **@jhoydis** ,\r\nApologies for the delay, and thank you for raising your concern. With TensorFlow 2.18.0, Keras 3.x is used by default, which might be cause for the issue. I manually installed Keras 2, and it worked fine for me. To install Keras 2, use the following command:\r\n```\r\n!pip install tf-keras\r\nimport tf_keras as keras\r\n```\r\nPlease find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/d8b0105db34a3a5c17acdc46ad603083/82385_tf-2-18-0-v.ipynb) here for reference.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82385"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82385"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.18

### Custom code

No

### OS platform and distribution

Ubuntu 22.04

### Mobile device

_No response_

### Python version

3.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

The issue was originally posted as Keras issue keras-team/keras#20581. They decided that this is a TF bug and not coming from Keras:

TensorFlow is able to correctly compute gradients for complex-valued variables. However, the Keras3 optimizers do not seem to be able to correctly apply complex-valued gradients. This worked with Keras 2.

Here is a code snippet that works in TF2.15, but leads to a Kernel crash with Keras 3.7 and TF 2.18 on a GPU.
The crash is caused by the function `optimizer.apply_gradients`.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

# Complex-valued variable (leading to a Kernel crash)
x = tf.Variable(tf.complex(3., 2.), trainable=True)
optimizer = tf.keras.optimizers.SGD()
with tf.GradientTape() as tape:
    loss = tf.abs(x)**2
grads = tape.gradient(loss, tape.watched_variables())
optimizer.apply_gradients(zip(grads, tape.watched_variables()))
print(x)

# Real-valued variable equivalent
x_r = tf.Variable(3., trainable=True)
x_i = tf.Variable(2., trainable=True)
optimizer = tf.keras.optimizers.SGD()
with tf.GradientTape() as tape:
    x = tf.complex(x_r, x_i)
    loss = tf.abs(x)**2
grads = tape.gradient(loss, tape.watched_variables())
optimizer.apply_gradients(zip(grads, tape.watched_variables()))
print(tf.complex(x_r, x_i))
```


### Relevant log output

_No response_"
2724598337,82461,Dirichlet noise returns Nan under jit_compile,closed,2024-12-07 13:33:18+00:00,2024-12-26T02:00:57Z,2024-12-26T02:00:54Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/82461,"['stat:awaiting response', 'type:bug', 'stale', 'comp:ops', 'TF 2.18']","[""I couldn't run with nightly"", 'Hi **@cmarlin** ,\r\nApologies for the delay, and thank you for raising your concern. The issue arises because you are multiplying `dir_alpha` by the `legal_action` tensor. If `legal_action` has a value of 0 for a specific action, the corresponding concentration parameter in the Dirichlet distribution becomes 0. This is invalid because the Dirichlet distribution requires all concentration parameters to be strictly positive. Additionally, this issue may occur when using JIT compilation, as XLA might handle zeros differently.\r\nTo resolve this, I added a small epsilon value to avoid zeros, and it worked fine for me. Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/3b920adf58bf3e078bb7b95fb5fe7857/82461_tf_2-18-0-nightly-v.ipynb) here for reference.\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82461"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82461"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

v2.18.0-rc2-4-g6550e4bd802 2.18.0

### Custom code

No

### OS platform and distribution

WSL2

### Mobile device

_No response_

### Python version

3.10.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Function return some Nan values if jit_compile=True

### Standalone code to reproduce the issue

```shell
import tensorflow as tf  # tf.__version__ '2.14.1'
import tensorflow_probability as tfp  # tfp.__version__ '0.22.1'


# @tf.function(jit_compile=True)  # uncomment to trigger bug
def test_exploration_noise(
    prnd: tf.Tensor,
    legal_actions: tf.Tensor,
):
    action_space_size = 9
    batch_size = 2048
    root_dirichlet_alpha = 0.35

    dir_alpha = tf.fill(
            [batch_size, action_space_size], root_dirichlet_alpha
        )
    distribution = tfp.distributions.Dirichlet(dir_alpha * legal_actions)
    noise = distribution.sample(seed=prnd)
    return noise

if __name__ == ""__main__"":
    seed = tf.constant([ 348206018, 1455008836], dtype=tf.int32)
    new_legal_actions = tf.ones([2048, 9]).numpy()
    new_legal_actions[1212] = [1, 0, 0, 0, 0, 0, 1, 1, 0]  # using line 288 won't trigger bug
    new_legal_actions = tf.convert_to_tensor(new_legal_actions)
    noise = test_exploration_noise(
            # root_dirichlet_alpha=config.root_dirichlet_alpha,
            prnd=seed,
            legal_actions=new_legal_actions,
    )
    print(noise[1212].numpy())
    tf.debugging.assert_all_finite(noise, ""invalid noise"")
```


### Relevant log output

```shell
without jit:
[0.00337291 0.         0.         0.         0.         0. 0.94923943 0.04738774 0.        ]

with jit:
[nan nan nan nan nan nan nan nan nan]
```
"
2725244964,82465,tensorflow error in pycharm in ubuntu 22.04,closed,2024-12-08 13:34:03+00:00,2025-01-07T02:02:26Z,2025-01-07T02:02:23Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/82465,"['stat:awaiting response', 'type:bug', 'stale', 'TF 2.18']","['\xa0 您好，邮件已经收到，我会尽快处理的。谢谢', 'Hi **@Chuan1937** ,\r\nCould you please provide details about the error you are facing? I tried running your code on Colab using TensorFlow 2.18.0, and it worked fine for me.\r\nPlease find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/b4532cb16caf48e07ddcb75f1c84e5f2/82465_tf_2-18-0-v.ipynb) here for reference.\r\nThank you!', ""The code is correct, my problem is that on Ubuntu, using the above method to import tensorflow functions will result in an error: there is no such function.Although there may be errors, the code can run normally. I don't know why."", 'Hi **@Chuan1937** ,\r\nApologies for the delay, and thank you for your patience. I tried running your code on Ubuntu using TensorFlow version 2.18.0, and it is working fine for me. I have attached it below, please check it once. Let me know if I did anything wrong here.\r\n```\r\n(tf) (tf) maayara@venkat-gpu1:~$ python3\r\nPython 3.9.20 (main, Oct  3 2024, 07:27:41) \r\n[GCC 11.2.0] :: Anaconda, Inc. on linux\r\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\r\n>>> import tensorflow as tf\r\n2024-12-16 08:10:24.296033: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\nE0000 00:00:1734336624.317288   45364 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\nE0000 00:00:1734336624.323644   45364 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n2024-12-16 08:10:24.346344: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\r\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n>>> print(tf.__version__)\r\n2.18.0\r\n>>> import matplotlib\r\n>>> import tensorflow.python.keras.models\r\n>>> from tensorflow.keras.optimizers import Adam\r\n>>> from tensorflow import keras\r\n>>> matplotlib.use(\'agg\')\r\n>>> import os\r\n>>> os.environ[\'TF_CPP_MIN_LOG_LEVEL\'] = \'3\'  # Suppress TensorFlow logs\r\n>>> from tensorflow.python import keras\r\n>>> from tensorflow.keras import backend as K\r\n>>> from tensorflow.keras.layers import (\r\n...     Add, Activation, LSTM, Conv1D, MaxPooling1D, UpSampling1D,\r\n...     Cropping1D, SpatialDropout1D, Bidirectional, BatchNormalization,add,InputSpec,\r\n... LayerNormalization,Layer, Dense, Dropout\r\n... )\r\n>>> \r\n```\r\nThank you!', ""I know the code is correct. But the problem is that it will have error report and it's can't popup keras or other api function.\r\nI have defined some deep learning model and run successfully on windows and ubuntu.\r\n\r\n![截图 2024-12-16 18-56-58](https://github.com/user-attachments/assets/cb2d9cf4-3288-429b-9210-7c1c6c65ac38)\r\n\r\n![截图 2024-12-16 19-01-12](https://github.com/user-attachments/assets/508f4468-ff83-43fa-9d97-42f2ac064a15)\r\n"", 'Thank you for your reply, I hope you can answer my questions！', 'Hi **@Chuan1937** ,\r\nApologies for the delay, and thank you for your patience. Could you please try importing Keras directly instead of importing it from TensorFlow? For example:\r\n`import keras`\r\ninstead of\r\n`from tensorflow import keras`\r\nLet us know if you are still facing the issue.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82465"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82465"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.18.0

### Custom code

Yes

### OS platform and distribution

linux ubuntu 22.04

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

tensorflow error in pycharm in ubuntu 22.04
![image](https://github.com/user-attachments/assets/1a13794b-9a9d-44b4-b81d-5ad3f585b814)
it's error in pycharm,but the code is correct and can run corretly

### Standalone code to reproduce the issue

```shell
import numpy as np
import matplotlib
import tensorflow.python.keras.models

matplotlib.use('agg')
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TensorFlow logs
from tensorflow.python import keras
from tensorflow.keras import backend as K
from tensorflow.keras.layers import (
    Add, Activation, LSTM, Conv1D, MaxPooling1D, UpSampling1D,
    Cropping1D, SpatialDropout1D, Bidirectional, BatchNormalization,add,InputSpec,
LayerNormalization,Layer, Dense, Dropout
)
from tensorflow.keras.optimizers import Adam
import tensorflow as tf
from tensorflow import keras
```


### Relevant log output

_No response_"
2726793015,82526,Linking an Android static library with TFLite GPU using CMake causes undefined symbol errors and can not get the correct install,closed,2024-12-09 11:39:32+00:00,2024-12-26T06:30:48Z,2024-12-24T08:27:20Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/82526,"['type:bug', 'comp:lite', 'TFLiteGpuDelegate', 'TF 2.18']","['and when set TFLITE_ENABLE_INSTALL=ON, how to get the full tflite envirment for dev other codes, after exec ""sudo make install""?', 'libkleidiai.a  need copy to install lib, or libxnnpack.a will be ld error', 'INFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for GPU.\r\nINFO: Loaded OpenCL library with dlopen.\r\nVERBOSE: Replacing 118 out of 118 node(s) with delegate (TfLiteGpuDelegateV2) node, yielding 1 partitions for the whole graph.\r\nERROR: TfLiteGpuDelegate Init: PRELU: Expected a 3D tensor of shape HxWxC or a 4D tensor of shape 1xHxWxC but got\r\nINFO: Created 0 GPU delegate kernels.\r\nERROR: TfLiteGpuDelegate Prepare: delegate is not initialized\r\nERROR: Node number 118 (TfLiteGpuDelegateV2) failed to prepare.\r\nERROR: Restored original execution plan after delegate application failure.\r\nCould not setup GPU delegate', 'Hi, @alexliyang\r\n\r\nI apologize for the delayed response, In Android TensorFlow Lite GPU delegate requires `OpenGL` `ES` and `EGL` for managing the GPU context. To fix the undefined symbol errors you need to make sure that the appropriate `OpenGL` `ES` and `EGL` libraries are linked. This can be done by modifying your `CMakeLists.txt` to include these libraries something like below please refer this similar issue https://github.com/tensorflow/tensorflow/issues/61312 and [TensorFlow Lite C++ minimal example](https://github.com/tensorflow/tensorflow/tree/v2.18.0/tensorflow/lite/examples/minimal) which may help you to solve your issue.\r\n\r\n\r\n```\r\ntarget_link_libraries (${PROJECT_NAME}\r\n        PUBLIC\r\n          tensorflow-lite\r\n          GLESv3\r\n          EGL\r\n          android\r\n)\r\n```\r\nIf issue still persists or Am I missing something here please let me know ?\r\nThank you for your cooperation and patience.', '@gaikwadrahul8 Thank you for your response, I refer issue #61312 and other repo to modify the CMakeLists.txt, now I can get the libtensorflow-lite.a , and all ld errors have been fixed.\r\nBut I get another error like following , the op PReLu is not supported in tensorflow-lite version 2.18.0?\r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for GPU.\r\nINFO: Loaded OpenCL library with dlopen.\r\nVERBOSE: Replacing 118 out of 118 node(s) with delegate (TfLiteGpuDelegateV2) node, yielding 1 partitions for the whole graph.\r\nERROR: TfLiteGpuDelegate Init: PRELU: Expected a 3D tensor of shape HxWxC or a 4D tensor of shape 1xHxWxC but got\r\nINFO: Created 0 GPU delegate kernels.\r\nERROR: TfLiteGpuDelegate Prepare: delegate is not initialized\r\nERROR: Node number 118 (TfLiteGpuDelegateV2) failed to prepare.\r\nERROR: Restored original execution plan after delegate application failure.\r\nCould not setup GPU delegate\r\n![image](https://github.com/user-attachments/assets/13932146-659f-4a71-9d0a-5994dcebe285)\r\n\r\nI check the model, all PReLu are 4D tensor of shape 1xHxWxC. but get the errors.', 'I find #39749 discuss this problem, but Now version 2.18.0 is ocurred , how to correct it ?', ""Hi, @alexliyang \r\nI apologize for the delayed response, I checked the [official documentation](https://ai.google.dev/edge/litert/performance/gpu) and it supports `PRELU` Op if you don't mind could you please give it try by downgrading the TensorFlow version to `2.17.1 or 2.16.1` and see is it working as expected or not ?\r\n\r\nIf you've have PyTorch model and want to convert to TensorFlow Lite then you can use [ai-edge-torch](https://github.com/google-ai-edge/ai-edge-torch) which is a python library that supports converting PyTorch models into a .tflite format, which can then be run with TensorFlow Lite and MediaPipe. This enables applications for Android, iOS and IOT that can run models completely on-device. AI Edge Torch offers broad CPU coverage, with initial GPU and NPU support. AI Edge Torch seeks to closely integrate with PyTorch, building on top of torch.export() and providing good coverage of Core ATen operators.\r\n\r\n\r\n\r\nIf issue still persists please let us know with updated error log for further investigation from our end.\r\n\r\nThank you for your cooperation and patience."", 'I check the model, maybe the torch model convert to tflite, prelu op need to be reshaped to hwc or 1hwc . I use flatc to handle the  model ,then the model can be loaded correctly.\r\nthank you very much!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82526"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82526"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf2.18

### Custom code

Yes

### OS platform and distribution

Ubuntu 20.04.6 LTS

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Linking an Android library with libtensorflow-lite.a using CMake with GPU delegate enabled causes undefined symbol errors
and can make install to get a complete include envirment.

### Standalone code to reproduce the issue

```shell
before cmake, do some changes:
tensorflow-2.18.0\tensorflow\lite\tools\cmake\modules\ml_dtypes\cmakelists.txt:
target_include_directories(ml_dtypes INTERFACE
  ""
$<BUILD_INTERFACE:$
{ML_DTYPES_SOURCE_DIR}>"" ""
$<INSTALL_INTERFACE:$
{CMAKE_INSTALL_INCLUDEDIR}>""
  ""$<BUILD_INTERFACE:${ML_DTYPES_SOURCE_DIR}/ml_dtypes>"" ""$<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}/ml_dtypes>"")

tensorflow-2.18.0\tensorflow\lite\cmakelists.txt:
change like https://github.com/tensorflow/tensorflow/issues/61312

although do these changes, errors occured like the following log output.

step1:
cmake ../tensorflow-2.18.0/tensorflow/lite -DCMAKE_TOOLCHAIN_FILE=/home/public/tflite/android-ndk-r25c/build/cmake/android.toolchain.cmake \
     -DTFLITE_ENABLE_GPU=ON -DXNNPACK_ENABLE_ARM_BF16=OFF -DANDROID_ABI=arm64-v8a  -DANDROID_PLATFORM=26  \
	 -DTFLITE_HOST_TOOLS_DIR=/home/public/tflite/flatbuffers-master/build/ \
	 -DFLATBUFFERS_FLATC_EXECUTABLE=/home/public/tflite/flatbuffers-master/build/flatc \
     -DTFLITE_ENABLE_INSTALL=ON  -DXNNPACK_ENABLE_ARM_BF16=OFF\
     -DCMAKE_INSTALL_PREFIX=/home/pulic/tflite/local_install
step2: cmake --build . -j
step3: sudo make install
step4: cmake --build . -j -t benchmark_model
```


### Relevant log output

```shell
after step1:
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""eigen"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_flags"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_hash"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_status"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_strings"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_synchronization"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_variant"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""ruy"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""pthreadpool"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_any"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_flat_hash_map"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""xnnpack-delegate"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""XNNPACK"" that is not in any export set.

after step4:
[ 97%] Linking CXX executable benchmark_model
ld: error: undefined symbol: eglGetProcAddress
>>> referenced by async_buffers.cc:35 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/async_buffers.cc:35)
>>>               async_buffers.cc.o:(tflite::gpu::AsyncBuffer::MapAHardwareBufferToGlBuffer()) in archive ../../libtensorflow-lite.a
>>> referenced by async_buffers.cc:38 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/async_buffers.cc:38)
>>>               async_buffers.cc.o:(tflite::gpu::AsyncBuffer::MapAHardwareBufferToGlBuffer()) in archive ../../libtensorflow-lite.a
>>> referenced by android_sync.cc:33 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/android_sync.cc:33)
>>>               android_sync.cc.o:((anonymous namespace)::IsGlSupported()::$_0::operator()() const) in archive ../../libtensorflow-lite.a
>>> referenced 3 more times

ld: error: undefined symbol: glGenBuffers
>>> referenced by async_buffers.cc:72 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/async_buffers.cc:72)
>>>               async_buffers.cc.o:(tflite::gpu::AsyncBuffer::AllocateOpenGlBuffer()) in archive ../../libtensorflow-lite.a

ld: error: undefined symbol: glBindBuffer
>>> referenced by async_buffers.cc:73 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/async_buffers.cc:73)
>>>               async_buffers.cc.o:(tflite::gpu::AsyncBuffer::AllocateOpenGlBuffer()) in archive ../../libtensorflow-lite.a
>>> referenced by async_buffers.cc:85 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/async_buffers.cc:85)
>>>               async_buffers.cc.o:(tflite::gpu::AsyncBuffer::AllocateOpenGlBuffer()) in archive ../../libtensorflow-lite.a

ld: error: undefined symbol: glBufferData
>>> referenced by async_buffers.cc:83 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/async_buffers.cc:83)
>>>               async_buffers.cc.o:(tflite::gpu::AsyncBuffer::AllocateOpenGlBuffer()) in archive ../../libtensorflow-lite.a

ld: error: undefined symbol: eglGetDisplay
>>> referenced by android_sync.cc:59 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/android_sync.cc:59)
>>>               android_sync.cc.o:(tflite::gpu::gl::WaitFdGpu(int)) in archive ../../libtensorflow-lite.a
>>> referenced by android_sync.cc:82 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/android_sync.cc:82)
>>>               android_sync.cc.o:(tflite::gpu::gl::CreateFdGpu()) in archive ../../libtensorflow-lite.a
>>> referenced by gl_call.h:84 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/gl_call.h:84)
>>>               egl_environment.cc.o:(tflite::gpu::gl::EglEnvironment::Init()) in archive ../../libtensorflow-lite.a
>>> referenced 1 more times

ld: error: undefined symbol: glFinish
>>> referenced by android_sync.cc:97 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/android_sync.cc:97)
>>>               android_sync.cc.o:(tflite::gpu::gl::CreateFdGpu()) in archive ../../libtensorflow-lite.a

ld: error: undefined symbol: glGetError
>>> referenced by gl_errors.cc:67 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/gl_errors.cc:67)
>>>               gl_errors.cc.o:(tflite::gpu::gl::GetOpenGlErrors()) in archive ../../libtensorflow-lite.a
>>> referenced by gl_errors.cc:71 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/gl_errors.cc:71)
>>>               gl_errors.cc.o:(tflite::gpu::gl::GetOpenGlErrors()) in archive ../../libtensorflow-lite.a
>>> referenced by gl_errors.cc:76 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/gl_errors.cc:76)
>>>               gl_errors.cc.o:(tflite::gpu::gl::GetOpenGlErrors()) in archive ../../libtensorflow-lite.a
>>> referenced 1 more times

ld: error: undefined symbol: eglGetError
>>> referenced by gl_errors.cc:84 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/gl_errors.cc:84)
>>>               gl_errors.cc.o:(tflite::gpu::gl::GetEglError()) in archive ../../libtensorflow-lite.a

ld: error: undefined symbol: eglBindAPI
>>> referenced by gl_call.h:84 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/gl_call.h:84)
>>>               egl_environment.cc.o:(tflite::gpu::gl::EglEnvironment::Init()) in archive ../../libtensorflow-lite.a
>>> referenced by gl_call.h:84 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/gl_call.h:84)
>>>               egl_environment.cc.o:(tflite::gpu::gl::EglEnvironment::Init()) in archive ../../libtensorflow-lite.a

ld: error: undefined symbol: eglGetCurrentContext
>>> referenced by egl_environment.cc:75 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/egl_environment.cc:75)
>>>               egl_environment.cc.o:(tflite::gpu::gl::EglEnvironment::Init()) in archive ../../libtensorflow-lite.a
>>> referenced by egl_environment.cc:78 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/egl_environment.cc:78)
>>>               egl_environment.cc.o:(tflite::gpu::gl::EglEnvironment::Init()) in archive ../../libtensorflow-lite.a

ld: error: undefined symbol: eglGetCurrentDisplay
>>> referenced by egl_environment.cc:76 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/egl_environment.cc:76)
>>>               egl_environment.cc.o:(tflite::gpu::gl::EglEnvironment::Init()) in archive ../../libtensorflow-lite.a

ld: error: undefined symbol: eglInitialize
>>> referenced by gl_call.h:84 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/gl_call.h:84)
>>>               egl_environment.cc.o:(tflite::gpu::gl::EglEnvironment::Init()) in archive ../../libtensorflow-lite.a
>>> referenced by gl_call.h:84 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/gl_call.h:84)
>>>               egl_environment.cc.o:(tflite::gpu::gl::EglEnvironment::Init()) in archive ../../libtensorflow-lite.a

ld: error: undefined symbol: glDeleteFramebuffers
>>> referenced by egl_environment.cc:59 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/egl_environment.cc:59)
>>>               egl_environment.cc.o:(tflite::gpu::gl::EglEnvironment::~EglEnvironment()) in archive ../../libtensorflow-lite.a

ld: error: undefined symbol: glDeleteTextures
>>> referenced by egl_environment.cc:62 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/egl_environment.cc:62)
>>>               egl_environment.cc.o:(tflite::gpu::gl::EglEnvironment::~EglEnvironment()) in archive ../../libtensorflow-lite.a

ld: error: undefined symbol: glGenFramebuffers
>>> referenced by egl_environment.cc:132 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/egl_environment.cc:132)
>>>               egl_environment.cc.o:(tflite::gpu::gl::EglEnvironment::ForceSyncTurning()) in archive ../../libtensorflow-lite.a

ld: error: undefined symbol: glBindFramebuffer
>>> referenced by egl_environment.cc:133 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/egl_environment.cc:133)
>>>               egl_environment.cc.o:(tflite::gpu::gl::EglEnvironment::ForceSyncTurning()) in archive ../../libtensorflow-lite.a

ld: error: undefined symbol: glGenTextures
>>> referenced by egl_environment.cc:135 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/egl_environment.cc:135)
>>>               egl_environment.cc.o:(tflite::gpu::gl::EglEnvironment::ForceSyncTurning()) in archive ../../libtensorflow-lite.a

ld: error: undefined symbol: glBindTexture
>>> referenced by egl_environment.cc:136 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/egl_environment.cc:136)
>>>               egl_environment.cc.o:(tflite::gpu::gl::EglEnvironment::ForceSyncTurning()) in archive ../../libtensorflow-lite.a

ld: error: undefined symbol: glFramebufferTexture2D
>>> referenced by egl_environment.cc:138 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/egl_environment.cc:138)
>>>               egl_environment.cc.o:(tflite::gpu::gl::EglEnvironment::ForceSyncTurning()) in archive ../../libtensorflow-lite.a

ld: error: undefined symbol: glViewport
>>> referenced by egl_environment.cc:144 (/home/public/tflite/tensorflow-2.18.0/tensorflow/lite/delegates/gpu/gl/egl_environment.cc:144)
>>>               egl_environment.cc.o:(tflite::gpu::gl::EglEnvironment::ForceSyncTurning()) in archive ../../libtensorflow-lite.a

ld: error: too many errors emitted, stopping now (use -error-limit=0 to see all errors)
clang++: error: linker command failed with exit code 1 (use -v to see invocation)
make[3]: *** [tools/benchmark/CMakeFiles/benchmark_model.dir/build.make:682: tools/benchmark/benchmark_model] Error 1
make[2]: *** [CMakeFiles/Makefile2:9168: tools/benchmark/CMakeFiles/benchmark_model.dir/all] Error 2
make[1]: *** [CMakeFiles/Makefile2:9175: tools/benchmark/CMakeFiles/benchmark_model.dir/rule] Error 2
make: *** [Makefile:2652: benchmark_model] Error 2
```
"
2730334124,82669,TF 2.18 fails to use GPU,closed,2024-12-10 14:47:43+00:00,2024-12-10T15:34:49Z,2024-12-10T15:34:35Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/82669,['type:bug'],"['I was able to run the code after I updated the path to LD_LIBRARY_PATH.\r\n\r\nThereore I am closing this issue. ', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82669"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82669"">No</a>\n', 'I was able to run the code after I updated the path to LD_LIBRARY_PATH.\r\n\r\nThereore I am closing this issue.']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

TF 2.18

### Custom code

No

### OS platform and distribution

Linux Ubuntu 22.04.4 LTS

### Mobile device

_No response_

### Python version

3.12.3

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

CUDA 12.6; CUDNN 9.0  

### GPU model and memory

NVIDIA GeForce RTX 3060  12 GBs

### Current behavior?


TF fails to connect to the GPU card on some operations. Specifically, it fails with the code from the TF Basics tutorials, located at   https://www.tensorflow.org/guide/basics : 

""history = new_model.fit(x, y,
                        epochs=100,
                        batch_size=32,
                        verbose=0)
""

The error is 

""
DNN library initialization failed. Look at the errors above for more details.
\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_24212]""
""

2. The code below returns :

print(""Python version: "", sys.version)
print(""TensorFlow version: "", tf.__version__)
print(tf.config.list_physical_devices('GPU'))
print(""Num GPUs Available: "", len(tf.config.list_physical_devices('GPU')))

The result returned is:

Python Version : 3.12.3 [GCC 13.2.0]
TensorFlow version: 2.18.0
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
Num GPUs Available: 1

If I understand this correctly, TF is telling me that it found ! GPU Device, but it is not able to connect.

Just FYI, PyTorch and Julia can use the GPU with no problem. Therefore I assume the problem is with TF, not with my system.



### Standalone code to reproduce the issue

```shell
import sys

# several messages are displayed when TF is imported in a local system
import tensorflow as tf


x = tf.linspace(-2, 2, 201)
x = tf.cast(x, tf.float32)

def f(x):
  y = x**2 + 2*x - 5
  return y

y = f(x) + tf.random.normal(shape=[201])

plt.plot(x.numpy(), y.numpy(), '.', label='Data')
plt.plot(x, f(x), label='Ground truth')
plt.legend();



class Model(tf.Module):

  def __init__(self):
    # Randomly generate weight and bias terms
    rand_init = tf.random.uniform(shape=[3], minval=0., maxval=5., seed=22)
    # Initialize model parameters
    self.w_q = tf.Variable(rand_init[0])
    self.w_l = tf.Variable(rand_init[1])
    self.b = tf.Variable(rand_init[2])
  
  @tf.function
  def __call__(self, x):
    # Quadratic Model : quadratic_weight * x^2 + linear_weight * x + bias
    return self.w_q * (x**2) + self.w_l * x + self.b


new_model = tf.keras.Sequential([
    tf.keras.layers.Lambda(lambda x: tf.stack([x, x**2], axis=1)),
    tf.keras.layers.Dense(units=1, kernel_initializer=tf.random.normal)])


print(""Python version: "", sys.version)
print(""TensorFlow version: "", tf.__version__)
print(tf.config.list_physical_devices('GPU'))
print(""Num GPUs Available: "", len(tf.config.list_physical_devices('GPU')))


new_model.compile(
    loss=tf.keras.losses.MSE,
    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01))

### ERROR HERE 
history = new_model.fit(x, y,
                        epochs=100,
                        batch_size=32,
                        verbose=0)
```


### Relevant log output

```shell
DNN library initialization failed. Look at the errors above for more details.
\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_24212]""
```
"
2739719597,82973,undefined symbol: tflite::StatefulNnApiDelegate::StatefulNnApiDelegate(tflite::StatefulNnApiDelegate::Options),closed,2024-12-14 09:11:22+00:00,2025-01-10T08:13:05Z,2024-12-20T11:18:16Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/82973,"['type:bug', 'comp:lite', 'TF 2.18']","['I tried the following script to set more NNAPI-related parameters, but it still didn\'t work\r\n\r\nReference link: [https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/delegates#nnapi-delegate-provider](url)\r\n\r\n```\r\nbazel build -c opt \\\r\n  --config=android_arm \\\r\n  --repo_env=HERMETIC_PYTHON_VERSION=3.12 \\\r\n  --define tflite_with_nnapi=true \\\r\n  --define use_nnapi=true \\\r\n  --define nnapi_accelerator_name="""" \\\r\n  --define nnapi_execution_preference=""low_power"" \\\r\n  --define nnapi_execution_priority=""high"" \\\r\n  --define nnapi_allow_fp16=false \\\r\n  --define nnapi_allow_dynamic_dimensions=false \\\r\n  --define nnapi_use_burst_mode=true \\\r\n  --verbose_failures \\\r\n  tensorflow/lite:libtensorflowlite.so\r\n```', 'Is there any tutorial for building LiteRT for Android?', ""Hi, @angelOnly \r\nThank you for trying script to set more NNAPI-related parameters but it didn't work so if you don't mind could you please downgrade the TensorFlow version to either 2.17.* or 2.16.* and see is it working fine or not ?\r\n\r\nWe have updated official documentation w.r.t LiteRT Delegates please refer [here](https://ai.google.dev/edge/litert/performance/delegates) and for GPU delegates for LiteRT and GPU ML operations support please refer this [official documentation](https://ai.google.dev/edge/litert/performance/gpu)\r\n\r\nTo migrate from NNAPI, see the instructions for [TensorFlow Lite in Google Play Services](https://www.tensorflow.org/lite/android/play_services) and optionally [TFLite GPU delegate](https://www.tensorflow.org/lite/android/delegates/gpu) for hardware acceleration please refer this [NNAPI Migration Guide](https://developer.android.com/ndk/guides/neuralnetworks/migration-guide)\r\n\r\nHi, @yg-dickson, Please refer this LiteRT [examples](https://github.com/tensorflow/examples/tree/master/lite/examples) of android and official documentation of [Build LiteRT for Android](https://ai.google.dev/edge/litert/android/lite_build)\r\n\r\n\r\nThank you for your cooperation and patience.\r\n"", ""Hello, thank you very much for your reply! \r\nI have read the example you gave. This is the compilation process of java inference, while I use c++ inference, which needs to compile the.so package instead of.aar. And I hope to support nnapi delegate. I don't know how to fix it.\r\n\r\n> Hi, @angelOnly Thank you for trying script to set more NNAPI-related parameters but it didn't work so if you don't mind could you please downgrade the TensorFlow version to either 2.17.* or 2.16.* and see is it working fine or not ?\r\n> \r\n> Hi, @yg-dickson, Please refer this LiteRT [examples](https://github.com/tensorflow/examples/tree/master/lite/examples) of android and official documentation of [Build LiteRT for Android](https://ai.google.dev/edge/litert/android/lite_build)\r\n> \r\n> Thank you for your cooperation and patience."", ""> Is there any tutorial for building LiteRT for Android?\r\n\r\nI can't find any relevant courses. Do you have any recommendations"", 'I have determined where the problem is, because the model does not support some operators of nnapi, resulting in GPU acceleration, but I still failed to compile and open nnapi, I used the gpu delegate to verify this problem.\r\nDownload the official posenet model verification, can be gpu accelerated, and our model does not support gpu acceleration\r\n\r\nnnapi support opt：https://www.tensorflow.org/lite/android/delegates/nnapi?hl=zh-cn#use_supported_models_and_ops\r\ngpu delegate Compiled.so package：https://github.com/ValYouW/tflite-dist/releases\r\n![image](https://github.com/user-attachments/assets/7e7068b1-9040-4de8-8c96-9a8978d6c278)\r\n<img width=""1298"" alt=""image"" src=""https://github.com/user-attachments/assets/758adafa-6ba0-45bd-80e5-bd6e53f5f1de"" />\r\n![image](https://github.com/user-attachments/assets/4069972b-2b77-441b-8db5-37035e890fb5)\r\n', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82973"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/82973"">No</a>\n', ""> Hi, @angelOnly Thank you for trying script to set more NNAPI-related parameters but it didn't work so if you don't mind could you please downgrade the TensorFlow version to either 2.17.* or 2.16.* and see is it working fine or not ?\r\n> \r\n> Hi, @yg-dickson, Please refer this LiteRT [examples](https://github.com/tensorflow/examples/tree/master/lite/examples) of android and official documentation of [Build LiteRT for Android](https://ai.google.dev/edge/litert/android/lite_build)\r\n> \r\n> Thank you for your cooperation and patience.\r\n\r\nFollowing this tutorial, I cannot build\r\ncom.google.ai.edge.litert:litert\r\ncom.google.ai.edge.litert:litert-gpu"", 'Hi, @yg-dickson \r\nApologize for the delayed response, could you please create new issue here :https://github.com/google-ai-edge/LiteRT/issues/new and mention what all steps you followed in that issue ? we will be happy to help you further. \r\n\r\nThank you for your cooperation and understanding.', 'LiteRT No one answered']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.18

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

3.12

### Bazel version

6.5

### GCC/compiler version

14.2

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When I was compiling my own cpp file with ndk-build, I reported the following error
```
ld: error: undefined symbol: tflite::StatefulNnApiDelegate::StatefulNnApiDelegate(tflite::StatefulNnApiDelegate::Options)
>>> referenced by TFLiteEngine.cpp:77
>>>               /Users/jiang/Downloads/ifeng/java/NdkBuilderne/app/src/main/obj/local/armeabi-v7a/objs/pose2dto3d_armeabi-v7a/TFLiteEngine.o:(TFLiteEngine::loadModel(AAssetManager*))
clang++: error: linker command failed with exit code 1 (use -v to see invocation
```

**compileSdkVersion 33**
**buildToolsVersion '30.0.3'**
**ndk.dir=/Users/jiang/Library/Android/sdk/ndk/22.1.7171670**

bazel shell
```
bazel build -c opt --config=android_arm --repo_env=HERMETIC_PYTHON_VERSION=3.12  --define tflite_with_nnapi=true --verbose_failures tensorflow/lite:libtensorflowlite.so
```

Android.mk
```
LOCAL_PATH := $(call my-dir)

cur_arch=armeabi-v7a
LOCAL_CPPFLAGS := -g

# 第三方.so
include $(CLEAR_VARS)
LOCAL_MODULE := libtensorflowlite
LOCAL_SRC_FILES := third/android/$(cur_arch)/lib/libtensorflowlite.so
include $(PREBUILT_SHARED_LIBRARY)

# 自己的c代码
include $(CLEAR_VARS)
LOCAL_MODULE    := pose2dto3d_$(cur_arch)
MY_C_LIST := $(wildcard $(LOCAL_PATH)/TFLiteEngineJNI.cpp)
MY_C_LIST += $(wildcard $(LOCAL_PATH)/TFLiteEngine.cpp)
MY_C_LIST += $(wildcard $(LOCAL_PATH)/DataProcess.cpp)
LOCAL_SRC_FILES := $(MY_C_LIST:$(LOCAL_PATH)/%=%)

# 第三方头文件
# tflite
MY_ALL_DIRS := $(wildcard $(LOCAL_PATH)/)
MY_ALL_DIRS += $(wildcard $(LOCAL_PATH)/third/android/$(cur_arch)/include)
LOCAL_C_INCLUDES := $(MY_ALL_DIRS)

LOCAL_LDLIBS += -llog -lz -landroid -lOpenSLES -lGLESv1_CM -lGLESv2 -lneuralnetworks

LOCAL_STATIC_LIBRARIES := libtensorflowlite

LOCAL_CFLAGS += -UNDEBUG -D_DEBUG
include $(BUILD_SHARED_LIBRARY)
```

Application.mk
```
APP_OPTIM :=release
APP_ABI := armeabi-v7a
APP_PLATFORM := android-27
APP_STL := c++_static
```

.cpp
```
# include <stdio.h>
# include <stdlib.h>
#include <android/asset_manager_jni.h>
#include <android/asset_manager.h>
#include <android/log.h>
# include <jni.h>
#include <sys/uio.h>
#include <cstdlib>
#include <fstream>
#include <iomanip>
#include <iostream>
#include <string>
#include ""tensorflow/lite/interpreter.h""
#include ""tensorflow/lite/model.h""
#include ""tensorflow/lite/kernels/register.h""
#include ""tensorflow/lite/optional_debug_tools.h""
#include ""tensorflow/lite/interpreter_builder.h""
#include ""tensorflow/lite/model_builder.h""
#include ""tensorflow/lite/delegates/nnapi/nnapi_delegate.h""
#include ""TFLiteEngine.h""
#include ""Pose3dModel.h""


TFLiteEngine::TFLiteEngine() {
    is_tflite_initialized = false;
}

TFLiteEngine::~TFLiteEngine() {}

void TFLiteEngine::loadModel(AAssetManager *mgr) {
    __android_log_print(ANDROID_LOG_DEBUG, ""POSE_3D_CPP"",
                        ""..................Entering loadModel...................."");

    if (!pose3dModel.is_tflite_initialized) {
        pose3dModel.asset = AAssetManager_open(mgr, MODEL_PATH, AASSET_MODE_BUFFER);
        if (pose3dModel.asset == nullptr) {
            __android_log_print(ANDROID_LOG_DEBUG, ""POSE_3D_CPP"", ""pose3dInference asset null----"");
            exit(1);
        }

        // 获取文件的大小
        off_t file_length = AAsset_getLength(pose3dModel.asset);
        // 从资产中读取数据到内存
        std::vector<char> model_data(file_length);
        AAsset_read(pose3dModel.asset, model_data.data(), file_length);

        // 1，创建模型和解释器对象，并加载模型
        pose3dModel.model = tflite::FlatBufferModel::BuildFromBuffer(model_data.data(),
                                                                     model_data.size());
        if (!pose3dModel.model) {
            __android_log_print(ANDROID_LOG_DEBUG, ""POSE_3D_CPP"",
                                ""pose3dInference 加载模型失败----"");
            exit(1);
        }

        __android_log_print(ANDROID_LOG_DEBUG, ""POSE_3D_CPP"", ""pose3dInference 加载模型成功----"");

        tflite::InterpreterBuilder builder(*(pose3dModel.model.get()), pose3dModel.resolver);
        builder(&(pose3dModel.interpreter));

        if (!pose3dModel.interpreter) {
            __android_log_print(ANDROID_LOG_DEBUG, ""POSE_3D_CPP"",
                                ""pose3dInference interpreter null----"");
            exit(1);
        }

        if (NUM_THREADS != -1) {
            pose3dModel.interpreter->SetNumThreads(NUM_THREADS);
        }

        // NNAPi设置
        tflite::StatefulNnApiDelegate::Options options;
        options.execution_preference = tflite::StatefulNnApiDelegate::Options::kSustainedSpeed;
        options.use_burst_computation = true;
        options.allow_fp16 = true;

        if ((pose3dModel.delegate = new tflite::StatefulNnApiDelegate(options)) == NULL) {
            __android_log_print(ANDROID_LOG_DEBUG, ""POSE_3D_CPP"", ""pose3dInference NNAPI delegate error----"");
            exit(1);
        }

        if (pose3dModel.delegate != NULL) {
            TfLiteStatus status = pose3dModel.interpreter->ModifyGraphWithDelegate(pose3dModel.delegate);
            if (status != TfLiteStatus::kTfLiteOk)
                __android_log_print(ANDROID_LOG_DEBUG, ""POSE_3D_CPP"", ""pose3dInference Failed to modify graph with delegate!----"");
        }

        if (pose3dModel.interpreter->AllocateTensors() != kTfLiteOk) {
            __android_log_print(ANDROID_LOG_DEBUG, ""POSE_3D_CPP"",
                                ""pose3dInference AllocateTensors ERROR----"");
            exit(1);
        }

        pose3dModel.input = pose3dModel.interpreter->typed_input_tensor<float>(0);
        if (pose3dModel.input == nullptr) {
            __android_log_print(ANDROID_LOG_DEBUG, ""POSE_3D_CPP"", ""pose3dInference input null----"");
            exit(1);
        }
        __android_log_print(ANDROID_LOG_DEBUG, ""POSE_3D_CPP"", ""pose3dInference 初始化input----"");

        is_tflite_initialized = true;
    }
    __android_log_print(ANDROID_LOG_DEBUG, ""POSE_3D_CPP"",
                        ""..................Exiting loadModel...................."");

    if (pose3dModel.asset != nullptr) {
        AAsset_close(pose3dModel.asset);
    }
}
```

### Standalone code to reproduce the issue

```shell
just ndk build my cpp

ndk-build V=1
```
```


### Relevant log output

_No response_"
2743957632,83119,keras.layers.GRU behaves differently in GPU and CPU,closed,2024-12-17 05:19:35+00:00,2024-12-27T06:44:26Z,2024-12-27T06:44:23Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/83119,"['stat:awaiting response', 'type:bug', 'comp:keras', 'comp:ops', 'TF 2.18']","['Hi **@lwk8891** ,\r\nApologies for the delay, and thank you for raising your concern. I tried running your code on Colab using TensorFlow 2.18.0 with both CPU [gist](https://colab.sandbox.google.com/gist/Venkat6871/4c365dfcd83e2d3c2e2ebafa0479fcd6/83119_tf-2-18-0-cpu-v.ipynb) and GPU and faced the same issue. The reason behind this issue is that when running on a GPU, TensorFlow uses the cuDNN-optimized GRU kernel. Even if you set `implementation=2`, the output may still differ on the GPU because the GRU layer internally optimizes for cuDNN, which can unpack the batch dimension for hidden states.\r\n\r\nTo resolve this, you need to explicitly disable the cuDNN kernel for the GRU. I achieved this by setting `reset_after=False`, and it produced the expected results. Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/78ae3171c3750f66b36298dbda06c94b/83119_tf_2-18-0-gpu-v.ipynb) here for your reference.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', '> Hi **@lwk8891** , Apologies for the delay, and thank you for raising your concern. I tried running your code on Colab using TensorFlow 2.18.0 with both CPU [gist](https://colab.sandbox.google.com/gist/Venkat6871/4c365dfcd83e2d3c2e2ebafa0479fcd6/83119_tf-2-18-0-cpu-v.ipynb) and GPU and faced the same issue. The reason behind this issue is that when running on a GPU, TensorFlow uses the cuDNN-optimized GRU kernel. Even if you set `implementation=2`, the output may still differ on the GPU because the GRU layer internally optimizes for cuDNN, which can unpack the batch dimension for hidden states.\r\n> \r\n> To resolve this, you need to explicitly disable the cuDNN kernel for the GRU. I achieved this by setting `reset_after=False`, and it produced the expected results. Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/78ae3171c3750f66b36298dbda06c94b/83119_tf_2-18-0-gpu-v.ipynb) here for your reference. Thank you!\r\n\r\nThank you. It solved the problem.\r\nHowever, would setting `reset_after=False` affect the performance of the program by disabling the cuDNN kernel?', 'Hi **@lwk8891** ,\r\nGlad to see your issue is resolved. However, I suspect there might be a performance impact when using reset_after=False.\r\nThank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/83119"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/83119"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

tf 2.18, tf 2.19

### Custom code

Yes

### OS platform and distribution

WSL Ubuntu 22.04.5 LTS

### Mobile device

_No response_

### Python version

3.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.6/9.6

### GPU model and memory

_No response_

### Current behavior?

The result of the following code is the length of the GRU output variable.

The result is 2 when I executed the code with no GPU by `export CUDA_VISIBLE_DEVICES= `.  One is the output sequence, and the other is the state of GRU. However, the result is 5 = 1 + batch_size when I executed the code with GPU. The first is the output sequence, and the others are the state of GRU with batch unpacking.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
from tensorflow.keras.layers import GRU

batch_size = 4
time_steps = 10
rnn_dimension = 16
input_dim = 8

x = tf.random.normal((batch_size, time_steps, input_dim))

gru = GRU(rnn_dimension, return_sequences=True, return_state=True)

gru_output = gru(x, training=True)
print(len(gru_output))
```


### Relevant log output

_No response_"
2748241445,83279,transfer learning with TF hub,closed,2024-12-18 16:18:50+00:00,2024-12-30T13:22:34Z,2024-12-30T13:22:31Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/83279,"['stat:awaiting response', 'type:bug', 'comp:apis', 'TF 2.18']","['@lincoln12833,\r\nHi, By default the colab notebook is using tensorflow v2.17 and v2.18 which contains keras3.0 which was causing the error. Could you please try to import keras2.0 with the below commands.\r\n\r\n```python\r\n!pip install tf-keras == 2.18.0\r\n\r\nimport tf_keras as keras\r\n```\r\n\r\nAlso I have modified some steps and then the code was executed without error/fail. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/a437f436540f2e799c37102e2fe7904b/transfer_learning_with_hub.ipynb).\r\nI have raised the PR in the Tensorflow/docs repo for the similar issue.\r\nhttps://github.com/tensorflow/docs/pull/2344\r\n\r\nThank you!', '![image](https://github.com/user-attachments/assets/a93d2add-5c97-48f5-8bfc-5edcfead09da)\r\nThe same configuration is running in the background, but it neither outputs nor ends.', 'I got that part working but I am getting the same error in this one after adding those lines https://github.com/lincoln12833/tensor_flow_hub_transfer_learning/blob/main/courses/udacity_intro_to_tensorflow_for_deep_learning/l06c01_tensorflow_hub_and_transfer_learning.ipynb @tilakrayal \r\n', '@lincoln12833,\r\nIn the code you are trying to import the keras as **import tf_keras as keras** and using tf.keras.sequential in the code. Could you try to change from layers.dense to keras.layers.dense and execute the code. In the above attached  gist, I have changed the tf.keras to keras, and try to execute the code.\r\n\r\nFrom:\r\n![image](https://github.com/user-attachments/assets/49b44cb4-9845-4624-a8a5-f954087419a8)\r\n\r\n\r\nTo:\r\n![image](https://github.com/user-attachments/assets/13a478df-4190-4a35-9017-66ed1c8898fa)\r\n\r\n\r\nThank you!\r\n\r\n\r\n', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', 'Thank you so much for all your help tilakrayal. This seemed to have fixed it.', '@lincoln12833,\r\nGlad the issue was resolved. Could you please feel free to move this issue to closed status. Thank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/83279"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/83279"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.8

### Custom code

No

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

If you use tensorflow_hub.KerasLayer(correct parmeters), in a squential model: it won't recognize it as an acceptable layer. 

### Standalone code to reproduce the issue

```shell
https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub
```


### Relevant log output

```shell
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-3-7db51c8d2d71> in <cell line: 3>()
      1 IMAGE_SHAPE = (224, 224)
      2 
----> 3 classifier = tf.keras.Sequential([
      4     hub.KerasLayer(classifier_model, input_shape=IMAGE_SHAPE+(3,))
      5 ])

1 frames
/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py in add(self, layer, rebuild)
     94                 layer = origin_layer
     95         if not isinstance(layer, Layer):
---> 96             raise ValueError(
     97                 ""Only instances of `keras.Layer` can be ""
     98                 f""added to a Sequential model. Received: {layer} ""

ValueError: Only instances of `keras.Layer` can be added to a Sequential model. Received: <tensorflow_hub.keras_layer.KerasLayer object at 0x7aafb7ccd2a0> (of type <class 'tensorflow_hub.keras_layer.KerasLayer'>)
```
"
2749710114,83331,Problems with TFLite operator performance profiling,closed,2024-12-19 09:19:11+00:00,2025-01-24T21:08:57Z,2025-01-24T21:08:53Z,pkgoogle,,https://github.com/tensorflow/tensorflow/issues/83331,"['type:bug', 'comp:lite', 'TF 2.16']","['Hi, @pkgoogle\r\nPlease take a look into this issue. Thank you', 'Hello, we will be moving this issue to [LiteRT](https://github.com/google-ai-edge/LiteRT). Please follow progress there.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/83331"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/83331"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

tf 2.16.1

### Custom code

No

### OS platform and distribution

_No response_

### Mobile device

Android Google Pixel 6

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I want to profile the operator performance of my custom tflite model in android phone 'Google Pixel 6'.
I have followed the tutorial [measurement](https://github.com/tensorflow/tensorflow/blob/2c2fa69bb57442e274777a277f7f8bb8256a5ef3/tensorflow/lite/g3doc/performance/measurement.md#trace-tensorflow-lite-internals) and built a very simple test program [[source code](https://github.com/4570235/LiteRTStarter)]. However, I encounter some problems.

Firstly, when I tested the model '[mobilenetv1.tflite](https://storage.googleapis.com/download.tensorflow.org/models/tflite/task_library/image_classification/android_java/mobilenet_v1_1.0_224_quantized_1_metadata_1.tflite)' from tflite example [image_classification](https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification), if my program depends on the newest version of TFLite
```groovy
implementation 'org.tensorflow:tensorflow-lite:2.16.1'
implementation 'org.tensorflow:tensorflow-lite-support:0.4.4'
``` 
then the Android Studio CPU Profiler shows 
![image](https://github.com/user-attachments/assets/1f101ba0-07d4-48ce-a65f-be2974611766)

I cannot see all the operators. After some testing, I figure out that the maximum version of TFLite that works is `tensorflow-lite:2.12.0` with `tensorflow-lite-support:0.4.0.`
```groovy
implementation 'org.tensorflow:tensorflow-lite:2.12.0'
implementation 'org.tensorflow:tensorflow-lite-support:0.4.0'
``` 
Here's the result: 
![image](https://github.com/user-attachments/assets/ef16d2a4-5430-41a1-8649-ad97b51888a0)

**So, is this a bug? How can I trace operator performance with the newest version of TFLite?**

Secondly, with `tensorflow-lite:2.12.0` and `tensorflow-lite-support:0.4.0` mentioned above, I tried to trace my custom model which is very similar to Qualcomm's '[quicksrnetsmall.tflite](https://aihub.qualcomm.com/models/quicksrnetsmall)'. Let's take 'quicksrnetsmall.tflite' as an sample and the Profiler shows
![image](https://github.com/user-attachments/assets/2f45f1cd-afc7-443a-a1be-36cd3b10bc47)

I cannot see any operators. **How can I fix it?**

### Standalone code to reproduce the issue

```shell
https://github.com/4570235/LiteRTStarter/blob/master/app/src/main/java/com/handleychen/litertstarter/Benchmark.java
```


### Relevant log output

_No response_"
2751686092,83371,TF - Problems when trying to use GPU on M3 Max,closed,2024-12-20 00:55:58+00:00,2025-01-02T08:58:10Z,2025-01-02T08:58:06Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/83371,"['stat:awaiting response', 'type:bug', 'TF 2.16']","['The issue you\'re encountering with TensorFlow on the Apple M3 Max GPU seems to be related to the Metal backend for TensorFlow. From the logs, we can see the following key information:\r\n\r\n1. **TensorFlow Metal Plugin**: The logs indicate that TensorFlow is trying to use the Metal API (`metal_plugin/src/device/metal_device.cc`) to run on the GPU, which is Apple\'s framework for GPU acceleration.\r\n2. **Error Message**: The error message `malloc: *** error for object 0x315008234: pointer being freed was not allocated` suggests a memory allocation issue, possibly related to TensorFlow interacting with the Metal API.\r\n\r\nHere\'s a step-by-step approach to troubleshoot and resolve the issue:\r\n\r\n### 1. **Verify Metal Backend Installation**\r\n   TensorFlow uses Metal (Apple\'s GPU API) for macOS devices with M1 and M2 chips, and now M3 chips as well. Make sure that you have the correct version of TensorFlow that supports the Metal backend. As of TensorFlow 2.16.2, Metal support should be in place, but compatibility with the M3 Max specifically may have issues that are not present in older M1 or M2 chips.\r\n\r\n   You can verify if TensorFlow is correctly using the Metal backend by running this code:\r\n\r\n   ```python\r\n   import tensorflow as tf\r\n   from tensorflow.python.keras import backend as K\r\n\r\n   devices = K.tensorflow_backend._get_available_devices()\r\n   print(devices)\r\n   ```\r\n\r\n   This will give you information about which devices TensorFlow is recognizing, including your Metal-compatible GPU. If the GPU is listed, it indicates that TensorFlow is correctly identifying and attempting to use the Metal GPU backend.\r\n\r\n### 2. **Use CPU Instead of GPU**\r\n   If the issue is exclusive to the Metal GPU backend, you might want to disable the GPU usage temporarily to verify that the CPU setup works fine. You can do this by setting the environment variable `CUDA_VISIBLE_DEVICES` to an empty string before running your script:\r\n\r\n   ```bash\r\n   export CUDA_VISIBLE_DEVICES=""""\r\n   python your_script.py\r\n   ```\r\n\r\n   This will force TensorFlow to use the CPU instead of the GPU, which should allow the program to run without crashing. \r\n\r\n### 3. **Ensure Latest macOS & TensorFlow Version**\r\n   Since you\'re using the M3 Max, which is relatively new, it\'s possible that TensorFlow\'s Metal plugin hasn\'t been fully optimized for the new architecture. Here’s what you can do:\r\n\r\n   - **Update macOS**: Make sure your macOS is up to date. Sometimes, macOS updates contain critical updates for the Metal API, which can affect TensorFlow’s ability to utilize the GPU correctly.\r\n   \r\n   - **Update TensorFlow**: Ensure you\'re using the latest nightly build or stable version of TensorFlow. Some Metal backend optimizations might not have been included in TensorFlow 2.16.2.\r\n\r\n     You can upgrade TensorFlow with pip:\r\n\r\n     ```bash\r\n     pip install --upgrade tensorflow\r\n     ```\r\n\r\n     Alternatively, you can try the latest nightly build, which may have better support for the M3 Max:\r\n\r\n     ```bash\r\n     pip install tensorflow-macos\r\n     ```\r\n\r\n     And if you want to ensure the latest support for Metal, you can install the TensorFlow nightly release for macOS:\r\n\r\n     ```bash\r\n     pip install tensorflow-macos==2.18.0-nightly\r\n     ```\r\n\r\n     After updating, try running the same code again to check if the issue is resolved.\r\n\r\n### 4. **Metal Device Compatibility**\r\n   TensorFlow’s Metal support is relatively new and evolving, so there could be issues related to certain hardware configurations like the M3 Max. While the GPU is being recognized in the logs, there might be subtle bugs or configuration issues specific to this model.\r\n\r\n   You could try running a simple GPU-accelerated operation (such as matrix multiplication or convolution) to see if TensorFlow crashes in a minimal setup. This would help confirm if the issue is with TensorFlow’s Metal implementation or something specific in your code.\r\n\r\n   Here\'s a minimal test you can try:\r\n\r\n   ```python\r\n   import tensorflow as tf\r\n   import numpy as np\r\n\r\n   # Create a simple tensor on the GPU\r\n   with tf.device(\'/GPU:0\'):\r\n       A = tf.random.normal([100, 100])\r\n       B = tf.random.normal([100, 100])\r\n       C = tf.matmul(A, B)\r\n       print(C)\r\n   ```\r\n\r\n   This test will let you know if TensorFlow can successfully execute basic GPU operations on the M3 Max.\r\n\r\n### 5. **Inspect TensorFlow Error Logs**\r\n   The error message you\'ve provided indicates that TensorFlow is crashing due to a memory issue (pointer being freed that wasn\'t allocated). To gain more insight into what\'s causing this crash, you can inspect more detailed logs using a debugger like `lldb` or `gdb` on macOS:\r\n\r\n   ```bash\r\n   lldb -- python your_script.py\r\n   ```\r\n\r\n   When the crash happens, you can type `bt` (backtrace) in the `lldb` prompt to get more detailed debugging information. This can help pinpoint the exact location in TensorFlow where the error occurs.\r\n\r\n### 6. **Try Disabling GPU Memory Growth**\r\n   If the issue is related to GPU memory allocation, you can try limiting GPU memory growth, which might help with memory fragmentation issues:\r\n\r\n   ```python\r\n   import tensorflow as tf\r\n\r\n   physical_devices = tf.config.list_physical_devices(\'GPU\')\r\n   tf.config.set_visible_devices(physical_devices[0], \'GPU\')\r\n   tf.config.experimental.set_memory_growth(physical_devices[0], True)\r\n   ```\r\n\r\n   This ensures that TensorFlow doesn’t try to allocate all available memory upfront, and it may help avoid memory allocation crashes.\r\n\r\nIf the problem persists, it might be worth reporting it to the [[TensorFlow GitHub repository](https://github.com/tensorflow/tensorflow/issues)](https://github.com/tensorflow/tensorflow/issues) to see if it\'s a known issue or if any fixes are planned for the M3 Max.', '\r\nHi **@tbjerke04** ,\r\nApologies for the delay, and thank you for raising your concern here. I tried running your code on an M3 Max with the GPU, and it is working fine for me. I have attached screenshots for your reference—please check them once, and let me know if I made any mistakes.\r\n![image (7)](https://github.com/user-attachments/assets/f1cc4edc-e559-44c0-b338-8a634d1c07b3)\r\n![image (6)](https://github.com/user-attachments/assets/494166f9-1ac0-4ade-85b5-1991aac40628)\r\n![image (8)](https://github.com/user-attachments/assets/b056f8b3-0b2f-4ff9-af13-8b08e9f2a5a9)\r\nThank you!', 'Hmm, okey thats weird. Many it is because I’m using Python 3.9.15 and not 3.9.6, as you do?\r\n\r\nI’ll have to troubleshoot a little more. I am using an Anaconda environment, so maybe that’s a problem too.\r\n\r\nAnyways, thanks for the update!\r\n\r\n\r\nHave a nice Christmas:)\r\n\r\nFra: Venkat6871 ***@***.***>\r\nDato: mandag, 23. desember 2024 kl. 11:08\r\nTil: tensorflow/tensorflow ***@***.***>\r\nKopi: Tobias Nøklegård Bjerke ***@***.***>, Mention ***@***.***>\r\nEmne: Re: [tensorflow/tensorflow] TF - Problems when trying to use GPU on M3 Max (Issue #83371)\r\n\r\nHi @tbjerke04<https://github.com/tbjerke04> ,\r\nApologies for the delay, and thank you for raising your concern here. I tried running your code on an M3 Max with the GPU, and it is working fine for me. I have attached screenshots for your reference—please check them once, and let me know if I made any mistakes.\r\nimage.7.png (view on web)<https://github.com/user-attachments/assets/f1cc4edc-e559-44c0-b338-8a634d1c07b3>\r\nimage.6.png (view on web)<https://github.com/user-attachments/assets/494166f9-1ac0-4ade-85b5-1991aac40628>\r\nimage.8.png (view on web)<https://github.com/user-attachments/assets/b056f8b3-0b2f-4ff9-af13-8b08e9f2a5a9>\r\nThank you!\r\n\r\n—\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/83371#issuecomment-2559355922>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/BNVZWFMCPY7IHSYBOVWMQOL2G7OJDAVCNFSM6AAAAABT6DTN2SVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDKNJZGM2TKOJSGI>.\r\nYou are receiving this because you were mentioned.Message ID: ***@***.***>\r\n', 'I have the same exact issue but on M1 air, runs well on cpu but not on metal GPU\r\n', 'Also @micedevai, the minimal code you provided works, the crash only seems to occur when you run an operation from keras', 'I tried to switch from an Anaconda environment to using Brew, and it actually solved the problem!\r\n\r\nSent from Outlook for iOS<https://aka.ms/o0ukef>\r\n________________________________\r\nFrom: Vincent Precious ***@***.***>\r\nSent: Wednesday, December 25, 2024 10:29:13 PM\r\nTo: tensorflow/tensorflow ***@***.***>\r\nCc: Tobias Nøklegård Bjerke ***@***.***>; Mention ***@***.***>\r\nSubject: Re: [tensorflow/tensorflow] TF - Problems when trying to use GPU on M3 Max (Issue #83371)\r\n\r\n\r\nAlso @micedevai<https://github.com/micedevai>, the minimal code you provided works, the crash only seems to occur when you run an operation from keras\r\n\r\n—\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/83371#issuecomment-2562003449>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/BNVZWFMZ2PSTNFWD4JAHR7T2HMPSTAVCNFSM6AAAAABT6DTN2SVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDKNRSGAYDGNBUHE>.\r\nYou are receiving this because you were mentioned.Message ID: ***@***.***>\r\n', '\r\nIt appears that the crash occurs specifically when running operations from Keras on the M3 Max GPU, while basic GPU operations such as matrix multiplication work fine. Based on the error message `malloc: *** error for object 0x315008234: pointer being freed was not allocated`, this seems to be a memory allocation or management issue related to TensorFlow\'s Metal backend.\r\n\r\nSince the minimal test works but Keras operations cause the crash, here are a few additional steps you can take to troubleshoot and resolve the issue:\r\n\r\n---\r\n\r\n### 1. **Try a Simplified Keras Model**\r\n\r\nSometimes, certain layers or configurations in Keras might trigger memory management issues. To narrow down the cause, try running a simple Keras model with the same Metal backend setup and see if the crash still occurs. This can help isolate whether it\'s a specific layer or operation causing the issue.\r\n\r\nHere\'s an example of a minimal Keras model:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers, models\r\n\r\n# Define a simple model\r\nmodel = models.Sequential([\r\n    layers.Dense(64, activation=\'relu\', input_shape=(100,)),\r\n    layers.Dense(10, activation=\'softmax\')\r\n])\r\n\r\n# Compile the model\r\nmodel.compile(optimizer=\'adam\', loss=\'sparse_categorical_crossentropy\', metrics=[\'accuracy\'])\r\n\r\n# Generate some random input data\r\nimport numpy as np\r\nx_train = np.random.random((1000, 100))\r\ny_train = np.random.randint(10, size=(1000,))\r\n\r\n# Train the model\r\nmodel.fit(x_train, y_train, epochs=5)\r\n```\r\n\r\nThis minimal Keras model can help determine if the crash is related to specific layers or operations in your full model.\r\n\r\n---\r\n\r\n### 2. **Disable Keras GPU Acceleration (For Debugging)**\r\n\r\nYou can try forcing Keras to run on the CPU instead of the GPU temporarily to isolate whether the problem is specific to the Metal backend with Keras. Set the environment variable to disable GPU usage:\r\n\r\n```bash\r\nexport CUDA_VISIBLE_DEVICES=""""\r\n```\r\n\r\nAlternatively, you can configure TensorFlow to explicitly use only the CPU within your script:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n# Set TensorFlow to use only the CPU\r\ntf.config.set_visible_devices([], \'GPU\')\r\n```\r\n\r\nIf the crash stops occurring when using the CPU, it strongly suggests the issue lies with GPU acceleration in Keras or the Metal backend.\r\n\r\n---\r\n\r\n### 3. **Disable Keras Layer Caching (Memory Fragmentation)**\r\n\r\nIf the issue is related to memory fragmentation, disabling Keras\'s layer caching might help. You can do this by clearing the session before running your Keras operations:\r\n\r\n```python\r\nfrom tensorflow.keras import backend as K\r\n\r\n# Clear the Keras session to reset the model\'s state\r\nK.clear_session()\r\n```\r\n\r\nClearing the session may help resolve issues related to GPU memory fragmentation or improper memory allocation during model creation and training.\r\n\r\n---\r\n\r\n### 4. **Check TensorFlow\'s Memory Management Settings**\r\n\r\nThe memory issue might be related to TensorFlow\'s GPU memory allocation strategy. You can adjust TensorFlow\'s memory growth settings to prevent it from allocating all available memory at once, which can help avoid crashes due to memory fragmentation.\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n# List available GPUs\r\nphysical_devices = tf.config.list_physical_devices(\'GPU\')\r\n\r\n# Set memory growth on GPU to avoid TensorFlow allocating all GPU memory upfront\r\nfor device in physical_devices:\r\n    tf.config.experimental.set_memory_growth(device, True)\r\n\r\n# Check that memory growth is enabled\r\nfor device in physical_devices:\r\n    print(f""Memory growth enabled for {device}"")\r\n```\r\n\r\nThis ensures that TensorFlow only allocates GPU memory as needed, which might reduce memory-related issues.\r\n\r\n---\r\n\r\n### 5. **Investigate the Crash Using Debugging Tools**\r\n\r\nIf the problem persists and you\'re getting a crash related to memory allocation, use **lldb** or **gdb** to get more information about the exact point of failure. You can use the following command in the terminal to debug your script:\r\n\r\n```bash\r\nlldb -- python your_script.py\r\n```\r\n\r\nOnce the crash happens, you can type `bt` in the `lldb` prompt to get a backtrace and pinpoint where the crash is occurring in TensorFlow\'s code. This may provide more insight into whether the issue lies with the TensorFlow Metal implementation, Keras, or the way resources are managed.\r\n\r\n---\r\n\r\n### 6. **Update TensorFlow and macOS**\r\n\r\nAs the M3 Max is a relatively new chip, TensorFlow may not yet be fully optimized for it. Ensure that you\'re running the latest versions of both macOS and TensorFlow to benefit from the latest fixes and improvements, especially related to Metal support.\r\n\r\nTo upgrade TensorFlow:\r\n\r\n```bash\r\npip install --upgrade tensorflow-macos\r\n```\r\n\r\nOr install the latest nightly version that may include better Metal support for newer hardware:\r\n\r\n```bash\r\npip install tensorflow-macos==2.18.0-nightly\r\n```\r\n\r\nAdditionally, make sure your macOS is up to date, as Apple frequently releases updates that improve compatibility with the Metal framework, which could help with TensorFlow\'s ability to utilize the GPU correctly.\r\n\r\n---\r\n\r\n### 7. **Report the Issue**\r\n\r\nIf none of these steps resolve the issue, it might be worth reporting the bug to TensorFlow\'s GitHub repository. The issue could be a known problem with the Metal backend on the M3 Max or an issue that has not been fixed yet. You can report the issue on TensorFlow\'s GitHub [[issue tracker](https://github.com/tensorflow/tensorflow/issues)](https://github.com/tensorflow/tensorflow/issues).\r\n\r\nProvide details about your hardware (M3 Max), macOS version, TensorFlow version, the error message, and any debugging information you\'ve gathered (such as crash logs or backtraces).\r\n\r\n---\r\n\r\nBy following these steps, you should be able to either resolve the issue or gather enough information to report the bug and potentially receive a fix.', 'Hi **@tbjerke04** ,\r\nGlad to see your issue is resolved. Please feel free to close this issue if everything is working as expected.\r\nThank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/83371"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/83371"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.16.2

### Custom code

Yes

### OS platform and distribution

Sequoia 15.2

### Mobile device

_No response_

### Python version

3.9.15

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

30-core (M3 Max)

### Current behavior?

I have tried to troubleshoot the problem together with ChatGPT o1, and after a lot of testing, it came to the conclusion that it might be a problem with tensorflow running om my M3 Max. It works fine with the CPU, but as soon as I try to use the GPU, no matter the complexity of the program, it crashes immediately.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
import numpy as np

# Dummy data
X_train = np.random.random((1000, 24, 9))
y_train = np.random.random((1000, 9))
X_val = np.random.random((200, 24, 9))
y_val = np.random.random((200, 9))

# Bygg enkel modell
model = Sequential([
    Flatten(input_shape=(24, 9)),
    Dense(64, activation='relu'),
    Dense(9, activation='linear')
])

model.compile(optimizer='adam', loss='mse')

# Tren modell
model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)
```


### Relevant log output

```shell
UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
2024-12-20 01:55:05.196093: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max
2024-12-20 01:55:05.196117: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB
2024-12-20 01:55:05.196122: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 13.50 GB
2024-12-20 01:55:05.196138: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2024-12-20 01:55:05.196152: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)
Epoch 1/10
2024-12-20 01:55:05.402051: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.
python(31809,0x1fb8e4240) malloc: *** error for object 0x315008234: pointer being freed was not allocated
python(31809,0x1fb8e4240) malloc: *** set a breakpoint in malloc_error_break to debug
zsh: abort
```
"
2753768096,83508,DLL load failure,closed,2024-12-21 05:15:18+00:00,2025-01-03T16:59:40Z,2025-01-03T16:59:37Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/83508,"['stat:awaiting response', 'type:bug', 'TF 2.18']","['same error here', 'Same error here', 'Hi **@Davischoice1** ,\r\nApologies for the delay. Could you please provide the tensorflow and the compatible version which you are trying to install. Also there are at least 3 possible scenarios:\r\n\r\nYou need to install the MSVC 2019 redistributable\r\nYour CPU does not support AVX2 instructions\r\nYour CPU/Python is on 32 bits\r\nThere is a library that is in a different location/not installed on your system that cannot be loaded.\r\nhttps://github.com/tensorflow/tensorflow/issues/61887\r\nThank you!', 'tensorflow version: 2.18.Orc2\r\n', 'actually is version 2.18.0 ', 'Hi **@langtontdangare** ,\r\nCould you please open another issue with all the relevant details? This will make it easier for us to track and assist you effectively.\r\nThank you!', 'Duplicate of https://github.com/tensorflow/tensorflow/issues/19584. Please do a search before opening new issues. This is a very old issue and manifests because old PCs with Windows cannot load libraries needed by TF because they have very old architecture sets.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/83508"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/83508"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.18

### Custom code

Yes

### OS platform and distribution

windows 10

### Mobile device

_No response_

### Python version

3.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

i want a successful run

### Standalone code to reproduce the issue

```shell
ImportError                               Traceback (most recent call last)
File ~\anaconda3\envs\tensorflow\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py:70
     69 try:
---> 70   from tensorflow.python._pywrap_tensorflow_internal import *
     71 # This try catch logic is because there is no bazel equivalent for py_extension.
     72 # Externally in opensource we must enable exceptions to load the shared object
     73 # by exposing the PyInit symbols with pybind. This error will only be
     74 # caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.
     75 
     76 # This logic is used in other internal projects using py_extension.

ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
Cell In[4], line 1
----> 1 import tensorflow as tf

File ~\anaconda3\envs\tensorflow\Lib\site-packages\tensorflow\__init__.py:40
     37 _os.environ.setdefault(""ENABLE_RUNTIME_UPTIME_TELEMETRY"", ""1"")
     39 # Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596
---> 40 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow  # pylint: disable=unused-import
     41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import KerasLazyLoader as _KerasLazyLoader

File ~\anaconda3\envs\tensorflow\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py:85
     83     sys.setdlopenflags(_default_dlopen_flags)
     84 except ImportError:
---> 85   raise ImportError(
     86       f'{traceback.format_exc()}'
     87       f'\n\nFailed to load the native TensorFlow runtime.\n'
     88       f'See https://www.tensorflow.org/install/errors '
     89       f'for some common causes and solutions.\n'
     90       f'If you need help, create an issue '
     91       f'at https://github.com/tensorflow/tensorflow/issues '
     92       f'and include the entire stack trace above this error message.')

ImportError: Traceback (most recent call last):
  File ""C:\Users\user\anaconda3\envs\tensorflow\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 70, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.
See https://www.tensorflow.org/install/errors for some common causes and solutions.
If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.
```


### Relevant log output

```shell
ImportError                               Traceback (most recent call last)
File ~\anaconda3\envs\tensorflow\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py:70
     69 try:
---> 70   from tensorflow.python._pywrap_tensorflow_internal import *
     71 # This try catch logic is because there is no bazel equivalent for py_extension.
     72 # Externally in opensource we must enable exceptions to load the shared object
     73 # by exposing the PyInit symbols with pybind. This error will only be
     74 # caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.
     75 
     76 # This logic is used in other internal projects using py_extension.

ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
Cell In[4], line 1
----> 1 import tensorflow as tf

File ~\anaconda3\envs\tensorflow\Lib\site-packages\tensorflow\__init__.py:40
     37 _os.environ.setdefault(""ENABLE_RUNTIME_UPTIME_TELEMETRY"", ""1"")
     39 # Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596
---> 40 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow  # pylint: disable=unused-import
     41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import KerasLazyLoader as _KerasLazyLoader

File ~\anaconda3\envs\tensorflow\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py:85
     83     sys.setdlopenflags(_default_dlopen_flags)
     84 except ImportError:
---> 85   raise ImportError(
     86       f'{traceback.format_exc()}'
     87       f'\n\nFailed to load the native TensorFlow runtime.\n'
     88       f'See https://www.tensorflow.org/install/errors '
     89       f'for some common causes and solutions.\n'
     90       f'If you need help, create an issue '
     91       f'at https://github.com/tensorflow/tensorflow/issues '
     92       f'and include the entire stack trace above this error message.')

ImportError: Traceback (most recent call last):
  File ""C:\Users\user\anaconda3\envs\tensorflow\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 70, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.
See https://www.tensorflow.org/install/errors for some common causes and solutions.
If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.
```
"
2756717996,83632,DLL Load Failed while Importing _pywrap_tensorflow_internal on Windows,closed,2024-12-23 21:08:35+00:00,2024-12-24T12:14:15Z,2024-12-24T12:14:12Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/83632,['type:bug'],"['Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/83632"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/83632"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.18.0

### Custom code

No

### OS platform and distribution

Microsoft Windows 11 Pro

### Mobile device

_No response_

### Python version

3.11.0

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When I try to import TensorFlow using the command `import tensorflow as tf`, I get the following error message:

`ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.`

This error prevents TensorFlow from starting properly. I am using the CPU version of TensorFlow and do not require CUDA/cuDNN. I have ensured that all necessary components for TensorFlow to function correctly are installed on my system.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""D:\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 70, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""D:\Python\Python311\Lib\site-packages\tensorflow\__init__.py"", line 40, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow  # pylint: disable=unused-import
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""D:\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 85, in <module>
    raise ImportError(
ImportError: Traceback (most recent call last):
  File ""D:\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 70, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.
```
"
2761011732,83802,Cannot Fine-Tune Hugging Face TF model on GPU (it works on CPU),closed,2024-12-27 15:31:24+00:00,2025-01-15T01:59:54Z,2025-01-15T01:59:51Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/83802,"['stat:awaiting response', 'type:bug', 'stale', 'TF 2.18']","['@carlosg-m,\r\nHi, By default the colab notebook is using tensorflow v2.17 and v2.18 which contains keras3.0 which was causing the error. Could you please try to import keras2.0 with the below commands.\r\n\r\n```python\r\n!pip install tf-keras == 2.18.0\r\n\r\nimport tf_keras as keras\r\n```\r\n\r\nAlso I have modified some steps and then the code was executed without error/fail. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/12745b17800316a04bc64f499ec33437/untitled2292.ipynb).\r\n\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/83802"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/83802"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.18.0

### Custom code

Yes

### OS platform and distribution

Ubuntu 24.04.1 LTS

### Mobile device

_No response_

### Python version

3.12.3

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.5.1 / 9

### GPU model and memory

Nvidia Tesla T4 GPU (16GB)

### Current behavior?

I'm trying to fine tune HuggingFace's `TFResNetModel` using `tf.keras`. The provided example works on CPU, however when I enable the GPU I get the following error. 

The GPU is running and working fine for a simple Keras model example. 

The problem seems to be related to the integration of tf.Keras and HuggingFace.

### Standalone code to reproduce the issue

```shell
os.environ['TF_USE_LEGACY_KERAS'] = '1'
import tensorflow as tf
from transformers import TFResNetModel

def create_model():
  
  base_model = TFResNetModel.from_pretrained(""microsoft/resnet-50"")
  inputs = tf.keras.Input((3,224,224), dtype='float32')

  x = base_model(inputs).pooler_output
  x = tf.keras.layers.Flatten()(x)
  x = tf.keras.layers.Dense(1, activation='sigmoid')(x)
  
  model = tf.keras.Model(inputs=inputs, outputs=x)
  return model

model = create_model()

model.layers[1].trainable = False

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), 
              loss=tf.keras.losses.BinaryCrossentropy())

model.fit(x=np.random.random(size=(10,3,224,224)), 
          y=np.random.random(size=(10,)), 
          batch_size=2, 
          epochs=20, 
          shuffle=True)
```


### Relevant log output

```shell
I0000 00:00:1735312999.999419   28671 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14793 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0001:00:00.0, compute capability: 7.5
Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFResNetModel: ['resnet.encoder.stages.2.layers.2.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.2.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.5.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.1.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.2.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.4.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.4.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.3.layers.0.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.3.layers.2.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.2.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.0.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.3.layers.0.shortcut.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.0.shortcut.normalization.num_batches_tracked', 'classifier.1.bias', 'resnet.encoder.stages.2.layers.2.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.3.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.5.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.4.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.0.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.3.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.0.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.0.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.3.layers.0.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.3.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.2.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.3.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.1.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.3.layers.1.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.0.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.0.shortcut.normalization.num_batches_tracked', 'resnet.encoder.stages.3.layers.2.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.2.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.2.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.3.layers.2.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.3.layers.1.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.0.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.1.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.3.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.3.layers.0.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.2.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.0.shortcut.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.1.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.5.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.1.layer.2.normalization.num_batches_tracked', 'classifier.1.weight', 'resnet.encoder.stages.1.layers.0.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.1.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.1.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.3.layers.1.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.1.layer.0.normalization.num_batches_tracked', 'resnet.embedder.embedder.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.0.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.3.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.1.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.0.layer.2.normalization.num_batches_tracked']
- This IS expected if you are initializing TFResNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFResNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
All the weights of TFResNetModel were initialized from the PyTorch model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use TFResNetModel for predictions without further training.
Epoch 1/20
2024-12-27 15:23:25.310845: I tensorflow/core/grappler/optimizers/generic_layout_optimizer.cc:403] Cancel Transpose nodes around Pad: transpose_before=model/tf_res_net_model/resnet/transpose pad=model/tf_res_net_model/resnet/embedder/embedder/Pad transpose_after=model/tf_res_net_model/resnet/embedder/embedder/convolution/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer
E0000 00:00:1735313005.557664   28780 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but source was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.
2024-12-27 15:23:25.558728: W tensorflow/core/framework/op_kernel.cc:1841] OP_REQUIRES failed at conv_ops_impl.h:1204 : INVALID_ARGUMENT: No DNN in stream executor.
2024-12-27 15:23:25.558788: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: No DNN in stream executor.
	 [[{{node model/tf_res_net_model/resnet/embedder/embedder/convolution/Conv2D}}]]

InvalidArgumentError: Graph execution error:

Detected at node model/tf_res_net_model/resnet/embedder/embedder/convolution/Conv2D defined at (most recent call last):
  File ""/databricks/python_shell/scripts/db_ipykernel_launcher.py"", line 242, in <module>

  File ""/databricks/python_shell/scripts/db_ipykernel_launcher.py"", line 238, in main

  File ""/databricks/python/lib/python3.12/site-packages/ipykernel/kernelapp.py"", line 701, in start

  File ""/databricks/python/lib/python3.12/site-packages/tornado/platform/asyncio.py"", line 205, in start

  File ""/usr/lib/python3.12/asyncio/base_events.py"", line 641, in run_forever

  File ""/usr/lib/python3.12/asyncio/base_events.py"", line 1987, in _run_once

  File ""/usr/lib/python3.12/asyncio/events.py"", line 88, in _run

  File ""/databricks/python/lib/python3.12/site-packages/ipykernel/kernelbase.py"", line 534, in dispatch_queue

  File ""/databricks/python/lib/python3.12/site-packages/ipykernel/kernelbase.py"", line 523, in process_one

  File ""/databricks/python/lib/python3.12/site-packages/ipykernel/kernelbase.py"", line 429, in dispatch_shell

  File ""/databricks/python/lib/python3.12/site-packages/ipykernel/kernelbase.py"", line 767, in execute_request

  File ""/databricks/python_shell/dbruntime/DatabricksShell.py"", line 285, in do_execute

  File ""/databricks/python/lib/python3.12/site-packages/ipykernel/ipkernel.py"", line 429, in do_execute

  File ""/databricks/python/lib/python3.12/site-packages/ipykernel/zmqshell.py"", line 549, in run_cell

  File ""/databricks/python/lib/python3.12/site-packages/IPython/core/interactiveshell.py"", line 3075, in run_cell

  File ""/databricks/python/lib/python3.12/site-packages/IPython/core/interactiveshell.py"", line 3130, in _run_cell

  File ""/databricks/python/lib/python3.12/site-packages/IPython/core/async_helpers.py"", line 129, in _pseudo_sync_runner

  File ""/databricks/python/lib/python3.12/site-packages/IPython/core/interactiveshell.py"", line 3334, in run_cell_async

  File ""/databricks/python/lib/python3.12/site-packages/IPython/core/interactiveshell.py"", line 3517, in run_ast_nodes

  File ""/databricks/python/lib/python3.12/site-packages/IPython/core/interactiveshell.py"", line 3577, in run_code

  File ""/root/.ipykernel/28671/command-3155791975121661-1239963347"", line 20, in <module>

  File ""/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py"", line 460, in safe_patch_function

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py"", line 65, in error_handler

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/engine/training.py"", line 1804, in fit

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/engine/training.py"", line 1398, in train_function

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/engine/training.py"", line 1381, in step_function

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/engine/training.py"", line 1370, in run_step

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/engine/training.py"", line 1147, in train_step

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py"", line 65, in error_handler

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/engine/training.py"", line 588, in __call__

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py"", line 65, in error_handler

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py"", line 1142, in __call__

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py"", line 96, in error_handler

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/engine/functional.py"", line 514, in call

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/engine/functional.py"", line 671, in _run_internal_graph

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py"", line 65, in error_handler

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/engine/training.py"", line 588, in __call__

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py"", line 65, in error_handler

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py"", line 1142, in __call__

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py"", line 96, in error_handler

  File ""/databricks/python/lib/python3.12/site-packages/transformers/modeling_tf_utils.py"", line 499, in run_call_with_unpacked_inputs

  File ""/databricks/python/lib/python3.12/site-packages/transformers/models/resnet/modeling_tf_resnet.py"", line 503, in call

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py"", line 65, in error_handler

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py"", line 1142, in __call__

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py"", line 96, in error_handler

  File ""/databricks/python/lib/python3.12/site-packages/transformers/modeling_tf_utils.py"", line 499, in run_call_with_unpacked_inputs

  File ""/databricks/python/lib/python3.12/site-packages/transformers/models/resnet/modeling_tf_resnet.py"", line 432, in call

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py"", line 65, in error_handler

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py"", line 1142, in __call__

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py"", line 96, in error_handler

  File ""/databricks/python/lib/python3.12/site-packages/transformers/models/resnet/modeling_tf_resnet.py"", line 124, in call

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py"", line 65, in error_handler

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py"", line 1142, in __call__

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py"", line 96, in error_handler

  File ""/databricks/python/lib/python3.12/site-packages/transformers/models/resnet/modeling_tf_resnet.py"", line 82, in call

  File ""/databricks/python/lib/python3.12/site-packages/transformers/models/resnet/modeling_tf_resnet.py"", line 78, in convolution

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py"", line 65, in error_handler

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py"", line 1142, in __call__

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py"", line 96, in error_handler

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/layers/convolutional/base_conv.py"", line 289, in call

  File ""/databricks/python/lib/python3.12/site-packages/tf_keras/src/layers/convolutional/base_conv.py"", line 261, in convolution_op

No DNN in stream executor.
	 [[{{node model/tf_res_net_model/resnet/embedder/embedder/convolution/Conv2D}}]] [Op:__inference_train_function_9105]
File <command-3155791975121661>, line 20
     15 model.layers[1].trainable = False
     17 model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), 
     18               loss=tf.keras.losses.BinaryCrossentropy())
---> 20 model.fit(x=np.random.random(size=(10,3,224,224)), 
     21           y=np.random.random(size=(10,)), 
     22           batch_size=2, 
     23           epochs=20, 
     24           shuffle=True)
File /databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:460, in safe_patch.<locals>.safe_patch_function(*args, **kwargs)
    441 if (
    442     active_session_failed
    443     or autologging_is_disabled(autologging_integration)
   (...)
    454     # warning behavior during original function execution, since autologging is being
    455     # skipped
    456     with set_non_mlflow_warnings_behavior_for_current_thread(
    457         disable_warnings=False,
    458         reroute_warnings=False,
    459     ):
--> 460         return original(*args, **kwargs)
    462 # Whether or not the original / underlying function has been called during the
    463 # execution of patched code
    464 original_has_been_called = False
File /databricks/python/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)
     67     filtered_tb = _process_traceback_frames(e.__traceback__)
     68     # To get the full stack trace, call:
     69     # `tf.debugging.disable_traceback_filtering()`
---> 70     raise e.with_traceback(filtered_tb) from None
     71 finally:
     72     del filtered_tb
File /databricks/python/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     51 try:
     52   ctx.ensure_initialized()
---> 53   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
     54                                       inputs, attrs, num_outputs)
     55 except core._NotOkStatusException as e:
     56   if name is not None:
```
"
2766207607,84027,Tensorflow BackupAndRestore method does not work,closed,2025-01-02 15:20:08+00:00,2025-01-10T13:07:46Z,2025-01-10T13:07:41Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/84027,"['stat:awaiting response', 'type:bug', 'comp:keras', '2.17']","['The error message you\'re encountering:\r\n\r\n```\r\nValueError: To use the BackupAndRestore method, your model must be built before you call `fit()`. Model is unbuilt. You can build it beforehand by calling it on a batch of data.\r\n```\r\n\r\nindicates that the `BackupAndRestore` callback expects the model to be built before calling `fit()`, but in your case, the model is not explicitly built before the training loop starts.\r\n\r\n### Understanding the Problem:\r\n- **`BackupAndRestore` callback** requires the model to be ""built"" before starting training. The model needs to know the input shapes and architecture in order to correctly manage the backup and restoration processes.\r\n- **Model Building**: When you define a `Sequential` model without specifying input shapes, TensorFlow won\'t know the input shape until data is passed to the model. Therefore, you need to either specify the input shape when defining the model or pass a batch of data to the model before calling `fit()`.\r\n\r\n### Solution 1: Define the Input Shape in the Model\r\n\r\nYou can explicitly define the input shape when creating the model, which ensures the model is ""built"" before training starts:\r\n\r\n```python\r\nimport keras\r\nimport numpy as np\r\n\r\nclass InterruptingCallback(keras.callbacks.Callback):\r\n   def on_epoch_begin(self, epoch, logs=None):\r\n     if epoch == 4:\r\n       raise RuntimeError(\'Interrupting!\')\r\n\r\ncallback = keras.callbacks.BackupAndRestore(backup_dir=""/tmp/backup"")\r\n\r\n# Define the model with an explicit input shape\r\nmodel = keras.models.Sequential([\r\n    keras.layers.InputLayer(input_shape=(20,)),  # Specify the input shape\r\n    keras.layers.Dense(10)\r\n])\r\n\r\nmodel.compile(keras.optimizers.SGD(), loss=\'mse\')\r\n\r\n# Now the model is built before training\r\ntry:\r\n    model.fit(np.arange(100).reshape(5, 20), np.zeros(5), epochs=10,\r\n              batch_size=1, callbacks=[callback, InterruptingCallback()],\r\n              verbose=0)\r\nexcept Exception as e:\r\n    print(e)\r\n\r\nhistory = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),\r\n                    epochs=10, batch_size=1, callbacks=[callback],\r\n                    verbose=0)\r\n\r\nprint(len(history.history[\'loss\']))\r\n```\r\n\r\n### Explanation:\r\n- **`InputLayer`**: By adding the `InputLayer` with an explicit `input_shape=(20,)`, you\'re telling Keras the expected shape of the input data, which ensures that the model is built before calling `fit()`.\r\n\r\n### Solution 2: Build the Model Before Calling `fit()`\r\n\r\nAlternatively, you can use a batch of data to build the model explicitly before training. This can be done using the `model.build()` method:\r\n\r\n```python\r\nimport keras\r\nimport numpy as np\r\n\r\nclass InterruptingCallback(keras.callbacks.Callback):\r\n   def on_epoch_begin(self, epoch, logs=None):\r\n     if epoch == 4:\r\n       raise RuntimeError(\'Interrupting!\')\r\n\r\ncallback = keras.callbacks.BackupAndRestore(backup_dir=""/tmp/backup"")\r\n\r\n# Define the model without specifying input shape\r\nmodel = keras.models.Sequential([\r\n    keras.layers.Dense(10)\r\n])\r\n\r\nmodel.compile(keras.optimizers.SGD(), loss=\'mse\')\r\n\r\n# Build the model by passing a batch of data\r\nmodel.build(input_shape=(None, 20))  # Here, 20 is the number of features in your input data\r\n\r\n# Now the model is built before calling fit\r\ntry:\r\n    model.fit(np.arange(100).reshape(5, 20), np.zeros(5), epochs=10,\r\n              batch_size=1, callbacks=[callback, InterruptingCallback()],\r\n              verbose=0)\r\nexcept Exception as e:\r\n    print(e)\r\n\r\nhistory = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),\r\n                    epochs=10, batch_size=1, callbacks=[callback],\r\n                    verbose=0)\r\n\r\nprint(len(history.history[\'loss\']))\r\n```\r\n\r\n### Explanation:\r\n- **`model.build()`**: This explicitly builds the model by providing the `input_shape`. After this call, the model is ready for training, and the `BackupAndRestore` callback will work correctly.\r\n\r\nTo fix the issue, you need to ensure that the model is built (either by specifying the input shape or by explicitly calling `model.build()`) before invoking `fit()`. Both solutions will address the error and allow the `BackupAndRestore` callback to function as expected.', 'Hi **@antipisa** ,\r\nThanks for raising your concern here. The raised [PR](https://github.com/keras-team/keras/pull/20714) has been merged. Could you please check and let us know if the issue still persists? \r\nThank you!', ' @Venkat6871 \r\nDoes Solution 1 work when the input layer is a normalization layer? E.g for this example\r\n```\r\n\r\nimport tensorflow as tf\r\n\r\nx = tf.random.uniform((100, 1))\r\ny = tf.random.uniform((100, 1))\r\nz = tf.random.uniform((100, 1))\r\n\r\nxyz = tf.concat([x, y, z], 1)\r\n\r\nhorsepower_normalizer = tf.keras.layers.Normalization(input_shape=(3,), axis=-1)\r\nhorsepower_normalizer.adapt(xyz)\r\n\r\nhorsepower_model = tf.keras.models.Sequential([\r\n    horsepower_normalizer,\r\n    tf.keras.layers.Dense(units=1)\r\n])\r\n\r\nhorsepower_model(xyz)\r\n\r\n```\r\n\r\nEDIT: This raises a UserWarning about using input_shape in a layer. Is there a better way? ', ""@Venkat6871 \r\nSolution 1 raises `ValueError: Only instances of `keras.Layer` can be added to a Sequential model. Received: (<InputLayer, name='input_layer_6, built=True>), (of type <class='tuple'>) ' ` "", 'Hi **@antipisa** ,\r\nApologies for the delay, and thank you for your patience. I tried running your code on Colab using TensorFlow 2.17.0 and 2.18.0 versions, but I am not facing any issues. Could you please check which warning you are encountering? Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/3c9e9d89bc8c9adbb8177cb409d18080/84027_tf_2-18-0-2-17-0-v.ipynb) here for your reference.\r\nThank you!', 'Hi @Venkat6871 , the problem is fixed if one imports the following way:\r\n\r\n```\r\nfrom tensorflow import keras\r\nfrom keras import layers\r\nfrom keras.layers import InputLayer, Dense\r\n```', 'Hi **@antipisa** ,\r\nGlad to see your issue is resolved! Please feel free to close this issue if everything is working as expected.\r\nThank you!', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/84027"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/84027"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

conda-forge 

### TensorFlow version

2.17

### Custom code

No

### OS platform and distribution

Linux RHEL8

### Mobile device

_No response_

### Python version

3.11.8

### Bazel version

_No response_

### GCC/compiler version

GCC 11.2.8

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

BackupAndRestore example code does not work

### Standalone code to reproduce the issue

```shell
import keras
import numpy as np

class InterruptingCallback(keras.callbacks.Callback):
   def on_epoch_begin(self, epoch, logs=None):
     if epoch == 4:
       raise RuntimeError('Interrupting!')
callback = keras.callbacks.BackupAndRestore(backup_dir=""/tmp/backup"")
model = keras.models.Sequential([keras.layers.Dense(10)])
model.compile(keras.optimizers.SGD(), loss='mse')
try:
   model.fit(np.arange(100).reshape(5, 20), np.zeros(5), epochs=10,
             batch_size=1, callbacks=[callback, InterruptingCallback()],
             verbose=0)
except Exception as e:
   print(e)
history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),
                     epochs=10, batch_size=1, callbacks=[callback],
                     verbose=0)
len(history.history['loss'])
```


### Relevant log output

```shell
ValueError: To use the BackupAndRestore method, your model must be built before you call `fit()`. Model is unbuilt. You can build it beforehand by calling it on a batch of data.
```
"
2766651959,84033,TFLITE NMS kernel Inconsistent Outputs and Out of Memory issues,closed,2025-01-02 21:14:57+00:00,2025-01-22T19:59:29Z,2025-01-22T19:59:26Z,gaikwadrahul8,,https://github.com/tensorflow/tensorflow/issues/84033,"['stat:awaiting tensorflower', 'type:bug', 'comp:lite', 'TF 2.18']","['Please add label ""comp:lite""', ""Hi, @sdp009 \r\nI apologize for the delayed response, I tried to run provided code in Google colab but I'm getting `Your session crashed after using all available RAM.` so that is due to OOM issue for reference I've added [gist-file](https://colab.sandbox.google.com/gist/gaikwadrahul8/964d0d400c3c474441d2981de546688a/tflite-issue-83754.ipynb) and output log screenshot below so we'll have to dig more into this issue and update you\r\n\r\n![image](https://github.com/user-attachments/assets/354efe32-6673-4d40-8ec1-50a645ff3933)\r\n\r\nThank you for your cooperation and patience.\r\n\r\n\r\n\r\n\r\n\r\n"", ""For easier debugging, please reduce the 'max_output_size' to a smaller value to avoid OOM issues.\r\n\r\nBut in actual practice, there are some scenarios where higher 'max_output_size' did caused OOM issues on resource constraint Android devices."", 'Hi @gaikwadrahul8 , did you got chance to inspect it further ? Thanks.', 'Hi, @pkgoogle\nPlease take a look into this issue. Thank you.', 'Hi @sdp009, we will be moving this to [LiteRT](https://github.com/google-ai-edge/litert). Please follow progress there.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/84033"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/84033"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

tf 2.16.2, tf 2.18, tf 2.19.0-dev2024122

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22

### Mobile device

Android

### Python version

3.10.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

The TFLITE NMS kernel output is not same as Tensorflow NMS output. Although the TFLITE NMS is a dynamic output shape layer, it is _**appending 0's**_ in the ""selected_indices"" output till ""max_output_size"", defeating the purpose of dynamic output.

**TFLITE NMS output must identically match with TF NMS output.**

For large ""max_output_size"", the TFLITE NMS results in super slow computation and many times it goes Out-of-memory on Android devices. The subsequent **Gather** ops, after NMS suffers heavily due to appended 0's in the TFLITE NMS output.

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/non_max_suppression.cc#L190C44-L190C59 

**Requesting to fix this behavior and ensure both TF and TFLITE NMS output are exactly same.**

![image](https://github.com/user-attachments/assets/6fe5e2eb-b2bf-45f7-8eb8-7a5900f5bb28)



### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

# Test inputs from : https://github.com/onnx/onnx/blob/main/docs/Operators.md#NonMaxSuppression : nonmaxsuppression_limit_output_size

boxes = np.array(
    [
        [0.0, 0.0, 1.0, 1.0],
        [0.0, 0.1, 1.0, 1.1],
        [0.0, -0.1, 1.0, 0.9],
        [0.0, 10.0, 1.0, 11.0],
        [0.0, 10.1, 1.0, 11.1],
        [0.0, 100.0, 1.0, 101.0],
    ]
).astype(np.float32)
scores = np.array([0.9, 0.75, 0.6, 0.95, 0.5, 0.3]).astype(np.float32)

import tensorflow as tf

max_output_size = tf.constant(tf.int32.max, dtype=tf.int32)
iou_threshold = 0.5

selected_indices = tf.image.non_max_suppression(
    boxes, scores, max_output_size, iou_threshold
)
print(selected_indices)    # returns expected output : tf.Tensor([3 0 5], shape=(3,), dtype=int32)

@tf.function(input_signature=[
    tf.TensorSpec(shape=[6, 4], dtype=tf.float32),
    tf.TensorSpec(shape=[6], dtype=tf.float32),
])
def nms_function(boxes, scores):
    return tf.image.non_max_suppression(boxes, scores, max_output_size=tf.constant(tf.int32.max, dtype=tf.int32), iou_threshold=0.5)

concrete_function = nms_function.get_concrete_function()
print(concrete_function(boxes, scores))    # returns expected output : tf.Tensor([3 0 5], shape=(3,), dtype=int32)


converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_function])
tflite_model = converter.convert()

with open('test_nms.tflite', 'wb') as f:
    f.write(tflite_model)

interpreter = tf.lite.Interpreter(model_path='test_nms.tflite')
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

interpreter.set_tensor(input_details[0]['index'], boxes)
interpreter.set_tensor(input_details[1]['index'], scores)

interpreter.invoke()

selected_indices = interpreter.get_tensor(output_details[0]['index'])
print(selected_indices)    # returns incorrect output appended with 0's : [3 0 5 ... 0 0 0]
print(selected_indices.shape)    # incorrect output of shape : (2147483647,)

# above causes OOM error
```


### Relevant log output

```shell
TF output = tf.Tensor([3 0 5], shape=(3,), dtype=int32)

TF Lite output = [3 0 5 ... 0 0 0]  ; shape = (2147483647,)
```
"
2768073649,84119,Tensortflow import issue after installation,closed,2025-01-03 19:35:37+00:00,2025-01-06T13:18:43Z,2025-01-05T14:37:30Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/84119,['type:bug'],"['check python version ,I think it need 3.10 version because it was giving the similar type of error in 3.12\r\nif still error persists try with gpu', ""Hi Manoj - I tried 3.10 ad 3.12. I don't believe they are now available for\r\ndownload. I also tried tensorflow-cpu, but it didn't help.\r\n\r\nWhere do you find tensorflow-gpu? I don't have a GPU, but my CPU is ARM\r\narch. Thanks\r\nDhimant\r\n\r\nOn Sat, Jan 4, 2025 at 6:22\u202fAM Manoj Nayak ***@***.***> wrote:\r\n\r\n> check python version ,I think it need 3.10 version because it was giving\r\n> the similar type of error in 3.12\r\n> if still error persists try with gpu\r\n>\r\n> —\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tensorflow/tensorflow/issues/84119#issuecomment-2571259338>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AOQLJ5YXCCGGJS2T2IU4IGT2I675TAVCNFSM6AAAAABUSHKZYKVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDKNZRGI2TSMZTHA>\r\n> .\r\n> You are receiving this because you authored the thread.Message ID:\r\n> ***@***.***>\r\n>\r\n"", 'Duplicate of https://github.com/tensorflow/tensorflow/issues/19584. Please do a search before opening new issues. Please only open new issues if there is information (like your CPU specs) that make your problem different than the existing one.', 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/84119"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/84119"">No</a>\n', 'I did search. You closed my previous issue.\r\n\r\nOn Sun, Jan 5, 2025 at 9:37\u202fAM Mihai Maruseac ***@***.***>\r\nwrote:\r\n\r\n> Duplicate of #19584\r\n> <https://github.com/tensorflow/tensorflow/issues/19584>. Please do a\r\n> search before opening new issues. Please only open new issues if there is\r\n> information (like your CPU specs) that make your problem different than the\r\n> existing one.\r\n>\r\n> —\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tensorflow/tensorflow/issues/84119#issuecomment-2571648088>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AOQLJ5ZHP7HZFBR75M5EAW32JE7UFAVCNFSM6AAAAABUSHKZYKVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDKNZRGY2DQMBYHA>\r\n> .\r\n> You are receiving this because you authored the thread.Message ID:\r\n> ***@***.***>\r\n>\r\n', 'Please reopen. This is not closed.\r\n\r\nOn Sun, Jan 5, 2025 at 9:37\u202fAM Mihai Maruseac ***@***.***>\r\nwrote:\r\n\r\n> Closed #84119 <https://github.com/tensorflow/tensorflow/issues/84119> as\r\n> completed.\r\n>\r\n> —\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tensorflow/tensorflow/issues/84119#event-15817564143>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AOQLJ55MYCPK3XWSP3DFHF32JE7UJAVCNFSM6AAAAABUSHKZYKVHI2DSMVQWIX3LMV45UABCJFZXG5LFIV3GK3TUJZXXI2LGNFRWC5DJN5XDWMJVHAYTONJWGQYTIMY>\r\n> .\r\n> You are receiving this because you authored the thread.Message ID:\r\n> ***@***.***>\r\n>\r\n', ""Opening multiple issues can be considered as spam. Let's move discussion to just one issue.""]","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.18

### Custom code

No

### OS platform and distribution

Windows 11

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I resintalled Python and my Anaconda environment and reinstalled using pip from notebook.

Please see attached installation log and then import logs

### Standalone code to reproduce the issue

```shell
pip install tensorflow

Collecting tensorflow
  Using cached tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)
Collecting tensorflow-intel==2.18.0 (from tensorflow)
  Using cached tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)
Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)
  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)
Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)
  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)
Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)
  Using cached flatbuffers-24.12.23-py2.py3-none-any.whl.metadata (876 bytes)
Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)
  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)
Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)
  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)
Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)
  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)
Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)
  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)
Requirement already satisfied: packaging in c:\users\dhima\anaconda3\lib\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)
Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\users\dhima\anaconda3\lib\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)
Requirement already satisfied: requests<3,>=2.21.0 in c:\users\dhima\anaconda3\lib\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)
Requirement already satisfied: setuptools in c:\users\dhima\anaconda3\lib\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)
Requirement already satisfied: six>=1.12.0 in c:\users\dhima\anaconda3\lib\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)
Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)
  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)
Requirement already satisfied: typing-extensions>=3.6.6 in c:\users\dhima\anaconda3\lib\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)
Requirement already satisfied: wrapt>=1.11.0 in c:\users\dhima\anaconda3\lib\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)
Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)
  Using cached grpcio-1.68.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)
Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)
  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)
Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)
  Using cached keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)
Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\users\dhima\anaconda3\lib\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)
Requirement already satisfied: h5py>=3.11.0 in c:\users\dhima\anaconda3\lib\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)
Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)
  Using cached ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)
Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\users\dhima\anaconda3\lib\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)
Requirement already satisfied: rich in c:\users\dhima\anaconda3\lib\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)
Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)
  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)
Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)
  Using cached optree-0.13.1-cp312-cp312-win_amd64.whl.metadata (48 kB)
Requirement already satisfied: charset-normalizer<4,>=2 in c:\users\dhima\anaconda3\lib\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in c:\users\dhima\anaconda3\lib\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)
Requirement already satisfied: urllib3<3,>=1.21.1 in c:\users\dhima\anaconda3\lib\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)
Requirement already satisfied: certifi>=2017.4.17 in c:\users\dhima\anaconda3\lib\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.12.14)
Requirement already satisfied: markdown>=2.6.8 in c:\users\dhima\anaconda3\lib\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)
Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)
  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)
Requirement already satisfied: werkzeug>=1.0.1 in c:\users\dhima\anaconda3\lib\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)
Requirement already satisfied: MarkupSafe>=2.1.1 in c:\users\dhima\anaconda3\lib\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)
Requirement already satisfied: markdown-it-py>=2.2.0 in c:\users\dhima\anaconda3\lib\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)
Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\users\dhima\anaconda3\lib\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)
Requirement already satisfied: mdurl~=0.1 in c:\users\dhima\anaconda3\lib\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)
Using cached tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)
Using cached tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)
Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)
Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)
Using cached flatbuffers-24.12.23-py2.py3-none-any.whl (30 kB)
Using cached gast-0.6.0-py3-none-any.whl (21 kB)
Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)
Using cached grpcio-1.68.1-cp312-cp312-win_amd64.whl (4.4 MB)
Using cached keras-3.7.0-py3-none-any.whl (1.2 MB)
Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)
Using cached ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)
Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)
Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)
Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)
Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)
Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)
Using cached optree-0.13.1-cp312-cp312-win_amd64.whl (292 kB)
Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow-intel, tensorflow
Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.12.23 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.1 keras-3.7.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0
```


### Relevant log output

```shell
import tensorflow as tf

O/p
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
File ~\anaconda3\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py:70
     69 try:
---> 70   from tensorflow.python._pywrap_tensorflow_internal import *
     71 # This try catch logic is because there is no bazel equivalent for py_extension.
     72 # Externally in opensource we must enable exceptions to load the shared object
     73 # by exposing the PyInit symbols with pybind. This error will only be
     74 # caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.
     75 
     76 # This logic is used in other internal projects using py_extension.

ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
Cell In[2], line 1
----> 1 import tensorflow as tf

File ~\anaconda3\Lib\site-packages\tensorflow\__init__.py:40
     37 _os.environ.setdefault(""ENABLE_RUNTIME_UPTIME_TELEMETRY"", ""1"")
     39 # Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596
---> 40 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow  # pylint: disable=unused-import
     41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import KerasLazyLoader as _KerasLazyLoader

File ~\anaconda3\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py:85
     83     sys.setdlopenflags(_default_dlopen_flags)
     84 except ImportError:
---> 85   raise ImportError(
     86       f'{traceback.format_exc()}'
     87       f'\n\nFailed to load the native TensorFlow runtime.\n'
     88       f'See https://www.tensorflow.org/install/errors '
     89       f'for some common causes and solutions.\n'
     90       f'If you need help, create an issue '
     91       f'at https://github.com/tensorflow/tensorflow/issues '
     92       f'and include the entire stack trace above this error message.')

ImportError: Traceback (most recent call last):
  File ""C:\Users\dhima\anaconda3\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 70, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.
See https://www.tensorflow.org/install/errors for some common causes and solutions.
If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.
```
"
2770520809,84205,[XLA] can't compile the tf.keras.layers.Conv2D when padding='valid',closed,2025-01-06 12:07:56+00:00,2025-01-23T01:59:30Z,2025-01-23T01:59:27Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/84205,"['stat:awaiting response', 'type:bug', 'stale', 'comp:xla', 'TF 2.18']","['@shaoyuyoung,\r\nI was able to reproduce the issue on TensorFlow v2.17, v2.18 and tf-nightly. Kindly find the gist of it here. Also Could you please confirm whether it was working with the versions which are older than the Tensorflow 2.16?  From v2.16, the TensorFlow contains Keras3.0 and the previous version contains Keras2.0. Thank you!', 'Thank you for your confirmation!\r\n\r\n\r\n> Also Could you please confirm whether it was working with the versions which are older than the Tensorflow 2.16?\r\n\r\nI will do this in my spare time :)', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/84205"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/84205"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

nightly

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

XLA can't compile the `tf.keras.layers.Conv2D` when `padding='valid'`. However, eager can pass the check.
There exists a misalignment

### Standalone code to reproduce the issue

```shell
import os
import tensorflow as tf
tf.keras.utils.set_random_seed(42)
tf.random.set_seed(42)

os.environ[""TF_CPP_MIN_LOG_LEVEL""] = ""3""
os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""


x = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], dtype=tf.float32)
inputs = [x]



class Model(tf.keras.Model):

    def __init__(self):
        super(Model, self).__init__()
        self.conv = tf.keras.layers.Conv2D(filters=1, kernel_size=4, padding='valid', activation='relu')

    def call(self, x):
        x = tf.reshape(x, [1, 3, 3, 1])
        x = self.conv(x)
        return x


model = Model()
model(*inputs)
print(""succeed on eager"")



class Model(tf.keras.Model):

    def __init__(self):
        super(Model, self).__init__()
        self.conv = tf.keras.layers.Conv2D(filters=1, kernel_size=4, padding='valid', activation='relu')

    @tf.function(jit_compile=True)
    def call(self, x):
        x = tf.reshape(x, [1, 3, 3, 1])
        x = self.conv(x)
        return x


model = Model()
model(*inputs)
print(""succeed on XLA"")
```


### Relevant log output

```shell
succeed on eager
Negative dimension size caused by subtracting 4 from 3 for '{{node conv2d_1_1/convolution}} = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=""VALID"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Reshape, conv2d_1_1/convolution/ReadVariableOp)' with input shapes: [1,3,3,1], [4,4,1,1].
```
"
2779725991,84577,Tensorflow.math.floormod(),closed,2025-01-10 09:40:55+00:00,2025-01-10T09:56:50Z,2025-01-10T09:56:47Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/84577,['type:bug'],"['Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/84577"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/84577"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.17.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

The operation tf.math.floormod supports float types, but when performing the operation on two float-type tensors, an internal error occurs.
`import tensorflow as tf
x = tf.constant([10, -15, 7.5], dtype=tf.float32)
y = tf.constant([3, -4, 2.5], dtype=tf.float32)
name = ""random_floormod_operation""
result_code = tf.math.floormod(x,y,name)
print(""!!!!!!!!!!!!!!!!!!!!!!!!!!!"")
print(result_code)`
**2025-01-10 09:34:03.279577: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-01-10 09:34:03.294385: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-01-10 09:34:03.312397: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-01-10 09:34:03.317811: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-01-10 09:34:03.330916: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-01-10 09:34:04.370985: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-01-10 09:34:05.819237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 513 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:38:00.0, compute capability: 8.6
2025-01-10 09:34:05.819757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22463 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:41:00.0, compute capability: 8.6
2025-01-10 09:34:05.820176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22463 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:44:00.0, compute capability: 8.6
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
W0000 00:00:1736501646.122604   70797 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.124987   70795 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.127360   70789 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.129708   70796 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.132058   70788 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.135845   70801 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.137479   70799 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.139073   70793 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.140713   70787 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.142340   70802 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.143637   70786 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.144931   70783 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.159628   70796 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
2025-01-10 09:34:06.630804: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:40] 'cuModuleLoadData(&module, data)' failed with 'CUDA_ERROR_UNSUPPORTED_PTX_VERSION'

2025-01-10 09:34:06.630843: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:40] 'cuModuleGetFunction(&function, module, kernel_name)' failed with 'CUDA_ERROR_INVALID_HANDLE'

2025-01-10 09:34:06.630870: W tensorflow/core/framework/op_kernel.cc:1828] INTERNAL: 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE'
2025-01-10 09:34:06.630894: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INTERNAL: 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE'
Traceback (most recent call last):
  File ""/root/myFuzzer/outputs/test5/code/tensorflow.math.floormod/tensorflow.math.floormod38.py"", line 5, in <module>
    result_code = tf.math.floormod(x,y,name)
  File ""/root/miniconda3/envs/fuzz4all/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py"", line 142, in wrapper
    return op(*args, **kwargs)
  File ""/root/miniconda3/envs/fuzz4all/lib/python3.10/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 4177, in floor_mod
    _ops.raise_from_not_ok_status(e, name)
  File ""/root/miniconda3/envs/fuzz4all/lib/python3.10/site-packages/tensorflow/python/framework/ops.py"", line 5983, in raise_from_not_ok_status
    raise core._status_to_exception(e) from None  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.InternalError: {{function_node __wrapped__FloorMod_device_/job:localhost/replica:0/task:0/device:GPU:0}} 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE' [Op:FloorMod] name: random_floormod_operation**
The operation runs normally under integer types.
`import tensorflow as tf
x = tf.constant([10, -15, 7], dtype=tf.int32)
y = tf.constant([3, -4, 2], dtype=tf.int32)
name = ""random_floormod_operation""
result_code = tf.math.floormod(x,y,name)
print(""!!!!!!!!!!!!!!!!!!!!!!!!!!!"")
print(result_code)`
**2025-01-10 09:38:07.541149: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-01-10 09:38:07.559247: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-01-10 09:38:07.564692: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-01-10 09:38:07.577837: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-01-10 09:38:08.635137: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-01-10 09:38:10.256193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 513 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:38:00.0, compute capability: 8.6
2025-01-10 09:38:10.256732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22463 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:41:00.0, compute capability: 8.6
2025-01-10 09:38:10.257179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22463 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:44:00.0, compute capability: 8.6
!!!!!!!!!!!!!!!!!!!!!!!!!!!
tf.Tensor([ 1 -3  1], shape=(3,), dtype=int32)**


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
x = tf.constant([10, -15, 7.5], dtype=tf.float32)
y = tf.constant([3, -4, 2.5], dtype=tf.float32)
name = ""random_floormod_operation""
result_code = tf.math.floormod(x,y,name)
```


### Relevant log output

_No response_"
2780133136,84585,Tensorflow.math.floormod(),closed,2025-01-10 12:58:11+00:00,2025-01-29T01:59:12Z,2025-01-29T01:59:09Z,Venkat6871,,https://github.com/tensorflow/tensorflow/issues/84585,"['stat:awaiting response', 'type:bug', 'stale', 'comp:apis', '2.17']","['Hi **@yangjingyuan000804** ,\r\nApologies for the delay, and welcome to TensorFlow! I tried running your code on Colab using TensorFlow 2.17.0 and 2.18.0 versions with GPU, and I did not encounter any issues. Please find the [gist](https://colab.sandbox.google.com/gist/Venkat6871/965cfd993a4a8029fd1fcc5d5b53d21c/84585_tf_2-17-0-2-18-0-v-gpu.ipynb) attached here for your reference.\r\nThank you!', 'This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.', ""This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/84585"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/84585"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.17.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

The operation tf.math.floormod supports float types, but when performing the operation on two float-type tensors with GPU, an internal error occurs.
`import tensorflow as tf x = tf.constant([10, -15, 7.5], dtype=tf.float32) y = tf.constant([3, -4, 2.5], dtype=tf.float32) name = ""random_floormod_operation"" result_code = tf.math.floormod(x,y,name) print(""!!!!!!!!!!!!!!!!!!!!!!!!!!!"") print(result_code)`
**2025-01-10 09:34:03.279577: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable TF_ENABLE_ONEDNN_OPTS=0.
2025-01-10 09:34:03.294385: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-01-10 09:34:03.312397: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-01-10 09:34:03.317811: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-01-10 09:34:03.330916: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-01-10 09:34:04.370985: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-01-10 09:34:05.819237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 513 MB memory: -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:38:00.0, compute capability: 8.6
2025-01-10 09:34:05.819757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22463 MB memory: -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:41:00.0, compute capability: 8.6
2025-01-10 09:34:05.820176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22463 MB memory: -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:44:00.0, compute capability: 8.6
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
W0000 00:00:1736501646.122604 70797 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.124987 70795 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.127360 70789 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.129708 70796 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.132058 70788 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.135845 70801 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.137479 70799 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.139073 70793 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.140713 70787 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.142340 70802 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.143637 70786 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.144931 70783 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
W0000 00:00:1736501646.159628 70796 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.
2025-01-10 09:34:06.630804: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:40] 'cuModuleLoadData(&module, data)' failed with 'CUDA_ERROR_UNSUPPORTED_PTX_VERSION'

2025-01-10 09:34:06.630843: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:40] 'cuModuleGetFunction(&function, module, kernel_name)' failed with 'CUDA_ERROR_INVALID_HANDLE'

2025-01-10 09:34:06.630870: W tensorflow/core/framework/op_kernel.cc:1828] INTERNAL: 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE'
2025-01-10 09:34:06.630894: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INTERNAL: 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE'
Traceback (most recent call last):
File ""/root/myFuzzer/outputs/test5/code/tensorflow.math.floormod/tensorflow.math.floormod38.py"", line 5, in
result_code = tf.math.floormod(x,y,name)
File ""/root/miniconda3/envs/fuzz4all/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py"", line 142, in wrapper
return op(*args, kwargs)
File ""/root/miniconda3/envs/fuzz4all/lib/python3.10/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 4177, in floor_mod
_ops.raise_from_not_ok_status(e, name)
File ""/root/miniconda3/envs/fuzz4all/lib/python3.10/site-packages/tensorflow/python/framework/ops.py"", line 5983, in raise_from_not_ok_status
raise core._status_to_exception(e) from None # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.InternalError: {{function_node _wrapped__FloorMod_device/job:localhost/replica:0/task:0/device:GPU:0}} 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE' [Op:FloorMod] name: random_floormod_operation
The operation runs normally under integer types with GPU.
`import tensorflow as tf x = tf.constant([10, -15, 7], dtype=tf.int32) y = tf.constant([3, -4, 2], dtype=tf.int32) name = ""random_floormod_operation"" result_code = tf.math.floormod(x,y,name) print(""!!!!!!!!!!!!!!!!!!!!!!!!!!!"") print(result_code)`
2025-01-10 09:38:07.541149: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-01-10 09:38:07.559247: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-01-10 09:38:07.564692: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-01-10 09:38:07.577837: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-01-10 09:38:08.635137: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-01-10 09:38:10.256193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 513 MB memory: -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:38:00.0, compute capability: 8.6
2025-01-10 09:38:10.256732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22463 MB memory: -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:41:00.0, compute capability: 8.6
2025-01-10 09:38:10.257179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22463 MB memory: -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:44:00.0, compute capability: 8.6
!!!!!!!!!!!!!!!!!!!!!!!!!!!
tf.Tensor([ 1 -3 1], shape=(3,), dtype=int32)

The float type is correct for the CPU as well.
`import tensorflow as tf
x = tf.constant([10, -15, 7.8], dtype=tf.float32)
y = tf.constant([3, -4, 2.5], dtype=tf.float32)
name = ""random_floormod_operation""
with tf.device('/CPU:0'):
    result_code = tf.math.floormod(x,y,name)
print(""!!!!!!!!!!!!!!!!!!!!!!!!!!!"")
print(result_code)`2025-01-10 12:57:31.435249: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-01-10 12:57:31.449893: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-01-10 12:57:31.467647: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-01-10 12:57:31.472965: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-01-10 12:57:31.486020: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-01-10 12:57:32.528966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-01-10 12:57:34.007683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 447 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:38:00.0, compute capability: 8.6
2025-01-10 12:57:34.008219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22463 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:41:00.0, compute capability: 8.6
2025-01-10 12:57:34.008642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22463 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:44:00.0, compute capability: 8.6
!!!!!!!!!!!!!!!!!!!!!!!!!!!
tf.Tensor([ 1.        -3.         0.3000002], shape=(3,), dtype=float32)


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
x = tf.constant([10, -15, 7.5], dtype=tf.float32)
y = tf.constant([3, -4, 2.5], dtype=tf.float32)
name = ""random_floormod_operation""
result_code = tf.math.floormod(x,y,name)
```


### Relevant log output

_No response_"
2793253924,85070,Unable to convert function return value to a Python type! Error Fix Solution Needed,closed,2025-01-16 16:40:25+00:00,2025-01-16T21:23:32Z,2025-01-16T21:23:29Z,tilakrayal,,https://github.com/tensorflow/tensorflow/issues/85070,['type:bug'],"[""This looks like a duplicate. Please don't open multiple issues for the same thing. Also, please don't ask for urgent help, this is an OSS community."", 'Are you satisfied with the resolution of your issue?\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/85070"">Yes</a>\n<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/85070"">No</a>\n']","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.10.1

### Custom code

Yes

### OS platform and distribution

Windows 10

### Mobile device

_No response_

### Python version

3.10.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I am using Windows 10
I use python 3.10.10, because when I use python 3.12, I couldn't install tensorflow-io
I installed tensorflow 2.10.1, because only tensorflow-text 2.10.0 is available on Windows 10.

Actually I am going to train model.
So I cloned tensorflow models repository
and made dataset, ...

I want help to run models/research/object_detection/model_main_tf2.py file without error.
Please help me.

### Standalone code to reproduce the issue

```shell
in tensorflow/python/framework/dtypes.py
line 29
_np_bfloat16 = _pywrap_bfloat16.TF_bfloat16_type()

Here I have error
TypeError: Unable to convert function return value to a Python type! The signature was
        () -> handle
```

### Relevant log output

```shell

```"
